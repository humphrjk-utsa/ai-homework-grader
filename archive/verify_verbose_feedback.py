#!/usr/bin/env python3
"""
Verify that verbose feedback is working in the Streamlit app
"""

import sqlite3
import json
import os
from pathlib import Path

def check_database_feedback():
    """Check if existing graded submissions have verbose feedback"""
    
    print("ğŸ” Checking database for verbose feedback...")
    
    db_path = "grading_database.db"
    
    if not os.path.exists(db_path):
        print("âŒ Database not found. Run some grading first.")
        return False
    
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    
    # Get graded submissions
    cursor.execute("""
        SELECT s.id, s.student_id, s.ai_feedback, s.ai_score
        FROM submissions s
        WHERE s.ai_feedback IS NOT NULL
        ORDER BY s.id DESC
        LIMIT 5
    """)
    
    submissions = cursor.fetchall()
    conn.close()
    
    if not submissions:
        print("âŒ No graded submissions found. Grade some submissions first.")
        return False
    
    print(f"âœ… Found {len(submissions)} graded submissions")
    
    # Check feedback structure
    for sub_id, student_id, ai_feedback, ai_score in submissions:
        print(f"\nğŸ“‹ Checking submission {sub_id} (Student: {student_id}, Score: {ai_score})")
        
        try:
            feedback_data = json.loads(ai_feedback)
            
            # Check comprehensive feedback
            if 'comprehensive_feedback' in feedback_data:
                comp_feedback = feedback_data['comprehensive_feedback']
                
                # Check instructor comments
                if 'instructor_comments' in comp_feedback:
                    comments_len = len(comp_feedback['instructor_comments'])
                    print(f"   âœ… Instructor comments: {comments_len} characters")
                else:
                    print("   âŒ Instructor comments missing")
                
                # Check detailed feedback
                if 'detailed_feedback' in comp_feedback:
                    detailed = comp_feedback['detailed_feedback']
                    
                    sections = [
                        'reflection_assessment',
                        'analytical_strengths',
                        'business_application', 
                        'learning_demonstration',
                        'areas_for_development',
                        'recommendations'
                    ]
                    
                    detailed_count = 0
                    for section in sections:
                        if section in detailed and detailed[section]:
                            detailed_count += len(detailed[section])
                    
                    print(f"   âœ… Detailed feedback: {detailed_count} total items")
                else:
                    print("   âŒ Detailed feedback missing")
            else:
                print("   âŒ Comprehensive feedback missing")
            
            # Check technical analysis
            if 'technical_analysis' in feedback_data:
                tech = feedback_data['technical_analysis']
                
                tech_sections = ['code_strengths', 'code_suggestions', 'technical_observations']
                tech_count = 0
                for section in tech_sections:
                    if section in tech and tech[section]:
                        tech_count += len(tech[section])
                
                print(f"   âœ… Technical analysis: {tech_count} total items")
            else:
                print("   âŒ Technical analysis missing")
                
        except Exception as e:
            print(f"   âŒ Feedback parsing error: {e}")
    
    return True

def check_web_interface_files():
    """Check that web interface files have been updated"""
    
    print("\nğŸŒ Checking web interface files...")
    
    # Check connect_web_interface.py
    interface_file = "connect_web_interface.py"
    
    if not os.path.exists(interface_file):
        print("âŒ connect_web_interface.py not found")
        return False
    
    with open(interface_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # Check for updated feedback display logic
    checks = [
        ('detailed_feedback', 'Detailed feedback section handling'),
        ('reflection_assessment', 'Reflection assessment display'),
        ('analytical_strengths', 'Analytical strengths display'),
        ('business_application', 'Business application display'),
        ('technical_analysis', 'Technical analysis display'),
        ('st.expander("ğŸ”§ Technical Analysis Details")', 'Technical analysis expander')
    ]
    
    for check_text, description in checks:
        if check_text in content:
            print(f"   âœ… {description}")
        else:
            print(f"   âŒ {description} missing")
    
    return True

def create_test_instructions():
    """Create instructions for testing the Streamlit app"""
    
    print("\nğŸ“‹ Creating test instructions...")
    
    instructions = """
# Testing Verbose Feedback in Streamlit App

## Steps to Test:

1. **Start the Streamlit app:**
   ```bash
   cd homework_grader
   streamlit run app.py
   ```

2. **Navigate to "Grade Submissions" page**

3. **Select an assignment and grade a submission:**
   - Choose "Individual (one at a time)" mode
   - Click "âš¡ Grade This Submission"
   - Wait for grading to complete

4. **Verify verbose feedback display:**
   - Check that "ğŸ’¬ Detailed Feedback" section appears
   - Verify "Overall Assessment" shows instructor comments
   - Confirm detailed sections appear:
     - ğŸ¤” Reflection & Critical Thinking
     - ğŸ’ª Analytical Strengths  
     - ğŸ’¼ Business Application
     - ğŸ“š Learning Demonstration
     - ğŸ¯ Areas for Development
     - ğŸ’¡ Recommendations
   - Expand "ğŸ”§ Technical Analysis Details" to see:
     - Code Strengths
     - Code Suggestions
     - Technical Observations

5. **Test manual review:**
   - Go to "ğŸ“ Manual Review" tab
   - Select a graded submission
   - Verify detailed feedback appears in expander

## Expected Results:

âœ… Comprehensive feedback with multiple detailed sections
âœ… Technical analysis in expandable section
âœ… Professional, encouraging tone appropriate for business students
âœ… Specific, actionable recommendations
âœ… Evidence of reflection assessment and learning demonstration

## If Issues Occur:

- Check browser console for JavaScript errors
- Verify database contains comprehensive feedback data
- Ensure Business Analytics Grader is being used (not fallback)
- Check that models are loaded and accessible
"""
    
    with open("VERBOSE_FEEDBACK_TEST_INSTRUCTIONS.md", 'w', encoding='utf-8') as f:
        f.write(instructions)
    
    print("âœ… Test instructions saved to VERBOSE_FEEDBACK_TEST_INSTRUCTIONS.md")

def main():
    """Main verification function"""
    
    print("ğŸ§ª Verifying Verbose Feedback System")
    print("=" * 50)
    
    # Check database
    db_ok = check_database_feedback()
    
    # Check web interface files
    web_ok = check_web_interface_files()
    
    # Create test instructions
    create_test_instructions()
    
    print("\nğŸ“Š Verification Summary:")
    print(f"   Database feedback: {'âœ…' if db_ok else 'âŒ'}")
    print(f"   Web interface: {'âœ…' if web_ok else 'âŒ'}")
    
    if db_ok and web_ok:
        print("\nğŸ‰ Verbose feedback system is ready!")
        print("ğŸ“‹ Follow the instructions in VERBOSE_FEEDBACK_TEST_INSTRUCTIONS.md to test the Streamlit app")
    else:
        print("\nâš ï¸ Some issues found. Check the messages above.")
        if not db_ok:
            print("   â€¢ Grade some submissions first to test database feedback")
        if not web_ok:
            print("   â€¢ Web interface may need updates")

if __name__ == "__main__":
    main()