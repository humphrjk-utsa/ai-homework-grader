{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1ffcdb8",
   "metadata": {},
   "source": [
    "# Lesson 8: Advanced Data Wrangling Techniques & Best Practices\n",
    "\n",
    "**Topic:** Complex Workflows, Chaining, and Professional Data Analysis\n",
    "\n",
    "**Time:** 60 minutes\n",
    "\n",
    "---\n",
    "\n",
    "## Background: The Capstone of Data Wrangling\n",
    "\n",
    "### Why This Lesson Is Different\n",
    "\n",
    "This is your **capstone lesson** - where everything comes together. Unlike previous lessons that focused on specific skills, this lesson teaches you to:\n",
    "- **Integrate multiple techniques** into sophisticated workflows\n",
    "- **Think like a professional analyst** about data quality and reproducibility\n",
    "- **Build production-ready code** that others can use and maintain\n",
    "- **Communicate insights** effectively to business stakeholders\n",
    "\n",
    "### Real-World Professional Context\n",
    "\n",
    "**What Professional Data Analysis Actually Looks Like:**\n",
    "\n",
    "In real business environments, you'll rarely use just one technique. Instead, you'll:\n",
    "1. **Import** data from multiple sources (CSV, Excel, databases)\n",
    "2. **Validate** data quality (missing values, outliers, business rules)\n",
    "3. **Clean** and standardize (text, dates, categories)\n",
    "4. **Transform** with complex logic (segmentation, scoring, classification)\n",
    "5. **Aggregate** and summarize (group by multiple dimensions)\n",
    "6. **Analyze** patterns and trends\n",
    "7. **Communicate** findings to stakeholders\n",
    "8. **Document** for reproducibility\n",
    "\n",
    "### Business Impact of Advanced Skills\n",
    "\n",
    "**Revenue Growth:**\n",
    "- Identify high-value customer segments for targeted marketing\n",
    "- Optimize product mix based on profitability analysis\n",
    "- Predict churn and implement retention strategies\n",
    "- Discover cross-sell and upsell opportunities\n",
    "\n",
    "**Cost Reduction:**\n",
    "- Automate manual data processing (saving hours/week)\n",
    "- Improve operational efficiency through data-driven insights\n",
    "- Reduce errors from manual data handling\n",
    "- Optimize inventory to reduce carrying costs\n",
    "\n",
    "**Risk Mitigation:**\n",
    "- Detect data quality issues before they impact decisions\n",
    "- Validate business rules automatically\n",
    "- Create audit trails for compliance\n",
    "- Identify anomalies and outliers\n",
    "\n",
    "**Strategic Planning:**\n",
    "- Provide evidence-based recommendations\n",
    "- Identify market opportunities and threats\n",
    "- Support long-term growth strategies\n",
    "- Enable data-driven decision making\n",
    "\n",
    "### Professional Skills You'll Master\n",
    "\n",
    "**Technical Skills:**\n",
    "- Complex pipeline construction (chaining 5+ operations)\n",
    "- Advanced conditional logic with `case_when()`\n",
    "- Data validation and quality checks\n",
    "- Creating reusable functions\n",
    "- Reproducible analysis workflows\n",
    "\n",
    "**Business Skills:**\n",
    "- Customer segmentation (RFM, value scoring)\n",
    "- KPI calculation and tracking\n",
    "- Executive reporting and visualization\n",
    "- Translating technical findings to business language\n",
    "- Making actionable recommendations\n",
    "\n",
    "**Professional Practices:**\n",
    "- Code organization and documentation\n",
    "- Version control readiness\n",
    "- Error handling and edge cases\n",
    "- Performance optimization\n",
    "- Collaboration and maintainability\n",
    "\n",
    "### What Success Looks Like\n",
    "\n",
    "By the end of this lesson, you'll be able to:\n",
    "- Build complex analysis pipelines that combine filtering, transformation, grouping, and summarization\n",
    "- Implement sophisticated business logic using `case_when()`\n",
    "- Validate data quality automatically\n",
    "- Create reusable analysis functions\n",
    "- Generate executive-ready reports\n",
    "- Write code that other analysts can understand and maintain\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this lesson, you will be able to:\n",
    "1. Chain multiple dplyr operations for complex workflows\n",
    "2. Use `case_when()` for sophisticated conditional logic\n",
    "3. Implement data validation and quality checks\n",
    "4. Create reproducible analysis workflows\n",
    "5. Apply best practices for professional data analysis\n",
    "6. Build reusable functions for common analyses\n",
    "7. Generate business-ready reports and summaries\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4732e1ce",
   "metadata": {},
   "source": [
    "## Part 1: Setup and Complex Sample Data\n",
    "\n",
    "### Understanding Complex Business Data\n",
    "\n",
    "Real business analysis requires working with datasets that have:\n",
    "- **Multiple dimensions** (product, region, customer type, time)\n",
    "- **Various data types** (numeric, categorical, dates)\n",
    "- **Relationships** between different attributes\n",
    "- **Enough volume** to reveal patterns\n",
    "\n",
    "### The Dataset We'll Analyze\n",
    "\n",
    "We'll create a realistic sales dataset with 50 transactions that includes:\n",
    "- **Products:** Laptop, Mouse, Keyboard, Monitor, Webcam, Headphones\n",
    "- **Categories:** Electronics, Peripherals\n",
    "- **Regions:** North, South, East, West\n",
    "- **Customer Types:** New, Returning, VIP\n",
    "- **Time Period:** Q1 2024 (January - March)\n",
    "- **Metrics:** Sales amount, quantity, dates\n",
    "\n",
    "### Business Questions We'll Answer\n",
    "\n",
    "1. Which regions and categories drive the most revenue?\n",
    "2. How do we segment customers by value?\n",
    "3. What are the transaction patterns by day of week?\n",
    "4. Which customers need follow-up?\n",
    "5. What are the key performance indicators (KPIs)?\n",
    "\n",
    "### Why Use set.seed()?\n",
    "\n",
    "`set.seed(123)` ensures reproducibility:\n",
    "- Same random data every time you run the code\n",
    "- Others can verify your results\n",
    "- Essential for professional analysis\n",
    "- Required for debugging and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b01dd0",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Load necessary packages\n",
    "library(tidyverse)\n",
    "library(lubridate)\n",
    "\n",
    "# Set seed for reproducibility\n",
    "set.seed(123)\n",
    "\n",
    "cat(\"Packages loaded successfully!\\n\")\n",
    "cat(\"Ready for advanced data wrangling!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b8967e",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "## Part 2: Complex Chained Operations\n",
    "\n",
    "### The Power of the Pipe (%>%)\n",
    "\n",
    "**Why Chaining Matters:**\n",
    "- **Readability:** Code reads like a story (do this, then this, then this)\n",
    "- **Efficiency:** No intermediate variables cluttering your environment\n",
    "- **Maintainability:** Easy to add/remove steps\n",
    "- **Professional:** Industry standard for R data analysis\n",
    "\n",
    "### Anatomy of a Complex Pipeline\n",
    "\n",
    "A professional analysis pipeline typically follows this structure:\n",
    "\n",
    "```r\n",
    "result <- data %>%\n",
    "  # 1. FILTER: Remove invalid/unwanted data\n",
    "  filter(condition) %>%\n",
    "  \n",
    "  # 2. MUTATE: Create new calculated fields\n",
    "  mutate(new_column = calculation) %>%\n",
    "  \n",
    "  # 3. GROUP: Define analysis dimensions\n",
    "  group_by(dimension1, dimension2) %>%\n",
    "  \n",
    "  # 4. SUMMARIZE: Calculate metrics\n",
    "  summarize(metric = aggregation) %>%\n",
    "  \n",
    "  # 5. MUTATE: Add derived metrics\n",
    "  mutate(share = metric / sum(metric)) %>%\n",
    "  \n",
    "  # 6. ARRANGE: Sort for presentation\n",
    "  arrange(desc(metric))\n",
    "```\n",
    "\n",
    "### Best Practices for Chaining\n",
    "\n",
    "**Do:**\n",
    "- Put each operation on its own line\n",
    "- Add comments explaining business logic\n",
    "- Use meaningful variable names\n",
    "- Test incrementally (run partial pipeline)\n",
    "- Keep pipelines focused (< 10 steps ideal)\n",
    "\n",
    "**Don't:**\n",
    "- Chain unrelated operations\n",
    "- Create overly complex one-liners\n",
    "- Forget to handle edge cases\n",
    "- Skip validation steps\n",
    "\n",
    "### Business Context: Regional Performance Analysis\n",
    "\n",
    "**Business Question:** Which region-category combinations drive the most revenue?\n",
    "\n",
    "**Why This Matters:**\n",
    "- Allocate marketing budget effectively\n",
    "- Optimize inventory by region\n",
    "- Identify growth opportunities\n",
    "- Set regional sales targets\n",
    "- Plan expansion strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section2",
   "metadata": {},
   "source": [
    "# BUSINESS USE CASE: Regional performance analysis for strategic planning\n",
    "#\n",
    "# Problem: Need to understand which region-category combinations perform best\n",
    "# Impact: Can't allocate resources effectively or identify growth opportunities\n",
    "# Solution: Build a complex pipeline that filters, calculates, groups, and analyzes\n",
    "\n",
    "regional_analysis <- sales_data %>%\n",
    "  # Step 1: FILTER - Remove low-value transactions\n",
    "  # Why: Focus on significant sales, reduce noise\n",
    "  # Business rule: Only analyze sales > $100\n",
    "  filter(Sales > 100) %>%\n",
    "  \n",
    "  # Step 2: MUTATE - Calculate revenue and add time dimensions\n",
    "  # Revenue = Sales * Quantity (total transaction value)\n",
    "  # Time dimensions enable temporal analysis\n",
    "  mutate(\n",
    "    Revenue = Sales * Quantity,\n",
    "    Month = month(OrderDate, label = TRUE),  # \"Jan\", \"Feb\", \"Mar\"\n",
    "    Quarter = quarter(OrderDate)              # 1 for Q1\n",
    "  ) %>%\n",
    "  \n",
    "  # Step 3: GROUP - Define analysis dimensions\n",
    "  # Why: We want metrics BY region AND category\n",
    "  # This creates groups for each unique combination\n",
    "  group_by(Region, Category) %>%\n",
    "  \n",
    "  # Step 4: SUMMARIZE - Calculate key metrics for each group\n",
    "  # These are the KPIs that matter to the business\n",
    "  summarize(\n",
    "    Total_Revenue = sum(Revenue),        # Total $ generated\n",
    "    Avg_Sale = mean(Sales),              # Average transaction size\n",
    "    Order_Count = n(),                   # Number of transactions\n",
    "    Total_Units = sum(Quantity),         # Total items sold\n",
    "    .groups = 'drop'                     # Remove grouping after summarize\n",
    "  ) %>%\n",
    "  \n",
    "  # Step 5: MUTATE - Calculate revenue share (% of total)\n",
    "  # Why: Executives want to see percentages, not just absolute numbers\n",
    "  # sum(Total_Revenue) calculates across all rows\n",
    "  mutate(\n",
    "    Revenue_Share = (Total_Revenue / sum(Total_Revenue)) * 100\n",
    "  ) %>%\n",
    "  \n",
    "  # Step 6: ARRANGE - Sort by revenue (highest first)\n",
    "  # Why: Put most important results at the top\n",
    "  # desc() means descending order\n",
    "  arrange(desc(Total_Revenue))\n",
    "\n",
    "cat(\"\ud83d\udcca REGIONAL PERFORMANCE ANALYSIS\\n\")\n",
    "cat(\"(Complex Pipeline: Filter \u2192 Mutate \u2192 Group \u2192 Summarize \u2192 Mutate \u2192 Arrange)\\n\\n\")\n",
    "\n",
    "print(regional_analysis)\n",
    "\n",
    "cat(\"\\n\ud83d\udca1 Business Insights:\\n\")\n",
    "cat(\"  \u2022 Top region-category combinations drive\", \n",
    "    round(sum(head(regional_analysis$Revenue_Share, 3)), 1), \"% of revenue\\n\")\n",
    "cat(\"  \u2022 Use this to allocate marketing budget\\n\")\n",
    "cat(\"  \u2022 Identify underperforming combinations for improvement\\n\")\n",
    "cat(\"  \u2022 Set realistic targets based on historical performance\\n\")\n",
    "\n",
    "cat(\"\\n\ud83c\udfaf Action Items:\\n\")\n",
    "cat(\"  1. Increase inventory in top-performing region-categories\\n\")\n",
    "cat(\"  2. Investigate why some combinations underperform\\n\")\n",
    "cat(\"  3. Replicate success factors from top performers\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chain1",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "## Part 3: Advanced Conditional Logic with case_when()\n",
    "\n",
    "### Why case_when() Is a Game-Changer\n",
    "\n",
    "**The Problem with if-else:**\n",
    "```r\n",
    "# Messy, hard to read:\n",
    "if (x < 100) {\n",
    "  \"Low\"\n",
    "} else if (x < 500) {\n",
    "  \"Medium\"\n",
    "} else {\n",
    "  \"High\"\n",
    "}\n",
    "```\n",
    "\n",
    "**The case_when() Solution:**\n",
    "```r\n",
    "# Clean, readable, vectorized:\n",
    "case_when(\n",
    "  x < 100 ~ \"Low\",\n",
    "  x < 500 ~ \"Medium\",\n",
    "  TRUE ~ \"High\"\n",
    ")\n",
    "```\n",
    "\n",
    "### How case_when() Works\n",
    "\n",
    "**Syntax:**\n",
    "```r\n",
    "case_when(\n",
    "  condition1 ~ result1,\n",
    "  condition2 ~ result2,\n",
    "  condition3 ~ result3,\n",
    "  TRUE ~ default_result  # Always include a default!\n",
    ")\n",
    "```\n",
    "\n",
    "**Key Points:**\n",
    "- Evaluates conditions **in order** (first match wins)\n",
    "- Use `~` (tilde) to separate condition from result\n",
    "- `TRUE ~` creates a default case (like \"else\")\n",
    "- Works with vectors (entire columns at once)\n",
    "- Can combine multiple conditions with `&` (AND) and `|` (OR)\n",
    "\n",
    "### Business Applications\n",
    "\n",
    "**Customer Segmentation:**\n",
    "```r\n",
    "case_when(\n",
    "  customer_type == \"VIP\" & revenue > 1000 ~ \"Platinum\",\n",
    "  customer_type == \"VIP\" | revenue > 1000 ~ \"Gold\",\n",
    "  revenue > 500 ~ \"Silver\",\n",
    "  TRUE ~ \"Bronze\"\n",
    ")\n",
    "```\n",
    "\n",
    "**Product Classification:**\n",
    "```r\n",
    "case_when(\n",
    "  price < 50 ~ \"Budget\",\n",
    "  price < 200 ~ \"Mid-Range\",\n",
    "  price < 1000 ~ \"Premium\",\n",
    "  TRUE ~ \"Luxury\"\n",
    ")\n",
    "```\n",
    "\n",
    "**Priority Assignment:**\n",
    "```r\n",
    "case_when(\n",
    "  days_since_contact > 30 & value_score == \"High\" ~ \"Urgent\",\n",
    "  days_since_contact > 14 ~ \"High\",\n",
    "  days_since_contact > 7 ~ \"Medium\",\n",
    "  TRUE ~ \"Low\"\n",
    ")\n",
    "```\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "**Do:**\n",
    "- Always include a `TRUE ~` default case\n",
    "- Order conditions from most specific to most general\n",
    "- Use clear, descriptive result values\n",
    "- Test edge cases\n",
    "- Comment complex logic\n",
    "\n",
    "**Don't:**\n",
    "- Forget the default case (leads to NA values)\n",
    "- Make conditions too complex (break into multiple case_when if needed)\n",
    "- Overlap conditions unintentionally\n",
    "- Use inconsistent result types (all text or all numbers)\n",
    "\n",
    "### Real-World Example: Customer Value Scoring\n",
    "\n",
    "**Business Need:** Segment customers for targeted marketing\n",
    "\n",
    "**Factors to Consider:**\n",
    "- Customer type (New, Returning, VIP)\n",
    "- Transaction value (Revenue)\n",
    "- Purchase frequency\n",
    "- Recency\n",
    "\n",
    "**Outcome:** Assign each customer to a tier (Platinum, Gold, Silver, Bronze)\n",
    "\n",
    "**Business Impact:**\n",
    "- Platinum: White-glove service, exclusive offers\n",
    "- Gold: Priority support, early access\n",
    "- Silver: Standard benefits, occasional perks\n",
    "- Bronze: Basic service, growth potential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section3",
   "metadata": {},
   "source": [
    "# BUSINESS USE CASE: Multi-dimensional customer value scoring\n",
    "#\n",
    "# Problem: Need to segment customers for targeted marketing and service levels\n",
    "# Impact: Can't personalize experience, missing revenue from high-value customers\n",
    "# Solution: Use case_when() to create sophisticated segmentation logic\n",
    "\n",
    "sales_classified <- sales_data %>%\n",
    "  mutate(\n",
    "    # Calculate total revenue (will use for classification)\n",
    "    Revenue = Sales * Quantity,\n",
    "    \n",
    "    # CLASSIFICATION 1: Sales Tier (simple, single condition)\n",
    "    # Purpose: Quick categorization of transaction size\n",
    "    Sales_Tier = case_when(\n",
    "      Sales < 200 ~ \"Low\",           # Small transactions\n",
    "      Sales >= 200 & Sales < 800 ~ \"Medium\",  # Mid-size transactions\n",
    "      Sales >= 800 ~ \"High\",         # Large transactions\n",
    "      TRUE ~ \"Unknown\"               # Safety net (should never happen)\n",
    "    ),\n",
    "    \n",
    "    # CLASSIFICATION 2: Customer Value Score (complex, multiple factors)\n",
    "    # Purpose: Identify most valuable customers for VIP treatment\n",
    "    # Logic: Combines customer type AND revenue\n",
    "    Value_Score = case_when(\n",
    "      # Platinum: VIP customers with high revenue\n",
    "      # & means AND (both conditions must be true)\n",
    "      CustomerType == \"VIP\" & Revenue > 1000 ~ \"Platinum\",\n",
    "      \n",
    "      # Gold: Either VIP OR high revenue (but not both)\n",
    "      # | means OR (at least one condition must be true)\n",
    "      CustomerType == \"VIP\" | Revenue > 1000 ~ \"Gold\",\n",
    "      \n",
    "      # Silver: Returning customers with decent revenue\n",
    "      CustomerType == \"Returning\" & Revenue > 500 ~ \"Silver\",\n",
    "      \n",
    "      # Bronze: Everyone else (new customers, low revenue)\n",
    "      TRUE ~ \"Bronze\"\n",
    "    ),\n",
    "    \n",
    "    # CLASSIFICATION 3: Follow-up Priority (derived from Value_Score)\n",
    "    # Purpose: Prioritize sales team outreach\n",
    "    # %in% checks if value is in a vector\n",
    "    Follow_Up_Priority = case_when(\n",
    "      Value_Score %in% c(\"Platinum\", \"Gold\") ~ \"High\",    # Top customers\n",
    "      Value_Score == \"Silver\" ~ \"Medium\",                  # Good customers\n",
    "      TRUE ~ \"Low\"                                         # Standard customers\n",
    "    )\n",
    "  )\n",
    "\n",
    "cat(\"\ud83c\udfaf CUSTOMER SEGMENTATION WITH case_when()\\n\\n\")\n",
    "\n",
    "# Show sample of classifications\n",
    "sales_classified %>%\n",
    "  select(OrderID, Sales, Revenue, Sales_Tier, CustomerType, Value_Score, Follow_Up_Priority) %>%\n",
    "  head(10) %>%\n",
    "  print()\n",
    "\n",
    "cat(\"\\n\ud83d\udca1 Business Logic Explained:\\n\")\n",
    "cat(\"  Platinum: VIP + Revenue > $1000 (top 5-10% of customers)\\n\")\n",
    "cat(\"  Gold: VIP OR Revenue > $1000 (high-value segment)\\n\")\n",
    "cat(\"  Silver: Returning + Revenue > $500 (loyal customers)\\n\")\n",
    "cat(\"  Bronze: All others (growth potential)\\n\")\n",
    "\n",
    "cat(\"\\n\ud83c\udfaf Action Plan by Segment:\\n\")\n",
    "cat(\"  Platinum: Dedicated account manager, exclusive offers\\n\")\n",
    "cat(\"  Gold: Priority support, early product access\\n\")\n",
    "cat(\"  Silver: Loyalty rewards, upgrade incentives\\n\")\n",
    "cat(\"  Bronze: Nurture campaigns, education content\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "case1",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Classify sales into tiers with multiple criteria\n",
    "sales_classified <- sales_data %>%\n",
    "  mutate(\n",
    "    # Revenue calculation\n",
    "    Revenue = Sales * Quantity,\n",
    "    \n",
    "    # Sales tier based on amount\n",
    "    Sales_Tier = case_when(\n",
    "      Sales < 200 ~ \"Low\",\n",
    "      Sales >= 200 & Sales < 800 ~ \"Medium\",\n",
    "      Sales >= 800 ~ \"High\",\n",
    "      TRUE ~ \"Unknown\"  # Default case\n",
    "    ),\n",
    "    \n",
    "    # Customer value score (combining multiple factors)\n",
    "    Value_Score = case_when(\n",
    "      CustomerType == \"VIP\" & Revenue > 1000 ~ \"Platinum\",\n",
    "      CustomerType == \"VIP\" | Revenue > 1000 ~ \"Gold\",\n",
    "      CustomerType == \"Returning\" & Revenue > 500 ~ \"Silver\",\n",
    "      TRUE ~ \"Bronze\"\n",
    "    ),\n",
    "    \n",
    "    # Priority flag for follow-up\n",
    "    Follow_Up_Priority = case_when(\n",
    "      Value_Score %in% c(\"Platinum\", \"Gold\") ~ \"High\",\n",
    "      Value_Score == \"Silver\" ~ \"Medium\",\n",
    "      TRUE ~ \"Low\"\n",
    "    )\n",
    "  )\n",
    "\n",
    "print(\"Sales with Classification (first 10):\")\n",
    "sales_classified %>%\n",
    "  select(OrderID, Sales, Revenue, Sales_Tier, CustomerType, Value_Score, Follow_Up_Priority) %>%\n",
    "  head(10) %>%\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "case2",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "## Part 4: Data Validation and Quality Checks\n",
    "\n",
    "### Why Data Validation Is Critical\n",
    "\n",
    "**The Cost of Bad Data:**\n",
    "- **Wrong decisions:** Garbage in, garbage out\n",
    "- **Lost revenue:** Missed opportunities from inaccurate analysis\n",
    "- **Wasted time:** Hours debugging issues caused by data problems\n",
    "- **Damaged credibility:** Stakeholders lose trust in your analysis\n",
    "- **Compliance risks:** Regulatory issues from data quality problems\n",
    "\n",
    "**Industry Statistics:**\n",
    "- Poor data quality costs organizations an average of $12.9 million annually (Gartner)\n",
    "- 27% of business leaders are unsure of data accuracy (Harvard Business Review)\n",
    "- Data scientists spend 60% of time cleaning and organizing data (Forbes)\n",
    "\n",
    "### Types of Data Quality Issues\n",
    "\n",
    "**1. Missing Values:**\n",
    "- NULL, NA, blank cells\n",
    "- Impact: Can't calculate metrics, skewed averages\n",
    "- Check: `sum(is.na(column))`\n",
    "\n",
    "**2. Invalid Values:**\n",
    "- Negative sales, zero quantities\n",
    "- Future dates, dates before business started\n",
    "- Impact: Incorrect calculations, failed business rules\n",
    "- Check: `sum(sales < 0)`, `sum(date > today())`\n",
    "\n",
    "**3. Duplicates:**\n",
    "- Same transaction recorded multiple times\n",
    "- Impact: Inflated metrics, double-counting\n",
    "- Check: `sum(duplicated(data))`\n",
    "\n",
    "**4. Outliers:**\n",
    "- Extreme values that may be errors\n",
    "- Impact: Skewed averages, misleading trends\n",
    "- Check: IQR method, z-scores\n",
    "\n",
    "**5. Inconsistencies:**\n",
    "- \"USA\" vs \"US\" vs \"United States\"\n",
    "- Impact: Failed joins, incorrect grouping\n",
    "- Check: `n_distinct()`, manual inspection\n",
    "\n",
    "### Professional Validation Workflow\n",
    "\n",
    "**Step 1: Completeness Checks**\n",
    "```r\n",
    "# Check for missing values\n",
    "summarize(\n",
    "  Missing_Sales = sum(is.na(Sales)),\n",
    "  Missing_Dates = sum(is.na(OrderDate))\n",
    ")\n",
    "```\n",
    "\n",
    "**Step 2: Business Rule Validation**\n",
    "```r\n",
    "# Check business logic\n",
    "summarize(\n",
    "  Negative_Sales = sum(Sales < 0),\n",
    "  Zero_Quantity = sum(Quantity <= 0),\n",
    "  Future_Dates = sum(OrderDate > today())\n",
    ")\n",
    "```\n",
    "\n",
    "**Step 3: Statistical Validation**\n",
    "```r\n",
    "# Check for outliers\n",
    "summarize(\n",
    "  Mean = mean(Sales),\n",
    "  SD = sd(Sales),\n",
    "  Q1 = quantile(Sales, 0.25),\n",
    "  Q3 = quantile(Sales, 0.75),\n",
    "  IQR = Q3 - Q1\n",
    ")\n",
    "```\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "**Do:**\n",
    "- Validate data BEFORE analysis\n",
    "- Document all validation checks\n",
    "- Create automated validation scripts\n",
    "- Set up alerts for data quality issues\n",
    "- Track data quality metrics over time\n",
    "\n",
    "**Don't:**\n",
    "- Assume data is clean\n",
    "- Skip validation to save time\n",
    "- Ignore validation failures\n",
    "- Delete outliers without investigation\n",
    "- Forget to communicate data quality issues\n",
    "\n",
    "### When to Flag vs Fix vs Remove\n",
    "\n",
    "**Flag (Keep but mark):**\n",
    "- Potential outliers that might be legitimate\n",
    "- Records with minor quality issues\n",
    "- Data that needs manual review\n",
    "\n",
    "**Fix (Correct the data):**\n",
    "- Known systematic errors\n",
    "- Standardization issues (case, format)\n",
    "- Calculable missing values\n",
    "\n",
    "**Remove (Exclude from analysis):**\n",
    "- Clearly invalid data\n",
    "- Duplicates\n",
    "- Test records\n",
    "- Data outside analysis scope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section4",
   "metadata": {},
   "source": [
    "# BUSINESS USE CASE: Automated data quality checks\n",
    "#\n",
    "# Problem: Need to ensure data quality before analysis\n",
    "# Impact: Bad data leads to wrong decisions and wasted time\n",
    "# Solution: Implement systematic validation checks\n",
    "\n",
    "# CHECK 1: Missing Values\n",
    "# Why: Missing data can skew calculations and cause errors\n",
    "missing_check <- sales_data %>%\n",
    "  summarize(\n",
    "    Missing_Sales = sum(is.na(Sales)),\n",
    "    Missing_Quantity = sum(is.na(Quantity)),\n",
    "    Missing_OrderDate = sum(is.na(OrderDate)),\n",
    "    Total_Rows = n(),\n",
    "    # Calculate percentage missing\n",
    "    Pct_Missing_Sales = (Missing_Sales / Total_Rows) * 100\n",
    "  )\n",
    "\n",
    "cat(\"\u2705 MISSING VALUE CHECK:\\n\\n\")\n",
    "print(missing_check)\n",
    "\n",
    "if (sum(missing_check[1:3]) == 0) {\n",
    "  cat(\"\\n\u2705 No missing values detected!\\n\")\n",
    "} else {\n",
    "  cat(\"\\n\u26a0\ufe0f  Missing values found - investigate before analysis!\\n\")\n",
    "}\n",
    "\n",
    "cat(\"\\n\ud83d\udca1 What to do if missing values found:\\n\")\n",
    "cat(\"  \u2022 < 5% missing: Consider imputation or removal\\n\")\n",
    "cat(\"  \u2022 5-20% missing: Investigate pattern, may indicate systematic issue\\n\")\n",
    "cat(\"  \u2022 > 20% missing: Serious data quality problem, contact data source\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "validate1",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# CHECK 2: Business Rule Validation\n",
    "# Why: Ensure data follows business logic and constraints\n",
    "\n",
    "validation_results <- sales_data %>%\n",
    "  summarize(\n",
    "    # Check for negative sales (should NEVER happen)\n",
    "    Negative_Sales = sum(Sales < 0),\n",
    "    \n",
    "    # Check for zero or negative quantity (invalid)\n",
    "    Zero_Quantity = sum(Quantity <= 0),\n",
    "    \n",
    "    # Check for future dates (impossible)\n",
    "    Future_Dates = sum(OrderDate > today()),\n",
    "    \n",
    "    # Check for extreme outliers (sales > $10,000)\n",
    "    # May be legitimate but worth investigating\n",
    "    Extreme_Sales = sum(Sales > 10000),\n",
    "    \n",
    "    # Check for very old dates (before business started)\n",
    "    # Assuming business started in 2020\n",
    "    Old_Dates = sum(OrderDate < as.Date(\"2020-01-01\"))\n",
    "  )\n",
    "\n",
    "cat(\"\u2705 BUSINESS RULE VALIDATION:\\n\\n\")\n",
    "print(validation_results)\n",
    "\n",
    "# Calculate total issues\n",
    "total_issues <- sum(validation_results)\n",
    "\n",
    "if (total_issues == 0) {\n",
    "  cat(\"\\n\u2705 All validation checks passed! Data is clean.\\n\")\n",
    "} else {\n",
    "  cat(\"\\n\u26a0\ufe0f \", total_issues, \" validation issue(s) found!\\n\")\n",
    "  cat(\"\\n\ud83d\udd0d Next steps:\\n\")\n",
    "  cat(\"  1. Investigate root cause of issues\\n\")\n",
    "  cat(\"  2. Contact data source if systematic problem\\n\")\n",
    "  cat(\"  3. Document any data cleaning decisions\\n\")\n",
    "  cat(\"  4. Consider flagging vs removing problematic records\\n\")\n",
    "}\n",
    "\n",
    "cat(\"\\n\ud83d\udca1 Validation Rules Explained:\\n\")\n",
    "cat(\"  Negative Sales: Physically impossible, indicates data error\\n\")\n",
    "cat(\"  Zero Quantity: Business rule violation, can't sell 0 items\\n\")\n",
    "cat(\"  Future Dates: Logically impossible, system error\\n\")\n",
    "cat(\"  Extreme Sales: May be legitimate but worth manual review\\n\")\n",
    "cat(\"  Old Dates: May indicate test data or migration issues\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "validate2",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Validate business rules\n",
    "validation_results <- sales_data %>%\n",
    "  summarize(\n",
    "    # Check for negative sales (should be 0)\n",
    "    Negative_Sales = sum(Sales < 0),\n",
    "    # Check for zero quantity (should be 0)\n",
    "    Zero_Quantity = sum(Quantity <= 0),\n",
    "    # Check for future dates (should be 0)\n",
    "    Future_Dates = sum(OrderDate > today()),\n",
    "    # Check for extreme outliers (sales > $10,000)\n",
    "    Extreme_Sales = sum(Sales > 10000)\n",
    "  )\n",
    "\n",
    "print(\"Business Rule Validation:\")\n",
    "print(validation_results)\n",
    "\n",
    "# Assert that all validations pass\n",
    "if (sum(validation_results) == 0) {\n",
    "  cat(\"\\n\u2705 All validation checks passed!\\n\")\n",
    "} else {\n",
    "  cat(\"\\n\u26a0\ufe0f Some validation checks failed!\\n\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "validate3",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Statistical validation: Check for outliers\n",
    "outlier_analysis <- sales_data %>%\n",
    "  summarize(\n",
    "    Mean_Sales = mean(Sales),\n",
    "    SD_Sales = sd(Sales),\n",
    "    Min_Sales = min(Sales),\n",
    "    Max_Sales = max(Sales),\n",
    "    Q1 = quantile(Sales, 0.25),\n",
    "    Median = median(Sales),\n",
    "    Q3 = quantile(Sales, 0.75),\n",
    "    IQR = Q3 - Q1\n",
    "  ) %>%\n",
    "  mutate(\n",
    "    Lower_Fence = Q1 - 1.5 * IQR,\n",
    "    Upper_Fence = Q3 + 1.5 * IQR\n",
    "  )\n",
    "\n",
    "print(\"Sales Distribution Analysis:\")\n",
    "print(outlier_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section5",
   "metadata": {},
   "source": [
    "## Part 5: Reproducible Workflows\n",
    "\n",
    "Creating analysis that others can understand, verify, and update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "repro1",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Create a reusable analysis function\n",
    "analyze_sales_by_dimension <- function(data, group_var) {\n",
    "  \"\"\"\n",
    "  Analyze sales data by any grouping variable\n",
    "  \n",
    "  Args:\n",
    "    data: Sales data frame\n",
    "    group_var: Column name to group by (as string)\n",
    "  \n",
    "  Returns:\n",
    "    Summary data frame with key metrics\n",
    "  \"\"\"\n",
    "  \n",
    "  data %>%\n",
    "    mutate(Revenue = Sales * Quantity) %>%\n",
    "    group_by(across(all_of(group_var))) %>%\n",
    "    summarize(\n",
    "      Total_Revenue = sum(Revenue),\n",
    "      Avg_Sale = mean(Sales),\n",
    "      Order_Count = n(),\n",
    "      Total_Units = sum(Quantity),\n",
    "      .groups = 'drop'\n",
    "    ) %>%\n",
    "    mutate(\n",
    "      Revenue_Share = (Total_Revenue / sum(Total_Revenue)) * 100\n",
    "    ) %>%\n",
    "    arrange(desc(Total_Revenue))\n",
    "}\n",
    "\n",
    "# Use the function for different analyses\n",
    "print(\"Analysis by Region:\")\n",
    "analyze_sales_by_dimension(sales_data, \"Region\") %>% print()\n",
    "\n",
    "print(\"\\nAnalysis by Product:\")\n",
    "analyze_sales_by_dimension(sales_data, \"Product\") %>% head(5) %>% print()\n",
    "\n",
    "print(\"\\nAnalysis by Customer Type:\")\n",
    "analyze_sales_by_dimension(sales_data, \"CustomerType\") %>% print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section6",
   "metadata": {},
   "source": [
    "## Part 6: Comprehensive Business Analysis\n",
    "\n",
    "Putting it all together: A complete analysis workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "business1",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Complete analysis pipeline\n",
    "comprehensive_analysis <- sales_data %>%\n",
    "  # Step 1: Data validation and cleaning\n",
    "  filter(\n",
    "    Sales > 0,\n",
    "    Quantity > 0,\n",
    "    !is.na(OrderDate)\n",
    "  ) %>%\n",
    "  # Step 2: Feature engineering\n",
    "  mutate(\n",
    "    Revenue = Sales * Quantity,\n",
    "    Month = month(OrderDate, label = TRUE),\n",
    "    Quarter = paste0(\"Q\", quarter(OrderDate)),\n",
    "    Weekday = wday(OrderDate, label = TRUE),\n",
    "    Is_Weekend = wday(OrderDate) %in% c(1, 7),\n",
    "    # Classification\n",
    "    Revenue_Tier = case_when(\n",
    "      Revenue < 500 ~ \"Low\",\n",
    "      Revenue < 2000 ~ \"Medium\",\n",
    "      TRUE ~ \"High\"\n",
    "    )\n",
    "  ) %>%\n",
    "  # Step 3: Group and summarize\n",
    "  group_by(Quarter, Region, Revenue_Tier) %>%\n",
    "  summarize(\n",
    "    Total_Revenue = sum(Revenue),\n",
    "    Order_Count = n(),\n",
    "    Avg_Revenue = mean(Revenue),\n",
    "    .groups = 'drop'\n",
    "  ) %>%\n",
    "  # Step 4: Calculate shares\n",
    "  group_by(Quarter) %>%\n",
    "  mutate(\n",
    "    Quarter_Share = (Total_Revenue / sum(Total_Revenue)) * 100\n",
    "  ) %>%\n",
    "  ungroup() %>%\n",
    "  # Step 5: Final sorting\n",
    "  arrange(Quarter, desc(Total_Revenue))\n",
    "\n",
    "print(\"Comprehensive Quarterly Analysis:\")\n",
    "print(comprehensive_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "business2",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Executive summary: Key metrics\n",
    "executive_summary <- sales_data %>%\n",
    "  mutate(Revenue = Sales * Quantity) %>%\n",
    "  summarize(\n",
    "    Total_Orders = n(),\n",
    "    Total_Revenue = sum(Revenue),\n",
    "    Avg_Order_Value = mean(Revenue),\n",
    "    Total_Units_Sold = sum(Quantity),\n",
    "    Unique_Products = n_distinct(Product),\n",
    "    Date_Range = paste(min(OrderDate), \"to\", max(OrderDate)),\n",
    "    VIP_Customers = sum(CustomerType == \"VIP\"),\n",
    "    VIP_Percentage = (VIP_Customers / n()) * 100\n",
    "  )\n",
    "\n",
    "cat(\"\\n=== EXECUTIVE SUMMARY ===\\n\")\n",
    "cat(\"Total Orders:\", executive_summary$Total_Orders, \"\\n\")\n",
    "cat(\"Total Revenue: $\", format(executive_summary$Total_Revenue, big.mark = \",\"), \"\\n\")\n",
    "cat(\"Average Order Value: $\", round(executive_summary$Avg_Order_Value, 2), \"\\n\")\n",
    "cat(\"Total Units Sold:\", executive_summary$Total_Units_Sold, \"\\n\")\n",
    "cat(\"Unique Products:\", executive_summary$Unique_Products, \"\\n\")\n",
    "cat(\"Date Range:\", executive_summary$Date_Range, \"\\n\")\n",
    "cat(\"VIP Customers:\", executive_summary$VIP_Customers, \n",
    "    \"(\", round(executive_summary$VIP_Percentage, 1), \"%)\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## Summary: Best Practices for Professional Data Analysis\n",
    "\n",
    "### 1. Complex Workflows:\n",
    "- Chain operations logically (filter \u2192 mutate \u2192 group \u2192 summarize \u2192 arrange)\n",
    "- Use meaningful intermediate variable names\n",
    "- Comment each major step\n",
    "\n",
    "### 2. Conditional Logic:\n",
    "- Use `case_when()` for multiple conditions\n",
    "- Always include a default case (`TRUE ~ ...`)\n",
    "- Test edge cases\n",
    "\n",
    "### 3. Data Validation:\n",
    "- Check for missing values\n",
    "- Validate business rules\n",
    "- Identify outliers\n",
    "- Document assumptions\n",
    "\n",
    "### 4. Reproducibility:\n",
    "- Set random seeds for consistency\n",
    "- Create reusable functions\n",
    "- Document your code\n",
    "- Use version control\n",
    "\n",
    "### 5. Professional Reporting:\n",
    "- Create executive summaries\n",
    "- Format numbers appropriately\n",
    "- Provide context for metrics\n",
    "- Make insights actionable\n",
    "\n",
    "### Key Functions Mastered:\n",
    "- `case_when()` - Complex conditional logic\n",
    "- `across()` - Apply functions to multiple columns\n",
    "- `all_of()` - Select columns programmatically\n",
    "- `n_distinct()` - Count unique values\n",
    "- Chaining with `%>%` - Build complex pipelines\n",
    "\n",
    "### You're Now Ready For:\n",
    "- Real-world business analytics projects\n",
    "- Complex data transformation challenges\n",
    "- Professional data analysis workflows\n",
    "- Advanced R programming\n",
    "\n",
    "**Congratulations on completing the Data Wrangling course!** \ud83c\udf89\n",
    "\n",
    "---\n",
    "\n",
    "**End of Lesson 8**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "name": "R"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}