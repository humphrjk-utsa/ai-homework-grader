{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Homework Assignment - Lesson 7: String Manipulation and Date/Time Data\n\n**Student Name:** [Enter Your Full Name Here]\n\n**Student ID:** [Enter Your Student ID]\n\n**Date Submitted:** [Enter Today's Date]\n\n**Due Date:** [Insert Due Date Here]\n\n---\n\n## Objective\n\nMaster string manipulation with `stringr` and date/time operations with `lubridate` for real-world business data cleaning and analysis.\n\n## Learning Goals\n\nBy completing this assignment, you will:\n- Clean and standardize messy text data using `stringr` functions\n- Parse and manipulate dates using `lubridate` functions\n- Extract information from text and dates for business insights\n- Combine string and date operations for customer segmentation\n- Create business-ready reports from raw data\n\n## Instructions\n\n- Complete all tasks in this notebook\n- Write your code in the designated TODO sections\n- Use the pipe operator (`%>%`) wherever possible\n- Add comments explaining your logic\n- Run all cells to verify your code works\n- Answer all reflection questions\n\n## Datasets\n\nYou will work with three CSV files:\n- `customer_feedback.csv` - Customer reviews with messy text\n- `transaction_log.csv` - Transaction records with dates\n- `product_catalog.csv` - Product descriptions needing standardization\n\n---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part1_intro",
   "metadata": {},
   "source": [
    "## Part 1: Data Import and Initial Exploration\n\n**Business Context:** Before cleaning data, you must understand its structure and quality issues.\n\n**Your Tasks:**\n1. Load required packages (`tidyverse` and `lubridate`)\n2. Import all three CSV files from the `data/` directory\n3. Examine the structure and identify data quality issues\n4. Display sample rows to understand the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Task 1.1: Load Required Packages\n# TODO: Load tidyverse (includes stringr)\n\n\n# TODO: Load lubridate\n\n\ncat(\"\u2705 Packages loaded successfully!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "import_data",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Task 1.2: Import Datasets\n# TODO: Import customer_feedback.csv into a variable called 'feedback'\nfeedback <- \n\n# TODO: Import transaction_log.csv into a variable called 'transactions'\ntransactions <- \n\n# TODO: Import product_catalog.csv into a variable called 'products'\nproducts <- \n\ncat(\"\u2705 Data imported successfully!\\n\")\ncat(\"Feedback rows:\", nrow(feedback), \"\\n\")\ncat(\"Transaction rows:\", nrow(transactions), \"\\n\")\ncat(\"Product rows:\", nrow(products), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explore_data",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Task 1.3: Initial Data Exploration\n\ncat(\"=== CUSTOMER FEEDBACK DATA ===\\n\")\n# TODO: Display structure of feedback using str()\n\n\n# TODO: Display first 5 rows of feedback\n\n\ncat(\"\\n=== TRANSACTION DATA ===\\n\")\n# TODO: Display structure of transactions\n\n\n# TODO: Display first 5 rows of transactions\n\n\ncat(\"\\n=== PRODUCT CATALOG DATA ===\\n\")\n# TODO: Display structure of products\n\n\n# TODO: Display first 5 rows of products\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part2_intro",
   "metadata": {},
   "source": [
    "## Part 2: String Cleaning and Standardization\n\n**Business Context:** Product names and feedback text often have inconsistent formatting that prevents accurate analysis.\n\n**Your Tasks:**\n1. Clean product names (remove extra spaces, standardize case)\n2. Standardize product categories\n3. Clean customer feedback text\n4. Extract customer names from feedback\n\n**Key Functions:** `str_trim()`, `str_squish()`, `str_to_lower()`, `str_to_upper()`, `str_to_title()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean_products",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Task 2.1: Clean Product Names\n# TODO: Create a new column 'product_name_clean' that:\n#   - Removes leading/trailing whitespace using str_trim()\n#   - Converts to Title Case using str_to_title()\n\nproducts_clean <- products %>%\n  mutate(\n    # Your code here:\n    \n  )\n\n# Display before and after\ncat(\"Product Name Cleaning Results:\\n\")\nproducts_clean %>%\n  select(product_name, product_name_clean) %>%\n  head(10) %>%\n  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean_categories",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Task 2.2: Standardize Product Categories\n# TODO: Create a new column 'category_clean' that:\n#   - Converts category to Title Case\n#   - Removes any extra whitespace\n\nproducts_clean <- products_clean %>%\n  mutate(\n    # Your code here:\n    \n  )\n\n# Show unique categories before and after\ncat(\"Original categories:\\n\")\nprint(unique(products$category))\n\ncat(\"\\nCleaned categories:\\n\")\nprint(unique(products_clean$category_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean_feedback",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Task 2.3: Clean Customer Feedback Text\n# TODO: Create a new column 'feedback_clean' that:\n#   - Converts text to lowercase using str_to_lower()\n#   - Removes extra whitespace using str_squish()\n\nfeedback_clean <- feedback %>%\n  mutate(\n    # Your code here:\n    \n  )\n\n# Display sample\ncat(\"Feedback Cleaning Sample:\\n\")\nfeedback_clean %>%\n  select(feedback_text, feedback_clean) %>%\n  head(5) %>%\n  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part3_intro",
   "metadata": {},
   "source": [
    "## Part 3: Pattern Detection and Extraction\n\n**Business Context:** Identifying products with specific features and extracting specifications helps with inventory management and marketing.\n\n**Your Tasks:**\n1. Identify products with specific keywords (wireless, premium, gaming)\n2. Extract numerical specifications from product names\n3. Detect sentiment words in customer feedback\n4. Extract email addresses from feedback\n\n**Key Functions:** `str_detect()`, `str_extract()`, `str_count()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detect_features",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Task 3.1: Detect Product Features\n# TODO: Create three new columns:\n#   - is_wireless: TRUE if product name contains \"wireless\" (case-insensitive)\n#   - is_premium: TRUE if product name contains \"pro\", \"premium\", or \"deluxe\"\n#   - is_gaming: TRUE if product name contains \"gaming\" or \"gamer\"\n# Hint: Use str_detect() with str_to_lower() for case-insensitive matching\n# Hint: Use | (pipe) in regex for OR conditions\n\nproducts_clean <- products_clean %>%\n  mutate(\n    # Your code here:\n    \n  )\n\n# Display results\ncat(\"Product Feature Detection:\\n\")\nproducts_clean %>%\n  select(product_name_clean, is_wireless, is_premium, is_gaming) %>%\n  head(10) %>%\n  print()\n\n# Summary statistics\ncat(\"\\nFeature Summary:\\n\")\ncat(\"Wireless products:\", sum(products_clean$is_wireless), \"\\n\")\ncat(\"Premium products:\", sum(products_clean$is_premium), \"\\n\")\ncat(\"Gaming products:\", sum(products_clean$is_gaming), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extract_specs",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Task 3.2: Extract Product Specifications\n# TODO: Create a new column 'size_number' that extracts the first number from product_name\n# Hint: Use str_extract() with pattern \"\\\\\\\\d+\" to match one or more digits\n\nproducts_clean <- products_clean %>%\n  mutate(\n    # Your code here:\n    \n  )\n\n# Display products with extracted sizes\ncat(\"Extracted Product Specifications:\\n\")\nproducts_clean %>%\n  filter(!is.na(size_number)) %>%\n  select(product_name_clean, size_number) %>%\n  head(10) %>%\n  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sentiment_analysis",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Task 3.3: Simple Sentiment Analysis\n# TODO: Create three new columns:\n#   - positive_words: count of positive words (\"great\", \"excellent\", \"love\", \"amazing\")\n#   - negative_words: count of negative words (\"bad\", \"terrible\", \"hate\", \"awful\")\n#   - sentiment_score: positive_words - negative_words\n# Hint: Use str_count() to count pattern occurrences\n\nfeedback_clean <- feedback_clean %>%\n  mutate(\n    # Your code here:\n    \n  )\n\n# Display sentiment analysis results\ncat(\"Sentiment Analysis Results:\\n\")\nfeedback_clean %>%\n  select(feedback_clean, positive_words, negative_words, sentiment_score) %>%\n  head(10) %>%\n  print()\n\n# Summary\ncat(\"\\nOverall Sentiment Summary:\\n\")\ncat(\"Average sentiment score:\", mean(feedback_clean$sentiment_score), \"\\n\")\ncat(\"Positive reviews:\", sum(feedback_clean$sentiment_score > 0), \"\\n\")\ncat(\"Negative reviews:\", sum(feedback_clean$sentiment_score < 0), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part4_intro",
   "metadata": {},
   "source": [
    "## Part 4: Date Parsing and Component Extraction\n\n**Business Context:** Transaction dates need to be parsed and analyzed to understand customer behavior patterns.\n\n**Your Tasks:**\n1. Parse transaction dates from text to Date objects\n2. Extract date components (year, month, day, weekday)\n3. Identify weekend vs weekday transactions\n4. Extract quarter and month names\n\n**Key Functions:** `ymd()`, `mdy()`, `dmy()`, `year()`, `month()`, `day()`, `wday()`, `quarter()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parse_dates",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Task 4.1: Parse Transaction Dates\n# TODO: Create a new column 'date_parsed' that parses the transaction_date column\n# Hint: Check the format of transaction_date first, then use ymd(), mdy(), or dmy()\n\ntransactions_clean <- transactions %>%\n  mutate(\n    # Your code here:\n    \n  )\n\n# Verify parsing worked\ncat(\"Date Parsing Results:\\n\")\ntransactions_clean %>%\n  select(transaction_date, date_parsed) %>%\n  head(10) %>%\n  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extract_components",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Task 4.2: Extract Date Components\n# TODO: Create the following new columns:\n#   - trans_year: Extract year from date_parsed\n#   - trans_month: Extract month number from date_parsed\n#   - trans_month_name: Extract month name (use label=TRUE, abbr=FALSE)\n#   - trans_day: Extract day of month from date_parsed\n#   - trans_weekday: Extract weekday name (use label=TRUE, abbr=FALSE)\n#   - trans_quarter: Extract quarter from date_parsed\n\ntransactions_clean <- transactions_clean %>%\n  mutate(\n    # Your code here:\n    \n  )\n\n# Display results\ncat(\"Date Component Extraction:\\n\")\ntransactions_clean %>%\n  select(date_parsed, trans_month_name, trans_weekday, trans_quarter) %>%\n  head(10) %>%\n  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weekend_flag",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Task 4.3: Identify Weekend Transactions\n# TODO: Create a new column 'is_weekend' that is TRUE if the transaction was on Saturday or Sunday\n# Hint: Use wday() which returns 1 for Sunday and 7 for Saturday\n# Hint: Use %in% c(1, 7) to check if day is weekend\n\ntransactions_clean <- transactions_clean %>%\n  mutate(\n    # Your code here:\n    \n  )\n\n# Summary\ncat(\"Weekend vs Weekday Transactions:\\n\")\ntable(transactions_clean$is_weekend) %>% print()\n\ncat(\"\\nPercentage of weekend transactions:\",\n    round(sum(transactions_clean$is_weekend) / nrow(transactions_clean) * 100, 1), \"%\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part5_intro",
   "metadata": {},
   "source": [
    "## Part 5: Date Calculations and Customer Recency Analysis\n\n**Business Context:** Understanding how recently customers transacted helps identify at-risk customers for re-engagement campaigns.\n\n**Your Tasks:**\n1. Calculate days since each transaction\n2. Categorize customers by recency (Recent, Moderate, Old)\n3. Identify customers who haven't transacted in 90+ days\n4. Calculate average days between transactions per customer\n\n**Key Functions:** `today()`, date arithmetic, `case_when()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "calculate_recency",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Task 5.1: Calculate Days Since Transaction\n# TODO: Create a new column 'days_since' that calculates days from date_parsed to today()\n# Hint: Use as.numeric(today() - date_parsed)\n\ntransactions_clean <- transactions_clean %>%\n  mutate(\n    # Your code here:\n    \n  )\n\n# Display results\ncat(\"Days Since Transaction:\\n\")\ntransactions_clean %>%\n  select(customer_name, date_parsed, days_since) %>%\n  arrange(desc(days_since)) %>%\n  head(10) %>%\n  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recency_categories",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Task 5.2: Categorize by Recency\n# TODO: Create a new column 'recency_category' using case_when():\n#   - \"Recent\" if days_since <= 30\n#   - \"Moderate\" if days_since <= 90\n#   - \"At Risk\" if days_since > 90\n\ntransactions_clean <- transactions_clean %>%\n  mutate(\n    # Your code here:\n    \n  )\n\n# Display distribution\ncat(\"Recency Category Distribution:\\n\")\ntable(transactions_clean$recency_category) %>% print()\n\n# Show at-risk customers\ncat(\"\\nAt-Risk Customers (>90 days):\\n\")\ntransactions_clean %>%\n  filter(recency_category == \"At Risk\") %>%\n  select(customer_name, date_parsed, days_since) %>%\n  arrange(desc(days_since)) %>%\n  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part6_intro",
   "metadata": {},
   "source": [
    "## Part 6: Combined String and Date Operations\n\n**Business Context:** Create personalized customer outreach messages based on purchase recency.\n\n**Your Tasks:**\n1. Extract first names from customer names\n2. Create personalized messages based on recency\n3. Analyze transaction patterns by weekday\n4. Identify best customers (recent + high value)\n\n**Key Functions:** Combine `str_extract()`, date calculations, `case_when()`, `group_by()`, `summarize()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extract_names",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Task 6.1: Extract First Names and Create Personalized Messages\n# TODO: Create two new columns:\n#   - first_name: Extract first name from customer_name (everything before first space)\n#   - personalized_message: Create message based on recency_category\n#     * Recent: \"Hi [name]! Thanks for your recent purchase!\"\n#     * Moderate: \"Hi [name], we miss you! Check out our new products.\"\n#     * At Risk: \"Hi [name], it's been a while! Here's a special offer for you.\"\n# Hint: Use str_extract() with pattern \"^\\\\\\\\w+\" for first name\n# Hint: Use paste() to combine strings in case_when()\n\ncustomer_outreach <- transactions_clean %>%\n  mutate(\n    # Your code here:\n    \n  )\n\n# Display personalized messages\ncat(\"Personalized Customer Messages:\\n\")\ncustomer_outreach %>%\n  select(customer_name, first_name, days_since, personalized_message) %>%\n  head(10) %>%\n  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weekday_analysis",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Task 6.2: Analyze Transaction Patterns by Weekday\n# TODO: Group by trans_weekday and calculate:\n#   - transaction_count: number of transactions\n#   - total_amount: sum of amount (if available)\n#   - avg_amount: average amount per transaction\n# TODO: Arrange by transaction_count descending\n\nweekday_patterns <- transactions_clean %>%\n  # Your code here:\n  \n\n# Display results\ncat(\"Transaction Patterns by Weekday:\\n\")\nprint(weekday_patterns)\n\n# Identify busiest day\nbusiest_day <- weekday_patterns$trans_weekday[1]\ncat(\"\\n\ud83d\udd25 Busiest day:\", as.character(busiest_day), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly_analysis",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Task 6.3: Monthly Transaction Analysis\n# TODO: Group by trans_month_name and calculate:\n#   - transaction_count\n#   - unique_customers: use n_distinct(customer_name)\n# TODO: Arrange by trans_month (to show chronological order)\n\nmonthly_patterns <- transactions_clean %>%\n  # Your code here:\n  \n\n# Display results\ncat(\"Monthly Transaction Patterns:\\n\")\nprint(monthly_patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part7_intro",
   "metadata": {},
   "source": [
    "## Part 7: Business Intelligence Summary\n\n**Business Context:** Create an executive summary that combines all your analyses into actionable insights.\n\n**Your Tasks:**\n1. Calculate key metrics across all datasets\n2. Identify top products and categories\n3. Summarize customer sentiment\n4. Provide data-driven recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "business_summary",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Task 7.1: Create Business Intelligence Dashboard\n\ncat(\"\\n\", rep(\"=\", 60), \"\\n\")\ncat(\"         BUSINESS INTELLIGENCE SUMMARY\\n\")\ncat(rep(\"=\", 60), \"\\n\\n\")\n\n# Product Analysis\ncat(\"\ud83d\udce6 PRODUCT ANALYSIS\\n\")\ncat(rep(\"\u2500\", 30), \"\\n\")\n# TODO: Calculate and display:\n#   - Total number of products\n#   - Number of wireless products\n#   - Number of premium products\n#   - Most common category\n\n\n# Customer Sentiment\ncat(\"\\n\ud83d\udcac CUSTOMER SENTIMENT\\n\")\ncat(rep(\"\u2500\", 30), \"\\n\")\n# TODO: Calculate and display:\n#   - Total feedback entries\n#   - Average sentiment score\n#   - Percentage of positive reviews\n#   - Percentage of negative reviews\n\n\n# Transaction Patterns\ncat(\"\\n\ud83d\udcca TRANSACTION PATTERNS\\n\")\ncat(rep(\"\u2500\", 30), \"\\n\")\n# TODO: Calculate and display:\n#   - Total transactions\n#   - Date range (earliest to latest)\n#   - Busiest weekday\n#   - Weekend transaction percentage\n\n\n# Customer Recency\ncat(\"\\n\ud83d\udc65 CUSTOMER RECENCY\\n\")\ncat(rep(\"\u2500\", 30), \"\\n\")\n# TODO: Calculate and display:\n#   - Number of recent customers (< 30 days)\n#   - Number of at-risk customers (> 90 days)\n#   - Percentage needing re-engagement\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "top_products",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Task 7.2: Identify Top Products by Category\n# TODO: Group products by category_clean and count products in each\n# TODO: Arrange by count descending\n# TODO: Display top 5 categories\n\ntop_categories <- products_clean %>%\n  # Your code here:\n  \n\ncat(\"Top Product Categories:\\n\")\nprint(top_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part8_intro",
   "metadata": {},
   "source": [
    "## Part 8: Reflection Questions\n\nAnswer the following questions based on your analysis. Write your answers in the markdown cells below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection1",
   "metadata": {},
   "source": [
    "### Question 8.1: Data Quality Impact\n\n**How did cleaning the text data (removing spaces, standardizing case) improve your ability to analyze the data? Provide specific examples from your homework.**\n\nYour answer here:\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection2",
   "metadata": {},
   "source": [
    "### Question 8.2: Pattern Detection Value\n\n**What business insights did you gain from detecting patterns in product names (wireless, premium, gaming)? How could a business use this information?**\n\nYour answer here:\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection3",
   "metadata": {},
   "source": [
    "### Question 8.3: Date Analysis Importance\n\n**Why is analyzing transaction dates by weekday and month important for business operations? Provide at least three specific business applications.**\n\nYour answer here:\n\n1. \n2. \n3. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection4",
   "metadata": {},
   "source": [
    "### Question 8.4: Customer Recency Strategy\n\n**Based on your recency analysis, what specific actions would you recommend for customers in each category (Recent, Moderate, At Risk)? How would you prioritize these actions?**\n\nYour answer here:\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection5",
   "metadata": {},
   "source": [
    "### Question 8.5: Sentiment Analysis Application\n\n**How could the sentiment analysis you performed be used to improve products or customer service? What are the limitations of this simple sentiment analysis approach?**\n\nYour answer here:\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection6",
   "metadata": {},
   "source": [
    "### Question 8.6: Real-World Application\n\n**Describe a real business scenario where you would need to combine string manipulation and date analysis (like you did in this homework). What insights would you be trying to discover?**\n\nYour answer here:\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## Summary and Submission\n\n### What You've Accomplished\n\nIn this homework, you've successfully:\n- \u2705 Cleaned and standardized messy text data using `stringr` functions\n- \u2705 Detected patterns and extracted information from text\n- \u2705 Parsed dates and extracted temporal components using `lubridate`\n- \u2705 Calculated customer recency for segmentation\n- \u2705 Analyzed transaction patterns by time periods\n- \u2705 Combined string and date operations for business insights\n- \u2705 Created personalized customer communications\n- \u2705 Generated executive-ready business intelligence summaries\n\n### Key Skills Mastered\n\n**String Manipulation:**\n- `str_trim()`, `str_squish()` - Whitespace handling\n- `str_to_lower()`, `str_to_upper()`, `str_to_title()` - Case conversion\n- `str_detect()` - Pattern detection\n- `str_extract()` - Information extraction\n- `str_count()` - Pattern counting\n\n**Date/Time Operations:**\n- `ymd()`, `mdy()`, `dmy()` - Date parsing\n- `year()`, `month()`, `day()`, `wday()` - Component extraction\n- `quarter()` - Period extraction\n- `today()` - Current date\n- Date arithmetic - Calculating differences\n\n**Business Applications:**\n- Data cleaning and standardization\n- Customer segmentation by recency\n- Sentiment analysis\n- Pattern identification\n- Temporal trend analysis\n- Personalized communication\n\n### Submission Checklist\n\nBefore submitting, ensure you have:\n- [ ] Entered your name, student ID, and date at the top\n- [ ] Completed all code tasks (Parts 1-7)\n- [ ] Run all cells successfully without errors\n- [ ] Answered all reflection questions (Part 8)\n- [ ] Used proper commenting in your code\n- [ ] Used the pipe operator (`%>%`) where appropriate\n- [ ] Verified your results make business sense\n- [ ] Checked for any remaining TODO comments\n\n### Grading Criteria\n\nYour homework will be evaluated on:\n- **Code Correctness (40%)**: All tasks completed correctly\n- **Code Quality (20%)**: Clean, well-commented, efficient code\n- **Business Understanding (20%)**: Demonstrates understanding of business applications\n- **Reflection Questions (15%)**: Thoughtful, complete answers\n- **Presentation (5%)**: Professional formatting and organization\n\n### Next Steps\n\nIn Lesson 8, you'll learn:\n- Advanced data wrangling with complex pipelines\n- Sophisticated conditional logic with `case_when()`\n- Data validation and quality checks\n- Creating reproducible analysis workflows\n- Professional best practices for business analytics\n\n**Great work on completing this assignment! \ud83c\udf89**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "name": "R",
   "version": "4.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}