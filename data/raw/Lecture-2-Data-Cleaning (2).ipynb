{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69ead280",
   "metadata": {},
   "source": [
    "## Lesson 2: Data Cleaning - Handling Missing Values and Outliers\n",
    "\n",
    "Welcome to Lesson 2! Now that you know the basics of R and data import, let's learn about **data cleaning** - one of the most important skills in data science.\n",
    "\n",
    "**What is Data Cleaning?**\n",
    "- The process of detecting and correcting errors and inconsistencies in data\n",
    "- Handling missing values (NAs) and outliers\n",
    "- Preparing data for analysis and visualization\n",
    "\n",
    "**Why is it important?**\n",
    "- Real-world data is often messy and incomplete\n",
    "- Poor data quality leads to incorrect analysis results\n",
    "- \"Garbage in, garbage out\" - clean data is essential for reliable insights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b96cfc3",
   "metadata": {},
   "source": [
    "## Loading Required Packages\n",
    "\n",
    "For data cleaning, we'll use the **tidyverse** collection of packages, which includes powerful tools for:\n",
    "- **dplyr**: Data manipulation (filtering, selecting, mutating)\n",
    "- **ggplot2**: Data visualization \n",
    "- **tidyr**: Data reshaping and cleaning\n",
    "\n",
    "Let's load the tidyverse package that contains all these tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee46e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── \u001b[1mAttaching core tidyverse packages\u001b[22m ──────────────────────── tidyverse 2.0.0 ──\n",
      "\u001b[32m✔\u001b[39m \u001b[34mdplyr    \u001b[39m 1.1.4     \u001b[32m✔\u001b[39m \u001b[34mreadr    \u001b[39m 2.1.5\n",
      "\u001b[32m✔\u001b[39m \u001b[34mforcats  \u001b[39m 1.0.0     \u001b[32m✔\u001b[39m \u001b[34mstringr  \u001b[39m 1.5.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2  \u001b[39m 3.5.2     \u001b[32m✔\u001b[39m \u001b[34mtibble   \u001b[39m 3.3.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mlubridate\u001b[39m 1.9.4     \u001b[32m✔\u001b[39m \u001b[34mtidyr    \u001b[39m 1.3.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mpurrr    \u001b[39m 1.1.0     \n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\u001b[36mℹ\u001b[39m Use the conflicted package (\u001b[3m\u001b[34m<http://conflicted.r-lib.org/>\u001b[39m\u001b[23m) to force all conflicts to become errors\n"
     ]
    }
   ],
   "source": [
    "# Load necessary packages\n",
    "library(tidyverse) # Loads dplyr, ggplot2, tidyr, and other data science tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50a85aa",
   "metadata": {},
   "source": [
    "## Creating Sample Data with Missing Values and Outliers\n",
    "\n",
    "For this lesson, we'll create a realistic dataset that contains common data problems:\n",
    "- **Missing values (NAs)**: Some data points are missing\n",
    "- **Outliers**: Extreme values that are very different from the rest\n",
    "\n",
    "**About our sample dataset:**\n",
    "- **ID**: Unique identifier for each observation\n",
    "- **Sales**: Sales amounts (we'll add some outliers here)\n",
    "- **Profit**: Profit values (we'll introduce missing values)\n",
    "- **Region**: Geographic regions (categorical data)\n",
    "\n",
    "**Why we use set.seed(123):**\n",
    "- Makes our random data reproducible\n",
    "- Everyone running this code will get the same \"random\" numbers\n",
    "- Essential for consistent results in tutorials and research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30924c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID     Sales     Profit Region\n",
      "1   1  88.79049  13.506780  North\n",
      "2   2  95.39645   7.636043   West\n",
      "3   3        NA   4.660881  South\n",
      "4   4 101.41017   8.910125  North\n",
      "5   5 102.58575         NA  South\n",
      "6   6 134.30130   6.355544  South\n",
      "7   7        NA   6.874804   West\n",
      "8   8  74.69878   1.566533   West\n",
      "9   9  86.26294  14.188935  North\n",
      "10 10  91.08676  10.766866  South\n",
      "11 11 124.48164   4.309315   West\n",
      "12 12 107.19628         NA   West\n",
      "13 13 108.01543  12.132321  North\n",
      "14 14 102.21365   8.524643  North\n",
      "15 15        NA  14.475628  South\n",
      "16 16 135.73826  14.390667   East\n",
      "17 17 109.95701  14.107905   West\n",
      "18 18  60.66766  13.443201   West\n",
      "19 19 500.00000  12.769588   East\n",
      "20 20  10.00000 -30.000000   West\n"
     ]
    }
   ],
   "source": [
    "# 1. Creating a sample dataset with missing values and outliers\n",
    "set.seed(123) # Ensures reproducible random numbers\n",
    "data_clean <- data.frame(\n",
    "  ID = 1:20, # Sequential ID numbers from 1 to 20\n",
    "  Sales = c(rnorm(18, mean = 100, sd = 20), 500, 10), # 18 normal values + 2 outliers (500, 10)\n",
    "  Profit = c(rnorm(19, mean = 10, sd = 5), -30), # 19 normal values + 1 outlier (-30)\n",
    "  Region = sample(c(\"East\", \"West\", \"North\", \"South\"), 20, replace = TRUE) # Random regions\n",
    ")\n",
    "\n",
    "# Introduce some missing values\n",
    "data_clean[c(3, 7, 15), \"Sales\"] <- NA # Set rows 3, 7, 15 Sales to missing\n",
    "data_clean[c(5, 12), \"Profit\"] <- NA # Set rows 5, 12 Profit to missing\n",
    "\n",
    "print(data_clean) # Display the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3128119b",
   "metadata": {},
   "source": [
    "## Understanding Missing Values (NAs)\n",
    "\n",
    "**Missing values** are represented by `NA` (Not Available) in R. They're common in real-world data due to:\n",
    "- Data entry errors\n",
    "- Equipment failures\n",
    "- Survey non-responses\n",
    "- Data not applicable to certain cases\n",
    "\n",
    "**Key functions for detecting missing values:**\n",
    "- `is.na()`: Returns TRUE/FALSE for each value\n",
    "- `sum(is.na())`: Counts missing values\n",
    "- `complete.cases()`: Identifies rows with no missing values\n",
    "\n",
    "Let's explore our dataset to see where the missing values are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa49ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 20 × 4 of type lgl</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>ID</th><th scope=col>Sales</th><th scope=col>Profit</th><th scope=col>Region</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td> TRUE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td> TRUE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td> TRUE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td> TRUE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td> TRUE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 20 × 4 of type lgl\n",
       "\\begin{tabular}{llll}\n",
       " ID & Sales & Profit & Region\\\\\n",
       "\\hline\n",
       "\t FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE &  TRUE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE &  TRUE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE &  TRUE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE &  TRUE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE &  TRUE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 20 × 4 of type lgl\n",
       "\n",
       "| ID | Sales | Profit | Region |\n",
       "|---|---|---|---|\n",
       "| FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE |  TRUE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE |  TRUE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE |  TRUE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE |  TRUE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE |  TRUE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE |\n",
       "\n"
      ],
      "text/plain": [
       "      ID    Sales Profit Region\n",
       " [1,] FALSE FALSE FALSE  FALSE \n",
       " [2,] FALSE FALSE FALSE  FALSE \n",
       " [3,] FALSE  TRUE FALSE  FALSE \n",
       " [4,] FALSE FALSE FALSE  FALSE \n",
       " [5,] FALSE FALSE  TRUE  FALSE \n",
       " [6,] FALSE FALSE FALSE  FALSE \n",
       " [7,] FALSE  TRUE FALSE  FALSE \n",
       " [8,] FALSE FALSE FALSE  FALSE \n",
       " [9,] FALSE FALSE FALSE  FALSE \n",
       "[10,] FALSE FALSE FALSE  FALSE \n",
       "[11,] FALSE FALSE FALSE  FALSE \n",
       "[12,] FALSE FALSE  TRUE  FALSE \n",
       "[13,] FALSE FALSE FALSE  FALSE \n",
       "[14,] FALSE FALSE FALSE  FALSE \n",
       "[15,] FALSE  TRUE FALSE  FALSE \n",
       "[16,] FALSE FALSE FALSE  FALSE \n",
       "[17,] FALSE FALSE FALSE  FALSE \n",
       "[18,] FALSE FALSE FALSE  FALSE \n",
       "[19,] FALSE FALSE FALSE  FALSE \n",
       "[20,] FALSE FALSE FALSE  FALSE "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2. Identifying Missing Values\n",
    "\n",
    "# Check for NA values in the entire data frame\n",
    "is.na(data_clean) # Returns TRUE/FALSE matrix showing where NAs are located"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac724c75",
   "metadata": {},
   "source": [
    "## Counting Missing Values\n",
    "\n",
    "Now let's get a summary of how many missing values we have in each column. This helps us understand the extent of the missing data problem:\n",
    "\n",
    "**`sapply()` function:**\n",
    "- Applies a function to each column of a data frame\n",
    "- Very useful for getting summaries across multiple columns\n",
    "- Here we're counting NAs in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46aa6cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>ID</dt><dd>0</dd><dt>Sales</dt><dd>3</dd><dt>Profit</dt><dd>2</dd><dt>Region</dt><dd>0</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[ID] 0\n",
       "\\item[Sales] 3\n",
       "\\item[Profit] 2\n",
       "\\item[Region] 0\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "ID\n",
       ":   0Sales\n",
       ":   3Profit\n",
       ":   2Region\n",
       ":   0\n",
       "\n"
      ],
      "text/plain": [
       "    ID  Sales Profit Region \n",
       "     0      3      2      0 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "5"
      ],
      "text/latex": [
       "5"
      ],
      "text/markdown": [
       "5"
      ],
      "text/plain": [
       "[1] 5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 5 × 4</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>ID</th><th scope=col>Sales</th><th scope=col>Profit</th><th scope=col>Region</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>3</th><td> 3</td><td>      NA</td><td> 4.660881</td><td>South</td></tr>\n",
       "\t<tr><th scope=row>5</th><td> 5</td><td>102.5858</td><td>       NA</td><td>South</td></tr>\n",
       "\t<tr><th scope=row>7</th><td> 7</td><td>      NA</td><td> 6.874804</td><td>West </td></tr>\n",
       "\t<tr><th scope=row>12</th><td>12</td><td>107.1963</td><td>       NA</td><td>West </td></tr>\n",
       "\t<tr><th scope=row>15</th><td>15</td><td>      NA</td><td>14.475628</td><td>South</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 5 × 4\n",
       "\\begin{tabular}{r|llll}\n",
       "  & ID & Sales & Profit & Region\\\\\n",
       "  & <int> & <dbl> & <dbl> & <chr>\\\\\n",
       "\\hline\n",
       "\t3 &  3 &       NA &  4.660881 & South\\\\\n",
       "\t5 &  5 & 102.5858 &        NA & South\\\\\n",
       "\t7 &  7 &       NA &  6.874804 & West \\\\\n",
       "\t12 & 12 & 107.1963 &        NA & West \\\\\n",
       "\t15 & 15 &       NA & 14.475628 & South\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 5 × 4\n",
       "\n",
       "| <!--/--> | ID &lt;int&gt; | Sales &lt;dbl&gt; | Profit &lt;dbl&gt; | Region &lt;chr&gt; |\n",
       "|---|---|---|---|---|\n",
       "| 3 |  3 |       NA |  4.660881 | South |\n",
       "| 5 |  5 | 102.5858 |        NA | South |\n",
       "| 7 |  7 |       NA |  6.874804 | West  |\n",
       "| 12 | 12 | 107.1963 |        NA | West  |\n",
       "| 15 | 15 |       NA | 14.475628 | South |\n",
       "\n"
      ],
      "text/plain": [
       "   ID Sales    Profit    Region\n",
       "3   3       NA  4.660881 South \n",
       "5   5 102.5858        NA South \n",
       "7   7       NA  6.874804 West  \n",
       "12 12 107.1963        NA West  \n",
       "15 15       NA 14.475628 South "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count NA values per column\n",
    "sapply(data_clean, function(x) sum(is.na(x))) # Apply sum(is.na()) to each column\n",
    "\n",
    "# Count total NA values in the data frame\n",
    "sum(is.na(data_clean)) # Total number of missing values across all columns\n",
    "\n",
    "# Identify rows with any NA values\n",
    "data_clean[!complete.cases(data_clean), ] # Show only rows that have at least one NA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bda3be",
   "metadata": {},
   "source": [
    "## Strategy 1: Removing Rows with Missing Values\n",
    "\n",
    "**Complete case analysis** is the simplest approach - just remove any row that has missing values.\n",
    "\n",
    "**Pros:**\n",
    "- Simple and straightforward\n",
    "- No need to make assumptions about missing data\n",
    "\n",
    "**Cons:**\n",
    "- Loses potentially valuable data\n",
    "- Can reduce sample size significantly\n",
    "- May introduce bias if missing data isn't random\n",
    "\n",
    "**When to use:** When you have plenty of data and missing values are random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eae4b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Data after removing NA rows:\"\n",
      "   ID     Sales     Profit Region\n",
      "1   1  88.79049  13.506780  North\n",
      "2   2  95.39645   7.636043   West\n",
      "4   4 101.41017   8.910125  North\n",
      "6   6 134.30130   6.355544  South\n",
      "8   8  74.69878   1.566533   West\n",
      "9   9  86.26294  14.188935  North\n",
      "10 10  91.08676  10.766866  South\n",
      "11 11 124.48164   4.309315   West\n",
      "13 13 108.01543  12.132321  North\n",
      "14 14 102.21365   8.524643  North\n",
      "16 16 135.73826  14.390667   East\n",
      "17 17 109.95701  14.107905   West\n",
      "18 18  60.66766  13.443201   West\n",
      "19 19 500.00000  12.769588   East\n",
      "20 20  10.00000 -30.000000   West\n"
     ]
    }
   ],
   "source": [
    "# 3. Strategies for Handling Missing Values\n",
    "\n",
    "# a) Removal of rows with NA values\n",
    "data_removed_na <- na.omit(data_clean) # Remove all rows containing any NA values\n",
    "print(\"Data after removing NA rows:\")\n",
    "print(data_removed_na) # Display the cleaned dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f294c7",
   "metadata": {},
   "source": [
    "## Strategy 2: Imputation - Mean Replacement\n",
    "\n",
    "**Mean imputation** replaces missing values with the average of the non-missing values.\n",
    "\n",
    "**How it works:**\n",
    "- Calculate the mean of all non-missing values in a column\n",
    "- Replace each NA with this mean value\n",
    "- Use `na.rm = TRUE` to exclude NAs from the mean calculation\n",
    "\n",
    "**When to use:**\n",
    "- For numeric data that's roughly normally distributed\n",
    "- When missing values are random\n",
    "- When you want to preserve the overall sample size\n",
    "\n",
    "**Note:** Mean imputation reduces variability in the data, so use it carefully!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e8cca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Data after mean imputation for Sales:\"\n",
      "   ID     Sales     Profit Region Sales_imputed_mean\n",
      "1   1  88.79049  13.506780  North           88.79049\n",
      "2   2  95.39645   7.636043   West           95.39645\n",
      "3   3        NA   4.660881  South          119.57662\n",
      "4   4 101.41017   8.910125  North          101.41017\n",
      "5   5 102.58575         NA  South          102.58575\n",
      "6   6 134.30130   6.355544  South          134.30130\n",
      "7   7        NA   6.874804   West          119.57662\n",
      "8   8  74.69878   1.566533   West           74.69878\n",
      "9   9  86.26294  14.188935  North           86.26294\n",
      "10 10  91.08676  10.766866  South           91.08676\n",
      "11 11 124.48164   4.309315   West          124.48164\n",
      "12 12 107.19628         NA   West          107.19628\n",
      "13 13 108.01543  12.132321  North          108.01543\n",
      "14 14 102.21365   8.524643  North          102.21365\n",
      "15 15        NA  14.475628  South          119.57662\n",
      "16 16 135.73826  14.390667   East          135.73826\n",
      "17 17 109.95701  14.107905   West          109.95701\n",
      "18 18  60.66766  13.443201   West           60.66766\n",
      "19 19 500.00000  12.769588   East          500.00000\n",
      "20 20  10.00000 -30.000000   West           10.00000\n"
     ]
    }
   ],
   "source": [
    "# b) Imputation: Replacing NA values\n",
    "\n",
    "# Mean imputation for 'Sales'\n",
    "data_imputed_mean <- data_clean %>%\n",
    "  mutate(Sales_imputed_mean = ifelse(is.na(Sales), # If Sales is NA...\n",
    "                                   mean(Sales, na.rm = TRUE), # Replace with mean (excluding NAs)\n",
    "                                   Sales)) # Otherwise keep original value\n",
    "print(\"Data after mean imputation for Sales:\")\n",
    "print(data_imputed_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1254373",
   "metadata": {},
   "source": [
    "## Strategy 3: Imputation - Median Replacement\n",
    "\n",
    "**Median imputation** replaces missing values with the median (middle value) of non-missing values.\n",
    "\n",
    "**Why use median instead of mean?**\n",
    "- **Robust to outliers**: Extreme values don't affect the median as much\n",
    "- **Better for skewed data**: When data isn't normally distributed\n",
    "- **More representative**: Often closer to \"typical\" values in the dataset\n",
    "\n",
    "**When to use:**\n",
    "- When your data has outliers\n",
    "- When data is skewed (not bell-shaped)\n",
    "- For ordinal data or continuous data with extreme values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc59ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median imputation for 'Profit'\n",
    "data_imputed_median <- data_clean %>%\n",
    "  mutate(Profit_imputed_median = ifelse(is.na(Profit), # If Profit is NA...\n",
    "                                      median(Profit, na.rm = TRUE), # Replace with median (excluding NAs)\n",
    "                                      Profit)) # Otherwise keep original value\n",
    "print(\"Data after median imputation for Profit:\")\n",
    "print(data_imputed_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ff755c",
   "metadata": {},
   "source": [
    "## Strategy 4: Mode Imputation for Categorical Data\n",
    "\n",
    "**Mode imputation** replaces missing values with the most frequently occurring value (the mode).\n",
    "\n",
    "**Perfect for categorical data:**\n",
    "- Text variables like Region, Product Type, etc.\n",
    "- Any data where average doesn't make sense\n",
    "- When you want to use the \"most common\" response\n",
    "\n",
    "**Creating a mode function:**\n",
    "Since R doesn't have a built-in mode function, we create our own. This function:\n",
    "1. Finds all unique values\n",
    "2. Counts how often each occurs\n",
    "3. Returns the most frequent one\n",
    "\n",
    "**Note:** Our Region column doesn't have NAs, but this shows how you'd handle them if they existed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29005bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mode imputation for 'Region' (if it had NAs, for demonstration)\n",
    "# Function to calculate mode (most frequent value)\n",
    "get_mode <- function(v) {\n",
    "  uniqv <- unique(v) # Get unique values\n",
    "  uniqv[which.max(tabulate(match(v, uniqv)))] # Return the most frequent one\n",
    "}\n",
    "\n",
    "# Example: if Region had NAs, impute with mode\n",
    "# data_imputed_mode <- data_clean %>%\n",
    "#   mutate(Region_imputed_mode = ifelse(is.na(Region), # If Region is NA...\n",
    "#                                     get_mode(Region[!is.na(Region)]), # Replace with mode\n",
    "#                                     Region)) # Otherwise keep original\n",
    "# print(\"Data after mode imputation for Region:\")\n",
    "# print(data_imputed_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c699a646",
   "metadata": {},
   "source": [
    "## Understanding Outliers\n",
    "\n",
    "**Outliers** are data points that are significantly different from other observations. They can be:\n",
    "- **Legitimate extreme values**: A luxury car sale in a dataset of regular cars\n",
    "- **Data entry errors**: Someone typed 5000 instead of 500\n",
    "- **Measurement errors**: Equipment malfunction\n",
    "\n",
    "**Why outliers matter:**\n",
    "- Can skew statistical analyses (mean, standard deviation)\n",
    "- May indicate important rare events\n",
    "- Can dominate visualizations and hide patterns\n",
    "- Need careful consideration - don't just delete them!\n",
    "\n",
    "Let's visualize our data to spot outliers using plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2e8adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Identifying and Visualizing Outliers\n",
    "\n",
    "# Boxplot for Sales\n",
    "ggplot(data_clean, aes(y = Sales)) + # Set Sales on y-axis\n",
    "  geom_boxplot() + # Create boxplot (shows median, quartiles, and outliers)\n",
    "  ggtitle(\"Boxplot of Sales\") # Add title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2204e7b",
   "metadata": {},
   "source": [
    "## Scatter Plot for Relationship Analysis\n",
    "\n",
    "**Scatter plots** help us see:\n",
    "- Relationships between two variables\n",
    "- Whether outliers affect both variables\n",
    "- Patterns in the data\n",
    "\n",
    "In our scatter plot, we're looking at the relationship between Profit and Sales. Outliers might appear as points far from the main cluster of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b6bfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot for Sales vs. Profit\n",
    "ggplot(data_clean, aes(x = Profit, y = Sales)) + # Set Profit on x-axis, Sales on y-axis\n",
    "  geom_point() + # Add points for each observation\n",
    "  ggtitle(\"Scatter Plot of Sales vs. Profit\") # Add title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93a17fa",
   "metadata": {},
   "source": [
    "## The IQR Method for Detecting Outliers\n",
    "\n",
    "**IQR (Interquartile Range)** is a statistical method to identify outliers:\n",
    "\n",
    "**How it works:**\n",
    "1. **Q1**: 25th percentile (first quartile)\n",
    "2. **Q3**: 75th percentile (third quartile)  \n",
    "3. **IQR**: Q3 - Q1 (the range containing middle 50% of data)\n",
    "4. **Outlier boundaries**: \n",
    "   - Lower: Q1 - 1.5 × IQR\n",
    "   - Upper: Q3 + 1.5 × IQR\n",
    "\n",
    "**Why 1.5 × IQR?** \n",
    "- Standard statistical convention\n",
    "- Captures about 99.3% of normal data\n",
    "- Points beyond these boundaries are considered outliers\n",
    "\n",
    "Let's apply this method to identify outliers in our Sales data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d62f438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using IQR method to identify outliers\n",
    "# For Sales\n",
    "Q1_sales <- quantile(data_clean$Sales, 0.25, na.rm = TRUE) # 25th percentile\n",
    "Q3_sales <- quantile(data_clean$Sales, 0.75, na.rm = TRUE) # 75th percentile\n",
    "IQR_sales <- Q3_sales - Q1_sales # Interquartile range\n",
    "\n",
    "# Calculate outlier boundaries using 1.5 * IQR rule\n",
    "outlier_threshold_upper_sales <- Q3_sales + 1.5 * IQR_sales # Upper boundary\n",
    "outlier_threshold_lower_sales <- Q1_sales - 1.5 * IQR_sales # Lower boundary\n",
    "\n",
    "# Find and display outliers\n",
    "data_clean %>%\n",
    "  filter(Sales > outlier_threshold_upper_sales | Sales < outlier_threshold_lower_sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93223e4",
   "metadata": {},
   "source": [
    "## Identifying Outliers in Profit Data\n",
    "\n",
    "Let's apply the same IQR method to our Profit variable. This will help us identify any extreme profit values that might be errors or unusual business events.\n",
    "\n",
    "**The process is identical:**\n",
    "1. Calculate Q1, Q3, and IQR for Profit\n",
    "2. Set outlier boundaries using 1.5 × IQR rule\n",
    "3. Filter data to show only outliers\n",
    "\n",
    "This systematic approach ensures we're consistent in how we identify outliers across different variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03b439d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Profit\n",
    "Q1_profit <- quantile(data_clean$Profit, 0.25, na.rm = TRUE) # 25th percentile\n",
    "Q3_profit <- quantile(data_clean$Profit, 0.75, na.rm = TRUE) # 75th percentile\n",
    "IQR_profit <- Q3_profit - Q1_profit # Interquartile range\n",
    "\n",
    "# Calculate outlier boundaries using 1.5 * IQR rule\n",
    "outlier_threshold_upper_profit <- Q3_profit + 1.5 * IQR_profit # Upper boundary\n",
    "outlier_threshold_lower_profit <- Q1_profit - 1.5 * IQR_profit # Lower boundary\n",
    "\n",
    "# Find and display outliers\n",
    "data_clean %>%\n",
    "  filter(Profit > outlier_threshold_upper_profit | Profit < outlier_threshold_lower_profit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed75bd9",
   "metadata": {},
   "source": [
    "## Outlier Treatment Method 1: Capping (Winsorization)\n",
    "\n",
    "**Capping** (also called Winsorization) replaces outliers with the boundary values rather than removing them entirely.\n",
    "\n",
    "**How it works:**\n",
    "- Values above the upper threshold → replaced with upper threshold\n",
    "- Values below the lower threshold → replaced with lower threshold  \n",
    "- All other values remain unchanged\n",
    "\n",
    "**Advantages:**\n",
    "- Keeps all data points (no sample size reduction)\n",
    "- Reduces impact of extreme values\n",
    "- Preserves the relative ranking of most data\n",
    "\n",
    "**When to use:**\n",
    "- When outliers are likely errors but you want to keep the observations\n",
    "- When sample size is important\n",
    "- When outliers are affecting statistical analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3102828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Basic Outlier Treatment\n",
    "\n",
    "# a) Capping (Winsorization) for Sales\n",
    "# Replace outliers with the upper/lower threshold\n",
    "data_capped <- data_clean %>%\n",
    "  mutate(Sales_capped = ifelse(Sales > outlier_threshold_upper_sales, # If above upper threshold...\n",
    "                              outlier_threshold_upper_sales, # Replace with upper threshold\n",
    "                              ifelse(Sales < outlier_threshold_lower_sales, # If below lower threshold...\n",
    "                                    outlier_threshold_lower_sales, # Replace with lower threshold\n",
    "                                    Sales))) # Otherwise keep original value\n",
    "print(\"Data after capping Sales outliers:\")\n",
    "print(data_capped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb10283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b) Removal of outliers\n",
    "data_outliers_removed <- data_clean %>%\n",
    "  # Keep only rows where Sales is within acceptable range\n",
    "  filter(Sales <= outlier_threshold_upper_sales & Sales >= outlier_threshold_lower_sales) %>%\n",
    "  # Keep only rows where Profit is within acceptable range\n",
    "  filter(Profit <= outlier_threshold_upper_profit & Profit >= outlier_threshold_lower_profit)\n",
    "print(\"Data after removing outliers:\")\n",
    "print(data_outliers_removed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b54eb3",
   "metadata": {},
   "source": [
    "## Outlier Treatment Method 2: Removal\n",
    "\n",
    "**Outlier removal** completely eliminates rows containing outlier values from the dataset.\n",
    "\n",
    "**How it works:**\n",
    "- Apply filters to keep only data within the acceptable range\n",
    "- Remove entire rows if they contain outliers in any specified column\n",
    "- Results in a \"cleaner\" but smaller dataset\n",
    "\n",
    "**Advantages:**\n",
    "- Eliminates problematic extreme values\n",
    "- Simpler statistical analyses\n",
    "- Clear, unambiguous approach\n",
    "\n",
    "**Disadvantages:**\n",
    "- Permanent loss of data\n",
    "- Reduces sample size\n",
    "- May remove legitimate but rare observations\n",
    "\n",
    "**Important decision:** Always document why you're removing outliers and consider domain expertise!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad0eb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Key Decisions in Data Cleaning\n",
    "\n",
    "**Important principle:** The choice of how to handle missing values and outliers depends on:\n",
    "\n",
    "### 📊 **Context and Domain Knowledge**\n",
    "- **Business understanding**: Is a $500 sale realistic or an error?\n",
    "- **Data collection process**: How were these values recorded?\n",
    "- **Impact on analysis**: Will outliers skew our results?\n",
    "\n",
    "### 📝 **Documentation is Critical**\n",
    "- **Record your decisions**: What did you change and why?\n",
    "- **Be transparent**: Others need to understand your methodology\n",
    "- **Consider alternatives**: What would happen with different approaches?\n",
    "\n",
    "### ⚖️ **Trade-offs to Consider**\n",
    "- **Sample size vs. data quality**: Remove vs. impute?\n",
    "- **Bias vs. completeness**: Are missing values random?\n",
    "- **Accuracy vs. precision**: Better to be approximately right than precisely wrong\n",
    "\n",
    "**Remember:** There's rarely one \"correct\" way to clean data - it's about making informed, defensible decisions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05b1334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: The choice of handling missing values and outliers depends on the context and domain knowledge.\n",
    "# Always document your decisions and reasoning for future reference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1187bf3",
   "metadata": {},
   "source": [
    "## Lesson 2 Summary: Data Cleaning Mastery\n",
    "\n",
    "Congratulations! You've learned essential data cleaning techniques. Here's what you can now do:\n",
    "\n",
    "### 🔍 **Missing Value Detection**\n",
    "- Use `is.na()` to identify missing values\n",
    "- Count NAs with `sum(is.na())` and `sapply()`\n",
    "- Find incomplete rows with `complete.cases()`\n",
    "\n",
    "### 🛠️ **Missing Value Treatment Strategies**\n",
    "- **Removal**: `na.omit()` for complete case analysis\n",
    "- **Mean imputation**: Replace NAs with average values\n",
    "- **Median imputation**: Better for skewed data and outliers\n",
    "- **Mode imputation**: For categorical variables\n",
    "\n",
    "### 📊 **Outlier Detection Methods**\n",
    "- **Visual inspection**: Boxplots and scatter plots\n",
    "- **IQR method**: Statistical approach using quartiles\n",
    "- **Threshold calculation**: Q1/Q3 ± 1.5 × IQR\n",
    "\n",
    "### ⚒️ **Outlier Treatment Techniques**\n",
    "- **Capping (Winsorization)**: Replace with boundary values\n",
    "- **Removal**: Filter out extreme values\n",
    "- **Documentation**: Always record your decisions and reasoning\n",
    "\n",
    "### 🎯 **Key Takeaways**\n",
    "- **No single correct approach**: Context and domain knowledge matter\n",
    "- **Document everything**: Your future self will thank you\n",
    "- **Consider trade-offs**: Sample size vs. data quality\n",
    "- **Visualize first**: Always look at your data before cleaning\n",
    "\n",
    "### 📈 **Next Steps**\n",
    "You're now ready for:\n",
    "- Advanced data manipulation with dplyr\n",
    "- Data transformation and feature engineering\n",
    "- Statistical analysis with clean, reliable data\n",
    "- Creating meaningful visualizations\n",
    "\n",
    "**Practice tip:** Try these techniques on real datasets to build your data cleaning intuition!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "python",
   "pygments_lexer": "r",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
