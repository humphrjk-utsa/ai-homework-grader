{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Homework Assignment - Lesson 7: String Manipulation and Date/Time Data\n",
    "\n",
    "**Student Name:** [Enter Your Full Name Here]\n",
    "\n",
    "**Student ID:** [Enter Your Student ID]\n",
    "\n",
    "**Date Submitted:** [Enter Today's Date]\n",
    "\n",
    "**Due Date:** [Insert Due Date Here]\n",
    "\n",
    "---\n",
    "\n",
    "## Objective\n",
    "\n",
    "Master string manipulation with `stringr` and date/time operations with `lubridate` for real-world business data cleaning and analysis.\n",
    "\n",
    "## Learning Goals\n",
    "\n",
    "By completing this assignment, you will:\n",
    "- Clean and standardize messy text data using `stringr` functions\n",
    "- Parse and manipulate dates using `lubridate` functions\n",
    "- Extract information from text and dates for business insights\n",
    "- Combine string and date operations for customer segmentation\n",
    "- Create business-ready reports from raw data\n",
    "\n",
    "## Instructions\n",
    "\n",
    "- Complete all tasks in this notebook\n",
    "- Write your code in the designated TODO sections\n",
    "- Use the pipe operator (`%>%`) wherever possible\n",
    "- Add comments explaining your logic\n",
    "- Run all cells to verify your code works\n",
    "- Answer all reflection questions\n",
    "\n",
    "## Datasets\n",
    "\n",
    "You will work with three CSV files:\n",
    "- `customer_feedback.csv` - Customer reviews with messy text\n",
    "- `transaction_log.csv` - Transaction records with dates\n",
    "- `product_catalog.csv` - Product descriptions needing standardization\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part1_intro",
   "metadata": {},
   "source": [
    "## Part 1: Data Import and Initial Exploration\n",
    "\n",
    "**Business Context:** Before cleaning data, you must understand its structure and quality issues.\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Load required packages (`tidyverse` and `lubridate`)\n",
    "2. Import all three CSV files from the `data/` directory\n",
    "3. Examine the structure and identify data quality issues\n",
    "4. Display sample rows to understand the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "setup",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2705 Packages loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Task 1.1: Load Required Packages\n",
    "library(tidyverse)  # includes stringr\n",
    "\n",
    "library(lubridate)\n",
    "\n",
    "cat(\"\u2705 Packages loaded successfully!\\n\")\n",
    "setwd('/Users/humphrjk/GitHub/ai-homework-grader-clean/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "import_data",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mRows: \u001b[22m\u001b[34m20\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m4\u001b[39m\n",
      "\u001b[36m\u2500\u2500\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m (2): customer_name, feedback_text\n",
      "\u001b[32mdbl\u001b[39m (2): feedback_id, rating\n",
      "\n",
      "\u001b[36m\u2139\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36m\u2139\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
      "\u001b[1mRows: \u001b[22m\u001b[34m30\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m4\u001b[39m\n",
      "\u001b[36m\u2500\u2500\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m  (1): customer_name\n",
      "\u001b[32mdbl\u001b[39m  (2): transaction_id, amount\n",
      "\u001b[34mdate\u001b[39m (1): transaction_date\n",
      "\n",
      "\u001b[36m\u2139\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36m\u2139\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
      "\u001b[1mRows: \u001b[22m\u001b[34m30\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m4\u001b[39m\n",
      "\u001b[36m\u2500\u2500\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m (2): product_name, category\n",
      "\u001b[32mdbl\u001b[39m (2): product_id, price\n",
      "\n",
      "\u001b[36m\u2139\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36m\u2139\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2705 Data imported successfully!\n",
      "Feedback rows: 20 \n",
      "Transaction rows: 30 \n",
      "Product rows: 30 \n"
     ]
    }
   ],
   "source": [
    "# Task 1.2: Import Datasets\n",
    "feedback <- read_csv(\"customer_feedback.csv\")\n",
    "\n",
    "transactions <- read_csv(\"transaction_log.csv\")\n",
    "\n",
    "products <- read_csv(\"product_catalog.csv\")\n",
    "\n",
    "cat(\"\u2705 Data imported successfully!\\n\")\n",
    "cat(\"Feedback rows:\", nrow(feedback), \"\\n\")\n",
    "cat(\"Transaction rows:\", nrow(transactions), \"\\n\")\n",
    "cat(\"Product rows:\", nrow(products), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "explore_data",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CUSTOMER FEEDBACK DATA ===\n",
      "spc_tbl_ [20 \u00d7 4] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n",
      " $ feedback_id  : num [1:20] 1 2 3 4 5 6 7 8 9 10 ...\n",
      " $ customer_name: chr [1:20] \"John Smith\" \"Jane Doe\" \"Bob Johnson\" \"Alice Williams\" ...\n",
      " $ feedback_text: chr [1:20] \"GREAT product! I LOVE it. Excellent quality.\" \"terrible experience. bad customer service. hate it.\" \"Amazing product!  Great value for money. Love it!\" \"awful quality. broke after one day. terrible.\" ...\n",
      " $ rating       : num [1:20] 5 1 5 1 5 2 5 1 5 2 ...\n",
      " - attr(*, \"spec\")=\n",
      "  .. cols(\n",
      "  ..   feedback_id = \u001b[32mcol_double()\u001b[39m,\n",
      "  ..   customer_name = \u001b[31mcol_character()\u001b[39m,\n",
      "  ..   feedback_text = \u001b[31mcol_character()\u001b[39m,\n",
      "  ..   rating = \u001b[32mcol_double()\u001b[39m\n",
      "  .. )\n",
      " - attr(*, \"problems\")=<externalptr> \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 5 \u00d7 4</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>feedback_id</th><th scope=col>customer_name</th><th scope=col>feedback_text</th><th scope=col>rating</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>1</td><td>John Smith    </td><td>GREAT product! I LOVE it. Excellent quality.       </td><td>5</td></tr>\n",
       "\t<tr><td>2</td><td>Jane Doe      </td><td>terrible experience. bad customer service. hate it.</td><td>1</td></tr>\n",
       "\t<tr><td>3</td><td>Bob Johnson   </td><td>Amazing product!  Great value for money. Love it!  </td><td>5</td></tr>\n",
       "\t<tr><td>4</td><td>Alice Williams</td><td>awful quality. broke after one day. terrible.      </td><td>1</td></tr>\n",
       "\t<tr><td>5</td><td>Charlie Brown </td><td>excellent purchase. works great. highly recommend! </td><td>5</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 5 \u00d7 4\n",
       "\\begin{tabular}{llll}\n",
       " feedback\\_id & customer\\_name & feedback\\_text & rating\\\\\n",
       " <dbl> & <chr> & <chr> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 1 & John Smith     & GREAT product! I LOVE it. Excellent quality.        & 5\\\\\n",
       "\t 2 & Jane Doe       & terrible experience. bad customer service. hate it. & 1\\\\\n",
       "\t 3 & Bob Johnson    & Amazing product!  Great value for money. Love it!   & 5\\\\\n",
       "\t 4 & Alice Williams & awful quality. broke after one day. terrible.       & 1\\\\\n",
       "\t 5 & Charlie Brown  & excellent purchase. works great. highly recommend!  & 5\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 5 \u00d7 4\n",
       "\n",
       "| feedback_id &lt;dbl&gt; | customer_name &lt;chr&gt; | feedback_text &lt;chr&gt; | rating &lt;dbl&gt; |\n",
       "|---|---|---|---|\n",
       "| 1 | John Smith     | GREAT product! I LOVE it. Excellent quality.        | 5 |\n",
       "| 2 | Jane Doe       | terrible experience. bad customer service. hate it. | 1 |\n",
       "| 3 | Bob Johnson    | Amazing product!  Great value for money. Love it!   | 5 |\n",
       "| 4 | Alice Williams | awful quality. broke after one day. terrible.       | 1 |\n",
       "| 5 | Charlie Brown  | excellent purchase. works great. highly recommend!  | 5 |\n",
       "\n"
      ],
      "text/plain": [
       "  feedback_id customer_name \n",
       "1 1           John Smith    \n",
       "2 2           Jane Doe      \n",
       "3 3           Bob Johnson   \n",
       "4 4           Alice Williams\n",
       "5 5           Charlie Brown \n",
       "  feedback_text                                       rating\n",
       "1 GREAT product! I LOVE it. Excellent quality.        5     \n",
       "2 terrible experience. bad customer service. hate it. 1     \n",
       "3 Amazing product!  Great value for money. Love it!   5     \n",
       "4 awful quality. broke after one day. terrible.       1     \n",
       "5 excellent purchase. works great. highly recommend!  5     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TRANSACTION DATA ===\n",
      "spc_tbl_ [30 \u00d7 4] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n",
      " $ transaction_id  : num [1:30] 1 2 3 4 5 6 7 8 9 10 ...\n",
      " $ customer_name   : chr [1:30] \"John Smith\" \"Jane Doe\" \"Bob Johnson\" \"Alice Williams\" ...\n",
      " $ transaction_date: Date[1:30], format: \"2024-01-15\" \"2024-02-20\" ...\n",
      " $ amount          : num [1:30] 300 50 600 150 90 ...\n",
      " - attr(*, \"spec\")=\n",
      "  .. cols(\n",
      "  ..   transaction_id = \u001b[32mcol_double()\u001b[39m,\n",
      "  ..   customer_name = \u001b[31mcol_character()\u001b[39m,\n",
      "  ..   transaction_date = \u001b[34mcol_date(format = \"\")\u001b[39m,\n",
      "  ..   amount = \u001b[32mcol_double()\u001b[39m\n",
      "  .. )\n",
      " - attr(*, \"problems\")=<externalptr> \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 5 \u00d7 4</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>transaction_id</th><th scope=col>customer_name</th><th scope=col>transaction_date</th><th scope=col>amount</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;date&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>1</td><td>John Smith    </td><td>2024-01-15</td><td>299.99</td></tr>\n",
       "\t<tr><td>2</td><td>Jane Doe      </td><td>2024-02-20</td><td> 49.99</td></tr>\n",
       "\t<tr><td>3</td><td>Bob Johnson   </td><td>2024-01-10</td><td>599.99</td></tr>\n",
       "\t<tr><td>4</td><td>Alice Williams</td><td>2024-03-05</td><td>149.99</td></tr>\n",
       "\t<tr><td>5</td><td>Charlie Brown </td><td>2024-02-14</td><td> 89.99</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 5 \u00d7 4\n",
       "\\begin{tabular}{llll}\n",
       " transaction\\_id & customer\\_name & transaction\\_date & amount\\\\\n",
       " <dbl> & <chr> & <date> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 1 & John Smith     & 2024-01-15 & 299.99\\\\\n",
       "\t 2 & Jane Doe       & 2024-02-20 &  49.99\\\\\n",
       "\t 3 & Bob Johnson    & 2024-01-10 & 599.99\\\\\n",
       "\t 4 & Alice Williams & 2024-03-05 & 149.99\\\\\n",
       "\t 5 & Charlie Brown  & 2024-02-14 &  89.99\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 5 \u00d7 4\n",
       "\n",
       "| transaction_id &lt;dbl&gt; | customer_name &lt;chr&gt; | transaction_date &lt;date&gt; | amount &lt;dbl&gt; |\n",
       "|---|---|---|---|\n",
       "| 1 | John Smith     | 2024-01-15 | 299.99 |\n",
       "| 2 | Jane Doe       | 2024-02-20 |  49.99 |\n",
       "| 3 | Bob Johnson    | 2024-01-10 | 599.99 |\n",
       "| 4 | Alice Williams | 2024-03-05 | 149.99 |\n",
       "| 5 | Charlie Brown  | 2024-02-14 |  89.99 |\n",
       "\n"
      ],
      "text/plain": [
       "  transaction_id customer_name  transaction_date amount\n",
       "1 1              John Smith     2024-01-15       299.99\n",
       "2 2              Jane Doe       2024-02-20        49.99\n",
       "3 3              Bob Johnson    2024-01-10       599.99\n",
       "4 4              Alice Williams 2024-03-05       149.99\n",
       "5 5              Charlie Brown  2024-02-14        89.99"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PRODUCT CATALOG DATA ===\n",
      "spc_tbl_ [30 \u00d7 4] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n",
      " $ product_id  : num [1:30] 1 2 3 4 5 6 7 8 9 10 ...\n",
      " $ product_name: chr [1:30] \"wireless MOUSE\" \"laptop PRO 15-inch\" \"USB-C Hub with HDMI\" \"27-inch Monitor 4K\" ...\n",
      " $ category    : chr [1:30] \"peripherals\" \"COMPUTERS\" \"accessories\" \"MONITORS\" ...\n",
      " $ price       : num [1:30] 30 1300 50 600 150 ...\n",
      " - attr(*, \"spec\")=\n",
      "  .. cols(\n",
      "  ..   product_id = \u001b[32mcol_double()\u001b[39m,\n",
      "  ..   product_name = \u001b[31mcol_character()\u001b[39m,\n",
      "  ..   category = \u001b[31mcol_character()\u001b[39m,\n",
      "  ..   price = \u001b[32mcol_double()\u001b[39m\n",
      "  .. )\n",
      " - attr(*, \"problems\")=<externalptr> \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 5 \u00d7 4</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>product_id</th><th scope=col>product_name</th><th scope=col>category</th><th scope=col>price</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>1</td><td>wireless MOUSE         </td><td>peripherals</td><td>  29.99</td></tr>\n",
       "\t<tr><td>2</td><td>laptop PRO 15-inch     </td><td>COMPUTERS  </td><td>1299.99</td></tr>\n",
       "\t<tr><td>3</td><td>USB-C Hub with HDMI    </td><td>accessories</td><td>  49.99</td></tr>\n",
       "\t<tr><td>4</td><td>27-inch Monitor 4K     </td><td>MONITORS   </td><td> 599.99</td></tr>\n",
       "\t<tr><td>5</td><td>mechanical keyboard RGB</td><td>Peripherals</td><td> 149.99</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 5 \u00d7 4\n",
       "\\begin{tabular}{llll}\n",
       " product\\_id & product\\_name & category & price\\\\\n",
       " <dbl> & <chr> & <chr> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 1 & wireless MOUSE          & peripherals &   29.99\\\\\n",
       "\t 2 & laptop PRO 15-inch      & COMPUTERS   & 1299.99\\\\\n",
       "\t 3 & USB-C Hub with HDMI     & accessories &   49.99\\\\\n",
       "\t 4 & 27-inch Monitor 4K      & MONITORS    &  599.99\\\\\n",
       "\t 5 & mechanical keyboard RGB & Peripherals &  149.99\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 5 \u00d7 4\n",
       "\n",
       "| product_id &lt;dbl&gt; | product_name &lt;chr&gt; | category &lt;chr&gt; | price &lt;dbl&gt; |\n",
       "|---|---|---|---|\n",
       "| 1 | wireless MOUSE          | peripherals |   29.99 |\n",
       "| 2 | laptop PRO 15-inch      | COMPUTERS   | 1299.99 |\n",
       "| 3 | USB-C Hub with HDMI     | accessories |   49.99 |\n",
       "| 4 | 27-inch Monitor 4K      | MONITORS    |  599.99 |\n",
       "| 5 | mechanical keyboard RGB | Peripherals |  149.99 |\n",
       "\n"
      ],
      "text/plain": [
       "  product_id product_name            category    price  \n",
       "1 1          wireless MOUSE          peripherals   29.99\n",
       "2 2          laptop PRO 15-inch      COMPUTERS   1299.99\n",
       "3 3          USB-C Hub with HDMI     accessories   49.99\n",
       "4 4          27-inch Monitor 4K      MONITORS     599.99\n",
       "5 5          mechanical keyboard RGB Peripherals  149.99"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Task 1.3: Initial Data Exploration\n",
    "\n",
    "cat(\"=== CUSTOMER FEEDBACK DATA ===\\n\")\n",
    "str(feedback)\n",
    "\n",
    "head(feedback, 5)\n",
    "\n",
    "cat(\"\\n=== TRANSACTION DATA ===\\n\")\n",
    "str(transactions)\n",
    "\n",
    "head(transactions, 5)\n",
    "\n",
    "cat(\"\\n=== PRODUCT CATALOG DATA ===\\n\")\n",
    "str(products)\n",
    "\n",
    "head(products, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part2_intro",
   "metadata": {},
   "source": [
    "## Part 2: String Cleaning and Standardization\n",
    "\n",
    "**Business Context:** Product names and feedback text often have inconsistent formatting that prevents accurate analysis.\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Clean product names (remove extra spaces, standardize case)\n",
    "2. Standardize product categories\n",
    "3. Clean customer feedback text\n",
    "4. Extract customer names from feedback\n",
    "\n",
    "**Key Functions:** `str_trim()`, `str_squish()`, `str_to_lower()`, `str_to_upper()`, `str_to_title()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "clean_products",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product Name Cleaning Results:\n",
      "\u001b[90m# A tibble: 10 \u00d7 2\u001b[39m\n",
      "   product_name            product_name_clean     \n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                  \n",
      "\u001b[90m 1\u001b[39m wireless MOUSE          Wireless Mouse         \n",
      "\u001b[90m 2\u001b[39m laptop PRO 15-inch      Laptop Pro 15-Inch     \n",
      "\u001b[90m 3\u001b[39m USB-C Hub with HDMI     Usb-C Hub With Hdmi    \n",
      "\u001b[90m 4\u001b[39m 27-inch Monitor 4K      27-Inch Monitor 4k     \n",
      "\u001b[90m 5\u001b[39m mechanical keyboard RGB Mechanical Keyboard Rgb\n",
      "\u001b[90m 6\u001b[39m Webcam HD 1080p         Webcam Hd 1080p        \n",
      "\u001b[90m 7\u001b[39m Gaming Headset Pro      Gaming Headset Pro     \n",
      "\u001b[90m 8\u001b[39m portable SSD 1TB        Portable Ssd 1tb       \n",
      "\u001b[90m 9\u001b[39m wireless Keyboard       Wireless Keyboard      \n",
      "\u001b[90m10\u001b[39m Gaming Mouse RGB        Gaming Mouse Rgb       \n"
     ]
    }
   ],
   "source": [
    "# Task 2.1: Clean Product Names\n",
    "products_clean <- products %>%\n",
    "  mutate(\n",
    "    product_name_clean = str_trim(product_name),\n",
    "    product_name_clean = str_to_title(product_name_clean)\n",
    "  )\n",
    "\n",
    "# Display before and after\n",
    "cat(\"Product Name Cleaning Results:\\n\")\n",
    "products_clean %>%\n",
    "  select(product_name, product_name_clean) %>%\n",
    "  head(10) %>%\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "clean_categories",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original categories:\n",
      " [1] \"peripherals\" \"COMPUTERS\"   \"accessories\" \"MONITORS\"    \"Peripherals\"\n",
      " [6] \"ACCESSORIES\" \"storage\"     \"PERIPHERALS\" \"monitors\"    \"STORAGE\"    \n",
      "[11] \"Accessories\" \"furniture\"   \"FURNITURE\"  \n",
      "\n",
      "Cleaned categories:\n",
      "[1] \"Peripherals\" \"Computers\"   \"Accessories\" \"Monitors\"    \"Storage\"    \n",
      "[6] \"Furniture\"  \n"
     ]
    }
   ],
   "source": [
    "# Task 2.2: Standardize Product Categories\n",
    "products_clean <- products_clean %>%\n",
    "  mutate(\n",
    "    category_clean = str_to_title(str_trim(category))\n",
    "  )\n",
    "\n",
    "# Show unique categories before and after\n",
    "cat(\"Original categories:\\n\")\n",
    "print(unique(products$category))\n",
    "\n",
    "cat(\"\\nCleaned categories:\\n\")\n",
    "print(unique(products_clean$category_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "clean_feedback",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feedback Cleaning Sample:\n",
      "\u001b[90m# A tibble: 5 \u00d7 2\u001b[39m\n",
      "  feedback_text                                       feedback_clean            \n",
      "  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                                               \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                     \n",
      "\u001b[90m1\u001b[39m GREAT product! I LOVE it. Excellent quality.        great product! i love it.\u2026\n",
      "\u001b[90m2\u001b[39m terrible experience. bad customer service. hate it. terrible experience. bad \u2026\n",
      "\u001b[90m3\u001b[39m Amazing product!  Great value for money. Love it!   amazing product! great va\u2026\n",
      "\u001b[90m4\u001b[39m awful quality. broke after one day. terrible.       awful quality. broke afte\u2026\n",
      "\u001b[90m5\u001b[39m excellent purchase. works great. highly recommend!  excellent purchase. works\u2026\n"
     ]
    }
   ],
   "source": [
    "# Task 2.3: Clean Customer Feedback Text\n",
    "feedback_clean <- feedback %>%\n",
    "  mutate(\n",
    "    feedback_clean = str_to_lower(feedback_text),\n",
    "    feedback_clean = str_squish(feedback_clean)\n",
    "  )\n",
    "\n",
    "# Display sample\n",
    "cat(\"Feedback Cleaning Sample:\\n\")\n",
    "feedback_clean %>%\n",
    "  select(feedback_text, feedback_clean) %>%\n",
    "  head(5) %>%\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part3_intro",
   "metadata": {},
   "source": [
    "## Part 3: Pattern Detection and Extraction\n",
    "\n",
    "**Business Context:** Identifying products with specific features and extracting specifications helps with inventory management and marketing.\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Identify products with specific keywords (wireless, premium, gaming)\n",
    "2. Extract numerical specifications from product names\n",
    "3. Detect sentiment words in customer feedback\n",
    "4. Extract email addresses from feedback\n",
    "\n",
    "**Key Functions:** `str_detect()`, `str_extract()`, `str_count()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "detect_features",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product Feature Detection:\n",
      "\u001b[90m# A tibble: 10 \u00d7 4\u001b[39m\n",
      "   product_name_clean      is_wireless is_premium is_gaming\n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                   \u001b[3m\u001b[90m<lgl>\u001b[39m\u001b[23m       \u001b[3m\u001b[90m<lgl>\u001b[39m\u001b[23m      \u001b[3m\u001b[90m<lgl>\u001b[39m\u001b[23m    \n",
      "\u001b[90m 1\u001b[39m Wireless Mouse          TRUE        FALSE      FALSE    \n",
      "\u001b[90m 2\u001b[39m Laptop Pro 15-Inch      FALSE       TRUE       FALSE    \n",
      "\u001b[90m 3\u001b[39m Usb-C Hub With Hdmi     FALSE       FALSE      FALSE    \n",
      "\u001b[90m 4\u001b[39m 27-Inch Monitor 4k      FALSE       FALSE      FALSE    \n",
      "\u001b[90m 5\u001b[39m Mechanical Keyboard Rgb FALSE       FALSE      FALSE    \n",
      "\u001b[90m 6\u001b[39m Webcam Hd 1080p         FALSE       FALSE      FALSE    \n",
      "\u001b[90m 7\u001b[39m Gaming Headset Pro      FALSE       TRUE       TRUE     \n",
      "\u001b[90m 8\u001b[39m Portable Ssd 1tb        FALSE       FALSE      FALSE    \n",
      "\u001b[90m 9\u001b[39m Wireless Keyboard       TRUE        FALSE      FALSE    \n",
      "\u001b[90m10\u001b[39m Gaming Mouse Rgb        FALSE       FALSE      TRUE     \n",
      "\n",
      "Feature Summary:\n",
      "Wireless products: 5 \n",
      "Premium products: 5 \n",
      "Gaming products: 5 \n"
     ]
    }
   ],
   "source": [
    "# Task 3.1: Detect Product Features\n",
    "products_clean <- products_clean %>%\n",
    "  mutate(\n",
    "    is_wireless = str_detect(str_to_lower(product_name), \"wireless\"),\n",
    "    is_premium = str_detect(str_to_lower(product_name), \"pro|premium|deluxe\"),\n",
    "    is_gaming = str_detect(str_to_lower(product_name), \"gaming|gamer\")\n",
    "  )\n",
    "\n",
    "# Display results\n",
    "cat(\"Product Feature Detection:\\n\")\n",
    "products_clean %>%\n",
    "  select(product_name_clean, is_wireless, is_premium, is_gaming) %>%\n",
    "  head(10) %>%\n",
    "  print()\n",
    "\n",
    "# Summary statistics\n",
    "cat(\"\\nFeature Summary:\\n\")\n",
    "cat(\"Wireless products:\", sum(products_clean$is_wireless), \"\\n\")\n",
    "cat(\"Premium products:\", sum(products_clean$is_premium), \"\\n\")\n",
    "cat(\"Gaming products:\", sum(products_clean$is_gaming), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "extract_specs",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Product Specifications:\n",
      "\u001b[90m# A tibble: 10 \u00d7 2\u001b[39m\n",
      "   product_name_clean      size_number\n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m      \n",
      "\u001b[90m 1\u001b[39m Laptop Pro 15-Inch      15         \n",
      "\u001b[90m 2\u001b[39m 27-Inch Monitor 4k      27         \n",
      "\u001b[90m 3\u001b[39m Webcam Hd 1080p         1080       \n",
      "\u001b[90m 4\u001b[39m Portable Ssd 1tb        1          \n",
      "\u001b[90m 5\u001b[39m Usb-C Cable 6ft         6          \n",
      "\u001b[90m 6\u001b[39m 24-Inch Monitor         24         \n",
      "\u001b[90m 7\u001b[39m External Hard Drive 2tb 2          \n",
      "\u001b[90m 8\u001b[39m Webcam 4k               4          \n",
      "\u001b[90m 9\u001b[39m Usb Hub 7-Port          7          \n",
      "\u001b[90m10\u001b[39m Hdmi Cable 10ft         10         \n"
     ]
    }
   ],
   "source": [
    "# Task 3.2: Extract Product Specifications\n",
    "products_clean <- products_clean %>%\n",
    "  mutate(\n",
    "    size_number = str_extract(product_name, \"\\\\d+\")\n",
    "  )\n",
    "\n",
    "# Display products with extracted sizes\n",
    "cat(\"Extracted Product Specifications:\\n\")\n",
    "products_clean %>%\n",
    "  filter(!is.na(size_number)) %>%\n",
    "  select(product_name_clean, size_number) %>%\n",
    "  head(10) %>%\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "sentiment_analysis",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Analysis Results:\n",
      "\u001b[90m# A tibble: 10 \u00d7 4\u001b[39m\n",
      "   feedback_clean                  positive_words negative_words sentiment_score\n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                                    \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m          \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m           \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m great product! i love it. exce\u2026              3              0               3\n",
      "\u001b[90m 2\u001b[39m terrible experience. bad custo\u2026              0              3              -\u001b[31m3\u001b[39m\n",
      "\u001b[90m 3\u001b[39m amazing product! great value f\u2026              3              0               3\n",
      "\u001b[90m 4\u001b[39m awful quality. broke after one\u2026              0              2              -\u001b[31m2\u001b[39m\n",
      "\u001b[90m 5\u001b[39m excellent purchase. works grea\u2026              2              0               2\n",
      "\u001b[90m 6\u001b[39m bad packaging. product arrived\u2026              0              1              -\u001b[31m1\u001b[39m\n",
      "\u001b[90m 7\u001b[39m love this product! amazing qua\u2026              3              0               3\n",
      "\u001b[90m 8\u001b[39m terrible design. doesn't work \u2026              0              2              -\u001b[31m2\u001b[39m\n",
      "\u001b[90m 9\u001b[39m great product. excellent custo\u2026              3              0               3\n",
      "\u001b[90m10\u001b[39m bad quality. not worth the mon\u2026              0              2              -\u001b[31m2\u001b[39m\n",
      "\n",
      "Overall Sentiment Summary:\n",
      "Average sentiment score: 0.4 \n",
      "Positive reviews: 10 \n",
      "Negative reviews: 10 \n"
     ]
    }
   ],
   "source": [
    "# Task 3.3: Simple Sentiment Analysis\n",
    "feedback_clean <- feedback_clean %>%\n",
    "  mutate(\n",
    "    positive_words = str_count(feedback_clean, \"great|excellent|love|amazing\"),\n",
    "    negative_words = str_count(feedback_clean, \"bad|terrible|hate|awful\"),\n",
    "    sentiment_score = positive_words - negative_words\n",
    "  )\n",
    "\n",
    "# Display sentiment analysis results\n",
    "cat(\"Sentiment Analysis Results:\\n\")\n",
    "feedback_clean %>%\n",
    "  select(feedback_clean, positive_words, negative_words, sentiment_score) %>%\n",
    "  head(10) %>%\n",
    "  print()\n",
    "\n",
    "# Summary\n",
    "cat(\"\\nOverall Sentiment Summary:\\n\")\n",
    "cat(\"Average sentiment score:\", mean(feedback_clean$sentiment_score), \"\\n\")\n",
    "cat(\"Positive reviews:\", sum(feedback_clean$sentiment_score > 0), \"\\n\")\n",
    "cat(\"Negative reviews:\", sum(feedback_clean$sentiment_score < 0), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part4_intro",
   "metadata": {},
   "source": [
    "## Part 4: Date Parsing and Component Extraction\n",
    "\n",
    "**Business Context:** Transaction dates need to be parsed and analyzed to understand customer behavior patterns.\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Parse transaction dates from text to Date objects\n",
    "2. Extract date components (year, month, day, weekday)\n",
    "3. Identify weekend vs weekday transactions\n",
    "4. Extract quarter and month names\n",
    "\n",
    "**Key Functions:** `ymd()`, `mdy()`, `dmy()`, `year()`, `month()`, `day()`, `wday()`, `quarter()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "parse_dates",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date Parsing Results:\n",
      "\u001b[90m# A tibble: 10 \u00d7 2\u001b[39m\n",
      "   transaction_date date_parsed\n",
      "   \u001b[3m\u001b[90m<date>\u001b[39m\u001b[23m           \u001b[3m\u001b[90m<date>\u001b[39m\u001b[23m     \n",
      "\u001b[90m 1\u001b[39m 2024-01-15       2024-01-15 \n",
      "\u001b[90m 2\u001b[39m 2024-02-20       2024-02-20 \n",
      "\u001b[90m 3\u001b[39m 2024-01-10       2024-01-10 \n",
      "\u001b[90m 4\u001b[39m 2024-03-05       2024-03-05 \n",
      "\u001b[90m 5\u001b[39m 2024-02-14       2024-02-14 \n",
      "\u001b[90m 6\u001b[39m 2024-03-20       2024-03-20 \n",
      "\u001b[90m 7\u001b[39m 2024-01-25       2024-01-25 \n",
      "\u001b[90m 8\u001b[39m 2024-02-28       2024-02-28 \n",
      "\u001b[90m 9\u001b[39m 2024-03-10       2024-03-10 \n",
      "\u001b[90m10\u001b[39m 2024-01-30       2024-01-30 \n"
     ]
    }
   ],
   "source": [
    "# Task 4.1: Parse Transaction Dates\n",
    "transactions_clean <- transactions %>%\n",
    "  mutate(\n",
    "    date_parsed = ymd(transaction_date)\n",
    "  )\n",
    "\n",
    "# Verify parsing worked\n",
    "cat(\"Date Parsing Results:\\n\")\n",
    "transactions_clean %>%\n",
    "  select(transaction_date, date_parsed) %>%\n",
    "  head(10) %>%\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "extract_components",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date Component Extraction:\n",
      "\u001b[90m# A tibble: 10 \u00d7 4\u001b[39m\n",
      "   date_parsed trans_month_name trans_weekday trans_quarter\n",
      "   \u001b[3m\u001b[90m<date>\u001b[39m\u001b[23m      \u001b[3m\u001b[90m<ord>\u001b[39m\u001b[23m            \u001b[3m\u001b[90m<ord>\u001b[39m\u001b[23m                 \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m 2024-01-15  January          Monday                    1\n",
      "\u001b[90m 2\u001b[39m 2024-02-20  February         Tuesday                   1\n",
      "\u001b[90m 3\u001b[39m 2024-01-10  January          Wednesday                 1\n",
      "\u001b[90m 4\u001b[39m 2024-03-05  March            Tuesday                   1\n",
      "\u001b[90m 5\u001b[39m 2024-02-14  February         Wednesday                 1\n",
      "\u001b[90m 6\u001b[39m 2024-03-20  March            Wednesday                 1\n",
      "\u001b[90m 7\u001b[39m 2024-01-25  January          Thursday                  1\n",
      "\u001b[90m 8\u001b[39m 2024-02-28  February         Wednesday                 1\n",
      "\u001b[90m 9\u001b[39m 2024-03-10  March            Sunday                    1\n",
      "\u001b[90m10\u001b[39m 2024-01-30  January          Tuesday                   1\n"
     ]
    }
   ],
   "source": [
    "# Task 4.2: Extract Date Components\n",
    "transactions_clean <- transactions_clean %>%\n",
    "  mutate(\n",
    "    trans_year = year(date_parsed),\n",
    "    trans_month = month(date_parsed),\n",
    "    trans_month_name = month(date_parsed, label = TRUE, abbr = FALSE),\n",
    "    trans_day = day(date_parsed),\n",
    "    trans_weekday = wday(date_parsed, label = TRUE, abbr = FALSE),\n",
    "    trans_quarter = quarter(date_parsed)\n",
    "  )\n",
    "\n",
    "# Display results\n",
    "cat(\"Date Component Extraction:\\n\")\n",
    "transactions_clean %>%\n",
    "  select(date_parsed, trans_month_name, trans_weekday, trans_quarter) %>%\n",
    "  head(10) %>%\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "weekend_flag",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weekend vs Weekday Transactions:\n",
      "\n",
      "FALSE  TRUE \n",
      "   23     7 \n",
      "\n",
      "Percentage of weekend transactions: 23.3 %\n"
     ]
    }
   ],
   "source": [
    "# Task 4.3: Identify Weekend Transactions\n",
    "transactions_clean <- transactions_clean %>%\n",
    "  mutate(\n",
    "    is_weekend = wday(date_parsed) %in% c(1, 7)\n",
    "  )\n",
    "\n",
    "# Summary\n",
    "cat(\"Weekend vs Weekday Transactions:\\n\")\n",
    "table(transactions_clean$is_weekend) %>% print()\n",
    "\n",
    "cat(\"\\nPercentage of weekend transactions:\",\n",
    "    round(sum(transactions_clean$is_weekend) / nrow(transactions_clean) * 100, 1), \"%\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part5_intro",
   "metadata": {},
   "source": [
    "## Part 5: Date Calculations and Customer Recency Analysis\n",
    "\n",
    "**Business Context:** Understanding how recently customers transacted helps identify at-risk customers for re-engagement campaigns.\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Calculate days since each transaction\n",
    "2. Categorize customers by recency (Recent, Moderate, Old)\n",
    "3. Identify customers who haven't transacted in 90+ days\n",
    "4. Calculate average days between transactions per customer\n",
    "\n",
    "**Key Functions:** `today()`, date arithmetic, `case_when()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "calculate_recency",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Days Since Transaction:\n",
      "\u001b[90m# A tibble: 10 \u00d7 3\u001b[39m\n",
      "   customer_name date_parsed days_since\n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m         \u001b[3m\u001b[90m<date>\u001b[39m\u001b[23m           \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m Noah Davis    2024-01-05         667\n",
      "\u001b[90m 2\u001b[39m Bob Johnson   2024-01-10         662\n",
      "\u001b[90m 3\u001b[39m Frank Miller  2024-01-12         660\n",
      "\u001b[90m 4\u001b[39m John Smith    2024-01-15         657\n",
      "\u001b[90m 5\u001b[39m Charlie Brown 2024-01-16         656\n",
      "\u001b[90m 6\u001b[39m Kate Brown    2024-01-20         652\n",
      "\u001b[90m 7\u001b[39m Jane Doe      2024-01-22         650\n",
      "\u001b[90m 8\u001b[39m Eve Adams     2024-01-25         647\n",
      "\u001b[90m 9\u001b[39m Quinn Thomas  2024-01-28         644\n",
      "\u001b[90m10\u001b[39m Henry Ford    2024-01-30         642\n"
     ]
    }
   ],
   "source": [
    "# Task 5.1: Calculate Days Since Transaction\n",
    "transactions_clean <- transactions_clean %>%\n",
    "  mutate(\n",
    "    days_since = as.numeric(today() - date_parsed)\n",
    "  )\n",
    "\n",
    "# Display results\n",
    "cat(\"Days Since Transaction:\\n\")\n",
    "transactions_clean %>%\n",
    "  select(customer_name, date_parsed, days_since) %>%\n",
    "  arrange(desc(days_since)) %>%\n",
    "  head(10) %>%\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "recency_categories",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recency Category Distribution:\n",
      "\n",
      "At Risk \n",
      "     30 \n",
      "\n",
      "At-Risk Customers (>90 days):\n",
      "\u001b[90m# A tibble: 30 \u00d7 3\u001b[39m\n",
      "   customer_name date_parsed days_since\n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m         \u001b[3m\u001b[90m<date>\u001b[39m\u001b[23m           \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m Noah Davis    2024-01-05         667\n",
      "\u001b[90m 2\u001b[39m Bob Johnson   2024-01-10         662\n",
      "\u001b[90m 3\u001b[39m Frank Miller  2024-01-12         660\n",
      "\u001b[90m 4\u001b[39m John Smith    2024-01-15         657\n",
      "\u001b[90m 5\u001b[39m Charlie Brown 2024-01-16         656\n",
      "\u001b[90m 6\u001b[39m Kate Brown    2024-01-20         652\n",
      "\u001b[90m 7\u001b[39m Jane Doe      2024-01-22         650\n",
      "\u001b[90m 8\u001b[39m Eve Adams     2024-01-25         647\n",
      "\u001b[90m 9\u001b[39m Quinn Thomas  2024-01-28         644\n",
      "\u001b[90m10\u001b[39m Henry Ford    2024-01-30         642\n",
      "\u001b[90m# \u2139 20 more rows\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "# Task 5.2: Categorize by Recency\n",
    "transactions_clean <- transactions_clean %>%\n",
    "  mutate(\n",
    "    recency_category = case_when(\n",
    "      days_since <= 30 ~ \"Recent\",\n",
    "      days_since <= 90 ~ \"Moderate\",\n",
    "      TRUE ~ \"At Risk\"\n",
    "    )\n",
    "  )\n",
    "\n",
    "# Display distribution\n",
    "cat(\"Recency Category Distribution:\\n\")\n",
    "table(transactions_clean$recency_category) %>% print()\n",
    "\n",
    "# Show at-risk customers\n",
    "cat(\"\\nAt-Risk Customers (>90 days):\\n\")\n",
    "transactions_clean %>%\n",
    "  filter(recency_category == \"At Risk\") %>%\n",
    "  select(customer_name, date_parsed, days_since) %>%\n",
    "  arrange(desc(days_since)) %>%\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part6_intro",
   "metadata": {},
   "source": [
    "## Part 6: Combined String and Date Operations\n",
    "\n",
    "**Business Context:** Create personalized customer outreach messages based on purchase recency.\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Extract first names from customer names\n",
    "2. Create personalized messages based on recency\n",
    "3. Analyze transaction patterns by weekday\n",
    "4. Identify best customers (recent + high value)\n",
    "\n",
    "**Key Functions:** Combine `str_extract()`, date calculations, `case_when()`, `group_by()`, `summarize()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "extract_names",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Personalized Customer Messages:\n",
      "\u001b[90m# A tibble: 10 \u00d7 4\u001b[39m\n",
      "   customer_name  first_name days_since personalized_message                    \n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m          \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m           \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                                   \n",
      "\u001b[90m 1\u001b[39m John Smith     John              657 Hi John , it's been a while! Here's a s\u2026\n",
      "\u001b[90m 2\u001b[39m Jane Doe       Jane              621 Hi Jane , it's been a while! Here's a s\u2026\n",
      "\u001b[90m 3\u001b[39m Bob Johnson    Bob               662 Hi Bob , it's been a while! Here's a sp\u2026\n",
      "\u001b[90m 4\u001b[39m Alice Williams Alice             607 Hi Alice , it's been a while! Here's a \u2026\n",
      "\u001b[90m 5\u001b[39m Charlie Brown  Charlie           627 Hi Charlie , it's been a while! Here's \u2026\n",
      "\u001b[90m 6\u001b[39m Diana Prince   Diana             592 Hi Diana , it's been a while! Here's a \u2026\n",
      "\u001b[90m 7\u001b[39m Eve Adams      Eve               647 Hi Eve , it's been a while! Here's a sp\u2026\n",
      "\u001b[90m 8\u001b[39m Frank Miller   Frank             613 Hi Frank , it's been a while! Here's a \u2026\n",
      "\u001b[90m 9\u001b[39m Grace Lee      Grace             602 Hi Grace , it's been a while! Here's a \u2026\n",
      "\u001b[90m10\u001b[39m Henry Ford     Henry             642 Hi Henry , it's been a while! Here's a \u2026\n"
     ]
    }
   ],
   "source": [
    "# Task 6.1: Extract First Names and Create Personalized Messages\n",
    "customer_outreach <- transactions_clean %>%\n",
    "  mutate(\n",
    "    first_name = str_extract(customer_name, \"^\\\\w+\"),\n",
    "    personalized_message = case_when(\n",
    "      recency_category == \"Recent\" ~ paste(\"Hi\", first_name, \"! Thanks for your recent purchase!\"),\n",
    "      recency_category == \"Moderate\" ~ paste(\"Hi\", first_name, \", we miss you! Check out our new products.\"),\n",
    "      TRUE ~ paste(\"Hi\", first_name, \", it's been a while! Here's a special offer for you.\")\n",
    "    )\n",
    "  )\n",
    "\n",
    "# Display personalized messages\n",
    "cat(\"Personalized Customer Messages:\\n\")\n",
    "customer_outreach %>%\n",
    "  select(customer_name, first_name, days_since, personalized_message) %>%\n",
    "  head(10) %>%\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "weekday_analysis",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transaction Patterns by Weekday:\n",
      "\u001b[90m# A tibble: 7 \u00d7 4\u001b[39m\n",
      "  trans_weekday transaction_count total_amount avg_amount\n",
      "  \u001b[3m\u001b[90m<ord>\u001b[39m\u001b[23m                     \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m        \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m      \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m Monday                        5        \u001b[4m1\u001b[24m090.       218.\n",
      "\u001b[90m2\u001b[39m Tuesday                       5         980.       196.\n",
      "\u001b[90m3\u001b[39m Friday                        5         960.       192.\n",
      "\u001b[90m4\u001b[39m Sunday                        4         940.       235.\n",
      "\u001b[90m5\u001b[39m Wednesday                     4         970.       242.\n",
      "\u001b[90m6\u001b[39m Thursday                      4        \u001b[4m1\u001b[24m010.       252.\n",
      "\u001b[90m7\u001b[39m Saturday                      3         700.       233.\n",
      "\n",
      "\ud83d\udd25 Busiest day: Monday \n"
     ]
    }
   ],
   "source": [
    "# Task 6.2: Analyze Transaction Patterns by Weekday\n",
    "weekday_patterns <- transactions_clean %>%\n",
    "  group_by(trans_weekday) %>%\n",
    "  summarize(\n",
    "    transaction_count = n(),\n",
    "    total_amount = sum(amount),\n",
    "    avg_amount = mean(amount),\n",
    "    .groups = 'drop'\n",
    "  ) %>%\n",
    "  arrange(desc(transaction_count))\n",
    "\n",
    "# Display results\n",
    "cat(\"Transaction Patterns by Weekday:\\n\")\n",
    "print(weekday_patterns)\n",
    "\n",
    "# Identify busiest day\n",
    "busiest_day <- weekday_patterns$trans_weekday[1]\n",
    "cat(\"\\n\ud83d\udd25 Busiest day:\", as.character(busiest_day), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "monthly_analysis",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monthly Transaction Patterns:\n",
      "\u001b[90m# A tibble: 3 \u00d7 4\u001b[39m\n",
      "  trans_month trans_month_name transaction_count unique_customers\n",
      "        \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<ord>\u001b[39m\u001b[23m                        \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m            \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m           1 January                         10               10\n",
      "\u001b[90m2\u001b[39m           2 February                        10               10\n",
      "\u001b[90m3\u001b[39m           3 March                           10                9\n"
     ]
    }
   ],
   "source": [
    "# Task 6.3: Monthly Transaction Analysis\n",
    "monthly_patterns <- transactions_clean %>%\n",
    "  group_by(trans_month, trans_month_name) %>%\n",
    "  summarize(\n",
    "    transaction_count = n(),\n",
    "    unique_customers = n_distinct(customer_name),\n",
    "    .groups = 'drop'\n",
    "  ) %>%\n",
    "  arrange(trans_month)\n",
    "\n",
    "# Display results\n",
    "cat(\"Monthly Transaction Patterns:\\n\")\n",
    "print(monthly_patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part7_intro",
   "metadata": {},
   "source": [
    "## Part 7: Business Intelligence Summary\n",
    "\n",
    "**Business Context:** Create an executive summary that combines all your analyses into actionable insights.\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Calculate key metrics across all datasets\n",
    "2. Identify top products and categories\n",
    "3. Summarize customer sentiment\n",
    "4. Provide data-driven recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "business_summary",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "         BUSINESS INTELLIGENCE SUMMARY\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "\n",
      "\ud83d\udce6 PRODUCT ANALYSIS\n",
      "\u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \n",
      "Total products: 30 \n",
      "Wireless products: 5 \n",
      "Premium products: 5 \n",
      "Most common category: Accessories \n",
      "\n",
      "\ud83d\udcac CUSTOMER SENTIMENT\n",
      "\u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \n",
      "Total feedback entries: 20 \n",
      "Average sentiment score: 0.4 \n",
      "Positive reviews: 50 %\n",
      "Negative reviews: 50 %\n",
      "\n",
      "\ud83d\udcca TRANSACTION PATTERNS\n",
      "\u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \n",
      "Total transactions: 30 \n",
      "Date range: 2024-01-05 to 2024-03-30 \n",
      "Busiest weekday: Monday \n",
      "Weekend transactions: 23.3 %\n",
      "\n",
      "\ud83d\udc65 CUSTOMER RECENCY\n",
      "\u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \u2500 \n",
      "Recent customers (< 30 days): 0 \n",
      "At-risk customers (> 90 days): 30 \n",
      "Needing re-engagement: 100 %\n",
      "\n",
      " = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n"
     ]
    }
   ],
   "source": [
    "# Task 7.1: Create Business Intelligence Dashboard\n",
    "\n",
    "cat(\"\\n\", rep(\"=\", 60), \"\\n\")\n",
    "cat(\"         BUSINESS INTELLIGENCE SUMMARY\\n\")\n",
    "cat(rep(\"=\", 60), \"\\n\\n\")\n",
    "\n",
    "# Product Analysis\n",
    "cat(\"\ud83d\udce6 PRODUCT ANALYSIS\\n\")\n",
    "cat(rep(\"\u2500\", 30), \"\\n\")\n",
    "cat(\"Total products:\", nrow(products_clean), \"\\n\")\n",
    "cat(\"Wireless products:\", sum(products_clean$is_wireless), \"\\n\")\n",
    "cat(\"Premium products:\", sum(products_clean$is_premium), \"\\n\")\n",
    "most_common_cat <- products_clean %>% \n",
    "  count(category_clean) %>% \n",
    "  arrange(desc(n)) %>% \n",
    "  slice(1) %>% \n",
    "  pull(category_clean)\n",
    "cat(\"Most common category:\", as.character(most_common_cat), \"\\n\")\n",
    "\n",
    "# Customer Sentiment\n",
    "cat(\"\\n\ud83d\udcac CUSTOMER SENTIMENT\\n\")\n",
    "cat(rep(\"\u2500\", 30), \"\\n\")\n",
    "cat(\"Total feedback entries:\", nrow(feedback_clean), \"\\n\")\n",
    "cat(\"Average sentiment score:\", round(mean(feedback_clean$sentiment_score), 2), \"\\n\")\n",
    "positive_pct <- round(sum(feedback_clean$sentiment_score > 0) / nrow(feedback_clean) * 100, 1)\n",
    "negative_pct <- round(sum(feedback_clean$sentiment_score < 0) / nrow(feedback_clean) * 100, 1)\n",
    "cat(\"Positive reviews:\", positive_pct, \"%\\n\")\n",
    "cat(\"Negative reviews:\", negative_pct, \"%\\n\")\n",
    "\n",
    "# Transaction Patterns\n",
    "cat(\"\\n\ud83d\udcca TRANSACTION PATTERNS\\n\")\n",
    "cat(rep(\"\u2500\", 30), \"\\n\")\n",
    "cat(\"Total transactions:\", nrow(transactions_clean), \"\\n\")\n",
    "earliest <- min(transactions_clean$date_parsed)\n",
    "latest <- max(transactions_clean$date_parsed)\n",
    "cat(\"Date range:\", format(earliest, \"%Y-%m-%d\"), \"to\", format(latest, \"%Y-%m-%d\"), \"\\n\")\n",
    "busiest <- weekday_patterns$trans_weekday[1]\n",
    "cat(\"Busiest weekday:\", as.character(busiest), \"\\n\")\n",
    "weekend_pct <- round(sum(transactions_clean$is_weekend) / nrow(transactions_clean) * 100, 1)\n",
    "cat(\"Weekend transactions:\", weekend_pct, \"%\\n\")\n",
    "\n",
    "# Customer Recency\n",
    "cat(\"\\n\ud83d\udc65 CUSTOMER RECENCY\\n\")\n",
    "cat(rep(\"\u2500\", 30), \"\\n\")\n",
    "recent_count <- sum(transactions_clean$recency_category == \"Recent\")\n",
    "at_risk_count <- sum(transactions_clean$recency_category == \"At Risk\")\n",
    "cat(\"Recent customers (< 30 days):\", recent_count, \"\\n\")\n",
    "cat(\"At-risk customers (> 90 days):\", at_risk_count, \"\\n\")\n",
    "reengagement_pct <- round(at_risk_count / nrow(transactions_clean) * 100, 1)\n",
    "cat(\"Needing re-engagement:\", reengagement_pct, \"%\\n\")\n",
    "\n",
    "cat(\"\\n\", rep(\"=\", 60), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "top_products",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Product Categories:\n",
      "\u001b[90m# A tibble: 5 \u00d7 2\u001b[39m\n",
      "  category_clean product_count\n",
      "  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                  \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m Accessories               12\n",
      "\u001b[90m2\u001b[39m Peripherals               10\n",
      "\u001b[90m3\u001b[39m Furniture                  3\n",
      "\u001b[90m4\u001b[39m Monitors                   2\n",
      "\u001b[90m5\u001b[39m Storage                    2\n"
     ]
    }
   ],
   "source": [
    "# Task 7.2: Identify Top Products by Category\n",
    "top_categories <- products_clean %>%\n",
    "  group_by(category_clean) %>%\n",
    "  summarize(\n",
    "    product_count = n(),\n",
    "    .groups = 'drop'\n",
    "  ) %>%\n",
    "  arrange(desc(product_count)) %>%\n",
    "  head(5)\n",
    "\n",
    "cat(\"Top Product Categories:\\n\")\n",
    "print(top_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part8_intro",
   "metadata": {},
   "source": [
    "## Part 8: Reflection Questions\n",
    "\n",
    "Answer the following questions based on your analysis. Write your answers in the markdown cells below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection1",
   "metadata": {},
   "source": "### Question 8.1: Data Quality Impact\n\n**How did cleaning the text data (removing spaces, standardizing case) improve your ability to analyze the data? Provide specific examples from your homework.**\n\nYour answer here:\n\nCleaning the text data significantly improved data analysis in several ways:\n\n1. **Category Standardization**: Before cleaning, \"Peripherals\", \"PERIPHERALS\", and \"peripherals\" were treated as three different categories. After using `str_to_title()`, they all became \"Peripherals\", allowing accurate category counts and grouping.\n\n2. **Accurate Pattern Matching**: Extra spaces in product names like \"  wireless MOUSE  \" would have caused `str_detect()` to miss patterns if we didn't use `str_trim()` first. After cleaning, we could reliably identify all wireless products.\n\n3. **Consistent Reporting**: Product names with mixed case like \"laptop PRO 15-inch\" looked unprofessional in reports. Using `str_to_title()` created consistent \"Laptop Pro 15-Inch\" formatting suitable for customer-facing dashboards.\n\n4. **Sentiment Analysis Accuracy**: Converting feedback to lowercase with `str_to_lower()` ensured we caught sentiment words regardless of capitalization (\"GREAT\", \"great\", \"Great\" all counted as positive).\n\nWithout these cleaning steps, our analysis would have undercounted categories, missed product features, and produced inconsistent reports."
  },
  {
   "cell_type": "markdown",
   "id": "reflection2",
   "metadata": {},
   "source": "### Question 8.2: Pattern Detection Value\n\n**What business insights did you gain from detecting patterns in product names (wireless, premium, gaming)? How could a business use this information?**\n\nYour answer here:\n\nPattern detection revealed valuable product segmentation insights:\n\n**Insights Gained:**\n- Identified which products have wireless capability (important for modern consumers)\n- Flagged premium products (Pro, HD, 4K) that command higher prices\n- Detected gaming products that appeal to a specific customer segment\n\n**Business Applications:**\n\n1. **Targeted Marketing**: Create separate email campaigns for wireless product buyers vs. wired product buyers, as they have different preferences.\n\n2. **Inventory Planning**: If premium products have higher profit margins, prioritize stocking them. If gaming products sell faster on weekends, adjust inventory accordingly.\n\n3. **Pricing Strategy**: Premium products can justify higher prices. Knowing which products are premium helps validate pricing decisions.\n\n4. **Cross-Selling**: Customers who buy gaming keyboards might be interested in gaming mice or headsets. Pattern detection enables product recommendation engines.\n\n5. **Product Development**: If wireless products are popular but we only have a few, this signals an opportunity to expand the wireless product line.\n\nThis automated feature detection is much faster than manual categorization and scales to thousands of products."
  },
  {
   "cell_type": "markdown",
   "id": "reflection3",
   "metadata": {},
   "source": "### Question 8.3: Date Analysis Importance\n\n**Why is analyzing transaction dates by weekday and month important for business operations? Provide at least three specific business applications.**\n\nYour answer here:\n\nDate analysis is critical for operational efficiency and strategic planning:\n\n1. **Staffing Optimization**: By identifying that Tuesday is the busiest day (from our weekday analysis), management can schedule more customer service representatives and warehouse staff on Tuesdays. This reduces wait times during peak periods and avoids overstaffing on slow days, directly impacting labor costs and customer satisfaction.\n\n2. **Marketing Campaign Timing**: If we discover that weekend transactions are lower (only 28% in our data), we could launch special weekend promotions to boost sales during slow periods. Conversely, knowing peak days helps us avoid launching campaigns when systems are already at capacity.\n\n3. **Inventory Management**: Monthly analysis reveals seasonal patterns. If March consistently has higher transaction volumes, we need to increase inventory in February. This prevents stockouts during busy periods and reduces excess inventory during slow months, optimizing working capital.\n\nAdditional applications include: scheduling system maintenance during low-traffic periods, planning promotional events around natural buying patterns, and forecasting cash flow based on historical transaction timing."
  },
  {
   "cell_type": "markdown",
   "id": "reflection4",
   "metadata": {},
   "source": "### Question 8.4: Customer Recency Strategy\n\n**Based on your recency analysis, what specific actions would you recommend for customers in each category (Recent, Moderate, At Risk)? How would you prioritize these actions?**\n\nYour answer here:\n\n**Recency-Based Action Plan:**\n\n**Recent Customers (< 30 days):**\n- Action: Thank you message + product care tips\n- Goal: Build loyalty and encourage positive reviews\n- Priority: Medium (they're already engaged)\n- Example: \"Hi John! Thanks for your recent purchase! Here are tips to get the most from your new laptop...\"\n\n**Moderate Customers (30-90 days):**\n- Action: Gentle reminder + new product showcase\n- Goal: Stay top-of-mind and encourage repeat purchase\n- Priority: Medium-High (prevent them from becoming at-risk)\n- Example: \"Hi Jane, we miss you! Check out our new wireless headphones that pair perfectly with your previous purchase.\"\n\n**At-Risk Customers (> 90 days):**\n- Action: Special discount offer + urgency messaging\n- Goal: Re-engage before they churn completely\n- Priority: HIGHEST (losing customers is expensive)\n- Example: \"Hi Bob, it's been a while! Here's a special 20% off offer just for you - expires in 48 hours!\"\n\n**Prioritization Rationale:**\nFocus on At-Risk customers first because acquiring new customers costs 5-7x more than retaining existing ones. A 20% discount to save a customer is cheaper than the marketing cost to acquire a replacement. Recent customers need minimal attention since they're already engaged."
  },
  {
   "cell_type": "markdown",
   "id": "reflection5",
   "metadata": {},
   "source": "### Question 8.5: Sentiment Analysis Application\n\n**How could the sentiment analysis you performed be used to improve products or customer service? What are the limitations of this simple sentiment analysis approach?**\n\nYour answer here:\n\n**Applications for Improvement:**\n\n1. **Product Quality Issues**: Products with consistently negative feedback (high \"bad\", \"terrible\", \"awful\" counts) need immediate quality review. This early warning system prevents reputation damage.\n\n2. **Customer Service Prioritization**: Customers who left negative reviews should receive immediate follow-up from customer service to resolve issues and potentially save the relationship.\n\n3. **Feature Enhancement**: Positive reviews mentioning specific features (\"love the wireless capability\") tell us what to emphasize in marketing and what features to include in future products.\n\n4. **Trend Monitoring**: Tracking sentiment scores over time reveals if product quality is improving or declining, enabling proactive management.\n\n**Limitations of Simple Approach:**\n\n1. **Context Ignorance**: \"not bad\" contains \"bad\" but is actually positive. Our simple count misses this nuance.\n\n2. **Sarcasm Blind**: \"Great, another broken product\" contains \"great\" but is clearly negative. Simple word counting can't detect sarcasm.\n\n3. **Limited Vocabulary**: We only check 8 words (4 positive, 4 negative). Real sentiment is more nuanced with hundreds of sentiment-bearing words.\n\n4. **No Intensity**: \"good\" and \"amazing\" both count as +1, but \"amazing\" expresses stronger sentiment.\n\n5. **Missing Neutral**: Some reviews are informational (\"arrived on time\") without clear sentiment.\n\nFor production use, we'd need more sophisticated NLP techniques or sentiment analysis APIs."
  },
  {
   "cell_type": "markdown",
   "id": "reflection6",
   "metadata": {},
   "source": "### Question 8.6: Real-World Application\n\n**Describe a real business scenario where you would need to combine string manipulation and date analysis (like you did in this homework). What insights would you be trying to discover?**\n\nYour answer here:\n\n**Scenario: E-commerce Customer Retention Analysis**\n\n**Business Problem:**\nAn online electronics retailer notices declining repeat purchase rates and wants to identify at-risk customers for a targeted win-back campaign.\n\n**Combined String & Date Analysis Needed:**\n\n1. **Customer Segmentation** (String):\n   - Extract customer names and email domains to identify B2B vs. B2C customers\n   - Parse product categories from purchase history to understand customer interests\n   - Detect VIP customers by identifying \"premium\" or \"pro\" products in their history\n\n2. **Recency Analysis** (Date):\n   - Calculate days since last purchase for each customer\n   - Identify customers who used to buy monthly but haven't purchased in 90+ days\n   - Determine if churn risk varies by day of week or season\n\n3. **Personalized Outreach** (Combined):\n   - Extract first names for personalization\n   - Create different messages based on both recency AND product interests\n   - Example: \"Hi Sarah, it's been 120 days since your last gaming purchase. Check out our new gaming keyboards!\"\n\n**Insights to Discover:**\n- Which customer segments have highest churn risk?\n- Do customers who buy on weekends have different retention patterns?\n- Are customers who bought premium products more loyal?\n- What's the optimal time to send re-engagement messages?\n- Do seasonal buyers need different retention strategies?\n\n**Business Impact:**\nThis analysis could increase customer lifetime value by 15-25% by preventing churn through timely, personalized interventions."
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## Summary and Submission\n",
    "\n",
    "### What You've Accomplished\n",
    "\n",
    "In this homework, you've successfully:\n",
    "- \u2705 Cleaned and standardized messy text data using `stringr` functions\n",
    "- \u2705 Detected patterns and extracted information from text\n",
    "- \u2705 Parsed dates and extracted temporal components using `lubridate`\n",
    "- \u2705 Calculated customer recency for segmentation\n",
    "- \u2705 Analyzed transaction patterns by time periods\n",
    "- \u2705 Combined string and date operations for business insights\n",
    "- \u2705 Created personalized customer communications\n",
    "- \u2705 Generated executive-ready business intelligence summaries\n",
    "\n",
    "### Key Skills Mastered\n",
    "\n",
    "**String Manipulation:**\n",
    "- `str_trim()`, `str_squish()` - Whitespace handling\n",
    "- `str_to_lower()`, `str_to_upper()`, `str_to_title()` - Case conversion\n",
    "- `str_detect()` - Pattern detection\n",
    "- `str_extract()` - Information extraction\n",
    "- `str_count()` - Pattern counting\n",
    "\n",
    "**Date/Time Operations:**\n",
    "- `ymd()`, `mdy()`, `dmy()` - Date parsing\n",
    "- `year()`, `month()`, `day()`, `wday()` - Component extraction\n",
    "- `quarter()` - Period extraction\n",
    "- `today()` - Current date\n",
    "- Date arithmetic - Calculating differences\n",
    "\n",
    "**Business Applications:**\n",
    "- Data cleaning and standardization\n",
    "- Customer segmentation by recency\n",
    "- Sentiment analysis\n",
    "- Pattern identification\n",
    "- Temporal trend analysis\n",
    "- Personalized communication\n",
    "\n",
    "### Submission Checklist\n",
    "\n",
    "Before submitting, ensure you have:\n",
    "- [ ] Entered your name, student ID, and date at the top\n",
    "- [ ] Completed all code tasks (Parts 1-7)\n",
    "- [ ] Run all cells successfully without errors\n",
    "- [ ] Answered all reflection questions (Part 8)\n",
    "- [ ] Used proper commenting in your code\n",
    "- [ ] Used the pipe operator (`%>%`) where appropriate\n",
    "- [ ] Verified your results make business sense\n",
    "- [ ] Checked for any remaining TODO comments\n",
    "\n",
    "### Grading Criteria\n",
    "\n",
    "Your homework will be evaluated on:\n",
    "- **Code Correctness (40%)**: All tasks completed correctly\n",
    "- **Code Quality (20%)**: Clean, well-commented, efficient code\n",
    "- **Business Understanding (20%)**: Demonstrates understanding of business applications\n",
    "- **Reflection Questions (15%)**: Thoughtful, complete answers\n",
    "- **Presentation (5%)**: Professional formatting and organization\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "In Lesson 8, you'll learn:\n",
    "- Advanced data wrangling with complex pipelines\n",
    "- Sophisticated conditional logic with `case_when()`\n",
    "- Data validation and quality checks\n",
    "- Creating reproducible analysis workflows\n",
    "- Professional best practices for business analytics\n",
    "\n",
    "**Great work on completing this assignment! \ud83c\udf89**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}