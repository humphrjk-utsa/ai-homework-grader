{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Homework Assignment 8: Advanced Data Wrangling - Capstone Project\n\n**Student Name:** [Enter Your Full Name Here]\n\n**Student ID:** [Enter Your Student ID]\n\n**Date Submitted:** [Enter Today's Date]\n\n**Due Date:** [Insert Due Date Here]\n\n---\n\n## \ud83c\udf93 Capstone Project Overview\n\nThis is your **final capstone assignment** that integrates everything you've learned in this R data wrangling course. You'll work with real business data to perform a comprehensive analysis that demonstrates mastery of:\n\n- Data import and validation\n- Data transformation with dplyr (select, filter, arrange, mutate, summarize, group_by)\n- String manipulation with stringr\n- Date/time operations with lubridate\n- Complex conditional logic with case_when()\n- Data quality checks and validation\n- Business intelligence reporting\n\n## \ud83c\udfaf Business Scenario\n\nYou are a data analyst for a growing e-commerce company. The executive team needs a comprehensive analysis of sales performance, customer behavior, and operational efficiency. Your analysis will directly inform strategic decisions about:\n- Resource allocation across regions\n- Customer retention strategies\n- Product portfolio optimization\n- Operational improvements\n\n## \ud83d\udcca Your Deliverables\n\n1. **Data Quality Report**: Validate and clean the data\n2. **Customer Segmentation**: Identify high-value customers and at-risk accounts\n3. **Product Performance Analysis**: Evaluate product categories and features\n4. **Regional Performance**: Compare performance across geographic regions\n5. **Temporal Trends**: Analyze patterns over time\n6. **Executive Dashboard**: Create a comprehensive business intelligence summary\n7. **Strategic Recommendations**: Provide data-driven business recommendations\n\n## \ud83d\udcc1 Dataset\n\nYou will work with `company_sales_data.csv` which contains:\n- Sales transactions with revenue, cost, and profit data\n- Customer information and transaction dates\n- Product details and categories\n- Regional information\n- Sales representative data\n\n## \u23f1\ufe0f Time Estimate\n\nPlan for 3-4 hours to complete this comprehensive analysis.\n\n## \ud83d\udcdd Instructions\n\n- Complete all tasks in order\n- Write your code in the designated TODO sections\n- Use the pipe operator (`%>%`) to chain operations\n- Add comments explaining your business logic\n- Run all cells to verify your code works\n- Answer all reflection questions\n- Create professional, business-ready outputs\n\n---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part1_intro",
   "metadata": {},
   "source": [
    "## Part 1: Data Import and Initial Validation\n\n**Business Context:** Before any analysis, professional data analysts must ensure data quality and understand the dataset structure.\n\n**Your Tasks:**\n1. Load all required packages\n2. Import the sales data\n3. Perform initial data exploration\n4. Validate data quality\n5. Document any issues found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Task 1.1: Load Required Packages\n# TODO: Load tidyverse (includes dplyr, stringr, ggplot2)\n\n\n# TODO: Load lubridate for date operations\n\n\ncat(\"\u2705 Packages loaded successfully!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "import_data",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Task 1.2: Import Sales Data\n# TODO: Import company_sales_data.csv from the data/ directory\n# Store it in a variable called 'sales_data'\nsales_data <- \n\ncat(\"\u2705 Data imported successfully!\\n\")\ncat(\"Total rows:\", nrow(sales_data), \"\\n\")\ncat(\"Total columns:\", ncol(sales_data), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explore_data",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Task 1.3: Initial Data Exploration\n\ncat(\"=== DATA STRUCTURE ===\\n\")\n# TODO: Display the structure using str()\n\n\ncat(\"\\n=== FIRST 10 ROWS ===\\n\")\n# TODO: Display first 10 rows\n\n\ncat(\"\\n=== SUMMARY STATISTICS ===\\n\")\n# TODO: Display summary statistics\n\n\ncat(\"\\n=== COLUMN NAMES ===\\n\")\n# TODO: Display all column names\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data_quality",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Task 1.4: Data Quality Validation\n\ncat(\"=== DATA QUALITY REPORT ===\\n\\n\")\n\n# TODO: Create a data quality summary with:\n#   - missing_values: count of NA values per column\n#   - negative_revenue: count of Revenue < 0\n#   - negative_cost: count of Cost < 0\n#   - zero_units: count of Units_Sold <= 0\n#   - duplicate_rows: count of duplicate rows\n\ndata_quality_summary <- list(\n  # Your code here:\n  \n)\n\n# Display quality report\ncat(\"Missing Values:\\n\")\nprint(data_quality_summary$missing_values)\n\ncat(\"\\nData Validation:\\n\")\ncat(\"Negative Revenue:\", data_quality_summary$negative_revenue, \"\\n\")\ncat(\"Negative Cost:\", data_quality_summary$negative_cost, \"\\n\")\ncat(\"Zero/Negative Units:\", data_quality_summary$zero_units, \"\\n\")\ncat(\"Duplicate Rows:\", data_quality_summary$duplicate_rows, \"\\n\")\n\nif (sum(data_quality_summary$negative_revenue, \n        data_quality_summary$negative_cost,\n        data_quality_summary$zero_units) == 0) {\n  cat(\"\\n\u2705 All validation checks passed!\\n\")\n} else {\n  cat(\"\\n\u26a0\ufe0f  Data quality issues detected!\\n\")\n}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part2_intro",
   "metadata": {},
   "source": [
    "## Part 2: Data Transformation and Feature Engineering\n\n**Business Context:** Raw data needs calculated fields and categorizations to generate business insights.\n\n**Your Tasks:**\n1. Calculate financial metrics (Profit, Profit_Margin, ROI)\n2. Create performance categories\n3. Clean and standardize text fields\n4. Parse and extract date components\n5. Create customer value scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "calculate_metrics",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Task 2.1: Calculate Financial Metrics\n# TODO: Create a new dataframe 'sales_enhanced' with these new columns:\n#   - profit: Revenue - Cost\n#   - profit_margin: (profit / Revenue) * 100\n#   - roi: (profit / Cost) * 100\n#   - revenue_per_unit: Revenue / Units_Sold\n#   - cost_per_unit: Cost / Units_Sold\n\nsales_enhanced <- sales_data %>%\n  mutate(\n    # Your code here:\n    \n  )\n\n# Display sample of calculated metrics\ncat(\"Financial Metrics Sample:\\n\")\nsales_enhanced %>%\n  select(Revenue, Cost, profit, profit_margin, roi) %>%\n  head(10) %>%\n  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create_categories",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Task 2.2: Create Performance Categories\n# TODO: Add these new categorical columns using case_when():\n#   - performance_tier: \"High\" if profit_margin > 40, \"Medium\" if > 25, else \"Low\"\n#   - revenue_size: \"Large\" if Revenue > 25000, \"Medium\" if > 15000, else \"Small\"\n#   - deal_type: \"Bulk\" if Units_Sold > 40, \"Standard\" if > 15, else \"Small\"\n#   - high_value_flag: \"Yes\" if Revenue > 20000, else \"No\"\n\nsales_enhanced <- sales_enhanced %>%\n  mutate(\n    # Your code here:\n    \n  )\n\n# Display category distribution\ncat(\"Performance Tier Distribution:\\n\")\ntable(sales_enhanced$performance_tier) %>% print()\n\ncat(\"\\nRevenue Size Distribution:\\n\")\ntable(sales_enhanced$revenue_size) %>% print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean_text",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Task 2.3: Clean and Standardize Text Fields\n# TODO: Create cleaned versions of text columns:\n#   - product_category_clean: Trim whitespace and convert to Title Case\n#   - region_clean: Trim whitespace and convert to Title Case\n#   - sales_rep_clean: Trim whitespace and convert to Title Case\n# Hint: Use str_trim() and str_to_title()\n\nsales_enhanced <- sales_enhanced %>%\n  mutate(\n    # Your code here:\n    \n  )\n\n# Show unique values before and after\ncat(\"Original Product Categories:\\n\")\nprint(unique(sales_data$Product_Category))\n\ncat(\"\\nCleaned Product Categories:\\n\")\nprint(unique(sales_enhanced$product_category_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parse_dates",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Task 2.4: Parse Dates and Extract Components\n# TODO: Add these date-related columns:\n#   - date_parsed: Parse the Date column (check format first!)\n#   - sale_year: Extract year\n#   - sale_month: Extract month number\n#   - sale_month_name: Extract month name (label=TRUE, abbr=FALSE)\n#   - sale_quarter: Extract quarter\n#   - sale_weekday: Extract weekday name (label=TRUE, abbr=FALSE)\n#   - is_weekend: TRUE if Saturday or Sunday\n# Hint: Use ymd(), mdy(), or dmy() depending on date format\n\nsales_enhanced <- sales_enhanced %>%\n  mutate(\n    # Your code here:\n    \n  )\n\n# Display date components\ncat(\"Date Components Sample:\\n\")\nsales_enhanced %>%\n  select(Date, date_parsed, sale_month_name, sale_weekday, is_weekend) %>%\n  head(10) %>%\n  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "customer_value",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Task 2.5: Create Customer Value Score\n# TODO: Create a 'customer_value_score' column using case_when():\n#   - \"Platinum\": high_value_flag = \"Yes\" AND performance_tier = \"High\"\n#   - \"Gold\": high_value_flag = \"Yes\" OR performance_tier = \"High\"\n#   - \"Silver\": revenue_size = \"Medium\" OR performance_tier = \"Medium\"\n#   - \"Bronze\": All others\n\nsales_enhanced <- sales_enhanced %>%\n  mutate(\n    # Your code here:\n    \n  )\n\n# Display value score distribution\ncat(\"Customer Value Score Distribution:\\n\")\ntable(sales_enhanced$customer_value_score) %>% print()\n\ncat(\"\\nValue Score by Performance Tier:\\n\")\ntable(sales_enhanced$customer_value_score, sales_enhanced$performance_tier) %>% print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part3_intro",
   "metadata": {},
   "source": [
    "## Part 3: Comprehensive Business Analysis\n\n**Business Context:** Executives need insights across multiple dimensions to make strategic decisions.\n\n**Your Tasks:**\n1. Analyze performance by region\n2. Evaluate product categories\n3. Assess sales representative performance\n4. Analyze temporal patterns\n5. Identify top performers and opportunities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regional_analysis",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Task 3.1: Regional Performance Analysis\n# TODO: Create 'regional_performance' by grouping by region_clean and calculating:\n#   - total_revenue: sum of Revenue\n#   - total_profit: sum of profit\n#   - avg_profit_margin: mean of profit_margin\n#   - transaction_count: count using n()\n#   - total_units: sum of Units_Sold\n#   - avg_deal_size: mean of Revenue\n# TODO: Add revenue_share: (total_revenue / sum(total_revenue)) * 100\n# TODO: Arrange by total_revenue descending\n\nregional_performance <- sales_enhanced %>%\n  # Your code here:\n  \n\ncat(\"=== REGIONAL PERFORMANCE ANALYSIS ===\\n\")\nprint(regional_performance)\n\n# Identify top region\ntop_region <- regional_performance$region_clean[1]\ncat(\"\\n\ud83c\udfc6 Top Performing Region:\", as.character(top_region), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "category_analysis",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Task 3.2: Product Category Analysis\n# TODO: Create 'category_performance' by grouping by product_category_clean\n# Calculate the same metrics as regional analysis\n# Add revenue_share and arrange by total_revenue descending\n\ncategory_performance <- sales_enhanced %>%\n  # Your code here:\n  \n\ncat(\"=== PRODUCT CATEGORY PERFORMANCE ===\\n\")\nprint(category_performance)\n\n# Identify top category\ntop_category <- category_performance$product_category_clean[1]\ncat(\"\\n\ud83c\udfc6 Top Performing Category:\", as.character(top_category), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sales_rep_analysis",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Task 3.3: Sales Representative Performance\n# TODO: Create 'sales_rep_performance' by grouping by sales_rep_clean\n# Calculate: total_revenue, total_profit, avg_profit_margin, transaction_count\n# Arrange by total_revenue descending and show top 10\n\nsales_rep_performance <- sales_enhanced %>%\n  # Your code here:\n  \n\ncat(\"=== TOP 10 SALES REPRESENTATIVES ===\\n\")\nprint(head(sales_rep_performance, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "temporal_analysis",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Task 3.4: Monthly Trend Analysis\n# TODO: Create 'monthly_trends' by grouping by sale_year and sale_month_name\n# Calculate: total_revenue, transaction_count, avg_profit_margin\n# Arrange by sale_year and sale_month\n\nmonthly_trends <- sales_enhanced %>%\n  # Your code here:\n  \n\ncat(\"=== MONTHLY SALES TRENDS ===\\n\")\nprint(monthly_trends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weekday_analysis",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Task 3.5: Weekday Pattern Analysis\n# TODO: Create 'weekday_patterns' by grouping by sale_weekday\n# Calculate: transaction_count, total_revenue, avg_revenue\n# Arrange by transaction_count descending\n\nweekday_patterns <- sales_enhanced %>%\n  # Your code here:\n  \n\ncat(\"=== TRANSACTION PATTERNS BY WEEKDAY ===\\n\")\nprint(weekday_patterns)\n\n# Calculate weekend vs weekday performance\nweekend_summary <- sales_enhanced %>%\n  group_by(is_weekend) %>%\n  summarize(\n    transaction_count = n(),\n    total_revenue = sum(Revenue),\n    .groups = 'drop'\n  )\n\ncat(\"\\n=== WEEKEND VS WEEKDAY ===\\n\")\nprint(weekend_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multi_dimensional",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Task 3.6: Multi-Dimensional Analysis\n# TODO: Create 'region_category_performance' by grouping by region_clean AND product_category_clean\n# Calculate: total_revenue, transaction_count, avg_profit_margin\n# Arrange by total_revenue descending and show top 15\n\nregion_category_performance <- sales_enhanced %>%\n  # Your code here:\n  \n\ncat(\"=== TOP 15 REGION-CATEGORY COMBINATIONS ===\\n\")\nprint(head(region_category_performance, 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part4_intro",
   "metadata": {},
   "source": [
    "## Part 4: Executive Dashboard and KPIs\n\n**Business Context:** Executives need a high-level summary of business performance with key metrics and insights.\n\n**Your Tasks:**\n1. Calculate overall business KPIs\n2. Identify top performers across all dimensions\n3. Highlight areas of concern\n4. Create a professional executive summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "calculate_kpis",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Task 4.1: Calculate Overall Business KPIs\n# TODO: Create 'business_kpis' with these metrics:\n#   - total_revenue: sum of Revenue\n#   - total_profit: sum of profit\n#   - overall_profit_margin: mean of profit_margin\n#   - total_transactions: count using n()\n#   - total_units_sold: sum of Units_Sold\n#   - avg_transaction_value: mean of Revenue\n#   - high_value_transaction_pct: percentage where high_value_flag = \"Yes\"\n#   - platinum_customer_pct: percentage where customer_value_score = \"Platinum\"\n\nbusiness_kpis <- sales_enhanced %>%\n  summarize(\n    # Your code here:\n    \n  )\n\ncat(\"\\n\", rep(\"=\", 70), \"\\n\")\ncat(\"           EXECUTIVE BUSINESS DASHBOARD\\n\")\ncat(rep(\"=\", 70), \"\\n\\n\")\n\ncat(\"\ud83d\udcca KEY PERFORMANCE INDICATORS\\n\")\ncat(rep(\"\u2500\", 40), \"\\n\")\ncat(\"Total Revenue: $\", format(business_kpis$total_revenue, big.mark=\",\"), \"\\n\")\ncat(\"Total Profit: $\", format(business_kpis$total_profit, big.mark=\",\"), \"\\n\")\ncat(\"Overall Profit Margin:\", round(business_kpis$overall_profit_margin, 1), \"%\\n\")\ncat(\"Total Transactions:\", business_kpis$total_transactions, \"\\n\")\ncat(\"Total Units Sold:\", format(business_kpis$total_units_sold, big.mark=\",\"), \"\\n\")\ncat(\"Avg Transaction Value: $\", format(round(business_kpis$avg_transaction_value, 2), big.mark=\",\"), \"\\n\")\ncat(\"High-Value Transactions:\", round(business_kpis$high_value_transaction_pct, 1), \"%\\n\")\ncat(\"Platinum Customers:\", round(business_kpis$platinum_customer_pct, 1), \"%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "top_performers",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Task 4.2: Identify Top Performers\n\ncat(\"\\n\ud83c\udfc6 TOP PERFORMERS\\n\")\ncat(rep(\"\u2500\", 40), \"\\n\")\n\n# TODO: Display top region (from regional_performance)\ncat(\"Top Region:\", as.character(regional_performance$region_clean[1]), \"\\n\")\ncat(\"  Revenue: $\", format(regional_performance$total_revenue[1], big.mark=\",\"), \"\\n\")\n\n# TODO: Display top product category (from category_performance)\ncat(\"\\nTop Product Category:\", as.character(category_performance$product_category_clean[1]), \"\\n\")\ncat(\"  Revenue: $\", format(category_performance$total_revenue[1], big.mark=\",\"), \"\\n\")\n\n# TODO: Display top sales rep (from sales_rep_performance)\ncat(\"\\nTop Sales Representative:\", as.character(sales_rep_performance$sales_rep_clean[1]), \"\\n\")\ncat(\"  Revenue: $\", format(sales_rep_performance$total_revenue[1], big.mark=\",\"), \"\\n\")\n\n# TODO: Display busiest weekday (from weekday_patterns)\ncat(\"\\nBusiest Weekday:\", as.character(weekday_patterns$sale_weekday[1]), \"\\n\")\ncat(\"  Transactions:\", weekday_patterns$transaction_count[1], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "performance_distribution",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Task 4.3: Performance Distribution Analysis\n\ncat(\"\\n\ud83d\udcc8 PERFORMANCE DISTRIBUTION\\n\")\ncat(rep(\"\u2500\", 40), \"\\n\")\n\n# TODO: Calculate and display distribution of performance_tier\nperformance_dist <- sales_enhanced %>%\n  group_by(performance_tier) %>%\n  summarize(\n    count = n(),\n    total_revenue = sum(Revenue),\n    percentage = (n() / nrow(sales_enhanced)) * 100,\n    .groups = 'drop'\n  ) %>%\n  arrange(desc(total_revenue))\n\nprint(performance_dist)\n\n# TODO: Calculate and display distribution of customer_value_score\ncat(\"\\n\ud83d\udc8e CUSTOMER VALUE DISTRIBUTION\\n\")\ncat(rep(\"\u2500\", 40), \"\\n\")\n\nvalue_dist <- sales_enhanced %>%\n  group_by(customer_value_score) %>%\n  summarize(\n    count = n(),\n    total_revenue = sum(Revenue),\n    percentage = (n() / nrow(sales_enhanced)) * 100,\n    .groups = 'drop'\n  ) %>%\n  arrange(desc(total_revenue))\n\nprint(value_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part5_intro",
   "metadata": {},
   "source": [
    "## Part 5: Strategic Insights and Recommendations\n\n**Business Context:** Data analysis must translate into actionable business recommendations.\n\n**Your Tasks:**\n1. Identify key business opportunities\n2. Highlight areas of concern\n3. Provide data-driven recommendations\n4. Prioritize action items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opportunities",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Task 5.1: Identify Growth Opportunities\n\ncat(\"\\n\ud83d\udca1 STRATEGIC OPPORTUNITIES\\n\")\ncat(rep(\"=\", 70), \"\\n\\n\")\n\n# TODO: Find underperforming regions with potential\n# (regions with low revenue but high profit margins)\nunderperforming_regions <- regional_performance %>%\n  filter(total_revenue < median(total_revenue) & avg_profit_margin > median(avg_profit_margin)) %>%\n  arrange(desc(avg_profit_margin))\n\ncat(\"1. UNDERPERFORMING REGIONS WITH HIGH MARGINS:\\n\")\nif(nrow(underperforming_regions) > 0) {\n  print(underperforming_regions)\n  cat(\"   \u2192 Opportunity: Increase marketing investment in these regions\\n\\n\")\n} else {\n  cat(\"   No underperforming regions with high margins identified\\n\\n\")\n}\n\n# TODO: Find product categories with growth potential\ncat(\"2. PRODUCT CATEGORY OPPORTUNITIES:\\n\")\ncat(\"   Top 3 categories by profit margin:\\n\")\ncategory_performance %>%\n  arrange(desc(avg_profit_margin)) %>%\n  head(3) %>%\n  select(product_category_clean, avg_profit_margin, total_revenue) %>%\n  print()\ncat(\"   \u2192 Opportunity: Expand inventory in high-margin categories\\n\\n\")\n\n# TODO: Analyze weekend vs weekday performance\ncat(\"3. TEMPORAL OPPORTUNITIES:\\n\")\nweekend_pct <- (sum(sales_enhanced$is_weekend) / nrow(sales_enhanced)) * 100\ncat(\"   Weekend transactions:\", round(weekend_pct, 1), \"%\\n\")\nif(weekend_pct < 25) {\n  cat(\"   \u2192 Opportunity: Increase weekend promotions and staffing\\n\\n\")\n} else {\n  cat(\"   \u2192 Weekend performance is strong\\n\\n\")\n}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerns",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Task 5.2: Identify Areas of Concern\n\ncat(\"\\n\u26a0\ufe0f  AREAS OF CONCERN\\n\")\ncat(rep(\"=\", 70), \"\\n\\n\")\n\n# TODO: Find low-performing regions\nlow_performing_regions <- regional_performance %>%\n  filter(avg_profit_margin < 30) %>%\n  arrange(avg_profit_margin)\n\ncat(\"1. LOW PROFIT MARGIN REGIONS:\\n\")\nif(nrow(low_performing_regions) > 0) {\n  print(low_performing_regions)\n  cat(\"   \u2192 Action: Review pricing and cost structure in these regions\\n\\n\")\n} else {\n  cat(\"   All regions performing well\\n\\n\")\n}\n\n# TODO: Identify small deal concentration\nsmall_deal_pct <- (sum(sales_enhanced$deal_type == \"Small\") / nrow(sales_enhanced)) * 100\ncat(\"2. DEAL SIZE DISTRIBUTION:\\n\")\ncat(\"   Small deals:\", round(small_deal_pct, 1), \"%\\n\")\nif(small_deal_pct > 40) {\n  cat(\"   \u2192 Concern: High concentration of small deals\\n\")\n  cat(\"   \u2192 Action: Implement upselling strategies\\n\\n\")\n} else {\n  cat(\"   Deal size distribution is healthy\\n\\n\")\n}\n\n# TODO: Check customer value distribution\nbronze_pct <- (sum(sales_enhanced$customer_value_score == \"Bronze\") / nrow(sales_enhanced)) * 100\ncat(\"3. CUSTOMER VALUE CONCERNS:\\n\")\ncat(\"   Bronze customers:\", round(bronze_pct, 1), \"%\\n\")\nif(bronze_pct > 50) {\n  cat(\"   \u2192 Concern: Large proportion of low-value customers\\n\")\n  cat(\"   \u2192 Action: Develop customer upgrade programs\\n\\n\")\n} else {\n  cat(\"   Customer value distribution is acceptable\\n\\n\")\n}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part6_intro",
   "metadata": {},
   "source": [
    "## Part 6: Capstone Reflection Questions\n\nAnswer the following questions based on your comprehensive analysis. These questions assess your understanding of the entire data wrangling workflow and its business applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection1",
   "metadata": {},
   "source": [
    "### Question 6.1: Data Wrangling Workflow\n\n**Describe the complete data wrangling workflow you followed in this capstone project. What were the most critical steps, and why? How did each step build upon the previous one?**\n\nYour answer here:\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection2",
   "metadata": {},
   "source": [
    "### Question 6.2: Integration of Skills\n\n**How did you integrate string manipulation, date/time operations, and data transformation techniques in this project? Provide specific examples where combining these skills was essential for generating insights.**\n\nYour answer here:\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection3",
   "metadata": {},
   "source": [
    "### Question 6.3: Business Impact\n\n**Based on your analysis, what are the top 3 most impactful business recommendations you would make to the executive team? For each recommendation, explain:**\n- What data supports this recommendation?\n- What is the expected business impact?\n- How would you measure success?\n\nYour answer here:\n\n1. \n\n2. \n\n3. \n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection4",
   "metadata": {},
   "source": [
    "### Question 6.4: Data Quality Importance\n\n**Why was data quality validation critical in this project? What would have happened if you had skipped the validation steps? Provide specific examples of how data quality issues could have led to incorrect business decisions.**\n\nYour answer here:\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection5",
   "metadata": {},
   "source": [
    "### Question 6.5: Grouped Analysis Value\n\n**How did grouped analysis (group_by + summarize) help you uncover insights that wouldn't be visible in the raw data? Provide at least three specific examples from your analysis.**\n\nYour answer here:\n\n1. \n\n2. \n\n3. \n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection6",
   "metadata": {},
   "source": [
    "### Question 6.6: Conditional Logic Application\n\n**Explain how you used case_when() to create business categories (performance tiers, customer value scores, etc.). Why is this type of categorization important for business decision-making? How would you validate that your categorization logic is appropriate?**\n\nYour answer here:\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection7",
   "metadata": {},
   "source": [
    "### Question 6.7: Temporal Analysis Insights\n\n**What temporal patterns did you discover in the data (weekday, monthly, quarterly)? How can businesses use these patterns for operational planning, staffing, inventory management, and marketing timing?**\n\nYour answer here:\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection8",
   "metadata": {},
   "source": [
    "### Question 6.8: Professional Development\n\n**Reflect on your growth throughout this course. What data wrangling skills do you feel most confident about? What areas would you like to develop further? How will you apply these skills in your professional career?**\n\nYour answer here:\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## Summary and Submission\n\n### \ud83c\udf89 Congratulations on Completing the Capstone!\n\nYou have successfully completed a comprehensive data wrangling project that demonstrates mastery of:\n\n**Technical Skills:**\n- \u2705 Data import and validation\n- \u2705 Data transformation with dplyr (select, filter, arrange, mutate, summarize, group_by)\n- \u2705 String manipulation with stringr (cleaning, detection, extraction)\n- \u2705 Date/time operations with lubridate (parsing, extraction, calculations)\n- \u2705 Complex conditional logic with case_when()\n- \u2705 Multi-dimensional grouped analysis\n- \u2705 Data quality checks and validation\n- \u2705 Professional business intelligence reporting\n\n**Business Skills:**\n- \u2705 Customer segmentation and value scoring\n- \u2705 Performance analysis across multiple dimensions\n- \u2705 Temporal trend identification\n- \u2705 KPI calculation and tracking\n- \u2705 Strategic opportunity identification\n- \u2705 Data-driven recommendation development\n- \u2705 Executive-level communication\n\n**Professional Practices:**\n- \u2705 Systematic data quality validation\n- \u2705 Clear, well-commented code\n- \u2705 Reproducible analysis workflow\n- \u2705 Business context integration\n- \u2705 Professional presentation of results\n\n### \ud83d\udccb Submission Checklist\n\nBefore submitting, ensure you have:\n- [ ] Entered your name, student ID, and date at the top\n- [ ] Completed all code tasks (Parts 1-5)\n- [ ] Run all cells successfully without errors\n- [ ] Verified all calculated metrics are reasonable\n- [ ] Answered all 8 reflection questions thoroughly\n- [ ] Created all required dataframes with correct variable names:\n  - [ ] sales_enhanced (with all calculated columns)\n  - [ ] regional_performance\n  - [ ] category_performance\n  - [ ] sales_rep_performance\n  - [ ] monthly_trends\n  - [ ] weekday_patterns\n  - [ ] region_category_performance\n  - [ ] business_kpis\n- [ ] Used proper commenting throughout your code\n- [ ] Used the pipe operator (`%>%`) appropriately\n- [ ] Checked for any remaining TODO comments\n- [ ] Verified your business recommendations are data-driven\n\n### \ud83d\udcca Grading Criteria\n\nYour capstone will be evaluated on:\n\n**Code Correctness (35%)**\n- All tasks completed correctly\n- Proper use of dplyr, stringr, and lubridate functions\n- Accurate calculations and transformations\n- Correct implementation of business logic\n\n**Code Quality (20%)**\n- Clean, well-organized code\n- Meaningful variable names\n- Helpful comments explaining logic\n- Efficient use of pipe operator\n- Professional code structure\n\n**Business Analysis (25%)**\n- Demonstrates understanding of business context\n- Meaningful insights and patterns identified\n- Appropriate categorization and segmentation\n- Data-driven recommendations\n- Strategic thinking\n\n**Reflection Questions (15%)**\n- Thoughtful, complete answers\n- Demonstrates deep understanding\n- Provides specific examples\n- Shows critical thinking\n- Connects concepts to real-world applications\n\n**Presentation (5%)**\n- Professional formatting\n- Clear, organized output\n- Complete student information\n- No errors or warnings\n- Executive-ready quality\n\n### \ud83c\udfaf What's Next?\n\nWith these data wrangling skills, you're ready for:\n- **Advanced R Programming**: Functions, loops, and automation\n- **Data Visualization**: Creating compelling charts with ggplot2\n- **Statistical Analysis**: Hypothesis testing and modeling\n- **Machine Learning**: Predictive analytics and classification\n- **R Markdown Reports**: Automated, reproducible reporting\n- **Shiny Dashboards**: Interactive web applications\n\n### \ud83d\udcbc Career Applications\n\nThese skills are directly applicable to roles such as:\n- Data Analyst\n- Business Intelligence Analyst\n- Marketing Analyst\n- Operations Analyst\n- Financial Analyst\n- Data Scientist\n\n### \ud83d\ude4f Thank You!\n\nThank you for your dedication and hard work throughout this course. The data wrangling skills you've developed are foundational for any data-driven career. Keep practicing, keep learning, and keep asking great questions!\n\n**Best of luck with your data analytics journey! \ud83d\ude80**\n\n---\n\n**End of Capstone Project**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "name": "R",
   "version": "4.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}