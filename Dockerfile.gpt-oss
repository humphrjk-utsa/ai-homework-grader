# GPT-OSS Server Dockerfile
# Note: MLX only works on Apple Silicon Macs
FROM python:3.9-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    build-essential \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements
COPY requirements.txt .

# Install Python dependencies
RUN pip install --no-cache-dir -r requirements.txt

# Install MLX (Apple Silicon only)
# For non-Mac deployment, this will need to be replaced with alternative
RUN pip install --no-cache-dir mlx mlx-lm flask

# Copy server file
COPY gpt_oss_server_working.py .
COPY distributed_config.json .

# Expose port
EXPOSE 5001

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD curl -f http://localhost:5001/health || exit 1

# Environment variables
ENV MODEL_NAME=lmstudio-community/gpt-oss-120b-MLX-8bit
ENV MAX_TOKENS=800
ENV TEMPERATURE=0.3
ENV FLASK_ENV=production

# Run server
CMD ["python", "gpt_oss_server_working.py"]
