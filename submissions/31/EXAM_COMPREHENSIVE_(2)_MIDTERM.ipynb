{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# MIDTERM EXAM: Comprehensive R Data Wrangling Assessment\n",
    "\n",
    "**Student Name:** Vivianna Cowan\n",
    "\n",
    "**Student ID:** kxb432\n",
    "\n",
    "**Date:** 10/19/2025\n",
    "\n",
    "**Time Limit:** No Time Limit\n",
    "\n",
    "---\n",
    "\n",
    "## Exam Overview\n",
    "\n",
    "This comprehensive midterm exam assesses your mastery of ALL R data wrangling skills covered in Lessons 1-8:\n",
    "\n",
    "- **Lesson 1:** R Basics and Data Import\n",
    "- **Lesson 2:** Data Cleaning (Missing Values & Outliers)\n",
    "- **Lesson 3:** Data Transformation Part 1 (select, filter, arrange)\n",
    "- **Lesson 4:** Data Transformation Part 2 (mutate, summarize, group_by)\n",
    "- **Lesson 5:** Data Reshaping (pivot_longer, pivot_wider)\n",
    "- **Lesson 6:** Combining Datasets (joins)\n",
    "- **Lesson 7:** String Manipulation & Date/Time\n",
    "- **Lesson 8:** Advanced Wrangling & Best Practices\n",
    "\n",
    "## Business Scenario\n",
    "\n",
    "You are a data analyst for a retail company. The executive team needs a comprehensive analysis of:\n",
    "- Sales performance across products and regions\n",
    "- Customer behavior and segmentation\n",
    "- Data quality issues and recommendations\n",
    "- Strategic insights for business growth\n",
    "\n",
    "## Instructions\n",
    "\n",
    "1. **Set your working directory** to where your data files are located\n",
    "2. Complete ALL tasks in order\n",
    "3. Write code in the TODO sections\n",
    "4. Use the pipe operator (%>%) to chain operations\n",
    "5. Add comments explaining your logic\n",
    "6. Run all cells to verify your code works\n",
    "7. Answer all reflection questions\n",
    "\n",
    "## Grading\n",
    "\n",
    "- **Code Correctness (40%)**: All tasks completed correctly\n",
    "- **Code Quality (20%)**: Clean, well-commented code\n",
    "- **Business Understanding (20%)**: Demonstrates understanding of context\n",
    "- **Analysis & Insights (15%)**: Meaningful insights and recommendations\n",
    "- **Reflection Questions (5%)**: Thoughtful answers\n",
    "\n",
    "## Academic Integrity\n",
    "\n",
    "This is an individual exam. You may use:\n",
    "- Course notes and lesson materials\n",
    "- R documentation and help files\n",
    "- Your previous homework assignments\n",
    "\n",
    "You may NOT:\n",
    "- Collaborate with other students\n",
    "- Use AI assistants or online forums\n",
    "- Share code or solutions\n",
    "\n",
    "---\n",
    "\n",
    "**Good luck! ðŸŽ“**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part1_intro",
   "metadata": {},
   "source": [
    "## Part 1: R Basics and Data Import (Lesson 1)\n",
    "\n",
    "**Skills Assessed:** Variables, data types, data import, working directory\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Set working directory\n",
    "2. Load required packages\n",
    "3. Import multiple datasets\n",
    "4. Examine data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "setup",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'/workspaces/assignment-1-version-3-vivicowan/assignment/Midterm'"
      ],
      "text/latex": [
       "'/workspaces/assignment-1-version-3-vivicowan/assignment/Midterm'"
      ],
      "text/markdown": [
       "'/workspaces/assignment-1-version-3-vivicowan/assignment/Midterm'"
      ],
      "text/plain": [
       "[1] \"/workspaces/assignment-1-version-3-vivicowan/assignment/Midterm\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'/workspaces/assignment-1-version-3-vivicowan/data'"
      ],
      "text/latex": [
       "'/workspaces/assignment-1-version-3-vivicowan/data'"
      ],
      "text/markdown": [
       "'/workspaces/assignment-1-version-3-vivicowan/data'"
      ],
      "text/plain": [
       "[1] \"/workspaces/assignment-1-version-3-vivicowan/data\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /workspaces/assignment-1-version-3-vivicowan/data \n"
     ]
    }
   ],
   "source": [
    "# Task 1.1: Set Working Directory\n",
    "# TODO: Set your working directory to where your data files are located\n",
    "# IMPORTANT: Students must set their own path!\n",
    "# Example: setwd(\"/Users/yourname/GitHub/ai-homework-grader-clean/data\")\n",
    "\n",
    "# Your code here:\n",
    "getwd()\n",
    "setwd(\"/workspaces/assignment-1-version-3-vivicowan/data\")\n",
    "    getwd()\n",
    "\n",
    "# Verify working directory\n",
    "cat(\"Current working directory:\", getwd(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "load_packages",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "â”€â”€ \u001b[1mAttaching core tidyverse packages\u001b[22m â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse 2.0.0 â”€â”€\n",
      "\u001b[32mâœ”\u001b[39m \u001b[34mdplyr    \u001b[39m 1.1.4     \u001b[32mâœ”\u001b[39m \u001b[34mreadr    \u001b[39m 2.1.5\n",
      "\u001b[32mâœ”\u001b[39m \u001b[34mforcats  \u001b[39m 1.0.1     \u001b[32mâœ”\u001b[39m \u001b[34mstringr  \u001b[39m 1.5.2\n",
      "\u001b[32mâœ”\u001b[39m \u001b[34mggplot2  \u001b[39m 4.0.0     \u001b[32mâœ”\u001b[39m \u001b[34mtibble   \u001b[39m 3.3.0\n",
      "\u001b[32mâœ”\u001b[39m \u001b[34mlubridate\u001b[39m 1.9.4     \u001b[32mâœ”\u001b[39m \u001b[34mtidyr    \u001b[39m 1.3.1\n",
      "\u001b[32mâœ”\u001b[39m \u001b[34mpurrr    \u001b[39m 1.1.0     \n",
      "â”€â”€ \u001b[1mConflicts\u001b[22m â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse_conflicts() â”€â”€\n",
      "\u001b[31mâœ–\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31mâœ–\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\u001b[36mâ„¹\u001b[39m Use the conflicted package (\u001b[3m\u001b[34m<http://conflicted.r-lib.org/>\u001b[39m\u001b[23m) to force all conflicts to become errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Packages loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Task 1.2: Load Required Packages\n",
    "# TODO: Load tidyverse (includes dplyr, tidyr, stringr, ggplot2)\n",
    "library(tidyverse)\n",
    "\n",
    "# TODO: Load lubridate for date operations\n",
    "library(lubridate)\n",
    "\n",
    "cat(\"âœ… Packages loaded successfully!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "import_data",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mRows: \u001b[22m\u001b[34m300\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m8\u001b[39m\n",
      "\u001b[36mâ”€â”€\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m  (3): Sales_Rep_Name, Region, Product_Category\n",
      "\u001b[32mdbl\u001b[39m  (4): TransactionID, Revenue, Cost, Units_Sold\n",
      "\u001b[34mdate\u001b[39m (1): Sale_Date\n",
      "\n",
      "\u001b[36mâ„¹\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mâ„¹\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
      "\u001b[1mRows: \u001b[22m\u001b[34m100\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m5\u001b[39m\n",
      "\u001b[36mâ”€â”€\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m  (3): Name, Email, City\n",
      "\u001b[32mdbl\u001b[39m  (1): CustomerID\n",
      "\u001b[34mdate\u001b[39m (1): Registration_Date\n",
      "\n",
      "\u001b[36mâ„¹\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mâ„¹\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mRows: \u001b[22m\u001b[34m50\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m4\u001b[39m\n",
      "\u001b[36mâ”€â”€\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m (2): Product_Name, Category\n",
      "\u001b[32mdbl\u001b[39m (2): ProductID, Supplier_ID\n",
      "\n",
      "\u001b[36mâ„¹\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mâ„¹\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
      "\u001b[1mRows: \u001b[22m\u001b[34m250\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m4\u001b[39m\n",
      "\u001b[36mâ”€â”€\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[32mdbl\u001b[39m  (3): OrderID, CustomerID, Total_Amount\n",
      "\u001b[34mdate\u001b[39m (1): Order_Date\n",
      "\n",
      "\u001b[36mâ„¹\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mâ„¹\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
      "\u001b[1mRows: \u001b[22m\u001b[34m400\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m4\u001b[39m\n",
      "\u001b[36mâ”€â”€\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[32mdbl\u001b[39m (4): OrderID, ProductID, Quantity, Unit_Price\n",
      "\n",
      "\u001b[36mâ„¹\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mâ„¹\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data imported successfully!\n",
      "Sales data: 300 rows\n",
      "Customers: 100 rows\n",
      "Products: 50 rows\n",
      "Orders: 250 rows\n",
      "Order items: 400 rows\n"
     ]
    }
   ],
   "source": [
    "# Task 1.3: Import Datasets\n",
    "# TODO: Import the following CSV files using read_csv():\n",
    "#   - company_sales_data.csv -> sales_data\n",
    "#   - customers.csv -> customers\n",
    "#   - products.csv -> products\n",
    "#   - orders.csv -> orders\n",
    "#   - order_items.csv -> order_items\n",
    "\n",
    "# Your code here:\n",
    "sales_data <- read_csv(\"company_sales_data.csv\")\n",
    "\n",
    "customers <- read_csv(\"customers.csv\")\n",
    "\n",
    "products <- read_csv(\"products.csv\")\n",
    "\n",
    "orders <- read_csv(\"orders.csv\")\n",
    "\n",
    "order_items <- read_csv(\"order_items.csv\")\n",
    "\n",
    "\n",
    "# Display import summary\n",
    "cat(\"âœ… Data imported successfully!\\n\")\n",
    "cat(\"Sales data:\", nrow(sales_data), \"rows\\n\")\n",
    "cat(\"Customers:\", nrow(customers), \"rows\\n\")\n",
    "cat(\"Products:\", nrow(products), \"rows\\n\")\n",
    "cat(\"Orders:\", nrow(orders), \"rows\\n\")\n",
    "cat(\"Order items:\", nrow(order_items), \"rows\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part2_intro",
   "metadata": {},
   "source": [
    "## Part 2: Data Cleaning - Missing Values & Outliers (Lesson 2)\n",
    "\n",
    "**Skills Assessed:** Identifying NAs, handling missing data, detecting outliers\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Check for missing values in sales_data\n",
    "2. Handle missing values appropriately\n",
    "3. Identify outliers in Revenue column\n",
    "4. Create a cleaned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "check_missing",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 300 Ã— 8 of type lgl</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>TransactionID</th><th scope=col>Sales_Rep_Name</th><th scope=col>Region</th><th scope=col>Product_Category</th><th scope=col>Revenue</th><th scope=col>Cost</th><th scope=col>Units_Sold</th><th scope=col>Sale_Date</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>â‹®</td><td>â‹®</td><td>â‹®</td><td>â‹®</td><td>â‹®</td><td>â‹®</td><td>â‹®</td><td>â‹®</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "\t<tr><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td><td>FALSE</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 300 Ã— 8 of type lgl\n",
       "\\begin{tabular}{llllllll}\n",
       " TransactionID & Sales\\_Rep\\_Name & Region & Product\\_Category & Revenue & Cost & Units\\_Sold & Sale\\_Date\\\\\n",
       "\\hline\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t â‹® & â‹® & â‹® & â‹® & â‹® & â‹® & â‹® & â‹®\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\t FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE & FALSE\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 300 Ã— 8 of type lgl\n",
       "\n",
       "| TransactionID | Sales_Rep_Name | Region | Product_Category | Revenue | Cost | Units_Sold | Sale_Date |\n",
       "|---|---|---|---|---|---|---|---|\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| â‹® | â‹® | â‹® | â‹® | â‹® | â‹® | â‹® | â‹® |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "| FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | FALSE |\n",
       "\n"
      ],
      "text/plain": [
       "      TransactionID Sales_Rep_Name Region Product_Category Revenue Cost \n",
       " [1,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       " [2,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       " [3,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       " [4,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       " [5,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       " [6,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       " [7,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       " [8,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       " [9,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       "[10,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       "[11,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       "[12,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       "[13,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       "[14,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       "[15,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       "[16,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       "[17,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       "[18,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       "[19,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       "[20,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       "[21,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       "[22,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       "[23,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       "[24,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       "[25,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       "[26,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       "[27,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       "[28,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       "[29,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       "[30,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       "[31,] â‹®             â‹®              â‹®      â‹®                â‹®       â‹®    \n",
       "[32,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       "[33,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       "[34,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       "[35,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       "[36,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       "[37,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       "[38,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       "[39,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       "[40,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       "[41,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       "[42,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       "[43,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       "[44,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       "[45,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       "[46,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       "[47,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       "[48,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       "[49,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       "[50,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       "[51,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       "[52,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       "[53,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       "[54,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       "[55,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       "[56,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       "[57,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       "[58,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       "[59,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       "[60,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       "[61,] FALSE         FALSE          FALSE  FALSE            FALSE   FALSE\n",
       "      Units_Sold Sale_Date\n",
       " [1,] FALSE      FALSE    \n",
       " [2,] FALSE      FALSE    \n",
       " [3,] FALSE      FALSE    \n",
       " [4,] FALSE      FALSE    \n",
       " [5,] FALSE      FALSE    \n",
       " [6,] FALSE      FALSE    \n",
       " [7,] FALSE      FALSE    \n",
       " [8,] FALSE      FALSE    \n",
       " [9,] FALSE      FALSE    \n",
       "[10,] FALSE      FALSE    \n",
       "[11,] FALSE      FALSE    \n",
       "[12,] FALSE      FALSE    \n",
       "[13,] FALSE      FALSE    \n",
       "[14,] FALSE      FALSE    \n",
       "[15,] FALSE      FALSE    \n",
       "[16,] FALSE      FALSE    \n",
       "[17,] FALSE      FALSE    \n",
       "[18,] FALSE      FALSE    \n",
       "[19,] FALSE      FALSE    \n",
       "[20,] FALSE      FALSE    \n",
       "[21,] FALSE      FALSE    \n",
       "[22,] FALSE      FALSE    \n",
       "[23,] FALSE      FALSE    \n",
       "[24,] FALSE      FALSE    \n",
       "[25,] FALSE      FALSE    \n",
       "[26,] FALSE      FALSE    \n",
       "[27,] FALSE      FALSE    \n",
       "[28,] FALSE      FALSE    \n",
       "[29,] FALSE      FALSE    \n",
       "[30,] FALSE      FALSE    \n",
       "[31,] â‹®          â‹®        \n",
       "[32,] FALSE      FALSE    \n",
       "[33,] FALSE      FALSE    \n",
       "[34,] FALSE      FALSE    \n",
       "[35,] FALSE      FALSE    \n",
       "[36,] FALSE      FALSE    \n",
       "[37,] FALSE      FALSE    \n",
       "[38,] FALSE      FALSE    \n",
       "[39,] FALSE      FALSE    \n",
       "[40,] FALSE      FALSE    \n",
       "[41,] FALSE      FALSE    \n",
       "[42,] FALSE      FALSE    \n",
       "[43,] FALSE      FALSE    \n",
       "[44,] FALSE      FALSE    \n",
       "[45,] FALSE      FALSE    \n",
       "[46,] FALSE      FALSE    \n",
       "[47,] FALSE      FALSE    \n",
       "[48,] FALSE      FALSE    \n",
       "[49,] FALSE      FALSE    \n",
       "[50,] FALSE      FALSE    \n",
       "[51,] FALSE      FALSE    \n",
       "[52,] FALSE      FALSE    \n",
       "[53,] FALSE      FALSE    \n",
       "[54,] FALSE      FALSE    \n",
       "[55,] FALSE      FALSE    \n",
       "[56,] FALSE      FALSE    \n",
       "[57,] FALSE      FALSE    \n",
       "[58,] FALSE      FALSE    \n",
       "[59,] FALSE      FALSE    \n",
       "[60,] FALSE      FALSE    \n",
       "[61,] FALSE      FALSE    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== MISSING VALUES SUMMARY ==========\n",
      "[1] 0\n",
      "\n",
      "Total missing values: 0 \n"
     ]
    }
   ],
   "source": [
    "# Task 2.1: Check for Missing Values\n",
    "# TODO: Create 'missing_summary' that shows count of NAs in each column of sales_data\n",
    "\n",
    "is.na(sales_data)\n",
    "missing_summary <- sum(is.na(sales_data))\n",
    "\n",
    "\n",
    "cat(\"========== MISSING VALUES SUMMARY ==========\\n\")\n",
    "print(missing_summary)\n",
    "cat(\"\\nTotal missing values:\", sum(missing_summary), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "handle_missing",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== DATA CLEANING RESULTS ==========\n",
      "Original rows: 300 \n",
      "Cleaned rows: 300 \n",
      "Rows removed: 0 \n"
     ]
    }
   ],
   "source": [
    "# Task 2.2: Handle Missing Values\n",
    "# TODO: Create 'sales_clean' by removing rows with ANY missing values\n",
    "\n",
    "\n",
    "sales_clean <- na.omit(sales_data)\n",
    "\n",
    "\n",
    "cat(\"========== DATA CLEANING RESULTS ==========\\n\")\n",
    "cat(\"Original rows:\", nrow(sales_data), \"\\n\")\n",
    "cat(\"Cleaned rows:\", nrow(sales_clean), \"\\n\")\n",
    "cat(\"Rows removed:\", nrow(sales_data) - nrow(sales_clean), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "detect_outliers",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== OUTLIER ANALYSIS ==========\n",
      "       Metric     Value\n",
      "1          Q1  15034.29\n",
      "2          Q3  37707.71\n",
      "3         IQR  22673.42\n",
      "4 Lower Bound -18975.84\n",
      "5 Upper Bound  71717.84\n",
      "\n",
      "Number of outliers detected: 0 \n"
     ]
    }
   ],
   "source": [
    "# Task 2.3: Detect Outliers in Revenue\n",
    "# TODO: Calculate outlier thresholds using IQR method\n",
    "#   - Calculate Q1 (25th percentile) and Q3 (75th percentile) of Revenue\n",
    "#   - Calculate IQR = Q3 - Q1\n",
    "#   - Lower bound = Q1 - 1.5 * IQR\n",
    "#   - Upper bound = Q3 + 1.5 * IQR\n",
    "# TODO: Create 'outlier_analysis' dataframe with these values\n",
    "\n",
    "Q1 <- quantile(sales_clean$Revenue, 0.25)\n",
    "Q3 <- quantile(sales_clean$Revenue, 0.75)\n",
    "IQR_value <- Q3 - Q1\n",
    "lower_bound <- Q1 - 1.5 * IQR_value\n",
    "upper_bound <- Q3 + 1.5 * IQR_value\n",
    "\n",
    "outlier_analysis <- data.frame(\n",
    "  Metric = c(\"Q1\", \"Q3\", \"IQR\", \"Lower Bound\", \"Upper Bound\"),\n",
    "  Value = c(Q1, Q3, IQR_value, lower_bound, upper_bound)\n",
    ")\n",
    "\n",
    "cat(\"========== OUTLIER ANALYSIS ==========\\n\")\n",
    "print(outlier_analysis)\n",
    "\n",
    "# Count outliers\n",
    "outlier_count <- sum(sales_clean$Revenue < lower_bound | sales_clean$Revenue > upper_bound)\n",
    "cat(\"\\nNumber of outliers detected:\", outlier_count, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part3_intro",
   "metadata": {},
   "source": [
    "## Part 3: Data Transformation Part 1 (Lesson 3)\n",
    "\n",
    "**Skills Assessed:** select(), filter(), arrange(), pipe operator\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Select specific columns\n",
    "2. Filter data by conditions\n",
    "3. Sort data\n",
    "4. Chain operations with pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "select_columns",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== SELECTED COLUMNS ==========\n",
      "Columns: Region Product_Category Revenue Units_Sold Sale_Date \n",
      "Rows: 300 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 5 Ã— 5</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>Region</th><th scope=col>Product_Category</th><th scope=col>Revenue</th><th scope=col>Units_Sold</th><th scope=col>Sale_Date</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;date&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>Latin America</td><td>Services</td><td>20750.92</td><td>78</td><td>2023-04-24</td></tr>\n",
       "\t<tr><td>Europe       </td><td>Hardware</td><td>32359.98</td><td>13</td><td>2023-06-09</td></tr>\n",
       "\t<tr><td>Europe       </td><td>Services</td><td>39268.40</td><td>34</td><td>2023-03-25</td></tr>\n",
       "\t<tr><td>Europe       </td><td>Hardware</td><td>28865.09</td><td>90</td><td>2023-04-11</td></tr>\n",
       "\t<tr><td>Latin America</td><td>Software</td><td> 3932.36</td><td>63</td><td>2023-08-26</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 5 Ã— 5\n",
       "\\begin{tabular}{lllll}\n",
       " Region & Product\\_Category & Revenue & Units\\_Sold & Sale\\_Date\\\\\n",
       " <chr> & <chr> & <dbl> & <dbl> & <date>\\\\\n",
       "\\hline\n",
       "\t Latin America & Services & 20750.92 & 78 & 2023-04-24\\\\\n",
       "\t Europe        & Hardware & 32359.98 & 13 & 2023-06-09\\\\\n",
       "\t Europe        & Services & 39268.40 & 34 & 2023-03-25\\\\\n",
       "\t Europe        & Hardware & 28865.09 & 90 & 2023-04-11\\\\\n",
       "\t Latin America & Software &  3932.36 & 63 & 2023-08-26\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 5 Ã— 5\n",
       "\n",
       "| Region &lt;chr&gt; | Product_Category &lt;chr&gt; | Revenue &lt;dbl&gt; | Units_Sold &lt;dbl&gt; | Sale_Date &lt;date&gt; |\n",
       "|---|---|---|---|---|\n",
       "| Latin America | Services | 20750.92 | 78 | 2023-04-24 |\n",
       "| Europe        | Hardware | 32359.98 | 13 | 2023-06-09 |\n",
       "| Europe        | Services | 39268.40 | 34 | 2023-03-25 |\n",
       "| Europe        | Hardware | 28865.09 | 90 | 2023-04-11 |\n",
       "| Latin America | Software |  3932.36 | 63 | 2023-08-26 |\n",
       "\n"
      ],
      "text/plain": [
       "  Region        Product_Category Revenue  Units_Sold Sale_Date \n",
       "1 Latin America Services         20750.92 78         2023-04-24\n",
       "2 Europe        Hardware         32359.98 13         2023-06-09\n",
       "3 Europe        Services         39268.40 34         2023-03-25\n",
       "4 Europe        Hardware         28865.09 90         2023-04-11\n",
       "5 Latin America Software          3932.36 63         2023-08-26"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Task 3.1: Select Specific Columns\n",
    "# TODO: Create 'sales_summary' with only these columns from sales_clean:\n",
    "#   Region, Product_Category, Revenue, Units_Sold, Sale_Date\n",
    "\n",
    "\n",
    "sales_summary <- sales_clean %>%\n",
    "  # Your code here:\n",
    "  select(Region, Product_Category, Revenue, Units_Sold, Sale_Date)\n",
    "\n",
    "cat(\"========== SELECTED COLUMNS ==========\\n\")\n",
    "cat(\"Columns:\", names(sales_summary), \"\\n\")\n",
    "cat(\"Rows:\", nrow(sales_summary), \"\\n\")\n",
    "head(sales_summary, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "filter_data",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== HIGH REVENUE SALES ==========\n",
      "Total high revenue transactions: 194 \n",
      "Total revenue from these sales: $ 6671906 \n"
     ]
    }
   ],
   "source": [
    "# Task 3.2: Filter High Revenue Sales\n",
    "# TODO: Create 'high_revenue_sales' by filtering sales_clean for Revenue > 20000\n",
    "\n",
    "\n",
    "high_revenue_sales <- sales_clean %>%\n",
    "  # Your code here:\n",
    "  filter(Revenue > 20000)\n",
    "\n",
    "cat(\"========== HIGH REVENUE SALES ==========\\n\")\n",
    "cat(\"Total high revenue transactions:\", nrow(high_revenue_sales), \"\\n\")\n",
    "cat(\"Total revenue from these sales: $\", sum(high_revenue_sales$Revenue), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "sort_data",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== TOP 10 SALES ==========\n",
      "\u001b[90m# A tibble: 300 Ã— 4\u001b[39m\n",
      "   Region        Product_Category Revenue Units_Sold\n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m         \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m              \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m      \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m Asia Pacific  Consulting        \u001b[4m4\u001b[24m\u001b[4m9\u001b[24m956.         88\n",
      "\u001b[90m 2\u001b[39m Europe        Software          \u001b[4m4\u001b[24m\u001b[4m9\u001b[24m867.         96\n",
      "\u001b[90m 3\u001b[39m Europe        Consulting        \u001b[4m4\u001b[24m\u001b[4m9\u001b[24m857.          1\n",
      "\u001b[90m 4\u001b[39m Asia Pacific  Consulting        \u001b[4m4\u001b[24m\u001b[4m9\u001b[24m239.         72\n",
      "\u001b[90m 5\u001b[39m Asia Pacific  Hardware          \u001b[4m4\u001b[24m\u001b[4m8\u001b[24m997.         92\n",
      "\u001b[90m 6\u001b[39m North America Services          \u001b[4m4\u001b[24m\u001b[4m8\u001b[24m884.         62\n",
      "\u001b[90m 7\u001b[39m Europe        Software          \u001b[4m4\u001b[24m\u001b[4m8\u001b[24m794.         77\n",
      "\u001b[90m 8\u001b[39m North America Hardware          \u001b[4m4\u001b[24m\u001b[4m8\u001b[24m772.         16\n",
      "\u001b[90m 9\u001b[39m North America Consulting        \u001b[4m4\u001b[24m\u001b[4m8\u001b[24m748.         63\n",
      "\u001b[90m10\u001b[39m Europe        Consulting        \u001b[4m4\u001b[24m\u001b[4m8\u001b[24m572.         22\n",
      "\u001b[90m# â„¹ 290 more rows\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "# Task 3.3: Sort by Revenue\n",
    "# TODO: Create 'top_sales' by arranging sales_clean by Revenue in descending order\n",
    "#       and keeping only the top 10 rows\n",
    "\n",
    "\n",
    "top_sales <- sales_clean %>%\n",
    "  # Your code here:\n",
    "  arrange(desc(Revenue))\n",
    "\n",
    "cat(\"========== TOP 10 SALES ==========\\n\")\n",
    "print(top_sales %>% select(Region, Product_Category, Revenue, Units_Sold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "chain_operations",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== REGIONAL TOP SALES ==========\n",
      "\u001b[90m# A tibble: 15 Ã— 3\u001b[39m\n",
      "   Region        Product_Category Revenue\n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m         \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m              \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m Asia Pacific  Consulting        \u001b[4m4\u001b[24m\u001b[4m9\u001b[24m956.\n",
      "\u001b[90m 2\u001b[39m Europe        Software          \u001b[4m4\u001b[24m\u001b[4m9\u001b[24m867.\n",
      "\u001b[90m 3\u001b[39m Europe        Consulting        \u001b[4m4\u001b[24m\u001b[4m9\u001b[24m857.\n",
      "\u001b[90m 4\u001b[39m Asia Pacific  Consulting        \u001b[4m4\u001b[24m\u001b[4m9\u001b[24m239.\n",
      "\u001b[90m 5\u001b[39m Asia Pacific  Hardware          \u001b[4m4\u001b[24m\u001b[4m8\u001b[24m997.\n",
      "\u001b[90m 6\u001b[39m North America Services          \u001b[4m4\u001b[24m\u001b[4m8\u001b[24m884.\n",
      "\u001b[90m 7\u001b[39m Europe        Software          \u001b[4m4\u001b[24m\u001b[4m8\u001b[24m794.\n",
      "\u001b[90m 8\u001b[39m North America Hardware          \u001b[4m4\u001b[24m\u001b[4m8\u001b[24m772.\n",
      "\u001b[90m 9\u001b[39m North America Consulting        \u001b[4m4\u001b[24m\u001b[4m8\u001b[24m748.\n",
      "\u001b[90m10\u001b[39m Europe        Consulting        \u001b[4m4\u001b[24m\u001b[4m8\u001b[24m572.\n",
      "\u001b[90m11\u001b[39m Europe        Hardware          \u001b[4m4\u001b[24m\u001b[4m8\u001b[24m529.\n",
      "\u001b[90m12\u001b[39m Latin America Services          \u001b[4m4\u001b[24m\u001b[4m8\u001b[24m210.\n",
      "\u001b[90m13\u001b[39m Asia Pacific  Consulting        \u001b[4m4\u001b[24m\u001b[4m8\u001b[24m063.\n",
      "\u001b[90m14\u001b[39m Europe        Hardware          \u001b[4m4\u001b[24m\u001b[4m8\u001b[24m043.\n",
      "\u001b[90m15\u001b[39m North America Services          \u001b[4m4\u001b[24m\u001b[4m7\u001b[24m896.\n"
     ]
    }
   ],
   "source": [
    "# Task 3.4: Chain Multiple Operations\n",
    "# TODO: Create 'regional_top_sales' by:\n",
    "#   1. Filtering for Revenue > 15000\n",
    "#   2. Selecting: Region, Product_Category, Revenue\n",
    "#   3. Arranging by Region (ascending) then Revenue (descending)\n",
    "#   4. Keeping top 15 rows\n",
    "# Use the pipe operator to chain all operations\n",
    "\n",
    "regional_top_sales <- sales_clean %>%\n",
    "  # Your code here:\n",
    "  select(Region, Product_Category, Revenue) %>%\n",
    "  filter(Revenue > 15000) %>%\n",
    "  arrange(Region) %>%\n",
    "  arrange(desc(Revenue)) %>%\n",
    "  slice(1:15)\n",
    "  \n",
    " \n",
    "\n",
    "cat(\"========== REGIONAL TOP SALES ==========\\n\")\n",
    "print(regional_top_sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part4_intro",
   "metadata": {},
   "source": [
    "## Part 4: Data Transformation Part 2 (Lesson 4)\n",
    "\n",
    "**Skills Assessed:** mutate(), summarize(), group_by()\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Create calculated columns with mutate()\n",
    "2. Calculate summary statistics\n",
    "3. Perform grouped analysis\n",
    "4. Generate business metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "mutate_columns",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== ENHANCED SALES DATA ==========\n",
      "New columns added: revenue_per_unit, high_value\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 5 Ã— 4</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>Revenue</th><th scope=col>Units_Sold</th><th scope=col>revenue_per_unit</th><th scope=col>high_value</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;lgl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>20750.92</td><td>78</td><td> 266.03744</td><td> TRUE</td></tr>\n",
       "\t<tr><td>32359.98</td><td>13</td><td>2489.22923</td><td> TRUE</td></tr>\n",
       "\t<tr><td>39268.40</td><td>34</td><td>1154.95294</td><td> TRUE</td></tr>\n",
       "\t<tr><td>28865.09</td><td>90</td><td> 320.72322</td><td> TRUE</td></tr>\n",
       "\t<tr><td> 3932.36</td><td>63</td><td>  62.41841</td><td>FALSE</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 5 Ã— 4\n",
       "\\begin{tabular}{llll}\n",
       " Revenue & Units\\_Sold & revenue\\_per\\_unit & high\\_value\\\\\n",
       " <dbl> & <dbl> & <dbl> & <lgl>\\\\\n",
       "\\hline\n",
       "\t 20750.92 & 78 &  266.03744 &  TRUE\\\\\n",
       "\t 32359.98 & 13 & 2489.22923 &  TRUE\\\\\n",
       "\t 39268.40 & 34 & 1154.95294 &  TRUE\\\\\n",
       "\t 28865.09 & 90 &  320.72322 &  TRUE\\\\\n",
       "\t  3932.36 & 63 &   62.41841 & FALSE\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 5 Ã— 4\n",
       "\n",
       "| Revenue &lt;dbl&gt; | Units_Sold &lt;dbl&gt; | revenue_per_unit &lt;dbl&gt; | high_value &lt;lgl&gt; |\n",
       "|---|---|---|---|\n",
       "| 20750.92 | 78 |  266.03744 |  TRUE |\n",
       "| 32359.98 | 13 | 2489.22923 |  TRUE |\n",
       "| 39268.40 | 34 | 1154.95294 |  TRUE |\n",
       "| 28865.09 | 90 |  320.72322 |  TRUE |\n",
       "|  3932.36 | 63 |   62.41841 | FALSE |\n",
       "\n"
      ],
      "text/plain": [
       "  Revenue  Units_Sold revenue_per_unit high_value\n",
       "1 20750.92 78          266.03744        TRUE     \n",
       "2 32359.98 13         2489.22923        TRUE     \n",
       "3 39268.40 34         1154.95294        TRUE     \n",
       "4 28865.09 90          320.72322        TRUE     \n",
       "5  3932.36 63           62.41841       FALSE     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Task 4.1: Create Calculated Columns\n",
    "# TODO: Add these new columns to sales_clean using mutate():\n",
    "#   - revenue_per_unit: Revenue / Units_Sold\n",
    "#   - high_value: \"Yes\" if Revenue > 20000, else \"No\"\n",
    "# Store result in 'sales_enhanced'\n",
    "\n",
    "sales_enhanced <- sales_clean %>%\n",
    "  mutate(\n",
    "    # Your code here:\n",
    "    revenue_per_unit = Revenue / Units_Sold,\n",
    "    high_value = Revenue > 20000\n",
    "  )\n",
    "\n",
    "cat(\"========== ENHANCED SALES DATA ==========\\n\")\n",
    "cat(\"New columns added: revenue_per_unit, high_value\\n\")\n",
    "head(sales_enhanced %>% select(Revenue, Units_Sold, revenue_per_unit, high_value), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "summarize_data",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== OVERALL SUMMARY ==========\n",
      "\u001b[90m# A tibble: 1 Ã— 4\u001b[39m\n",
      "  total_revenue avg_revenue total_units transaction_count\n",
      "          \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m       \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m       \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m             \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m      7\u001b[4m7\u001b[24m\u001b[4m7\u001b[24m\u001b[4m1\u001b[24m711.      \u001b[4m2\u001b[24m\u001b[4m5\u001b[24m906.       \u001b[4m1\u001b[24m\u001b[4m6\u001b[24m169               300\n"
     ]
    }
   ],
   "source": [
    "# Task 4.2: Calculate Overall Summary Statistics\n",
    "# TODO: Create 'overall_summary' with these metrics from sales_enhanced:\n",
    "#   - total_revenue: sum of Revenue\n",
    "#   - avg_revenue: mean of Revenue\n",
    "#   - total_units: sum of Units_Sold\n",
    "#   - transaction_count: count using n()\n",
    "\n",
    "\n",
    "overall_summary <- sales_enhanced %>%\n",
    "  \n",
    "    # Your code here:\n",
    "    summarise(\n",
    "        total_revenue = sum(Revenue),\n",
    "        avg_revenue = mean(Revenue),\n",
    "        total_units = sum(Units_Sold),\n",
    "        transaction_count = n()\n",
    "\n",
    "    )\n",
    "  \n",
    "\n",
    "cat(\"========== OVERALL SUMMARY ==========\\n\")\n",
    "print(overall_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "group_by_region",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== REGIONAL SUMMARY ==========\n",
      "\u001b[90m# A tibble: 4 Ã— 4\u001b[39m\n",
      "  Region        total_revenue avg_revenue transaction_count\n",
      "  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                 \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m       \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m             \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m Europe             2\u001b[4m2\u001b[24m\u001b[4m2\u001b[24m\u001b[4m4\u001b[24m182.      \u001b[4m2\u001b[24m\u001b[4m7\u001b[24m124.                82\n",
      "\u001b[90m2\u001b[39m Latin America      2\u001b[4m1\u001b[24m\u001b[4m1\u001b[24m\u001b[4m2\u001b[24m037.      \u001b[4m2\u001b[24m\u001b[4m5\u001b[24m446.                83\n",
      "\u001b[90m3\u001b[39m Asia Pacific       1\u001b[4m8\u001b[24m\u001b[4m0\u001b[24m\u001b[4m4\u001b[24m243.      \u001b[4m2\u001b[24m\u001b[4m6\u001b[24m929.                67\n",
      "\u001b[90m4\u001b[39m North America      1\u001b[4m6\u001b[24m\u001b[4m3\u001b[24m\u001b[4m1\u001b[24m248.      \u001b[4m2\u001b[24m\u001b[4m3\u001b[24m989.                68\n"
     ]
    }
   ],
   "source": [
    "# Task 4.3: Regional Performance Analysis\n",
    "# TODO: Create 'regional_summary' by grouping sales_enhanced by Region\n",
    "#       and calculating:\n",
    "#   - total_revenue: sum of Revenue\n",
    "#   - avg_revenue: mean of Revenue\n",
    "#   - transaction_count: count using n()\n",
    "# Then arrange by total_revenue descending\n",
    "# Hint: Use group_by() %>% summarize() %>% arrange()\n",
    "\n",
    "regional_summary <- sales_enhanced %>%\n",
    "  # Your code here:\n",
    "  group_by(Region) %>%\n",
    "  summarise(\n",
    "    total_revenue = sum(Revenue),\n",
    "    avg_revenue = mean(Revenue),\n",
    "    transaction_count = n()\n",
    "  ) %>%\n",
    "  arrange(desc(total_revenue))\n",
    "\n",
    "cat(\"========== REGIONAL SUMMARY ==========\\n\")\n",
    "print(regional_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "group_by_category",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== CATEGORY SUMMARY ==========\n",
      "\u001b[90m# A tibble: 4 Ã— 4\u001b[39m\n",
      "  Product_Category total_revenue avg_revenue transaction_count\n",
      "  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                    \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m       \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m             \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m Consulting            1\u001b[4m9\u001b[24m\u001b[4m7\u001b[24m\u001b[4m8\u001b[24m840.      \u001b[4m2\u001b[24m\u001b[4m6\u001b[24m037.                76\n",
      "\u001b[90m2\u001b[39m Services              1\u001b[4m9\u001b[24m\u001b[4m6\u001b[24m\u001b[4m1\u001b[24m565.      \u001b[4m2\u001b[24m\u001b[4m7\u001b[24m244.                72\n",
      "\u001b[90m3\u001b[39m Hardware              1\u001b[4m9\u001b[24m\u001b[4m5\u001b[24m\u001b[4m1\u001b[24m325.      \u001b[4m2\u001b[24m\u001b[4m6\u001b[24m730.                73\n",
      "\u001b[90m4\u001b[39m Software              1\u001b[4m8\u001b[24m\u001b[4m7\u001b[24m\u001b[4m9\u001b[24m981.      \u001b[4m2\u001b[24m\u001b[4m3\u001b[24m797.                79\n"
     ]
    }
   ],
   "source": [
    "# Task 4.4: Product Category Analysis\n",
    "# TODO: Create 'category_summary' by grouping by Product_Category\n",
    "#       and calculating the same metrics as regional_summary\n",
    "#       Then arrange by total_revenue descending\n",
    "\n",
    "category_summary <- sales_enhanced %>%\n",
    "  # Your code here:\n",
    "  group_by(Product_Category) %>%\n",
    "  summarise(\n",
    "    total_revenue = sum(Revenue),\n",
    "    avg_revenue = mean(Revenue),\n",
    "    transaction_count = n()\n",
    "  ) %>%\n",
    "  arrange(desc(total_revenue))\n",
    "\n",
    "cat(\"========== CATEGORY SUMMARY ==========\\n\")\n",
    "print(category_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part5_intro",
   "metadata": {},
   "source": [
    "## Part 5: Data Reshaping with tidyr (Lesson 5)\n",
    "\n",
    "**Skills Assessed:** pivot_longer(), pivot_wider(), tidy data principles\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Reshape data from wide to long format\n",
    "2. Reshape data from long to wide format\n",
    "3. Create analysis-ready datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "create_wide_data",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== REGION-CATEGORY DATA (LONG FORMAT) ==========\n",
      "\u001b[90m# A tibble: 10 Ã— 3\u001b[39m\n",
      "   Region        Product_Category total_revenue\n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m         \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                    \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m Asia Pacific  Consulting             \u001b[4m7\u001b[24m\u001b[4m5\u001b[24m\u001b[4m9\u001b[24m641.\n",
      "\u001b[90m 2\u001b[39m Asia Pacific  Hardware               \u001b[4m2\u001b[24m\u001b[4m7\u001b[24m\u001b[4m1\u001b[24m979.\n",
      "\u001b[90m 3\u001b[39m Asia Pacific  Services               \u001b[4m3\u001b[24m\u001b[4m3\u001b[24m\u001b[4m1\u001b[24m826.\n",
      "\u001b[90m 4\u001b[39m Asia Pacific  Software               \u001b[4m4\u001b[24m\u001b[4m4\u001b[24m\u001b[4m0\u001b[24m797.\n",
      "\u001b[90m 5\u001b[39m Europe        Consulting             \u001b[4m3\u001b[24m\u001b[4m9\u001b[24m\u001b[4m0\u001b[24m670.\n",
      "\u001b[90m 6\u001b[39m Europe        Hardware               \u001b[4m7\u001b[24m\u001b[4m7\u001b[24m\u001b[4m7\u001b[24m044.\n",
      "\u001b[90m 7\u001b[39m Europe        Services               \u001b[4m5\u001b[24m\u001b[4m1\u001b[24m\u001b[4m3\u001b[24m507.\n",
      "\u001b[90m 8\u001b[39m Europe        Software               \u001b[4m5\u001b[24m\u001b[4m4\u001b[24m\u001b[4m2\u001b[24m961.\n",
      "\u001b[90m 9\u001b[39m Latin America Consulting             \u001b[4m4\u001b[24m\u001b[4m3\u001b[24m\u001b[4m3\u001b[24m397.\n",
      "\u001b[90m10\u001b[39m Latin America Hardware               \u001b[4m4\u001b[24m\u001b[4m7\u001b[24m\u001b[4m4\u001b[24m257.\n"
     ]
    }
   ],
   "source": [
    "# Task 5.1: Create Wide Format Data\n",
    "# First, create a summary by Region and Product_Category\n",
    "region_category_revenue <- sales_enhanced %>%\n",
    "  group_by(Region, Product_Category) %>%\n",
    "  summarize(total_revenue = sum(Revenue), .groups = 'drop')\n",
    "\n",
    "cat(\"========== REGION-CATEGORY DATA (LONG FORMAT) ==========\\n\")\n",
    "print(head(region_category_revenue, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "pivot_wider",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== REVENUE DATA (WIDE FORMAT) ==========\n",
      "\u001b[90m# A tibble: 4 Ã— 5\u001b[39m\n",
      "  Region        Consulting Hardware Services Software\n",
      "  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m              \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m    \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m    \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m    \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m Asia Pacific     \u001b[4m7\u001b[24m\u001b[4m5\u001b[24m\u001b[4m9\u001b[24m641.  \u001b[4m2\u001b[24m\u001b[4m7\u001b[24m\u001b[4m1\u001b[24m979.  \u001b[4m3\u001b[24m\u001b[4m3\u001b[24m\u001b[4m1\u001b[24m826.  \u001b[4m4\u001b[24m\u001b[4m4\u001b[24m\u001b[4m0\u001b[24m797.\n",
      "\u001b[90m2\u001b[39m Europe           \u001b[4m3\u001b[24m\u001b[4m9\u001b[24m\u001b[4m0\u001b[24m670.  \u001b[4m7\u001b[24m\u001b[4m7\u001b[24m\u001b[4m7\u001b[24m044.  \u001b[4m5\u001b[24m\u001b[4m1\u001b[24m\u001b[4m3\u001b[24m507.  \u001b[4m5\u001b[24m\u001b[4m4\u001b[24m\u001b[4m2\u001b[24m961.\n",
      "\u001b[90m3\u001b[39m Latin America    \u001b[4m4\u001b[24m\u001b[4m3\u001b[24m\u001b[4m3\u001b[24m397.  \u001b[4m4\u001b[24m\u001b[4m7\u001b[24m\u001b[4m4\u001b[24m257.  \u001b[4m6\u001b[24m\u001b[4m4\u001b[24m\u001b[4m4\u001b[24m772.  \u001b[4m5\u001b[24m\u001b[4m5\u001b[24m\u001b[4m9\u001b[24m611.\n",
      "\u001b[90m4\u001b[39m North America    \u001b[4m3\u001b[24m\u001b[4m9\u001b[24m\u001b[4m5\u001b[24m132.  \u001b[4m4\u001b[24m\u001b[4m2\u001b[24m\u001b[4m8\u001b[24m046.  \u001b[4m4\u001b[24m\u001b[4m7\u001b[24m\u001b[4m1\u001b[24m460.  \u001b[4m3\u001b[24m\u001b[4m3\u001b[24m\u001b[4m6\u001b[24m611.\n"
     ]
    }
   ],
   "source": [
    "# Task 5.2: Reshape to Wide Format\n",
    "# TODO: Create 'revenue_wide' by pivoting region_category_revenue\n",
    "#       so that Product_Category values become column names\n",
    "#       with total_revenue as the values\n",
    "\n",
    "\n",
    "revenue_wide <- region_category_revenue %>%\n",
    "  # Your code here:\n",
    "  pivot_wider(\n",
    "    names_from = \"Product_Category\",\n",
    "    values_from = \"total_revenue\"\n",
    "  )\n",
    "\n",
    "cat(\"========== REVENUE DATA (WIDE FORMAT) ==========\\n\")\n",
    "print(revenue_wide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "pivot_longer",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== REVENUE DATA (BACK TO LONG FORMAT) ==========\n",
      "\u001b[90m# A tibble: 10 Ã— 3\u001b[39m\n",
      "   Region        Product_Category revenue\n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m         \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m              \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m Asia Pacific  Consulting       \u001b[4m7\u001b[24m\u001b[4m5\u001b[24m\u001b[4m9\u001b[24m641.\n",
      "\u001b[90m 2\u001b[39m Asia Pacific  Hardware         \u001b[4m2\u001b[24m\u001b[4m7\u001b[24m\u001b[4m1\u001b[24m979.\n",
      "\u001b[90m 3\u001b[39m Asia Pacific  Services         \u001b[4m3\u001b[24m\u001b[4m3\u001b[24m\u001b[4m1\u001b[24m826.\n",
      "\u001b[90m 4\u001b[39m Asia Pacific  Software         \u001b[4m4\u001b[24m\u001b[4m4\u001b[24m\u001b[4m0\u001b[24m797.\n",
      "\u001b[90m 5\u001b[39m Europe        Consulting       \u001b[4m3\u001b[24m\u001b[4m9\u001b[24m\u001b[4m0\u001b[24m670.\n",
      "\u001b[90m 6\u001b[39m Europe        Hardware         \u001b[4m7\u001b[24m\u001b[4m7\u001b[24m\u001b[4m7\u001b[24m044.\n",
      "\u001b[90m 7\u001b[39m Europe        Services         \u001b[4m5\u001b[24m\u001b[4m1\u001b[24m\u001b[4m3\u001b[24m507.\n",
      "\u001b[90m 8\u001b[39m Europe        Software         \u001b[4m5\u001b[24m\u001b[4m4\u001b[24m\u001b[4m2\u001b[24m961.\n",
      "\u001b[90m 9\u001b[39m Latin America Consulting       \u001b[4m4\u001b[24m\u001b[4m3\u001b[24m\u001b[4m3\u001b[24m397.\n",
      "\u001b[90m10\u001b[39m Latin America Hardware         \u001b[4m4\u001b[24m\u001b[4m7\u001b[24m\u001b[4m4\u001b[24m257.\n"
     ]
    }
   ],
   "source": [
    "# Task 5.3: Reshape Back to Long Format\n",
    "# TODO: Create 'revenue_long' by pivoting revenue_wide back to long format\n",
    "#       Column names (except Region) should go into 'Product_Category'\n",
    "#       Values should go into 'revenue'\n",
    "\n",
    "\n",
    "revenue_long <- revenue_wide %>%\n",
    "  # Your code here:\n",
    "  pivot_longer(\n",
    "    cols = -Region,\n",
    "    names_to = \"Product_Category\",\n",
    "    values_to = \"revenue\"\n",
    "  )\n",
    "\n",
    "cat(\"========== REVENUE DATA (BACK TO LONG FORMAT) ==========\\n\")\n",
    "print(head(revenue_long, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part6_intro",
   "metadata": {},
   "source": [
    "## Part 6: Combining Datasets with Joins (Lesson 6)\n",
    "\n",
    "**Skills Assessed:** left_join(), inner_join(), data integration\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Join customers with orders\n",
    "2. Join orders with order_items\n",
    "3. Create integrated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "join_customers_orders",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== CUSTOMER ORDERS ==========\n",
      "Total rows: 200 \n",
      "Columns: 8 \n"
     ]
    }
   ],
   "source": [
    "# Task 6.1: Join Customers and Orders\n",
    "# TODO: Create 'customer_orders' by left joining customers with orders\n",
    "#       Join on CustomerID\n",
    "\n",
    "\n",
    "customer_orders <- left_join(customers, orders, by = \"CustomerID\")\n",
    "\n",
    "\n",
    "cat(\"========== CUSTOMER ORDERS ==========\\n\")\n",
    "cat(\"Total rows:\", nrow(customer_orders), \"\\n\")\n",
    "cat(\"Columns:\", ncol(customer_orders), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "join_orders_items",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== ORDERS WITH ITEMS ==========\n",
      "Total rows: 400 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 5 Ã— 7</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>OrderID</th><th scope=col>CustomerID</th><th scope=col>Order_Date</th><th scope=col>Total_Amount</th><th scope=col>ProductID</th><th scope=col>Quantity</th><th scope=col>Unit_Price</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;date&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>1</td><td> 87</td><td>2023-08-30</td><td>424.30</td><td> 2</td><td>3</td><td>115.72</td></tr>\n",
       "\t<tr><td>1</td><td> 87</td><td>2023-08-30</td><td>424.30</td><td>22</td><td>5</td><td>206.62</td></tr>\n",
       "\t<tr><td>1</td><td> 87</td><td>2023-08-30</td><td>424.30</td><td>26</td><td>5</td><td> 61.75</td></tr>\n",
       "\t<tr><td>3</td><td> 37</td><td>2024-03-19</td><td>549.07</td><td>19</td><td>1</td><td>474.92</td></tr>\n",
       "\t<tr><td>6</td><td>101</td><td>2023-07-22</td><td>189.85</td><td>32</td><td>4</td><td>272.64</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 5 Ã— 7\n",
       "\\begin{tabular}{lllllll}\n",
       " OrderID & CustomerID & Order\\_Date & Total\\_Amount & ProductID & Quantity & Unit\\_Price\\\\\n",
       " <dbl> & <dbl> & <date> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 1 &  87 & 2023-08-30 & 424.30 &  2 & 3 & 115.72\\\\\n",
       "\t 1 &  87 & 2023-08-30 & 424.30 & 22 & 5 & 206.62\\\\\n",
       "\t 1 &  87 & 2023-08-30 & 424.30 & 26 & 5 &  61.75\\\\\n",
       "\t 3 &  37 & 2024-03-19 & 549.07 & 19 & 1 & 474.92\\\\\n",
       "\t 6 & 101 & 2023-07-22 & 189.85 & 32 & 4 & 272.64\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 5 Ã— 7\n",
       "\n",
       "| OrderID &lt;dbl&gt; | CustomerID &lt;dbl&gt; | Order_Date &lt;date&gt; | Total_Amount &lt;dbl&gt; | ProductID &lt;dbl&gt; | Quantity &lt;dbl&gt; | Unit_Price &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|\n",
       "| 1 |  87 | 2023-08-30 | 424.30 |  2 | 3 | 115.72 |\n",
       "| 1 |  87 | 2023-08-30 | 424.30 | 22 | 5 | 206.62 |\n",
       "| 1 |  87 | 2023-08-30 | 424.30 | 26 | 5 |  61.75 |\n",
       "| 3 |  37 | 2024-03-19 | 549.07 | 19 | 1 | 474.92 |\n",
       "| 6 | 101 | 2023-07-22 | 189.85 | 32 | 4 | 272.64 |\n",
       "\n"
      ],
      "text/plain": [
       "  OrderID CustomerID Order_Date Total_Amount ProductID Quantity Unit_Price\n",
       "1 1        87        2023-08-30 424.30        2        3        115.72    \n",
       "2 1        87        2023-08-30 424.30       22        5        206.62    \n",
       "3 1        87        2023-08-30 424.30       26        5         61.75    \n",
       "4 3        37        2024-03-19 549.07       19        1        474.92    \n",
       "5 6       101        2023-07-22 189.85       32        4        272.64    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Task 6.2: Join Orders and Order Items\n",
    "# TODO: Create 'orders_with_items' by inner joining orders with order_items\n",
    "#       Join on OrderID\n",
    "\n",
    "\n",
    "orders_with_items <- inner_join(orders, order_items, by = \"OrderID\")\n",
    "\n",
    "\n",
    "cat(\"========== ORDERS WITH ITEMS ==========\\n\")\n",
    "cat(\"Total rows:\", nrow(orders_with_items), \"\\n\")\n",
    "head(orders_with_items, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part7_intro",
   "metadata": {},
   "source": [
    "## Part 7: String Manipulation & Date/Time Operations (Lesson 7)\n",
    "\n",
    "**Skills Assessed:** stringr functions, lubridate functions\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Clean text data\n",
    "2. Parse dates\n",
    "3. Extract date components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "clean_text",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== CLEANED TEXT DATA ==========\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 5 Ã— 4</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>Region</th><th scope=col>region_clean</th><th scope=col>Product_Category</th><th scope=col>category_clean</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>Latin America</td><td>Latin America</td><td>Services</td><td>Services</td></tr>\n",
       "\t<tr><td>Europe       </td><td>Europe       </td><td>Hardware</td><td>Hardware</td></tr>\n",
       "\t<tr><td>Europe       </td><td>Europe       </td><td>Services</td><td>Services</td></tr>\n",
       "\t<tr><td>Europe       </td><td>Europe       </td><td>Hardware</td><td>Hardware</td></tr>\n",
       "\t<tr><td>Latin America</td><td>Latin America</td><td>Software</td><td>Software</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 5 Ã— 4\n",
       "\\begin{tabular}{llll}\n",
       " Region & region\\_clean & Product\\_Category & category\\_clean\\\\\n",
       " <chr> & <chr> & <chr> & <chr>\\\\\n",
       "\\hline\n",
       "\t Latin America & Latin America & Services & Services\\\\\n",
       "\t Europe        & Europe        & Hardware & Hardware\\\\\n",
       "\t Europe        & Europe        & Services & Services\\\\\n",
       "\t Europe        & Europe        & Hardware & Hardware\\\\\n",
       "\t Latin America & Latin America & Software & Software\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 5 Ã— 4\n",
       "\n",
       "| Region &lt;chr&gt; | region_clean &lt;chr&gt; | Product_Category &lt;chr&gt; | category_clean &lt;chr&gt; |\n",
       "|---|---|---|---|\n",
       "| Latin America | Latin America | Services | Services |\n",
       "| Europe        | Europe        | Hardware | Hardware |\n",
       "| Europe        | Europe        | Services | Services |\n",
       "| Europe        | Europe        | Hardware | Hardware |\n",
       "| Latin America | Latin America | Software | Software |\n",
       "\n"
      ],
      "text/plain": [
       "  Region        region_clean  Product_Category category_clean\n",
       "1 Latin America Latin America Services         Services      \n",
       "2 Europe        Europe        Hardware         Hardware      \n",
       "3 Europe        Europe        Services         Services      \n",
       "4 Europe        Europe        Hardware         Hardware      \n",
       "5 Latin America Latin America Software         Software      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Task 7.1: Clean Text Data\n",
    "# TODO: Add these columns to sales_enhanced using mutate():\n",
    "#   - region_clean: Region with trimmed whitespace and Title Case\n",
    "#   - category_clean: Product_Category with trimmed whitespace and Title Case\n",
    "\n",
    "\n",
    "sales_enhanced <- sales_enhanced %>%\n",
    "  mutate(\n",
    "    # Your code here:\n",
    "    region_clean = str_trim(Region),\n",
    "    region_clean = str_to_title(Region),\n",
    "    \n",
    "    category_clean = str_trim(Product_Category),\n",
    "    category_clean = str_to_title(Product_Category)\n",
    "\n",
    "  )\n",
    "\n",
    "cat(\"========== CLEANED TEXT DATA ==========\\n\")\n",
    "head(sales_enhanced %>% select(Region, region_clean, Product_Category, category_clean), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "parse_dates",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== DATE COMPONENTS ==========\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 5 Ã— 4</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>Sale_Date</th><th scope=col>date_parsed</th><th scope=col>sale_month</th><th scope=col>sale_weekday</th></tr>\n",
       "\t<tr><th scope=col>&lt;date&gt;</th><th scope=col>&lt;date&gt;</th><th scope=col>&lt;ord&gt;</th><th scope=col>&lt;ord&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>2023-04-24</td><td>2023-04-24</td><td>Apr</td><td>Mon</td></tr>\n",
       "\t<tr><td>2023-06-09</td><td>2023-06-09</td><td>Jun</td><td>Fri</td></tr>\n",
       "\t<tr><td>2023-03-25</td><td>2023-03-25</td><td>Mar</td><td>Sat</td></tr>\n",
       "\t<tr><td>2023-04-11</td><td>2023-04-11</td><td>Apr</td><td>Tue</td></tr>\n",
       "\t<tr><td>2023-08-26</td><td>2023-08-26</td><td>Aug</td><td>Sat</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 5 Ã— 4\n",
       "\\begin{tabular}{llll}\n",
       " Sale\\_Date & date\\_parsed & sale\\_month & sale\\_weekday\\\\\n",
       " <date> & <date> & <ord> & <ord>\\\\\n",
       "\\hline\n",
       "\t 2023-04-24 & 2023-04-24 & Apr & Mon\\\\\n",
       "\t 2023-06-09 & 2023-06-09 & Jun & Fri\\\\\n",
       "\t 2023-03-25 & 2023-03-25 & Mar & Sat\\\\\n",
       "\t 2023-04-11 & 2023-04-11 & Apr & Tue\\\\\n",
       "\t 2023-08-26 & 2023-08-26 & Aug & Sat\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 5 Ã— 4\n",
       "\n",
       "| Sale_Date &lt;date&gt; | date_parsed &lt;date&gt; | sale_month &lt;ord&gt; | sale_weekday &lt;ord&gt; |\n",
       "|---|---|---|---|\n",
       "| 2023-04-24 | 2023-04-24 | Apr | Mon |\n",
       "| 2023-06-09 | 2023-06-09 | Jun | Fri |\n",
       "| 2023-03-25 | 2023-03-25 | Mar | Sat |\n",
       "| 2023-04-11 | 2023-04-11 | Apr | Tue |\n",
       "| 2023-08-26 | 2023-08-26 | Aug | Sat |\n",
       "\n"
      ],
      "text/plain": [
       "  Sale_Date  date_parsed sale_month sale_weekday\n",
       "1 2023-04-24 2023-04-24  Apr        Mon         \n",
       "2 2023-06-09 2023-06-09  Jun        Fri         \n",
       "3 2023-03-25 2023-03-25  Mar        Sat         \n",
       "4 2023-04-11 2023-04-11  Apr        Tue         \n",
       "5 2023-08-26 2023-08-26  Aug        Sat         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Task 7.2: Parse Dates and Extract Components\n",
    "# TODO: Add these date-related columns using mutate():\n",
    "#   - date_parsed: Parse Sale_Date column (use ymd(), mdy(), or dmy() as appropriate)\n",
    "#   - sale_month: Extract month name from date_parsed\n",
    "#   - sale_weekday: Extract weekday name from date_parsed\n",
    "\n",
    "\n",
    "sales_enhanced <- sales_enhanced %>%\n",
    "  mutate(\n",
    "    # Your code here:\n",
    "    date_parsed = ymd(Sale_Date),\n",
    "    sale_month = month(date_parsed, label = TRUE),\n",
    "    sale_weekday = wday(date_parsed, label = TRUE)\n",
    "  )\n",
    "\n",
    "cat(\"========== DATE COMPONENTS ==========\\n\")\n",
    "head(sales_enhanced %>% select(Sale_Date, date_parsed, sale_month, sale_weekday), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part8_intro",
   "metadata": {},
   "source": [
    "## Part 8: Advanced Wrangling & Business Intelligence (Lesson 8)\n",
    "\n",
    "**Skills Assessed:** case_when(), complex logic, KPIs\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Create business categories with case_when()\n",
    "2. Calculate KPIs\n",
    "3. Generate executive summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "case_when_logic",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== PERFORMANCE TIERS ==========\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "  High    Low Medium \n",
       "   154     74     72 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Task 8.1: Create Performance Categories\n",
    "# TODO: Add 'performance_tier' column using case_when():\n",
    "#   - \"High\" if Revenue > 25000\n",
    "#   - \"Medium\" if Revenue > 15000\n",
    "#   - \"Low\" otherwise\n",
    "\n",
    "sales_enhanced <- sales_enhanced %>%\n",
    "  mutate(\n",
    "    performance_tier = case_when(\n",
    "      # Your code here:\n",
    "      Revenue > 25000 ~ \"High\",\n",
    "      Revenue > 15000 ~ \"Medium\",\n",
    "      Revenue < 15000 ~ \"Low\"\n",
    "      \n",
    "    )\n",
    "  )\n",
    "\n",
    "cat(\"========== PERFORMANCE TIERS ==========\\n\")\n",
    "table(sales_enhanced$performance_tier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "calculate_kpis",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== BUSINESS KPIs ==========\n",
      "\u001b[90m# A tibble: 1 Ã— 4\u001b[39m\n",
      "  total_revenue total_transactions avg_transaction_value high_value_pct\n",
      "          \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m              \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m                 \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m          \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m      7\u001b[4m7\u001b[24m\u001b[4m7\u001b[24m\u001b[4m1\u001b[24m711.                300                \u001b[4m2\u001b[24m\u001b[4m5\u001b[24m906.              0\n"
     ]
    }
   ],
   "source": [
    "# Task 8.2: Calculate Business KPIs\n",
    "# TODO: Create 'business_kpis' with these metrics:\n",
    "#   - total_revenue: sum of Revenue\n",
    "#   - total_transactions: count of rows\n",
    "#   - avg_transaction_value: mean of Revenue\n",
    "#   - high_value_pct: percentage where high_value = \"Yes\"\n",
    "\n",
    "business_kpis <- sales_enhanced %>%\n",
    "  summarize(\n",
    "    # Your code here:\n",
    "    total_revenue = sum(Revenue),\n",
    "    total_transactions = n(),\n",
    "    avg_transaction_value = mean(Revenue),\n",
    "    high_value_pct = mean(high_value == \"Yes\", na.rm = TRUE) * 100\n",
    "\n",
    "  )\n",
    "\n",
    "cat(\"========== BUSINESS KPIs ==========\\n\")\n",
    "print(business_kpis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection_intro",
   "metadata": {},
   "source": [
    "## Part 9: Reflection Questions\n",
    "\n",
    "Answer the following questions based on your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection1",
   "metadata": {},
   "source": [
    "### Question 9.1: Data Cleaning Impact\n",
    "\n",
    "**How did handling missing values and outliers affect your analysis? Why is data cleaning important before performing business analysis?**\n",
    "\n",
    "Your answer here: \n",
    "Handling missing values and outliers was very useful. The data had few missing values, making it convenient to present the necessary information. Similarly, a few outliers meant the data remained accurate and unskewed. It is crucial to clean data before analysis because of how outliers and missing values can significantly impact the entire outcome.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection2",
   "metadata": {},
   "source": [
    "### Question 9.2: Grouped Analysis Value\n",
    "\n",
    "**What insights did you gain from the regional and category summaries that you couldn't see in the raw data? How can businesses use this type of grouped analysis?**\n",
    "\n",
    "Your answer here: \n",
    "\n",
    "The regional and category summaries helped me see patterns that werenâ€™t obvious in the raw data, like which regions brought in the most revenue and which product categories performed best. Grouping the data made it easier to spot trends and differences across areas. Businesses can use this kind of analysis to focus on whatâ€™s working, improve weaker regions, and make better strategic decisions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection3",
   "metadata": {},
   "source": [
    "### Question 9.3: Data Reshaping Purpose\n",
    "\n",
    "**Why would you need to reshape data between wide and long formats? Provide a business scenario where each format would be useful.**\n",
    "\n",
    "Your answer here: Reshaping data between wide and long formats is important because different analyses require data to be formatted and structured in specific ways. The wide format is useful when you want to compare values easily, like between separate columns for a quick snapshot. The long format works better for visualizations or trend analysis, such as tracking changes over time.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection4",
   "metadata": {},
   "source": [
    "### Question 9.4: Joining Datasets\n",
    "\n",
    "**What is the difference between left_join() and inner_join()? When would you use each one in a business context?**\n",
    "\n",
    "Your answer here: The main difference is that left_join() keeps all the rows from the left table, even if thereâ€™s no matching data in the right table, while inner_join() only keeps rows that have matches in both tables. In a business setting, youâ€™d use left_join() when you want to keep your full list of customers even if some havenâ€™t made a purchase. An inner_join() can be used when you only want to analyze data for matching customers who made a purchase at a specific time.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection5",
   "metadata": {},
   "source": [
    "### Question 9.5: Skills Integration\n",
    "\n",
    "**Which R data wrangling skill (from Lessons 1-8) do you think is most valuable for business analytics? Why?**\n",
    "\n",
    "Your answer here: I think the most valuable R data wrangling skill for business analytics is data cleaning. This step ensures that the data is accurate, consistent, and ready for analysis, which directly impacts the quality of insights and decisions. Clean data helps prevent costly mistakes and allows analysts to confidently identify trends, measure performance, and make reliable recommendations.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## Exam Complete!\n",
    "\n",
    "### What You've Demonstrated\n",
    "\n",
    "âœ… **Lesson 1:** R basics and data import\n",
    "âœ… **Lesson 2:** Data cleaning (missing values & outliers)\n",
    "âœ… **Lesson 3:** Data transformation (select, filter, arrange)\n",
    "âœ… **Lesson 4:** Advanced transformation (mutate, summarize, group_by)\n",
    "âœ… **Lesson 5:** Data reshaping (pivot_longer, pivot_wider)\n",
    "âœ… **Lesson 6:** Combining datasets (joins)\n",
    "âœ… **Lesson 7:** String manipulation & date/time operations\n",
    "âœ… **Lesson 8:** Advanced wrangling & business intelligence\n",
    "\n",
    "### Submission Checklist\n",
    "\n",
    "Before submitting, ensure:\n",
    "- [ ] All code cells run without errors\n",
    "- [ ] All TODO sections completed\n",
    "- [ ] All required dataframes created with correct names\n",
    "- [ ] All 5 reflection questions answered\n",
    "- [ ] Student name and ID filled in at top\n",
    "\n",
    "**Good work! ðŸŽ‰**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
