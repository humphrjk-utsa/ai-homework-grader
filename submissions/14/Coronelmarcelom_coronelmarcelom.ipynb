{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Homework Assignment - Lesson 7: String Manipulation and Date/Time Data\n",
    "\n",
    "**Student Name:** Marcelo Coronel\n",
    "\n",
    "**Student ID:** ome589\n",
    "\n",
    "**Date Submitted:** 10/7/2025\n",
    "\n",
    "**Due Date:** 10/19/2025\n",
    "\n",
    "---\n",
    "\n",
    "## Objective\n",
    "\n",
    "Master string manipulation with `stringr` and date/time operations with `lubridate` for real-world business data cleaning and analysis.\n",
    "\n",
    "## Learning Goals\n",
    "\n",
    "By completing this assignment, you will:\n",
    "- Clean and standardize messy text data using `stringr` functions\n",
    "- Parse and manipulate dates using `lubridate` functions\n",
    "- Extract information from text and dates for business insights\n",
    "- Combine string and date operations for customer segmentation\n",
    "- Create business-ready reports from raw data\n",
    "\n",
    "## Instructions\n",
    "\n",
    "- Complete all tasks in this notebook\n",
    "- Write your code in the designated TODO sections\n",
    "- Use the pipe operator (`%>%`) wherever possible\n",
    "- Add comments explaining your logic\n",
    "- Run all cells to verify your code works\n",
    "- Answer all reflection questions\n",
    "\n",
    "## Datasets\n",
    "\n",
    "You will work with three CSV files:\n",
    "- `customer_feedback.csv` - Customer reviews with messy text\n",
    "- `transaction_log.csv` - Transaction records with dates\n",
    "- `product_catalog.csv` - Product descriptions needing standardization\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part1_intro",
   "metadata": {},
   "source": [
    "## Part 1: Data Import and Initial Exploration\n",
    "\n",
    "**Business Context:** Before cleaning data, you must understand its structure and quality issues.\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Load required packages (`tidyverse` and `lubridate`)\n",
    "2. Import all three CSV files from the `data/` directory\n",
    "3. Examine the structure and identify data quality issues\n",
    "4. Display sample rows to understand the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "setup",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'/workspaces/Fall2025-MS3083-Base_Template/data'"
      ],
      "text/latex": [
       "'/workspaces/Fall2025-MS3083-Base\\_Template/data'"
      ],
      "text/markdown": [
       "'/workspaces/Fall2025-MS3083-Base_Template/data'"
      ],
      "text/plain": [
       "[1] \"/workspaces/Fall2025-MS3083-Base_Template/data\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Packages loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Task 1.1: Load Required Packages\n",
    "# TODO: Load tidyverse (includes stringr)\n",
    "library(tidyverse)\n",
    "\n",
    "# TODO: Load lubridate\n",
    "library(lubridate)\n",
    "\n",
    "setwd(\"/workspaces/Fall2025-MS3083-Base_Template/data\")\n",
    "getwd()\n",
    "cat(\"✅ Packages loaded successfully!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "import_data",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mRows: \u001b[22m\u001b[34m100\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m6\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m  (3): Customer_Name, Feedback_Text, Contact_Info\n",
      "\u001b[32mdbl\u001b[39m  (2): FeedbackID, CustomerID\n",
      "\u001b[34mdate\u001b[39m (1): Feedback_Date\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
      "\u001b[1mRows: \u001b[22m\u001b[34m150\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m5\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m (2): Transaction_DateTime, Status\n",
      "\u001b[32mdbl\u001b[39m (3): LogID, CustomerID, Amount\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
      "\u001b[1mRows: \u001b[22m\u001b[34m75\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m5\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m (3): Product_Description, Category, In_Stock\n",
      "\u001b[32mdbl\u001b[39m (2): ProductID, Price\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data imported successfully!\n",
      "Feedback rows: 100 \n",
      "Transaction rows: 150 \n",
      "Product rows: 75 \n"
     ]
    }
   ],
   "source": [
    "# Task 1.2: Import Datasets\n",
    "# TODO: Import customer_feedback.csv into a variable called 'feedback'\n",
    "feedback <- read_csv(\"/workspaces/Fall2025-MS3083-Base_Template/data/customer_feedback.csv\")\n",
    "\n",
    "# TODO: Import transaction_log.csv into a variable called 'transactions'\n",
    "transactions <- read_csv(\"/workspaces/Fall2025-MS3083-Base_Template/data/transaction_log.csv\")\n",
    "\n",
    "# TODO: Import product_catalog.csv into a variable called 'products'\n",
    "products <- read_csv(\"/workspaces/Fall2025-MS3083-Base_Template/data/product_catalog.csv\")\n",
    "\n",
    "cat(\"✅ Data imported successfully!\\n\")\n",
    "cat(\"Feedback rows:\", nrow(feedback), \"\\n\")\n",
    "cat(\"Transaction rows:\", nrow(transactions), \"\\n\")\n",
    "cat(\"Product rows:\", nrow(products), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "explore_data",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CUSTOMER FEEDBACK DATA ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spc_tbl_ [100 × 6] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n",
      " $ FeedbackID   : num [1:100] 1 2 3 4 5 6 7 8 9 10 ...\n",
      " $ CustomerID   : num [1:100] 12 40 34 1 47 13 13 37 49 23 ...\n",
      " $ Customer_Name: chr [1:100] \"Bob Wilson\" \"sarah johnson\" \"jane smith\" \"JANE SMITH\" ...\n",
      " $ Feedback_Text: chr [1:100] \"Highly recommend this item\" \"Excellent service\" \"Poor quality control\" \"average product, nothing special\" ...\n",
      " $ Contact_Info : chr [1:100] \"bob.wilson@test.org\" \"555-123-4567\" \"jane_smith@company.com\" \"jane_smith@company.com\" ...\n",
      " $ Feedback_Date: Date[1:100], format: \"2024-02-23\" \"2024-01-21\" ...\n",
      " - attr(*, \"spec\")=\n",
      "  .. cols(\n",
      "  ..   FeedbackID = \u001b[32mcol_double()\u001b[39m,\n",
      "  ..   CustomerID = \u001b[32mcol_double()\u001b[39m,\n",
      "  ..   Customer_Name = \u001b[31mcol_character()\u001b[39m,\n",
      "  ..   Feedback_Text = \u001b[31mcol_character()\u001b[39m,\n",
      "  ..   Contact_Info = \u001b[31mcol_character()\u001b[39m,\n",
      "  ..   Feedback_Date = \u001b[34mcol_date(format = \"\")\u001b[39m\n",
      "  .. )\n",
      " - attr(*, \"problems\")=<externalptr> \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 5 × 6</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>FeedbackID</th><th scope=col>CustomerID</th><th scope=col>Customer_Name</th><th scope=col>Feedback_Text</th><th scope=col>Contact_Info</th><th scope=col>Feedback_Date</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;date&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>1</td><td>12</td><td>Bob Wilson   </td><td>Highly recommend this item      </td><td>bob.wilson@test.org   </td><td>2024-02-23</td></tr>\n",
       "\t<tr><td>2</td><td>40</td><td>sarah johnson</td><td>Excellent service               </td><td>555-123-4567          </td><td>2024-01-21</td></tr>\n",
       "\t<tr><td>3</td><td>34</td><td>jane smith   </td><td>Poor quality control            </td><td>jane_smith@company.com</td><td>2023-09-02</td></tr>\n",
       "\t<tr><td>4</td><td> 1</td><td>JANE SMITH   </td><td>average product, nothing special</td><td>jane_smith@company.com</td><td>2023-08-21</td></tr>\n",
       "\t<tr><td>5</td><td>47</td><td>michael brown</td><td>AMAZING customer support!!!     </td><td>555-123-4567          </td><td>2023-04-24</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 5 × 6\n",
       "\\begin{tabular}{llllll}\n",
       " FeedbackID & CustomerID & Customer\\_Name & Feedback\\_Text & Contact\\_Info & Feedback\\_Date\\\\\n",
       " <dbl> & <dbl> & <chr> & <chr> & <chr> & <date>\\\\\n",
       "\\hline\n",
       "\t 1 & 12 & Bob Wilson    & Highly recommend this item       & bob.wilson@test.org    & 2024-02-23\\\\\n",
       "\t 2 & 40 & sarah johnson & Excellent service                & 555-123-4567           & 2024-01-21\\\\\n",
       "\t 3 & 34 & jane smith    & Poor quality control             & jane\\_smith@company.com & 2023-09-02\\\\\n",
       "\t 4 &  1 & JANE SMITH    & average product, nothing special & jane\\_smith@company.com & 2023-08-21\\\\\n",
       "\t 5 & 47 & michael brown & AMAZING customer support!!!      & 555-123-4567           & 2023-04-24\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 5 × 6\n",
       "\n",
       "| FeedbackID &lt;dbl&gt; | CustomerID &lt;dbl&gt; | Customer_Name &lt;chr&gt; | Feedback_Text &lt;chr&gt; | Contact_Info &lt;chr&gt; | Feedback_Date &lt;date&gt; |\n",
       "|---|---|---|---|---|---|\n",
       "| 1 | 12 | Bob Wilson    | Highly recommend this item       | bob.wilson@test.org    | 2024-02-23 |\n",
       "| 2 | 40 | sarah johnson | Excellent service                | 555-123-4567           | 2024-01-21 |\n",
       "| 3 | 34 | jane smith    | Poor quality control             | jane_smith@company.com | 2023-09-02 |\n",
       "| 4 |  1 | JANE SMITH    | average product, nothing special | jane_smith@company.com | 2023-08-21 |\n",
       "| 5 | 47 | michael brown | AMAZING customer support!!!      | 555-123-4567           | 2023-04-24 |\n",
       "\n"
      ],
      "text/plain": [
       "  FeedbackID CustomerID Customer_Name Feedback_Text                   \n",
       "1 1          12         Bob Wilson    Highly recommend this item      \n",
       "2 2          40         sarah johnson Excellent service               \n",
       "3 3          34         jane smith    Poor quality control            \n",
       "4 4           1         JANE SMITH    average product, nothing special\n",
       "5 5          47         michael brown AMAZING customer support!!!     \n",
       "  Contact_Info           Feedback_Date\n",
       "1 bob.wilson@test.org    2024-02-23   \n",
       "2 555-123-4567           2024-01-21   \n",
       "3 jane_smith@company.com 2023-09-02   \n",
       "4 jane_smith@company.com 2023-08-21   \n",
       "5 555-123-4567           2023-04-24   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TRANSACTION DATA ===\n",
      "spc_tbl_ [150 × 5] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n",
      " $ LogID               : num [1:150] 1 2 3 4 5 6 7 8 9 10 ...\n",
      " $ CustomerID          : num [1:150] 26 21 12 6 32 27 31 30 31 13 ...\n",
      " $ Transaction_DateTime: chr [1:150] \"4/5/24 14:30\" \"3/15/24 14:30\" \"3/15/24 14:30\" \"3/20/24 9:15\" ...\n",
      " $ Amount              : num [1:150] 277 175 252 215 269 ...\n",
      " $ Status              : chr [1:150] \"Pending\" \"Pending\" \"Pending\" \"Pending\" ...\n",
      " - attr(*, \"spec\")=\n",
      "  .. cols(\n",
      "  ..   LogID = \u001b[32mcol_double()\u001b[39m,\n",
      "  ..   CustomerID = \u001b[32mcol_double()\u001b[39m,\n",
      "  ..   Transaction_DateTime = \u001b[31mcol_character()\u001b[39m,\n",
      "  ..   Amount = \u001b[32mcol_double()\u001b[39m,\n",
      "  ..   Status = \u001b[31mcol_character()\u001b[39m\n",
      "  .. )\n",
      " - attr(*, \"problems\")=<externalptr> \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 5 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>LogID</th><th scope=col>CustomerID</th><th scope=col>Transaction_DateTime</th><th scope=col>Amount</th><th scope=col>Status</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>1</td><td>26</td><td>4/5/24 14:30 </td><td>277.22</td><td>Pending  </td></tr>\n",
       "\t<tr><td>2</td><td>21</td><td>3/15/24 14:30</td><td>175.16</td><td>Pending  </td></tr>\n",
       "\t<tr><td>3</td><td>12</td><td>3/15/24 14:30</td><td>251.71</td><td>Pending  </td></tr>\n",
       "\t<tr><td>4</td><td> 6</td><td>3/20/24 9:15 </td><td>214.98</td><td>Pending  </td></tr>\n",
       "\t<tr><td>5</td><td>32</td><td>3/20/24 9:15 </td><td>268.91</td><td>Completed</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 5 × 5\n",
       "\\begin{tabular}{lllll}\n",
       " LogID & CustomerID & Transaction\\_DateTime & Amount & Status\\\\\n",
       " <dbl> & <dbl> & <chr> & <dbl> & <chr>\\\\\n",
       "\\hline\n",
       "\t 1 & 26 & 4/5/24 14:30  & 277.22 & Pending  \\\\\n",
       "\t 2 & 21 & 3/15/24 14:30 & 175.16 & Pending  \\\\\n",
       "\t 3 & 12 & 3/15/24 14:30 & 251.71 & Pending  \\\\\n",
       "\t 4 &  6 & 3/20/24 9:15  & 214.98 & Pending  \\\\\n",
       "\t 5 & 32 & 3/20/24 9:15  & 268.91 & Completed\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 5 × 5\n",
       "\n",
       "| LogID &lt;dbl&gt; | CustomerID &lt;dbl&gt; | Transaction_DateTime &lt;chr&gt; | Amount &lt;dbl&gt; | Status &lt;chr&gt; |\n",
       "|---|---|---|---|---|\n",
       "| 1 | 26 | 4/5/24 14:30  | 277.22 | Pending   |\n",
       "| 2 | 21 | 3/15/24 14:30 | 175.16 | Pending   |\n",
       "| 3 | 12 | 3/15/24 14:30 | 251.71 | Pending   |\n",
       "| 4 |  6 | 3/20/24 9:15  | 214.98 | Pending   |\n",
       "| 5 | 32 | 3/20/24 9:15  | 268.91 | Completed |\n",
       "\n"
      ],
      "text/plain": [
       "  LogID CustomerID Transaction_DateTime Amount Status   \n",
       "1 1     26         4/5/24 14:30         277.22 Pending  \n",
       "2 2     21         3/15/24 14:30        175.16 Pending  \n",
       "3 3     12         3/15/24 14:30        251.71 Pending  \n",
       "4 4      6         3/20/24 9:15         214.98 Pending  \n",
       "5 5     32         3/20/24 9:15         268.91 Completed"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PRODUCT CATALOG DATA ===\n",
      "spc_tbl_ [75 × 5] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n",
      " $ ProductID          : num [1:75] 1 2 3 4 5 6 7 8 9 10 ...\n",
      " $ Product_Description: chr [1:75] \"Apple iPhone 14 Pro - 128GB - Space Black\" \"samsung galaxy s23 ultra 256gb\" \"Apple iPhone 14 Pro - 128GB - Space Black\" \"Apple iPhone 14 Pro - 128GB - Space Black\" ...\n",
      " $ Category           : chr [1:75] \"TV\" \"TV\" \"Audio\" \"Shoes\" ...\n",
      " $ Price              : num [1:75] 964 1817 853 649 586 ...\n",
      " $ In_Stock           : chr [1:75] \"Limited\" \"Yes\" \"Yes\" \"Yes\" ...\n",
      " - attr(*, \"spec\")=\n",
      "  .. cols(\n",
      "  ..   ProductID = \u001b[32mcol_double()\u001b[39m,\n",
      "  ..   Product_Description = \u001b[31mcol_character()\u001b[39m,\n",
      "  ..   Category = \u001b[31mcol_character()\u001b[39m,\n",
      "  ..   Price = \u001b[32mcol_double()\u001b[39m,\n",
      "  ..   In_Stock = \u001b[31mcol_character()\u001b[39m\n",
      "  .. )\n",
      " - attr(*, \"problems\")=<externalptr> \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 5 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>ProductID</th><th scope=col>Product_Description</th><th scope=col>Category</th><th scope=col>Price</th><th scope=col>In_Stock</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>1</td><td>Apple iPhone 14 Pro - 128GB - Space Black</td><td>TV         </td><td> 963.53</td><td>Limited</td></tr>\n",
       "\t<tr><td>2</td><td>samsung galaxy s23 ultra 256gb           </td><td>TV         </td><td>1817.44</td><td>Yes    </td></tr>\n",
       "\t<tr><td>3</td><td>Apple iPhone 14 Pro - 128GB - Space Black</td><td>Audio      </td><td> 852.79</td><td>Yes    </td></tr>\n",
       "\t<tr><td>4</td><td>Apple iPhone 14 Pro - 128GB - Space Black</td><td>Shoes      </td><td> 648.58</td><td>Yes    </td></tr>\n",
       "\t<tr><td>5</td><td>samsung galaxy s23 ultra 256gb           </td><td>Electronics</td><td> 586.35</td><td>Limited</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 5 × 5\n",
       "\\begin{tabular}{lllll}\n",
       " ProductID & Product\\_Description & Category & Price & In\\_Stock\\\\\n",
       " <dbl> & <chr> & <chr> & <dbl> & <chr>\\\\\n",
       "\\hline\n",
       "\t 1 & Apple iPhone 14 Pro - 128GB - Space Black & TV          &  963.53 & Limited\\\\\n",
       "\t 2 & samsung galaxy s23 ultra 256gb            & TV          & 1817.44 & Yes    \\\\\n",
       "\t 3 & Apple iPhone 14 Pro - 128GB - Space Black & Audio       &  852.79 & Yes    \\\\\n",
       "\t 4 & Apple iPhone 14 Pro - 128GB - Space Black & Shoes       &  648.58 & Yes    \\\\\n",
       "\t 5 & samsung galaxy s23 ultra 256gb            & Electronics &  586.35 & Limited\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 5 × 5\n",
       "\n",
       "| ProductID &lt;dbl&gt; | Product_Description &lt;chr&gt; | Category &lt;chr&gt; | Price &lt;dbl&gt; | In_Stock &lt;chr&gt; |\n",
       "|---|---|---|---|---|\n",
       "| 1 | Apple iPhone 14 Pro - 128GB - Space Black | TV          |  963.53 | Limited |\n",
       "| 2 | samsung galaxy s23 ultra 256gb            | TV          | 1817.44 | Yes     |\n",
       "| 3 | Apple iPhone 14 Pro - 128GB - Space Black | Audio       |  852.79 | Yes     |\n",
       "| 4 | Apple iPhone 14 Pro - 128GB - Space Black | Shoes       |  648.58 | Yes     |\n",
       "| 5 | samsung galaxy s23 ultra 256gb            | Electronics |  586.35 | Limited |\n",
       "\n"
      ],
      "text/plain": [
       "  ProductID Product_Description                       Category    Price  \n",
       "1 1         Apple iPhone 14 Pro - 128GB - Space Black TV           963.53\n",
       "2 2         samsung galaxy s23 ultra 256gb            TV          1817.44\n",
       "3 3         Apple iPhone 14 Pro - 128GB - Space Black Audio        852.79\n",
       "4 4         Apple iPhone 14 Pro - 128GB - Space Black Shoes        648.58\n",
       "5 5         samsung galaxy s23 ultra 256gb            Electronics  586.35\n",
       "  In_Stock\n",
       "1 Limited \n",
       "2 Yes     \n",
       "3 Yes     \n",
       "4 Yes     \n",
       "5 Limited "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Task 1.3: Initial Data Exploration\n",
    "\n",
    "cat(\"=== CUSTOMER FEEDBACK DATA ===\\n\")\n",
    "# Display structure of feedback using str()\n",
    "str(feedback)\n",
    "\n",
    "# Display first 5 rows of feedback\n",
    "head(feedback, 5)\n",
    "\n",
    "cat(\"\\n=== TRANSACTION DATA ===\\n\")\n",
    "# Display structure of transactions\n",
    "str(transactions)\n",
    "\n",
    "# Display first 5 rows of transactions\n",
    "head(transactions, 5)\n",
    "\n",
    "cat(\"\\n=== PRODUCT CATALOG DATA ===\\n\")\n",
    "# Display structure of products\n",
    "str(products)\n",
    "\n",
    "# Display first 5 rows of products\n",
    "head(products, 5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part2_intro",
   "metadata": {},
   "source": [
    "## Part 2: String Cleaning and Standardization\n",
    "\n",
    "**Business Context:** Product names and feedback text often have inconsistent formatting that prevents accurate analysis.\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Clean product names (remove extra spaces, standardize case)\n",
    "2. Standardize product categories\n",
    "3. Clean customer feedback text\n",
    "4. Extract customer names from feedback\n",
    "\n",
    "**Key Functions:** `str_trim()`, `str_squish()`, `str_to_lower()`, `str_to_upper()`, `str_to_title()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "clean_products",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product Name Cleaning Results:\n",
      "\u001b[90m# A tibble: 10 × 2\u001b[39m\n",
      "   Product_Description                        \n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                                      \n",
      "\u001b[90m 1\u001b[39m \u001b[90m\"\u001b[39mApple iPhone 14 Pro - 128GB - Space Black\u001b[90m\"\u001b[39m\n",
      "\u001b[90m 2\u001b[39m \u001b[90m\"\u001b[39msamsung galaxy s23 ultra 256gb\u001b[90m\"\u001b[39m           \n",
      "\u001b[90m 3\u001b[39m \u001b[90m\"\u001b[39mApple iPhone 14 Pro - 128GB - Space Black\u001b[90m\"\u001b[39m\n",
      "\u001b[90m 4\u001b[39m \u001b[90m\"\u001b[39mApple iPhone 14 Pro - 128GB - Space Black\u001b[90m\"\u001b[39m\n",
      "\u001b[90m 5\u001b[39m \u001b[90m\"\u001b[39msamsung galaxy s23 ultra 256gb\u001b[90m\"\u001b[39m           \n",
      "\u001b[90m 6\u001b[39m \u001b[90m\"\u001b[39mApple iPhone 14 Pro - 128GB - Space Black\u001b[90m\"\u001b[39m\n",
      "\u001b[90m 7\u001b[39m \u001b[90m\"\u001b[39mDELL XPS 13 Laptop - Intel i7 - 16GB RAM\u001b[90m\"\u001b[39m \n",
      "\u001b[90m 8\u001b[39m \u001b[90m\"\u001b[39mhp envy printer - wireless - color\u001b[90m\"\u001b[39m       \n",
      "\u001b[90m 9\u001b[39m \u001b[90m\"\u001b[39mNike Air Max 270 - Size 10 - Black/White\u001b[90m\"\u001b[39m \n",
      "\u001b[90m10\u001b[39m \u001b[90m\"\u001b[39mLG 55\\\" 4K Smart TV - OLED Display\u001b[90m\"\u001b[39m       \n",
      "   product_name_clean                         \n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                                      \n",
      "\u001b[90m 1\u001b[39m \u001b[90m\"\u001b[39mApple iPhone 14 Pro - 128GB - Space Black\u001b[90m\"\u001b[39m\n",
      "\u001b[90m 2\u001b[39m \u001b[90m\"\u001b[39mSamsung Galaxy S23 Ultra 256GB\u001b[90m\"\u001b[39m           \n",
      "\u001b[90m 3\u001b[39m \u001b[90m\"\u001b[39mApple iPhone 14 Pro - 128GB - Space Black\u001b[90m\"\u001b[39m\n",
      "\u001b[90m 4\u001b[39m \u001b[90m\"\u001b[39mApple iPhone 14 Pro - 128GB - Space Black\u001b[90m\"\u001b[39m\n",
      "\u001b[90m 5\u001b[39m \u001b[90m\"\u001b[39mSamsung Galaxy S23 Ultra 256GB\u001b[90m\"\u001b[39m           \n",
      "\u001b[90m 6\u001b[39m \u001b[90m\"\u001b[39mApple iPhone 14 Pro - 128GB - Space Black\u001b[90m\"\u001b[39m\n",
      "\u001b[90m 7\u001b[39m \u001b[90m\"\u001b[39mDELL XPS 13 Laptop - Intel i7 - 16GB RAM\u001b[90m\"\u001b[39m \n",
      "\u001b[90m 8\u001b[39m \u001b[90m\"\u001b[39mHP Envy Printer - Wireless - Color\u001b[90m\"\u001b[39m       \n",
      "\u001b[90m 9\u001b[39m \u001b[90m\"\u001b[39mNike Air Max 270 - Size 10 - Black/White\u001b[90m\"\u001b[39m \n",
      "\u001b[90m10\u001b[39m \u001b[90m\"\u001b[39mLG 55\\\" 4K Smart TV - OLED Display\u001b[90m\"\u001b[39m       \n"
     ]
    }
   ],
   "source": [
    "# Task 2.1: Clean Product Names\n",
    "# TODO: Create a new column 'product_name_clean' that:\n",
    "#   - Removes leading/trailing whitespace using str_trim()\n",
    "#   - Converts to Title Case using str_to_title()\n",
    "#   - Corrects brand names and units using str_replace_all()\n",
    "\n",
    "products_clean <- products %>%\n",
    "  mutate(\n",
    "    product_name_clean = Product_Description %>%\n",
    "      str_trim() %>%               # remove spaces\n",
    "      str_to_title() %>%           # convert to Title Case\n",
    "      str_replace_all(c(           # fix specific brand & unit capitalization\n",
    "        \"Iphone\" = \"iPhone\",\n",
    "        \"Tv\" = \"TV\",\n",
    "        \"Hp\" = \"HP\",\n",
    "        \"Lg\" = \"LG\",\n",
    "        \"Gb\" = \"GB\",\n",
    "        \"gb\" = \"GB\",\n",
    "        \"Dell\" = \"DELL\",\n",
    "        \"Xps\" = \"XPS\",\n",
    "        \"Ram\" = \"RAM\",\n",
    "        \"Oled\" = \"OLED\",\n",
    "        \"4k\" = \"4K\",\n",
    "        \"I7\" = \"i7\"\n",
    "      ))                         # manually fixed capitalization/specs. No more inconsistencies\n",
    "  )\n",
    "\n",
    "# Display before and after\n",
    "cat(\"Product Name Cleaning Results:\\n\")\n",
    "products_clean %>%\n",
    "  select(Product_Description, product_name_clean) %>%\n",
    "  head(10) %>%\n",
    "  print(n = 10, width = Inf)    # I ensured I could see all columns in the output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "clean_categories",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original categories:\n",
      "[1] \"TV\"          \"Audio\"       \"Shoes\"       \"Electronics\" \"Computers\"  \n",
      "\n",
      "Cleaned categories:\n",
      "[1] \"TV\"          \"Audio\"       \"Shoes\"       \"Electronics\" \"Computers\"  \n"
     ]
    }
   ],
   "source": [
    "# Task 2.2: Standardize Product Categories\n",
    "# TODO: Create a new column 'category_clean' that:\n",
    "#   - Converts category to Title Case\n",
    "#   - Removes any extra whitespace\n",
    "\n",
    "products_clean <- products_clean %>%\n",
    "  mutate(\n",
    "    category_clean = Category %>%\n",
    "      str_trim() %>%         # remove extra spaces\n",
    "      str_to_title() %>%     # convert to Title Case\n",
    "      str_replace_all(\"Tv\", \"TV\")  # ensuring TV is capitalized the same way as it is in product names\n",
    "  )\n",
    "\n",
    "# Show unique categories before and after\n",
    "cat(\"Original categories:\\n\")\n",
    "print(unique(products$Category))\n",
    "\n",
    "cat(\"\\nCleaned categories:\\n\")\n",
    "print(unique(products_clean$category_clean))\n",
    "\n",
    "# Note: Without str_replace_all(\"Tv\", \"TV\"), \"Tv\" would have been the label even though in product names I had \"TV\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ba7b900f",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'FeedbackID'</li><li>'CustomerID'</li><li>'Customer_Name'</li><li>'Feedback_Text'</li><li>'Contact_Info'</li><li>'Feedback_Date'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'FeedbackID'\n",
       "\\item 'CustomerID'\n",
       "\\item 'Customer\\_Name'\n",
       "\\item 'Feedback\\_Text'\n",
       "\\item 'Contact\\_Info'\n",
       "\\item 'Feedback\\_Date'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'FeedbackID'\n",
       "2. 'CustomerID'\n",
       "3. 'Customer_Name'\n",
       "4. 'Feedback_Text'\n",
       "5. 'Contact_Info'\n",
       "6. 'Feedback_Date'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"FeedbackID\"    \"CustomerID\"    \"Customer_Name\" \"Feedback_Text\"\n",
       "[5] \"Contact_Info\"  \"Feedback_Date\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# checking my columns\n",
    "colnames(feedback)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "clean_feedback",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feedback Cleaning Sample:\n",
      "\u001b[90m# A tibble: 5 × 2\u001b[39m\n",
      "  Feedback_Text                    feedback_clean                  \n",
      "  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                            \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                           \n",
      "\u001b[90m1\u001b[39m Highly recommend this item       highly recommend this item      \n",
      "\u001b[90m2\u001b[39m Excellent service                excellent service               \n",
      "\u001b[90m3\u001b[39m Poor quality control             poor quality control            \n",
      "\u001b[90m4\u001b[39m average product, nothing special average product, nothing special\n",
      "\u001b[90m5\u001b[39m AMAZING customer support!!!      amazing customer support!!!     \n"
     ]
    }
   ],
   "source": [
    "# Task 2.3: Clean Customer Feedback Text\n",
    "# TODO: Create a new column 'feedback_clean' that:\n",
    "#   - Converts text to lowercase using str_to_lower()\n",
    "#   - Removes extra whitespace using str_squish()\n",
    "\n",
    "feedback_clean <- feedback %>%\n",
    "  mutate(\n",
    "    feedback_clean = Feedback_Text %>%\n",
    "      str_to_lower() %>%   # convert text to lowercase\n",
    "      str_squish()         # remove extra spaces\n",
    "  )\n",
    "\n",
    "# Display sample\n",
    "cat(\"Feedback Cleaning Sample:\\n\")\n",
    "feedback_clean %>%\n",
    "  select(Feedback_Text, feedback_clean) %>%\n",
    "  head(5) %>%\n",
    "  print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part3_intro",
   "metadata": {},
   "source": [
    "## Part 3: Pattern Detection and Extraction\n",
    "\n",
    "**Business Context:** Identifying products with specific features and extracting specifications helps with inventory management and marketing.\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Identify products with specific keywords (wireless, premium, gaming)\n",
    "2. Extract numerical specifications from product names\n",
    "3. Detect sentiment words in customer feedback\n",
    "4. Extract email addresses from feedback\n",
    "\n",
    "**Key Functions:** `str_detect()`, `str_extract()`, `str_count()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "detect_features",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product Feature Detection:\n",
      "\u001b[90m# A tibble: 10 × 4\u001b[39m\n",
      "   product_name_clean                          is_wireless is_premium is_gaming\n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                                       \u001b[3m\u001b[90m<lgl>\u001b[39m\u001b[23m       \u001b[3m\u001b[90m<lgl>\u001b[39m\u001b[23m      \u001b[3m\u001b[90m<lgl>\u001b[39m\u001b[23m    \n",
      "\u001b[90m 1\u001b[39m \u001b[90m\"\u001b[39mApple iPhone 14 Pro - 128GB - Space Black\u001b[90m\"\u001b[39m FALSE       TRUE       FALSE    \n",
      "\u001b[90m 2\u001b[39m \u001b[90m\"\u001b[39mSamsung Galaxy S23 Ultra 256GB\u001b[90m\"\u001b[39m            FALSE       FALSE      FALSE    \n",
      "\u001b[90m 3\u001b[39m \u001b[90m\"\u001b[39mApple iPhone 14 Pro - 128GB - Space Black\u001b[90m\"\u001b[39m FALSE       TRUE       FALSE    \n",
      "\u001b[90m 4\u001b[39m \u001b[90m\"\u001b[39mApple iPhone 14 Pro - 128GB - Space Black\u001b[90m\"\u001b[39m FALSE       TRUE       FALSE    \n",
      "\u001b[90m 5\u001b[39m \u001b[90m\"\u001b[39mSamsung Galaxy S23 Ultra 256GB\u001b[90m\"\u001b[39m            FALSE       FALSE      FALSE    \n",
      "\u001b[90m 6\u001b[39m \u001b[90m\"\u001b[39mApple iPhone 14 Pro - 128GB - Space Black\u001b[90m\"\u001b[39m FALSE       TRUE       FALSE    \n",
      "\u001b[90m 7\u001b[39m \u001b[90m\"\u001b[39mDELL XPS 13 Laptop - Intel i7 - 16GB RAM\u001b[90m\"\u001b[39m  FALSE       FALSE      FALSE    \n",
      "\u001b[90m 8\u001b[39m \u001b[90m\"\u001b[39mHP Envy Printer - Wireless - Color\u001b[90m\"\u001b[39m        TRUE        FALSE      FALSE    \n",
      "\u001b[90m 9\u001b[39m \u001b[90m\"\u001b[39mNike Air Max 270 - Size 10 - Black/White\u001b[90m\"\u001b[39m  FALSE       FALSE      FALSE    \n",
      "\u001b[90m10\u001b[39m \u001b[90m\"\u001b[39mLG 55\\\" 4K Smart TV - OLED Display\u001b[90m\"\u001b[39m        FALSE       FALSE      FALSE    \n",
      "\n",
      "Feature Summary:\n",
      "Wireless products: 17 \n",
      "Premium products: 13 \n",
      "Gaming products: 0 \n"
     ]
    }
   ],
   "source": [
    "# Task 3.1: Detect Product Features\n",
    "# TODO: Create three new columns:\n",
    "#   - is_wireless: TRUE if product name contains \"wireless\" (case-insensitive)\n",
    "#   - is_premium: TRUE if product name contains \"pro\", \"premium\", or \"deluxe\"\n",
    "#   - is_gaming: TRUE if product name contains \"gaming\" or \"gamer\"\n",
    "# Hint: Use str_detect() with str_to_lower() for case-insensitive matching\n",
    "# Hint: Use | (pipe) in regex for OR conditions\n",
    "\n",
    "products_clean <- products_clean %>%\n",
    "  mutate(\n",
    "    is_wireless = str_detect(str_to_lower(product_name_clean), \"wireless\"),\n",
    "    is_premium  = str_detect(str_to_lower(product_name_clean), \"pro|premium|deluxe\"),\n",
    "    is_gaming   = str_detect(str_to_lower(product_name_clean), \"gaming|gamer\")\n",
    "  )\n",
    "\n",
    "# Display results\n",
    "cat(\"Product Feature Detection:\\n\")\n",
    "products_clean %>%\n",
    "  select(product_name_clean, is_wireless, is_premium, is_gaming) %>%\n",
    "  head(10) %>%\n",
    "  print()\n",
    "\n",
    "# Summary statistics\n",
    "cat(\"\\nFeature Summary:\\n\")\n",
    "cat(\"Wireless products:\", sum(products_clean$is_wireless), \"\\n\")\n",
    "cat(\"Premium products:\", sum(products_clean$is_premium), \"\\n\")\n",
    "cat(\"Gaming products:\", sum(products_clean$is_gaming), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "extract_specs",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Product Specifications:\n",
      "\u001b[90m# A tibble: 10 × 2\u001b[39m\n",
      "   product_name_clean                          size_number\n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                                       \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m      \n",
      "\u001b[90m 1\u001b[39m \u001b[90m\"\u001b[39mApple iPhone 14 Pro - 128GB - Space Black\u001b[90m\"\u001b[39m 14         \n",
      "\u001b[90m 2\u001b[39m \u001b[90m\"\u001b[39mSamsung Galaxy S23 Ultra 256GB\u001b[90m\"\u001b[39m            23         \n",
      "\u001b[90m 3\u001b[39m \u001b[90m\"\u001b[39mApple iPhone 14 Pro - 128GB - Space Black\u001b[90m\"\u001b[39m 14         \n",
      "\u001b[90m 4\u001b[39m \u001b[90m\"\u001b[39mApple iPhone 14 Pro - 128GB - Space Black\u001b[90m\"\u001b[39m 14         \n",
      "\u001b[90m 5\u001b[39m \u001b[90m\"\u001b[39mSamsung Galaxy S23 Ultra 256GB\u001b[90m\"\u001b[39m            23         \n",
      "\u001b[90m 6\u001b[39m \u001b[90m\"\u001b[39mApple iPhone 14 Pro - 128GB - Space Black\u001b[90m\"\u001b[39m 14         \n",
      "\u001b[90m 7\u001b[39m \u001b[90m\"\u001b[39mDELL XPS 13 Laptop - Intel i7 - 16GB RAM\u001b[90m\"\u001b[39m  13         \n",
      "\u001b[90m 8\u001b[39m \u001b[90m\"\u001b[39mNike Air Max 270 - Size 10 - Black/White\u001b[90m\"\u001b[39m  270        \n",
      "\u001b[90m 9\u001b[39m \u001b[90m\"\u001b[39mLG 55\\\" 4K Smart TV - OLED Display\u001b[90m\"\u001b[39m        55         \n",
      "\u001b[90m10\u001b[39m \u001b[90m\"\u001b[39mSony Wh-1000xm4 Wireless Headphones\u001b[90m\"\u001b[39m       1000       \n"
     ]
    }
   ],
   "source": [
    "# Task 3.2: Extract Product Specifications\n",
    "# TODO: Create a new column 'size_number' that extracts the first number from product_name\n",
    "# Hint: Use str_extract() with pattern \"\\\\d+\" to match one or more digits\n",
    "\n",
    "products_clean <- products_clean %>%\n",
    "  mutate(\n",
    "    size_number = str_extract(product_name_clean, \"\\\\d+\")  # extracting the first numeric value\n",
    "  )\n",
    "\n",
    "# Display products with extracted sizes\n",
    "cat(\"Extracted Product Specifications:\\n\")\n",
    "products_clean %>%\n",
    "  filter(!is.na(size_number)) %>%\n",
    "  select(product_name_clean, size_number) %>%\n",
    "  head(10) %>%\n",
    "  print()\n",
    "\n",
    "# My understanding is that we would do this to know what model something is.\n",
    "# For example, \"iPhone 14\" → 14, \"XPS 13\" → 13, and \"LG 55\\\" TV\" → 55.\n",
    "# I think the only issue would be with the LG 55 where 55 represents inches not necessarily a model number.\n",
    "# But maybe that's still a good way of distinguishing it from other lg TVs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "sentiment_analysis",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Analysis Results:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90m# A tibble: 10 × 4\u001b[39m\n",
      "   feedback_clean                  positive_words negative_words sentiment_score\n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                                    \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m          \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m           \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m highly recommend this item                   0              0               0\n",
      "\u001b[90m 2\u001b[39m excellent service                            1              0               1\n",
      "\u001b[90m 3\u001b[39m poor quality control                         0              1              -\u001b[31m1\u001b[39m\n",
      "\u001b[90m 4\u001b[39m average product, nothing speci…              0              0               0\n",
      "\u001b[90m 5\u001b[39m amazing customer support!!!                  1              0               1\n",
      "\u001b[90m 6\u001b[39m amazing customer support!!!                  1              0               1\n",
      "\u001b[90m 7\u001b[39m average product, nothing speci…              0              0               0\n",
      "\u001b[90m 8\u001b[39m good value for money                         1              0               1\n",
      "\u001b[90m 9\u001b[39m highly recommend this item                   0              0               0\n",
      "\u001b[90m10\u001b[39m highly recommend this item                   0              0               0\n",
      "\n",
      "Overall Sentiment Summary:\n",
      "Average sentiment score: 0.21 \n",
      "Positive reviews: 42 \n",
      "Negative reviews: 29 \n"
     ]
    }
   ],
   "source": [
    "# Task 3.3: Simple Sentiment Analysis\n",
    "# TODO: Create three new columns:\n",
    "#   - positive_words: count of positive words (\"great\", \"excellent\", \"love\", \"amazing\")\n",
    "#   - negative_words: count of negative words (\"bad\", \"terrible\", \"hate\", \"awful\")\n",
    "#   - sentiment_score: positive_words - negative_words\n",
    "# Hint: Use str_count() to count pattern occurrences\n",
    "\n",
    "feedback_clean <- feedback_clean %>%\n",
    "  mutate(\n",
    "    positive_words = str_count(feedback_clean, \"great|excellent|love|amazing|good|fantastic|awesome\"), \n",
    "    negative_words = str_count(feedback_clean, \"bad|terrible|hate|awful|poor|horrible|worst\"),\n",
    "    sentiment_score = positive_words - negative_words\n",
    "  )\n",
    "\n",
    "# Display sentiment analysis results\n",
    "cat(\"Sentiment Analysis Results:\\n\")\n",
    "feedback_clean %>%\n",
    "  select(feedback_clean, positive_words, negative_words, sentiment_score) %>%\n",
    "  head(10) %>%\n",
    "  print()\n",
    "\n",
    "# Summary\n",
    "cat(\"\\nOverall Sentiment Summary:\\n\")\n",
    "cat(\"Average sentiment score:\", mean(feedback_clean$sentiment_score), \"\\n\")\n",
    "cat(\"Positive reviews:\", sum(feedback_clean$sentiment_score > 0), \"\\n\")\n",
    "cat(\"Negative reviews:\", sum(feedback_clean$sentiment_score < 0), \"\\n\")\n",
    "\n",
    "# My Understanding:\n",
    "\n",
    "  # We are able to separate positive and negative reviews\n",
    "  # based on the words used in the feedback.\n",
    "  # each word serves as a +1 or -1 in the sentiment score depending on whether it is positive or negative.\n",
    "  # Then by simply subtracting the negative word count from the positive word count,\n",
    "  # we get an overall sentiment score for each review.\n",
    "\n",
    "  # The only issue is that even if some of these words were used, it is possible that\n",
    "  # they were used in a different context (e.g., \"I don't love this product\" would still count \"love\" as a positive word).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part4_intro",
   "metadata": {},
   "source": [
    "## Part 4: Date Parsing and Component Extraction\n",
    "\n",
    "**Business Context:** Transaction dates need to be parsed and analyzed to understand customer behavior patterns.\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Parse transaction dates from text to Date objects\n",
    "2. Extract date components (year, month, day, weekday)\n",
    "3. Identify weekend vs weekday transactions\n",
    "4. Extract quarter and month names\n",
    "\n",
    "**Key Functions:** `ymd()`, `mdy()`, `dmy()`, `year()`, `month()`, `day()`, `wday()`, `quarter()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f5de2d1e",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'4/5/24 14:30'</li><li>'3/15/24 14:30'</li><li>'3/15/24 14:30'</li><li>'3/20/24 9:15'</li><li>'3/20/24 9:15'</li><li>'3/20/24 9:15'</li><li>'3/20/24 9:15'</li><li>'3/15/24 14:30'</li><li>'25-03-2024 16:45:30'</li><li>'4/5/24 14:30'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item '4/5/24 14:30'\n",
       "\\item '3/15/24 14:30'\n",
       "\\item '3/15/24 14:30'\n",
       "\\item '3/20/24 9:15'\n",
       "\\item '3/20/24 9:15'\n",
       "\\item '3/20/24 9:15'\n",
       "\\item '3/20/24 9:15'\n",
       "\\item '3/15/24 14:30'\n",
       "\\item '25-03-2024 16:45:30'\n",
       "\\item '4/5/24 14:30'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. '4/5/24 14:30'\n",
       "2. '3/15/24 14:30'\n",
       "3. '3/15/24 14:30'\n",
       "4. '3/20/24 9:15'\n",
       "5. '3/20/24 9:15'\n",
       "6. '3/20/24 9:15'\n",
       "7. '3/20/24 9:15'\n",
       "8. '3/15/24 14:30'\n",
       "9. '25-03-2024 16:45:30'\n",
       "10. '4/5/24 14:30'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"4/5/24 14:30\"        \"3/15/24 14:30\"       \"3/15/24 14:30\"      \n",
       " [4] \"3/20/24 9:15\"        \"3/20/24 9:15\"        \"3/20/24 9:15\"       \n",
       " [7] \"3/20/24 9:15\"        \"3/15/24 14:30\"       \"25-03-2024 16:45:30\"\n",
       "[10] \"4/5/24 14:30\"       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checking Dates Formats\n",
    "head(transactions$Transaction_DateTime, 10) \n",
    "\n",
    "# noticed its called Transaction_DateTime not Transaction_Date\n",
    "# most are mdy but some are dmy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "parse_dates",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date Parsing Results:\n",
      "\u001b[90m# A tibble: 10 × 2\u001b[39m\n",
      "   Transaction_DateTime date_parsed        \n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                \u001b[3m\u001b[90m<dttm>\u001b[39m\u001b[23m             \n",
      "\u001b[90m 1\u001b[39m 4/5/24 14:30         2024-04-05 \u001b[90m14:30:00\u001b[39m\n",
      "\u001b[90m 2\u001b[39m 3/15/24 14:30        2024-03-15 \u001b[90m14:30:00\u001b[39m\n",
      "\u001b[90m 3\u001b[39m 3/15/24 14:30        2024-03-15 \u001b[90m14:30:00\u001b[39m\n",
      "\u001b[90m 4\u001b[39m 3/20/24 9:15         2024-03-20 \u001b[90m09:15:00\u001b[39m\n",
      "\u001b[90m 5\u001b[39m 3/20/24 9:15         2024-03-20 \u001b[90m09:15:00\u001b[39m\n",
      "\u001b[90m 6\u001b[39m 3/20/24 9:15         2024-03-20 \u001b[90m09:15:00\u001b[39m\n",
      "\u001b[90m 7\u001b[39m 3/20/24 9:15         2024-03-20 \u001b[90m09:15:00\u001b[39m\n",
      "\u001b[90m 8\u001b[39m 3/15/24 14:30        2024-03-15 \u001b[90m14:30:00\u001b[39m\n",
      "\u001b[90m 9\u001b[39m 25-03-2024 16:45:30  2024-03-25 \u001b[90m16:45:30\u001b[39m\n",
      "\u001b[90m10\u001b[39m 4/5/24 14:30         2024-04-05 \u001b[90m14:30:00\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "# Task 4.1: Parse Transaction Dates\n",
    "# TODO: Create a new column 'date_parsed' that parses the Transaction_DateTime column\n",
    "# Hint: Check the format of Transaction_DateTime first, then use ymd(), mdy(), or dmy()\n",
    "\n",
    "transactions_clean <- transactions %>%\n",
    "  mutate(\n",
    "    date_parsed = parse_date_time(    # I used parse_date_time to handle multiple formats (extra challenge)\n",
    "      Transaction_DateTime,\n",
    "      orders = c(\"mdy HM\", \"dmy HMS\", \"dmy HM\",\"ymd_HMS\"),  # all possible formats\n",
    "      quiet = TRUE\n",
    "    )\n",
    "  )\n",
    "# Verify parsing worked\n",
    "cat(\"Date Parsing Results:\\n\")\n",
    "transactions_clean %>%\n",
    "  select(Transaction_DateTime, date_parsed) %>%  # correct column name (includes time)\n",
    "  head(10) %>%\n",
    "  print()\n",
    "\n",
    "# originally got NAs because some dates are in dmy format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "extract_components",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date Component Extraction:\n",
      "\u001b[90m# A tibble: 10 × 4\u001b[39m\n",
      "   date_parsed         trans_month_name trans_weekday trans_quarter\n",
      "   \u001b[3m\u001b[90m<dttm>\u001b[39m\u001b[23m              \u001b[3m\u001b[90m<ord>\u001b[39m\u001b[23m            \u001b[3m\u001b[90m<ord>\u001b[39m\u001b[23m                 \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m 2024-04-05 \u001b[90m14:30:00\u001b[39m April            Friday                    2\n",
      "\u001b[90m 2\u001b[39m 2024-03-15 \u001b[90m14:30:00\u001b[39m March            Friday                    1\n",
      "\u001b[90m 3\u001b[39m 2024-03-15 \u001b[90m14:30:00\u001b[39m March            Friday                    1\n",
      "\u001b[90m 4\u001b[39m 2024-03-20 \u001b[90m09:15:00\u001b[39m March            Wednesday                 1\n",
      "\u001b[90m 5\u001b[39m 2024-03-20 \u001b[90m09:15:00\u001b[39m March            Wednesday                 1\n",
      "\u001b[90m 6\u001b[39m 2024-03-20 \u001b[90m09:15:00\u001b[39m March            Wednesday                 1\n",
      "\u001b[90m 7\u001b[39m 2024-03-20 \u001b[90m09:15:00\u001b[39m March            Wednesday                 1\n",
      "\u001b[90m 8\u001b[39m 2024-03-15 \u001b[90m14:30:00\u001b[39m March            Friday                    1\n",
      "\u001b[90m 9\u001b[39m 2024-03-25 \u001b[90m16:45:30\u001b[39m March            Monday                    1\n",
      "\u001b[90m10\u001b[39m 2024-04-05 \u001b[90m14:30:00\u001b[39m April            Friday                    2\n"
     ]
    }
   ],
   "source": [
    "# Task 4.2: Extract Date Components\n",
    "# TODO: Create the following new columns:\n",
    "#   - trans_year: Extract year from date_parsed\n",
    "#   - trans_month: Extract month number from date_parsed\n",
    "#   - trans_month_name: Extract month name (use label=TRUE, abbr=FALSE)\n",
    "#   - trans_day: Extract day of month from date_parsed\n",
    "#   - trans_weekday: Extract weekday name (use label=TRUE, abbr=FALSE)\n",
    "#   - trans_quarter: Extract quarter from date_parsed\n",
    "\n",
    "transactions_clean <- transactions_clean %>%\n",
    "  mutate(\n",
    "    trans_year = year(date_parsed),\n",
    "    trans_month = month(date_parsed),\n",
    "    trans_month_name = month(date_parsed, label = TRUE, abbr = FALSE),\n",
    "    trans_day = day(date_parsed),\n",
    "    trans_weekday = wday(date_parsed, label = TRUE, abbr = FALSE),\n",
    "    trans_quarter = quarter(date_parsed)\n",
    "  )\n",
    "\n",
    "# Display results\n",
    "cat(\"Date Component Extraction:\\n\")\n",
    "transactions_clean %>%\n",
    "  select(date_parsed, trans_month_name, trans_weekday, trans_quarter) %>%\n",
    "  head(10) %>%\n",
    "  print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "weekend_flag",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weekend vs Weekday Transactions:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FALSE \n",
      "  150 \n",
      "\n",
      "Percentage of weekend transactions: 0 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 3 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>trans_weekday</th><th scope=col>n</th></tr>\n",
       "\t<tr><th scope=col>&lt;ord&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>Monday   </td><td>61</td></tr>\n",
       "\t<tr><td>Wednesday</td><td>34</td></tr>\n",
       "\t<tr><td>Friday   </td><td>55</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 3 × 2\n",
       "\\begin{tabular}{ll}\n",
       " trans\\_weekday & n\\\\\n",
       " <ord> & <int>\\\\\n",
       "\\hline\n",
       "\t Monday    & 61\\\\\n",
       "\t Wednesday & 34\\\\\n",
       "\t Friday    & 55\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 3 × 2\n",
       "\n",
       "| trans_weekday &lt;ord&gt; | n &lt;int&gt; |\n",
       "|---|---|\n",
       "| Monday    | 61 |\n",
       "| Wednesday | 34 |\n",
       "| Friday    | 55 |\n",
       "\n"
      ],
      "text/plain": [
       "  trans_weekday n \n",
       "1 Monday        61\n",
       "2 Wednesday     34\n",
       "3 Friday        55"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 1 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>is_weekend</th><th scope=col>n</th></tr>\n",
       "\t<tr><th scope=col>&lt;lgl&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>FALSE</td><td>150</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 1 × 2\n",
       "\\begin{tabular}{ll}\n",
       " is\\_weekend & n\\\\\n",
       " <lgl> & <int>\\\\\n",
       "\\hline\n",
       "\t FALSE & 150\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 1 × 2\n",
       "\n",
       "| is_weekend &lt;lgl&gt; | n &lt;int&gt; |\n",
       "|---|---|\n",
       "| FALSE | 150 |\n",
       "\n"
      ],
      "text/plain": [
       "  is_weekend n  \n",
       "1 FALSE      150"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Task 4.3: Identify Weekend Transactions\n",
    "# TODO: Create a new column 'is_weekend' that is TRUE if the transaction was on Saturday or Sunday\n",
    "# Hint: Use wday() which returns 1 for Sunday and 7 for Saturday\n",
    "# Hint: Use %in% c(1, 7) to check if day is weekend\n",
    "\n",
    "transactions_clean <- transactions_clean %>%\n",
    "  mutate(\n",
    "    is_weekend = wday(date_parsed) %in% c(1, 7)  # TRUE if Sunday (1) or Saturday (7)\n",
    "  )\n",
    "\n",
    "# Summary\n",
    "cat(\"Weekend vs Weekday Transactions:\\n\")\n",
    "table(transactions_clean$is_weekend) %>% print()\n",
    "\n",
    "cat(\"\\nPercentage of weekend transactions:\",\n",
    "    round(sum(transactions_clean$is_weekend) / nrow(transactions_clean) * 100, 1), \"%\\n\")\n",
    "\n",
    "\n",
    "# Following instructions my output gave a 150 for False and said there were 0 weekend transactions.\n",
    "# It seemed suspicious\n",
    "# I had to check why weekend was 0% (Extra Work)\n",
    "transactions_clean %>%\n",
    "  count(trans_weekday)\n",
    "\n",
    "transactions_clean %>%\n",
    "  count(is_weekend)\n",
    "\n",
    "# Turns out there simply was no transactions on weekends in this dataset. Interestingly only Mondays, Wednesdays, and Fridays.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part5_intro",
   "metadata": {},
   "source": [
    "## Part 5: Date Calculations and Customer Recency Analysis\n",
    "\n",
    "**Business Context:** Understanding how recently customers transacted helps identify at-risk customers for re-engagement campaigns.\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Calculate days since each transaction\n",
    "2. Categorize customers by recency (Recent, Moderate, Old)\n",
    "3. Identify customers who haven't transacted in 90+ days\n",
    "4. Calculate average days between transactions per customer\n",
    "\n",
    "**Key Functions:** `today()`, date arithmetic, `case_when()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bb263fa8",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Join Verification:\n",
      "\u001b[90m# A tibble: 10 × 3\u001b[39m\n",
      "   CustomerID Customer_Name   date_parsed        \n",
      "        \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m           \u001b[3m\u001b[90m<dttm>\u001b[39m\u001b[23m             \n",
      "\u001b[90m 1\u001b[39m         26 Susan Harris    2024-04-05 \u001b[90m14:30:00\u001b[39m\n",
      "\u001b[90m 2\u001b[39m         21 Mary Thompson   2024-03-15 \u001b[90m14:30:00\u001b[39m\n",
      "\u001b[90m 3\u001b[39m         12 Bob Wilson      2024-03-15 \u001b[90m14:30:00\u001b[39m\n",
      "\u001b[90m 4\u001b[39m          6 Chris Martin    2024-03-20 \u001b[90m09:15:00\u001b[39m\n",
      "\u001b[90m 5\u001b[39m         32 \u001b[31mNA\u001b[39m              2024-03-20 \u001b[90m09:15:00\u001b[39m\n",
      "\u001b[90m 6\u001b[39m         27 Jennifer Taylor 2024-03-20 \u001b[90m09:15:00\u001b[39m\n",
      "\u001b[90m 7\u001b[39m         31 \u001b[31mNA\u001b[39m              2024-03-20 \u001b[90m09:15:00\u001b[39m\n",
      "\u001b[90m 8\u001b[39m         30 William Kim     2024-03-15 \u001b[90m14:30:00\u001b[39m\n",
      "\u001b[90m 9\u001b[39m         31 \u001b[31mNA\u001b[39m              2024-03-25 \u001b[90m16:45:30\u001b[39m\n",
      "\u001b[90m10\u001b[39m         13 John Doe        2024-04-05 \u001b[90m14:30:00\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 6 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>CustomerID</th><th scope=col>Customer_Name</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>26</td><td>Susan Harris   </td></tr>\n",
       "\t<tr><td>21</td><td>Mary Thompson  </td></tr>\n",
       "\t<tr><td>12</td><td>Bob Wilson     </td></tr>\n",
       "\t<tr><td> 6</td><td>Chris Martin   </td></tr>\n",
       "\t<tr><td>32</td><td>NA             </td></tr>\n",
       "\t<tr><td>27</td><td>Jennifer Taylor</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 6 × 2\n",
       "\\begin{tabular}{ll}\n",
       " CustomerID & Customer\\_Name\\\\\n",
       " <dbl> & <chr>\\\\\n",
       "\\hline\n",
       "\t 26 & Susan Harris   \\\\\n",
       "\t 21 & Mary Thompson  \\\\\n",
       "\t 12 & Bob Wilson     \\\\\n",
       "\t  6 & Chris Martin   \\\\\n",
       "\t 32 & NA             \\\\\n",
       "\t 27 & Jennifer Taylor\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 6 × 2\n",
       "\n",
       "| CustomerID &lt;dbl&gt; | Customer_Name &lt;chr&gt; |\n",
       "|---|---|\n",
       "| 26 | Susan Harris    |\n",
       "| 21 | Mary Thompson   |\n",
       "| 12 | Bob Wilson      |\n",
       "|  6 | Chris Martin    |\n",
       "| 32 | NA              |\n",
       "| 27 | Jennifer Taylor |\n",
       "\n"
      ],
      "text/plain": [
       "  CustomerID Customer_Name  \n",
       "1 26         Susan Harris   \n",
       "2 21         Mary Thompson  \n",
       "3 12         Bob Wilson     \n",
       "4  6         Chris Martin   \n",
       "5 32         NA             \n",
       "6 27         Jennifer Taylor"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Before doing the following tasks, I needed to ensure customer names were available for analysis.\n",
    "# Customer_Name values come from the feedback dataset (joined by CustomerID) since the transactions file did not originally include names.\n",
    "\n",
    "# Clean and deduplicate customer names in feedback\n",
    "feedback_cleaned <- feedback %>%\n",
    "  mutate(Customer_Name = str_to_title(Customer_Name)) %>%\n",
    "  distinct(CustomerID, .keep_all = TRUE)  # one unique name per CustomerID\n",
    "\n",
    "# Join cleaned names into transactions (many transactions per customer is fine)\n",
    "transactions_joined <- transactions_clean %>%\n",
    "  left_join(\n",
    "    feedback_cleaned %>% select(CustomerID, Customer_Name),\n",
    "    by = \"CustomerID\"  # standard many-to-one join\n",
    "  )\n",
    "\n",
    "# Confirm join worked\n",
    "cat(\"Join Verification:\\n\")\n",
    "transactions_joined %>%\n",
    "  select(CustomerID, Customer_Name, date_parsed) %>%\n",
    "  head(10) %>%\n",
    "  print()\n",
    "\n",
    "# Verify cleaned unique names\n",
    "transactions_joined %>%\n",
    "  select(CustomerID, Customer_Name) %>%\n",
    "  distinct() %>%\n",
    "  head()\n",
    "\n",
    "# This entire cell is extra work - not required for assignment \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "calculate_recency",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Days Since Transaction:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90m# A tibble: 10 × 3\u001b[39m\n",
      "   Customer_Name  date_parsed         days_since\n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m          \u001b[3m\u001b[90m<dttm>\u001b[39m\u001b[23m                   \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m Mary Thompson  2024-03-15 \u001b[90m14:30:00\u001b[39m        574\n",
      "\u001b[90m 2\u001b[39m Bob Wilson     2024-03-15 \u001b[90m14:30:00\u001b[39m        574\n",
      "\u001b[90m 3\u001b[39m William Kim    2024-03-15 \u001b[90m14:30:00\u001b[39m        574\n",
      "\u001b[90m 4\u001b[39m Michael Brown  2024-03-15 \u001b[90m14:30:00\u001b[39m        574\n",
      "\u001b[90m 5\u001b[39m Kevin Wong     2024-03-15 \u001b[90m14:30:00\u001b[39m        574\n",
      "\u001b[90m 6\u001b[39m Rachel Adams   2024-03-15 \u001b[90m14:30:00\u001b[39m        574\n",
      "\u001b[90m 7\u001b[39m Jane Smith     2024-03-15 \u001b[90m14:30:00\u001b[39m        574\n",
      "\u001b[90m 8\u001b[39m James Anderson 2024-03-15 \u001b[90m14:30:00\u001b[39m        574\n",
      "\u001b[90m 9\u001b[39m Kevin Wong     2024-03-15 \u001b[90m14:30:00\u001b[39m        574\n",
      "\u001b[90m10\u001b[39m William Kim    2024-03-15 \u001b[90m14:30:00\u001b[39m        574\n"
     ]
    }
   ],
   "source": [
    "# Task 5.1: Calculate Days Since Transaction\n",
    "# TODO: Create a new column 'days_since' that calculates days from date_parsed to today()\n",
    "# Hint: Use as.numeric(today() - date_parsed)\n",
    "\n",
    "transactions_joined <- transactions_joined %>%  # I used my joined dataset with names instead of transactions_clean\n",
    "  mutate(\n",
    "    days_since = as.numeric(today() - as_date(date_parsed))  # calculates time difference in days\n",
    "  )\n",
    "\n",
    "# Display results\n",
    "cat(\"Days Since Transaction:\\n\")\n",
    "transactions_joined %>%\n",
    "  select(Customer_Name, date_parsed, days_since) %>%\n",
    "  arrange(desc(days_since)) %>%\n",
    "  head(10) %>%\n",
    "  print()\n",
    "\n",
    "# Some Customer_Name values may still be NA because not every customer left feedback.\n",
    "# Still better than having no names at all. Thanks to my extra joining work \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "recency_categories",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recency Category Distribution:\n",
      "\n",
      "At Risk \n",
      "    150 \n",
      "\n",
      "At-Risk Customers (>90 days):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90m# A tibble: 150 × 3\u001b[39m\n",
      "   Customer_Name  date_parsed         days_since\n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m          \u001b[3m\u001b[90m<dttm>\u001b[39m\u001b[23m                   \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m Mary Thompson  2024-03-15 \u001b[90m14:30:00\u001b[39m        574\n",
      "\u001b[90m 2\u001b[39m Bob Wilson     2024-03-15 \u001b[90m14:30:00\u001b[39m        574\n",
      "\u001b[90m 3\u001b[39m William Kim    2024-03-15 \u001b[90m14:30:00\u001b[39m        574\n",
      "\u001b[90m 4\u001b[39m Michael Brown  2024-03-15 \u001b[90m14:30:00\u001b[39m        574\n",
      "\u001b[90m 5\u001b[39m Kevin Wong     2024-03-15 \u001b[90m14:30:00\u001b[39m        574\n",
      "\u001b[90m 6\u001b[39m Rachel Adams   2024-03-15 \u001b[90m14:30:00\u001b[39m        574\n",
      "\u001b[90m 7\u001b[39m Jane Smith     2024-03-15 \u001b[90m14:30:00\u001b[39m        574\n",
      "\u001b[90m 8\u001b[39m James Anderson 2024-03-15 \u001b[90m14:30:00\u001b[39m        574\n",
      "\u001b[90m 9\u001b[39m Kevin Wong     2024-03-15 \u001b[90m14:30:00\u001b[39m        574\n",
      "\u001b[90m10\u001b[39m William Kim    2024-03-15 \u001b[90m14:30:00\u001b[39m        574\n",
      "\u001b[90m# ℹ 140 more rows\u001b[39m\n",
      "All Customers:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "150"
      ],
      "text/latex": [
       "150"
      ],
      "text/markdown": [
       "150"
      ],
      "text/plain": [
       "[1] 150"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Customer Count Comparison:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 1 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>Total_Customers</th><th scope=col>At_Risk_Customers</th></tr>\n",
       "\t<tr><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>150</td><td>150</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 1 × 2\n",
       "\\begin{tabular}{ll}\n",
       " Total\\_Customers & At\\_Risk\\_Customers\\\\\n",
       " <int> & <int>\\\\\n",
       "\\hline\n",
       "\t 150 & 150\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 1 × 2\n",
       "\n",
       "| Total_Customers &lt;int&gt; | At_Risk_Customers &lt;int&gt; |\n",
       "|---|---|\n",
       "| 150 | 150 |\n",
       "\n"
      ],
      "text/plain": [
       "  Total_Customers At_Risk_Customers\n",
       "1 150             150              "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Task 5.2: Categorize by Recency\n",
    "# TODO: Create a new column 'recency_category' using case_when():\n",
    "#   - \"Recent\" if days_since <= 30\n",
    "#   - \"Moderate\" if days_since <= 90\n",
    "#   - \"At Risk\" if days_since > 90\n",
    "\n",
    "# Still using my joined dataset (transactions_joined) since it includes Customer_Name\n",
    "# this makes it easier to interpret results and identify at-risk customers later.\n",
    "\n",
    "\n",
    "transactions_joined <- transactions_joined %>%\n",
    "  mutate(\n",
    "    recency_category = case_when(\n",
    "      days_since <= 30 ~ \"Recent\",\n",
    "      days_since <= 90 ~ \"Moderate\",\n",
    "      days_since > 90  ~ \"At Risk\",\n",
    "      TRUE ~ NA_character_  # just in case\n",
    "    )\n",
    "  )\n",
    "\n",
    "# Display distribution\n",
    "cat(\"Recency Category Distribution:\\n\")\n",
    "table(transactions_joined$recency_category) %>% print()\n",
    "\n",
    "# Show at-risk customers\n",
    "cat(\"\\nAt-Risk Customers (>90 days):\\n\")\n",
    "transactions_joined %>%\n",
    "  filter(recency_category == \"At Risk\") %>%\n",
    "  select(Customer_Name, date_parsed, days_since) %>%\n",
    "  arrange(desc(days_since)) %>%\n",
    "  print()\n",
    "\n",
    "# Number of Customers\n",
    "cat(\"All Customers:\\n\")\n",
    "nrow(transactions_joined)\n",
    "\n",
    "\n",
    "# Now that we know who is at risk, we could target them with special offers or follow-ups\n",
    "# and since my joined dataset includes names, we can personalize outreach thanks to that earlier join work.\n",
    "\n",
    "# One final thing — since this dataset is from 2024 and the class takes place in Fall 2025,\n",
    "# all customers are technically \"At Risk\" because the most recent transaction occurred over a year ago\n",
    "# which is more than 90 days. But I followed the instructions as given.\n",
    "\n",
    "\n",
    "\n",
    "# Comparing counts side by side to show that all customers are at risk\n",
    "cat(\"\\nCustomer Count Comparison:\\n\")\n",
    "data.frame(\n",
    "  Total_Customers = nrow(transactions_joined),\n",
    "  At_Risk_Customers = nrow(transactions_joined %>% \n",
    "    filter(recency_category == \"At Risk\"))\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part6_intro",
   "metadata": {},
   "source": [
    "## Part 6: Combined String and Date Operations\n",
    "\n",
    "**Business Context:** Create personalized customer outreach messages based on purchase recency.\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Extract first names from customer names\n",
    "2. Create personalized messages based on recency\n",
    "3. Analyze transaction patterns by weekday\n",
    "4. Identify best customers (recent + high value)\n",
    "\n",
    "**Key Functions:** Combine `str_extract()`, date calculations, `case_when()`, `group_by()`, `summarize()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "extract_names",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Personalized Customer Messages:\n",
      "\u001b[90m# A tibble: 10 × 4\u001b[39m\n",
      "   Customer_Name   first_name      days_since personalized_message              \n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m           \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                             \n",
      "\u001b[90m 1\u001b[39m Susan Harris    Susan                  553 Hi Susan , it's been a while! Her…\n",
      "\u001b[90m 2\u001b[39m Mary Thompson   Mary                   574 Hi Mary , it's been a while! Here…\n",
      "\u001b[90m 3\u001b[39m Bob Wilson      Bob                    574 Hi Bob , it's been a while! Here'…\n",
      "\u001b[90m 4\u001b[39m Chris Martin    Chris                  569 Hi Chris , it's been a while! Her…\n",
      "\u001b[90m 5\u001b[39m \u001b[31mNA\u001b[39m              Valued Customer        569 Hi Valued Customer , it's been a …\n",
      "\u001b[90m 6\u001b[39m Jennifer Taylor Jennifer               569 Hi Jennifer , it's been a while! …\n",
      "\u001b[90m 7\u001b[39m \u001b[31mNA\u001b[39m              Valued Customer        569 Hi Valued Customer , it's been a …\n",
      "\u001b[90m 8\u001b[39m William Kim     William                574 Hi William , it's been a while! H…\n",
      "\u001b[90m 9\u001b[39m \u001b[31mNA\u001b[39m              Valued Customer        564 Hi Valued Customer , it's been a …\n",
      "\u001b[90m10\u001b[39m John Doe        John                   553 Hi John , it's been a while! Here…\n"
     ]
    }
   ],
   "source": [
    "# Task 6.1: Extract First Names and Create Personalized Messages\n",
    "# TODO: Create two new columns:\n",
    "#   - first_name: Extract first name from Customer_Name (everything before the first space)\n",
    "#   - personalized_message: Create message based on recency_category\n",
    "#     * Recent: \"Hi [name]! Thanks for your recent purchase!\"\n",
    "#     * Moderate: \"Hi [name], we miss you! Check out our new products.\"\n",
    "#     * At Risk: \"Hi [name], it's been a while! Here's a special offer for you.\"\n",
    "\n",
    "# Using my joined dataset (transactions_joined) so I can include customer names in messages.\n",
    "customer_outreach <- transactions_joined %>%\n",
    "  mutate(\n",
    "    first_name = str_extract(Customer_Name, \"^\\\\w+\"),\n",
    "    personalized_message = case_when(\n",
    "      recency_category == \"Recent\" ~ paste(\"Hi\", first_name, \"! Thanks for your recent purchase!\"),\n",
    "      recency_category == \"Moderate\" ~ paste(\"Hi\", first_name, \", we miss you! Check out our new products.\"),\n",
    "      recency_category == \"At Risk\" ~ paste(\"Hi\", first_name, \", it's been a while! Here's a special offer for you.\"),\n",
    "      TRUE ~ NA_character_\n",
    "    )\n",
    "  )\n",
    "\n",
    "# some customers show NA for names — these are transactions without matching feedback records.\n",
    "# I want to take these out for a better final output (extra work) maybe if it is NA then say valued customer instead\n",
    "customer_outreach <- customer_outreach %>%\n",
    "  mutate(\n",
    "    first_name = if_else(is.na(first_name), \"Valued Customer\", first_name),\n",
    "    personalized_message = str_replace(\n",
    "      personalized_message,\n",
    "      \"Hi NA\",\n",
    "      \"Hi Valued Customer\"\n",
    "    )\n",
    "  )\n",
    "\n",
    "\n",
    "# Display personalized messages\n",
    "cat(\"Personalized Customer Messages:\\n\")\n",
    "customer_outreach %>%\n",
    "  select(Customer_Name, first_name, days_since, personalized_message) %>%\n",
    "  head(10) %>%\n",
    "  print()\n",
    "\n",
    "# again thanks to my earlier joining work, I was able to include customer names in the messages.\n",
    "# and again since all customers are technically \"At Risk\" due to the dataset being from 2024,\n",
    "# all messages will reflect that status. But I followed the instructions as given.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weekday_analysis",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transaction Patterns by Weekday:\n",
      "\u001b[90m# A tibble: 3 × 4\u001b[39m\n",
      "  trans_weekday transaction_count total_amount avg_amount\n",
      "  \u001b[3m\u001b[90m<ord>\u001b[39m\u001b[23m                     \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m        \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m      \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m Monday                       61       \u001b[4m1\u001b[24m\u001b[4m5\u001b[24m367.       252.\n",
      "\u001b[90m2\u001b[39m Friday                       55       \u001b[4m1\u001b[24m\u001b[4m4\u001b[24m789.       269.\n",
      "\u001b[90m3\u001b[39m Wednesday                    34        \u001b[4m7\u001b[24m578.       223.\n",
      "\n",
      "🔥 Busiest day: Monday \n"
     ]
    }
   ],
   "source": [
    "# Task 6.2: Analyze Transaction Patterns by Weekday\n",
    "# TODO: Group by trans_weekday and calculate:\n",
    "#   - transaction_count: number of transactions\n",
    "#   - total_amount: sum of amount (if available)\n",
    "#   - avg_amount: average amount per transaction\n",
    "# TODO: Arrange by transaction_count descending\n",
    "\n",
    "weekday_patterns <- transactions_joined %>% #still using my joined dataset (extra work)\n",
    "  group_by(trans_weekday) %>%\n",
    "  summarise(\n",
    "    transaction_count = n(),\n",
    "    total_amount = sum(Amount, na.rm = TRUE),\n",
    "    avg_amount = mean(Amount, na.rm = TRUE)\n",
    "  ) %>%\n",
    "  arrange(desc(transaction_count))\n",
    "\n",
    "# Display results\n",
    "cat(\"Transaction Patterns by Weekday:\\n\")\n",
    "print(weekday_patterns)\n",
    "\n",
    "# Identify busiest day\n",
    "busiest_day <- weekday_patterns$trans_weekday[1]\n",
    "cat(\"\\n🔥 Busiest day:\", as.character(busiest_day), \"\\n\")\n",
    "\n",
    "# Based on the summary above, Monday had the highest number of transactions.\n",
    "# This suggests customers were most active at the start of the week.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "monthly_analysis",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monthly Transaction Patterns:\n",
      "\u001b[90m# A tibble: 2 × 4\u001b[39m\n",
      "  trans_month trans_month_name transaction_count unique_customers\n",
      "        \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<ord>\u001b[39m\u001b[23m                        \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m            \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m           3 March                           89               21\n",
      "\u001b[90m2\u001b[39m           4 April                           61               23\n"
     ]
    }
   ],
   "source": [
    "# Task 6.3: Monthly Transaction Analysis\n",
    "# TODO: Group by trans_month_name and calculate:\n",
    "#   - transaction_count\n",
    "#   - unique_customers: use n_distinct(Customer_Name)\n",
    "# TODO: Arrange by trans_month (to show chronological order)\n",
    "\n",
    "monthly_patterns <- transactions_joined %>% # Using transactions_joined so we can count unique customers by name.(extra work)\n",
    "  group_by(trans_month, trans_month_name) %>%\n",
    "  summarise(\n",
    "    transaction_count = n(),\n",
    "    unique_customers = n_distinct(Customer_Name),\n",
    "    .groups = \"drop\"\n",
    "  ) %>%\n",
    "  arrange(trans_month)\n",
    "\n",
    "\n",
    "# Display results\n",
    "cat(\"Monthly Transaction Patterns:\\n\")\n",
    "print(monthly_patterns)\n",
    "\n",
    "# Looks like transactions only occurred in March and April.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part7_intro",
   "metadata": {},
   "source": [
    "## Part 7: Business Intelligence Summary\n",
    "\n",
    "**Business Context:** Create an executive summary that combines all your analyses into actionable insights.\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Calculate key metrics across all datasets\n",
    "2. Identify top products and categories\n",
    "3. Summarize customer sentiment\n",
    "4. Provide data-driven recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0a0ab0e0",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'LogID'</li><li>'CustomerID'</li><li>'Transaction_DateTime'</li><li>'Amount'</li><li>'Status'</li><li>'date_parsed'</li><li>'trans_year'</li><li>'trans_month'</li><li>'trans_month_name'</li><li>'trans_day'</li><li>'trans_weekday'</li><li>'trans_quarter'</li><li>'is_weekend'</li><li>'Customer_Name'</li><li>'days_since'</li><li>'recency_category'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'LogID'\n",
       "\\item 'CustomerID'\n",
       "\\item 'Transaction\\_DateTime'\n",
       "\\item 'Amount'\n",
       "\\item 'Status'\n",
       "\\item 'date\\_parsed'\n",
       "\\item 'trans\\_year'\n",
       "\\item 'trans\\_month'\n",
       "\\item 'trans\\_month\\_name'\n",
       "\\item 'trans\\_day'\n",
       "\\item 'trans\\_weekday'\n",
       "\\item 'trans\\_quarter'\n",
       "\\item 'is\\_weekend'\n",
       "\\item 'Customer\\_Name'\n",
       "\\item 'days\\_since'\n",
       "\\item 'recency\\_category'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'LogID'\n",
       "2. 'CustomerID'\n",
       "3. 'Transaction_DateTime'\n",
       "4. 'Amount'\n",
       "5. 'Status'\n",
       "6. 'date_parsed'\n",
       "7. 'trans_year'\n",
       "8. 'trans_month'\n",
       "9. 'trans_month_name'\n",
       "10. 'trans_day'\n",
       "11. 'trans_weekday'\n",
       "12. 'trans_quarter'\n",
       "13. 'is_weekend'\n",
       "14. 'Customer_Name'\n",
       "15. 'days_since'\n",
       "16. 'recency_category'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"LogID\"                \"CustomerID\"           \"Transaction_DateTime\"\n",
       " [4] \"Amount\"               \"Status\"               \"date_parsed\"         \n",
       " [7] \"trans_year\"           \"trans_month\"          \"trans_month_name\"    \n",
       "[10] \"trans_day\"            \"trans_weekday\"        \"trans_quarter\"       \n",
       "[13] \"is_weekend\"           \"Customer_Name\"        \"days_since\"          \n",
       "[16] \"recency_category\"    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colnames(transactions_joined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "business_summary",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "         BUSINESS INTELLIGENCE SUMMARY\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "\n",
      "📦 PRODUCT ANALYSIS\n",
      "─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ \n",
      "Total Products: 75 \n",
      "Wireless Products: 17 \n",
      "Premium Products: 0 \n",
      "Most Common Category: Electronics \n",
      "\n",
      "💬 CUSTOMER SENTIMENT\n",
      "─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ \n",
      "Total Feedback Entries: 100 \n",
      "Average Sentiment Score: 0.21 \n",
      "Positive Reviews (%): 42 \n",
      "Negative Reviews (%): 29 \n",
      "\n",
      "📊 TRANSACTION PATTERNS\n",
      "─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ \n",
      "Total Transactions: 150 \n",
      "Date Range: 2024-03-15 to 2024-04-05 \n",
      "Busiest Weekday: 2 \n",
      "Weekend Transaction %: 0 \n",
      "\n",
      "👥 CUSTOMER RECENCY\n",
      "─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ \n",
      "Recent Customers (<30 days): 0 \n",
      "At-Risk Customers (>90 days): 25 \n",
      "Need Re-engagement (%): 100 \n",
      "\n",
      "Note: All customers appear 'At Risk' because the dataset's latest transaction is from 2024.\n"
     ]
    }
   ],
   "source": [
    "# Task 7.1: Create Business Intelligence Dashboard\n",
    "\n",
    "cat(\"\\n\", rep(\"=\", 60), \"\\n\")\n",
    "cat(\"         BUSINESS INTELLIGENCE SUMMARY\\n\")\n",
    "cat(rep(\"=\", 60), \"\\n\\n\")\n",
    "\n",
    "# 📦 PRODUCT ANALYSIS\n",
    "cat(\"📦 PRODUCT ANALYSIS\\n\")\n",
    "cat(rep(\"─\", 30), \"\\n\")\n",
    "\n",
    "# Total number of products\n",
    "total_products <- nrow(products_clean)\n",
    "\n",
    "# Number of wireless products\n",
    "wireless_products <- products_clean %>%\n",
    "  filter(str_detect(Product_Description, regex(\"wireless\", ignore_case = TRUE))) %>%\n",
    "  nrow()\n",
    "\n",
    "# Number of premium products\n",
    "premium_products <- products_clean %>%\n",
    "  filter(str_detect(Category, regex(\"premium\", ignore_case = TRUE))) %>%\n",
    "  nrow()\n",
    "\n",
    "# Most common category\n",
    "most_common_category <- products_clean %>%\n",
    "  count(category_clean, sort = TRUE) %>%\n",
    "  slice(1) %>%\n",
    "  pull(category_clean)\n",
    "\n",
    "# Display results\n",
    "cat(\"Total Products:\", total_products, \"\\n\")\n",
    "cat(\"Wireless Products:\", wireless_products, \"\\n\")\n",
    "cat(\"Premium Products:\", premium_products, \"\\n\")\n",
    "cat(\"Most Common Category:\", most_common_category, \"\\n\")\n",
    "\n",
    "\n",
    "# 💬 CUSTOMER SENTIMENT\n",
    "cat(\"\\n💬 CUSTOMER SENTIMENT\\n\")\n",
    "cat(rep(\"─\", 30), \"\\n\")\n",
    "\n",
    "# Total feedback entries\n",
    "total_feedback <- nrow(feedback_clean)\n",
    "\n",
    "# Average sentiment score\n",
    "avg_sentiment <- mean(feedback_clean$sentiment_score, na.rm = TRUE)\n",
    "\n",
    "# Percentage of positive and negative reviews\n",
    "positive_reviews <- sum(feedback_clean$sentiment_score > 0, na.rm = TRUE)\n",
    "negative_reviews <- sum(feedback_clean$sentiment_score < 0, na.rm = TRUE)\n",
    "\n",
    "positive_pct <- round((positive_reviews / total_feedback) * 100, 1)\n",
    "negative_pct <- round((negative_reviews / total_feedback) * 100, 1)\n",
    "\n",
    "# Display results\n",
    "cat(\"Total Feedback Entries:\", total_feedback, \"\\n\")\n",
    "cat(\"Average Sentiment Score:\", avg_sentiment, \"\\n\")\n",
    "cat(\"Positive Reviews (%):\", positive_pct, \"\\n\")\n",
    "cat(\"Negative Reviews (%):\", negative_pct, \"\\n\")\n",
    "\n",
    "\n",
    "# 📊 TRANSACTION PATTERNS\n",
    "cat(\"\\n📊 TRANSACTION PATTERNS\\n\")\n",
    "cat(rep(\"─\", 30), \"\\n\")\n",
    "\n",
    "# Total transactions\n",
    "total_transactions <- nrow(transactions_joined)\n",
    "\n",
    "# Date range (earliest to latest)\n",
    "date_min <- min(transactions_joined$date_parsed, na.rm = TRUE)\n",
    "date_max <- max(transactions_joined$date_parsed, na.rm = TRUE)\n",
    "\n",
    "# Busiest weekday\n",
    "busiest_day <- transactions_joined %>%\n",
    "  count(trans_weekday, sort = TRUE) %>%\n",
    "  slice(1) %>%\n",
    "  pull(trans_weekday)\n",
    "\n",
    "# Weekend transaction %\n",
    "weekend_pct <- round(sum(transactions_joined$is_weekend, na.rm = TRUE) / total_transactions * 100, 1)\n",
    "\n",
    "# Display results\n",
    "cat(\"Total Transactions:\", total_transactions, \"\\n\")\n",
    "cat(\"Date Range:\", format(date_min, \"%Y-%m-%d\"), \"to\", format(date_max, \"%Y-%m-%d\"), \"\\n\")\n",
    "cat(\"Busiest Weekday:\", busiest_day, \"\\n\")\n",
    "cat(\"Weekend Transaction %:\", weekend_pct, \"\\n\")\n",
    "\n",
    "\n",
    "# 👥 CUSTOMER RECENCY\n",
    "cat(\"\\n👥 CUSTOMER RECENCY\\n\")\n",
    "cat(rep(\"─\", 30), \"\\n\")\n",
    "\n",
    "# Recent customers (<30 days)\n",
    "recent_customers <- transactions_joined %>%\n",
    "  filter(days_since <= 30) %>%\n",
    "  summarise(n = n_distinct(Customer_Name)) %>%\n",
    "  pull(n)\n",
    "\n",
    "# At-risk customers (>90 days)\n",
    "at_risk_customers <- transactions_joined %>%\n",
    "  filter(days_since > 90) %>%\n",
    "  summarise(n = n_distinct(Customer_Name)) %>%\n",
    "  pull(n)\n",
    "\n",
    "# Total unique customers\n",
    "total_customers <- transactions_joined %>%\n",
    "  summarise(n = n_distinct(Customer_Name)) %>%\n",
    "  pull(n)\n",
    "\n",
    "# % needing re-engagement\n",
    "reengagement_pct <- round((at_risk_customers / total_customers) * 100, 1)\n",
    "\n",
    "# Display results\n",
    "cat(\"Recent Customers (<30 days):\", recent_customers, \"\\n\")\n",
    "cat(\"At-Risk Customers (>90 days):\", at_risk_customers, \"\\n\")\n",
    "cat(\"Need Re-engagement (%):\", reengagement_pct, \"\\n\")\n",
    "\n",
    "cat(\"\\nNote: All customers appear 'At Risk' because the dataset's latest transaction is from 2024.\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "top_products",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Product Categories:\n",
      "\u001b[90m# A tibble: 5 × 2\u001b[39m\n",
      "  category_clean product_count\n",
      "  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                  \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m Electronics               21\n",
      "\u001b[90m2\u001b[39m Computers                 15\n",
      "\u001b[90m3\u001b[39m Audio                     14\n",
      "\u001b[90m4\u001b[39m TV                        14\n",
      "\u001b[90m5\u001b[39m Shoes                     11\n"
     ]
    }
   ],
   "source": [
    "# Task 7.2: Identify Top Products by Category\n",
    "# TODO: Group products by category_clean and count products in each\n",
    "# TODO: Arrange by count descending\n",
    "# TODO: Display top 5 categories\n",
    "\n",
    "top_categories <- products_clean %>%\n",
    "  group_by(category_clean) %>%\n",
    "  summarise(product_count = n()) %>%\n",
    "  arrange(desc(product_count)) %>%\n",
    "  head(5)\n",
    "\n",
    "cat(\"Top Product Categories:\\n\")\n",
    "print(top_categories)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part8_intro",
   "metadata": {},
   "source": [
    "## Part 8: Reflection Questions\n",
    "\n",
    "Answer the following questions based on your analysis. Write your answers in the markdown cells below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection1",
   "metadata": {},
   "source": [
    "### Question 8.1: Data Quality Impact\n",
    "\n",
    "**How did cleaning the text data (removing spaces, standardizing case) improve your ability to analyze the data? Provide specific examples from your homework.**\n",
    "\n",
    "Cleaning the text data by removing extra spaces and standardizing case made a big difference in how accurate my joins and counts were. Before cleaning, names like “susan harris” and “Susan Harris ” wouldn’t have matched between the transactions and feedback tables, which caused missing or duplicate rows.\n",
    "\n",
    "After using functions like str_trim() and str_to_title(), I was able to join the datasets correctly and get full customer names in transactions_joined. That made later tasks like the personalized messages and recency grouping much cleaner and more readable. Overall, cleaning the text fixed issues that would’ve caused wrong totals and messy analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection2",
   "metadata": {},
   "source": [
    "### Question 8.2: Pattern Detection Value\n",
    "\n",
    "**What business insights did you gain from detecting patterns in product names (wireless, premium, gaming)? How could a business use this information?**\n",
    "\n",
    "Looking for patterns in product names helped me see what the company was focused on. I found 17 wireless products out of 75 total, but none labeled as premium. That shows a clear focus on convenience-based tech but maybe a gap in higher-end inventory.\n",
    "\n",
    "A business could use this by promoting wireless products more since there’s clear demand, and also by checking why nothing is marked as premium. It might mean mislabeled data or a missed chance to reach high-value customers. This also helped me notice how important consistent labeling is for future analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection3",
   "metadata": {},
   "source": [
    "### Question 8.3: Date Analysis Importance\n",
    "\n",
    "**Why is analyzing transaction dates by weekday and month important for business operations? Provide at least three specific business applications.**\n",
    "\n",
    "Analyzing transaction dates by weekday and month is crucial for understanding customer behavior trends and optimizing business operations.\n",
    "\n",
    "1) Scheduling Promotions and Staffing:\n",
    "Identifying that Mondays were the busiest day helped reveal when customer activity peaked. Businesses can use this insight to schedule promotions, increase staff availability, or restock inventory before high-traffic days.\n",
    "\n",
    "2) Seasonal and Monthly Planning:\n",
    "Grouping transactions by month (March and April in this dataset) showed a short sales window, suggesting either a limited campaign or seasonal activity. This helps management plan future product launches, budget allocations, or targeted campaigns around high-performing months.\n",
    "\n",
    "3) Performance Monitoring and Forecasting:\n",
    "Regularly analyzing date-based patterns allows businesses to detect declining engagement or shifts in demand early. For example, a drop in transactions after April could indicate customer churn, prompting re-engagement efforts or adjustments to marketing strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection4",
   "metadata": {},
   "source": [
    "### Question 8.4: Customer Recency Strategy\n",
    "\n",
    "**Based on your recency analysis, what specific actions would you recommend for customers in each category (Recent, Moderate, At Risk)? How would you prioritize these actions?**\n",
    "\n",
    "Based on the recency analysis, each customer category requires a different engagement approach to maximize retention and sales potential.\n",
    "\n",
    "Recent (≤ 30 days):\n",
    "These customers are already engaged. The focus should be on reinforcing satisfaction—for example, through thank-you emails, loyalty points, or personalized product recommendations to encourage repeat purchases.\n",
    "\n",
    "Moderate (31–90 days):\n",
    "These customers are at risk of disengaging. The best strategy is to reconnect with new product updates or limited-time discounts to bring them back before they lapse completely.\n",
    "\n",
    "At Risk (> 90 days):\n",
    "This group requires re-engagement campaigns, such as special offers, reactivation emails, or surveys to understand why they stopped purchasing.\n",
    "\n",
    "Priority:\n",
    "Start with At Risk customers since they represent potential lost revenue, followed by Moderate to prevent further churn. Recent customers should receive maintenance-level engagement to sustain their loyalty.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection5",
   "metadata": {},
   "source": [
    "### Question 8.5: Sentiment Analysis Application\n",
    "\n",
    "**How could the sentiment analysis you performed be used to improve products or customer service? What are the limitations of this simple sentiment analysis approach?**\n",
    "\n",
    "The sentiment analysis gave a basic idea of how customers felt, showing about 42% positive and 29% negative reviews. That’s useful for spotting general trends, like which products people liked or complained about the most. Businesses could use this to improve product quality or customer service based on recurring feedback themes.\n",
    "\n",
    "But this method was really limited. It just counts certain words as positive or negative without understanding how they’re used. For example, a review saying “not good” or “barely works” might still get flagged as partly positive because of the individual words. It also doesn’t capture tone, sarcasm, or mixed feelings. A better system would use NLP or manual tagging that looks at full phrases and context instead of single-word scoring.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection6",
   "metadata": {},
   "source": [
    "### Question 8.6: Real-World Application\n",
    "\n",
    "**Describe a real business scenario where you would need to combine string manipulation and date analysis (like you did in this homework). What insights would you be trying to discover?**\n",
    "\n",
    "A real-world example would be in online retail or e-commerce. A company could use string functions to find keywords like “wireless” or “gaming” in product titles, then use date analysis to see when those products sell the most.\n",
    "In my dataset, wireless items were common and Mondays were the busiest day. A business could use that to plan promotions earlier in the week and focus ad spending on popular product types. Combining text and date analysis helps reveal what sells best and when, so marketing and restocking can be timed smarter.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## Summary and Submission\n",
    "\n",
    "### What You've Accomplished\n",
    "\n",
    "In this homework, you've successfully:\n",
    "- ✅ Cleaned and standardized messy text data using `stringr` functions\n",
    "- ✅ Detected patterns and extracted information from text\n",
    "- ✅ Parsed dates and extracted temporal components using `lubridate`\n",
    "- ✅ Calculated customer recency for segmentation\n",
    "- ✅ Analyzed transaction patterns by time periods\n",
    "- ✅ Combined string and date operations for business insights\n",
    "- ✅ Created personalized customer communications\n",
    "- ✅ Generated executive-ready business intelligence summaries\n",
    "\n",
    "### Key Skills Mastered\n",
    "\n",
    "**String Manipulation:**\n",
    "- `str_trim()`, `str_squish()` - Whitespace handling\n",
    "- `str_to_lower()`, `str_to_upper()`, `str_to_title()` - Case conversion\n",
    "- `str_detect()` - Pattern detection\n",
    "- `str_extract()` - Information extraction\n",
    "- `str_count()` - Pattern counting\n",
    "\n",
    "**Date/Time Operations:**\n",
    "- `ymd()`, `mdy()`, `dmy()` - Date parsing\n",
    "- `year()`, `month()`, `day()`, `wday()` - Component extraction\n",
    "- `quarter()` - Period extraction\n",
    "- `today()` - Current date\n",
    "- Date arithmetic - Calculating differences\n",
    "\n",
    "**Business Applications:**\n",
    "- Data cleaning and standardization\n",
    "- Customer segmentation by recency\n",
    "- Sentiment analysis\n",
    "- Pattern identification\n",
    "- Temporal trend analysis\n",
    "- Personalized communication\n",
    "\n",
    "### Submission Checklist\n",
    "\n",
    "Before submitting, ensure you have:\n",
    "- [ ] Entered your name, student ID, and date at the top\n",
    "- [ ] Completed all code tasks (Parts 1-7)\n",
    "- [ ] Run all cells successfully without errors\n",
    "- [ ] Answered all reflection questions (Part 8)\n",
    "- [ ] Used proper commenting in your code\n",
    "- [ ] Used the pipe operator (`%>%`) where appropriate\n",
    "- [ ] Verified your results make business sense\n",
    "- [ ] Checked for any remaining TODO comments\n",
    "\n",
    "### Grading Criteria\n",
    "\n",
    "Your homework will be evaluated on:\n",
    "- **Code Correctness (40%)**: All tasks completed correctly\n",
    "- **Code Quality (20%)**: Clean, well-commented, efficient code\n",
    "- **Business Understanding (20%)**: Demonstrates understanding of business applications\n",
    "- **Reflection Questions (15%)**: Thoughtful, complete answers\n",
    "- **Presentation (5%)**: Professional formatting and organization\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "In Lesson 8, you'll learn:\n",
    "- Advanced data wrangling with complex pipelines\n",
    "- Sophisticated conditional logic with `case_when()`\n",
    "- Data validation and quality checks\n",
    "- Creating reproducible analysis workflows\n",
    "- Professional best practices for business analytics\n",
    "\n",
    "**Great work on completing this assignment! 🎉**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
