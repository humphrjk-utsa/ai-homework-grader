{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0628f0f4",
   "metadata": {},
   "source": [
    "# Homework Assignment - Lesson 2: Data Cleaning - Handling Missing Values and Outliers\n",
    "\n",
    "**Student Name:** [YOUR NAME HERE]  \n",
    "**Date:** [TODAY'S DATE]  \n",
    "**Course:** Data Management  \n",
    "\n",
    "---\n",
    "\n",
    "## Instructions\n",
    "\n",
    "Complete all the tasks below by adding your R code in the code cells and your written responses in markdown cells. This assignment focuses on real-world data cleaning techniques including handling missing values and outliers.\n",
    "\n",
    "**ðŸ’¡ Key Learning Goals:**\n",
    "- Identify and handle missing values using multiple strategies\n",
    "- Detect and treat outliers using statistical methods\n",
    "- Make informed decisions about data quality trade-offs\n",
    "- Document your data cleaning process and reasoning\n",
    "\n",
    "**ðŸ“‹ SUBMISSION**: When you're done, see [GITHUB_CLASSROOM_SUBMISSION.md](../../GITHUB_CLASSROOM_SUBMISSION.md) for complete submission instructions.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b99adf0",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9d18a6",
   "metadata": {},
   "source": [
    "### Part 1: Data Import and Initial Assessment\n",
    "\n",
    "In this section, you'll import a \"messy\" dataset that contains missing values and outliers, simulating real-world data quality challenges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc395004",
   "metadata": {},
   "source": [
    "#### 1.1 Environment Setup\n",
    "\n",
    "Load the required packages for data cleaning and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa15a71d",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'/workspaces/assignment-2-wfaniyi/assignment/Homework'"
      ],
      "text/latex": [
       "'/workspaces/assignment-2-wfaniyi/assignment/Homework'"
      ],
      "text/markdown": [
       "'/workspaces/assignment-2-wfaniyi/assignment/Homework'"
      ],
      "text/plain": [
       "[1] \"/workspaces/assignment-2-wfaniyi/assignment/Homework\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1.1 â€” Environment Setup\n",
    "# (Skip tidyverse to avoid install prompts)\n",
    "# library(tidyverse)\n",
    "\n",
    "# Confirm where this notebook runs (should end with /Homework)\n",
    "getwd()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2096d578",
   "metadata": {},
   "source": [
    "#### 1.2 Import Messy Dataset\n",
    "\n",
    "Import the provided messy sales dataset that contains real-world data quality issues including missing values, outliers, and inconsistencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f92518c5",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ../../data/messy_sales_data.csv | shape: 200 rows x 6 cols\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 Ã— 6</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>TransactionID</th><th scope=col>Customer_Name</th><th scope=col>Product_Category</th><th scope=col>Sales_Amount</th><th scope=col>Purchase_Date</th><th scope=col>Quantity</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>1</td><td>           </td><td>Home       </td><td> 362.3175</td><td>          </td><td>  2</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>2</td><td>Alice Brown</td><td>Clothing   </td><td> 573.0791</td><td>2023-10-21</td><td>  3</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>3</td><td>Jane Doe   </td><td>Electronics</td><td> 487.6874</td><td>2023-12-28</td><td> -1</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>4</td><td>Jane Doe   </td><td>Electronics</td><td>5000.0000</td><td>2023-06-16</td><td>  7</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>5</td><td>John Smith </td><td>Books      </td><td> 344.1746</td><td>2023-05-05</td><td>100</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>6</td><td>John Smith </td><td>Books      </td><td> 434.9527</td><td>2023-11-28</td><td>  4</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 Ã— 6\n",
       "\\begin{tabular}{r|llllll}\n",
       "  & TransactionID & Customer\\_Name & Product\\_Category & Sales\\_Amount & Purchase\\_Date & Quantity\\\\\n",
       "  & <int> & <chr> & <chr> & <dbl> & <chr> & <int>\\\\\n",
       "\\hline\n",
       "\t1 & 1 &             & Home        &  362.3175 &            &   2\\\\\n",
       "\t2 & 2 & Alice Brown & Clothing    &  573.0791 & 2023-10-21 &   3\\\\\n",
       "\t3 & 3 & Jane Doe    & Electronics &  487.6874 & 2023-12-28 &  -1\\\\\n",
       "\t4 & 4 & Jane Doe    & Electronics & 5000.0000 & 2023-06-16 &   7\\\\\n",
       "\t5 & 5 & John Smith  & Books       &  344.1746 & 2023-05-05 & 100\\\\\n",
       "\t6 & 6 & John Smith  & Books       &  434.9527 & 2023-11-28 &   4\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 Ã— 6\n",
       "\n",
       "| <!--/--> | TransactionID &lt;int&gt; | Customer_Name &lt;chr&gt; | Product_Category &lt;chr&gt; | Sales_Amount &lt;dbl&gt; | Purchase_Date &lt;chr&gt; | Quantity &lt;int&gt; |\n",
       "|---|---|---|---|---|---|---|\n",
       "| 1 | 1 | <!----> | Home        |  362.3175 | <!----> |   2 |\n",
       "| 2 | 2 | Alice Brown | Clothing    |  573.0791 | 2023-10-21 |   3 |\n",
       "| 3 | 3 | Jane Doe    | Electronics |  487.6874 | 2023-12-28 |  -1 |\n",
       "| 4 | 4 | Jane Doe    | Electronics | 5000.0000 | 2023-06-16 |   7 |\n",
       "| 5 | 5 | John Smith  | Books       |  344.1746 | 2023-05-05 | 100 |\n",
       "| 6 | 6 | John Smith  | Books       |  434.9527 | 2023-11-28 |   4 |\n",
       "\n"
      ],
      "text/plain": [
       "  TransactionID Customer_Name Product_Category Sales_Amount Purchase_Date\n",
       "1 1                           Home              362.3175                 \n",
       "2 2             Alice Brown   Clothing          573.0791    2023-10-21   \n",
       "3 3             Jane Doe      Electronics       487.6874    2023-12-28   \n",
       "4 4             Jane Doe      Electronics      5000.0000    2023-06-16   \n",
       "5 5             John Smith    Books             344.1746    2023-05-05   \n",
       "6 6             John Smith    Books             434.9527    2023-11-28   \n",
       "  Quantity\n",
       "1   2     \n",
       "2   3     \n",
       "3  -1     \n",
       "4   7     \n",
       "5 100     \n",
       "6   4     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t200 obs. of  6 variables:\n",
      " $ TransactionID   : int  1 2 3 4 5 6 7 8 9 10 ...\n",
      " $ Customer_Name   : chr  \"\" \"Alice Brown\" \"Jane Doe\" \"Jane Doe\" ...\n",
      " $ Product_Category: chr  \"Home\" \"Clothing\" \"Electronics\" \"Electronics\" ...\n",
      " $ Sales_Amount    : num  362 573 488 5000 344 ...\n",
      " $ Purchase_Date   : chr  \"\" \"2023-10-21\" \"2023-12-28\" \"2023-06-16\" ...\n",
      " $ Quantity        : int  2 3 -1 7 100 4 0 7 3 2 ...\n"
     ]
    }
   ],
   "source": [
    "# 1.2 â€” Import Messy Dataset\n",
    "df <- read.csv(\"../../data/messy_sales_data.csv\")  # go up two levels, then into data/\n",
    "cat(\"Loaded ../../data/messy_sales_data.csv | shape:\", nrow(df), \"rows x\", ncol(df), \"cols\\n\")\n",
    "head(df); str(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cc88b0",
   "metadata": {},
   "source": [
    "#### 1.3 Initial Data Assessment\n",
    "\n",
    "Perform a comprehensive inspection of the messy dataset to understand its structure and identify data quality issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f2616bc0",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in parse(text = input): <text>:35:0: unexpected end of input\n33:     max    = sapply(df[num_co_]()\n34: \n   ^\n",
     "output_type": "error",
     "traceback": [
      "Error in parse(text = input): <text>:35:0: unexpected end of input\n33:     max    = sapply(df[num_co_]()\n34: \n   ^\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "# 1.3 â€” Initial Data Assessment (uses df loaded in 1.2)\n",
    "\n",
    "# Basic shape\n",
    "cat(\"Rows:\", nrow(df), \" | Cols:\", ncol(df), \"\\n\")\n",
    "\n",
    "# Structure and quick summary\n",
    "str(df)\n",
    "summary(df)\n",
    "\n",
    "# Missing values per column (count + percent)\n",
    "miss_by_col <- data.frame(\n",
    "  column = names(df),\n",
    "  n_missing = colSums(is.na(df)),\n",
    "  pct_missing = round(100 * colSums(is.na(df)) / nrow(df), 2)\n",
    ")\n",
    "miss_by_col <- miss_by_col[order(-miss_by_col$pct_missing), ]\n",
    "print(miss_by_col, row.names = FALSE)\n",
    "\n",
    "# Duplicate rows\n",
    "cat(\"Duplicate rows:\", sum(duplicated(df)), \"\\n\")\n",
    "\n",
    "# Numeric columns: distribution stats\n",
    "num_cols <- names(df)[sapply(df, is.numeric)]\n",
    "if (length(num_cols) > 0) {\n",
    "  num_summary <- data.frame(\n",
    "    column = num_cols,\n",
    "    mean   = sapply(df[num_cols], function(x) mean(x, na.rm=TRUE)),\n",
    "    sd     = sapply(df[num_cols], function(x) sd(x, na.rm=TRUE)),\n",
    "    min    = sapply(df[num_cols], function(x) min(x, na.rm=TRUE)),\n",
    "    q1     = sapply(df[num_cols], function(x) quantile(x, 0.25, na.rm=TRUE)),\n",
    "    median = sapply(df[num_cols], function(x) median(x, na.rm=TRUE)),\n",
    "    q3     = sapply(df[num_cols], function(x) quantile(x, 0.75, na.rm=TRUE)),\n",
    "    max    = sapply(df[num_co_]()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f0b0f6",
   "metadata": {},
   "source": [
    "# Structure and summary of the data\n",
    "print(\"=== DATA STRUCTURE ===\")\n",
    "str(messy_sales)\n",
    "\n",
    "print(\"=== SUMMARY STATISTICS ===\")\n",
    "summary(messy_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6ba3b1",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "**Data Quality Assessment:**\n",
    "\n",
    "Based on the imported messy_sales dataset, document all the data quality issues you observe:\n",
    "\n",
    "1. **Missing Values:** [Look for NA values - which columns have missing data?]\n",
    "\n",
    "2. **Potential Outliers:** [Check Sales_Amount and Quantity - do any values seem extreme?]\n",
    "\n",
    "3. **Data Inconsistencies:** [Look at Product_Category - are there inconsistent naming conventions?]\n",
    "\n",
    "4. **Data Types:** [Are Purchase_Date and Sales_Amount using appropriate data types?]\n",
    "\n",
    "5. **Invalid Values:** [Are there any logically impossible values like negative quantities?]\n",
    "\n",
    "**YOUR OBSERVATIONS:**\n",
    "\n",
    "[Write your detailed observations here after running the code above]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d136e7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Part 2: Missing Value Analysis and Treatment\n",
    "\n",
    "In this section, you'll identify missing values and apply different strategies to handle them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c60d90",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Complete the following tasks to thoroughly understand the missing value patterns in your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49897c6",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# 2.1 â€” Quantify missingness\n",
    "col_missing <- colSums(is.na(df))\n",
    "miss_summary <- data.frame(\n",
    "  column = names(col_missing),\n",
    "  n_missing = as.integer(col_missing),\n",
    "  pct_missing = round(100 * col_missing / nrow(df), 2)\n",
    ")[order(-col_missing), ]\n",
    "print(miss_summary, row.names = FALSE)\n",
    "cat(\"TOTAL missing cells:\", sum(is.na(df)),\n",
    "    \" | fully-complete rows:\", sum(complete.cases(df)), \"\\n\")\n",
    "\n",
    "# artifact for grading\n",
    "write.csv(miss_summary, \"missing_values_summary.csv\", row.names = FALSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787161c8",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# 2.2 â€” Removal (listwise deletion)\n",
    "df_removed <- na.omit(df)\n",
    "cat(\"After removal:\", nrow(df_removed), \"rows x\", ncol(df_removed), \"cols\\n\")\n",
    "write.csv(df_removed, \"clean_removed_missing.csv\", row.names = FALSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d24625",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Remove all rows with missing values\n",
    "sales_removed_na <- # YOUR CODE HERE\n",
    "\n",
    "# Compare dimensions\n",
    "print(\"Original dataset dimensions:\")\n",
    "print(dim(messy_sales))\n",
    "print(\"After removing NA rows:\")\n",
    "print(dim(sales_removed_na))\n",
    "print(paste(\"Rows lost:\", nrow(messy_sales) - nrow(sales_removed_na)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3704e9",
   "metadata": {},
   "source": [
    "#### 2.3 Missing Value Treatment - Option B (Imputation)\n",
    "\n",
    "\n",
    "Apply appropriate imputation strategies for different types of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a705ae02",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After imputation: 200 rows x 6 cols; NAs: 0 \n"
     ]
    }
   ],
   "source": [
    "# 2.3 â€” Simple imputation: mean for numeric, mode otherwise\n",
    "Mode <- function(x){ ux <- unique(x[!is.na(x)]); ux[which.max(tabulate(match(x, ux)))] }\n",
    "impute_simple <- function(d){\n",
    "  out <- d\n",
    "  for(nm in names(out)){\n",
    "    x <- out[[nm]]\n",
    "    if(is.numeric(x)){\n",
    "      out[[nm]][is.na(x)] <- mean(x, na.rm = TRUE)\n",
    "    } else {\n",
    "      if(!all(is.na(x))) out[[nm]][is.na(x)] <- Mode(x)\n",
    "    }\n",
    "  }\n",
    "  stopifnot(sum(is.na(out)) == 0)  # must end with zero NAs\n",
    "  out\n",
    "}\n",
    "df_imputed <- impute_simple(df)\n",
    "cat(\"After imputation:\", nrow(df_imputed), \"rows x\", ncol(df_imputed), \"cols; NAs:\", sum(is.na(df_imputed)), \"\\n\")\n",
    "write.csv(df_imputed, \"clean_imputed.csv\", row.names = FALSE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812ae2f5",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "### TODO: Create a mode function for categorical variables\n",
    "get_mode <- function(v) {\n",
    "  ### YOUR CODE HERE\n",
    "  ### Hint: Use unique(), tabulate(), match(), and which.max()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc223b7",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in parse(text = input): <text>:3:0: unexpected end of input\n1: ### TODO: Impute Customer_Name with mode (for categorical missing values)\n2: sales_imputed$Customer_Name <- # YOUR CODE HERE\n  ^\n",
     "output_type": "error",
     "traceback": [
      "Error in parse(text = input): <text>:3:0: unexpected end of input\n1: ### TODO: Impute Customer_Name with mode (for categorical missing values)\n2: sales_imputed$Customer_Name <- # YOUR CODE HERE\n  ^\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "### TODO: Impute Customer_Name with mode (for categorical missing values)\n",
    "sales_imputed$Customer_Name <- # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d32f7d",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "### To practice median imputation, try it on Quantity column\n",
    "### TODO: Impute Quantity with median (alternative approach for numeric data)\n",
    "sales_imputed$Quantity <- # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b33ef08",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "### Verify imputation success\n",
    "print(\"Missing values after imputation:\")\n",
    "print(colSums(is.na(sales_imputed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac6fc99",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#### 2.4 Compare Missing Value Strategies Analyze the impact of different missing value treatment approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824146f8",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Compare summary statistics\n",
    "print(\"=== ORIGINAL DATA ===\")\n",
    "summary(messy_sales$Sales_Amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3665b24",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "print(\"=== AFTER REMOVING NAs ===\")\n",
    "summary(sales_removed_na$Sales_Amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60582ad",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "print(\"=== AFTER IMPUTATION ===\")\n",
    "summary(sales_imputed$Sales_Amount)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb65895f",
   "metadata": {},
   "source": [
    "\n",
    "**Analysis Questions:**\n",
    "\n",
    "1. **Which approach would you recommend for this dataset and why?**\n",
    "\n",
    "[YOUR ANSWER HERE]\n",
    "\n",
    "2. **What are the trade-offs between removal and imputation?**\n",
    "\n",
    "[YOUR ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a50824",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\"### Part 3: Outlier Detection and Treatment\n",
    "\",\n",
    "\n",
    "Using your imputed dataset, identify and handle outliers in the Sales_Amount variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737913d7",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Quartiles & IQR for Sales_Amount\n",
    "stopifnot(\"Sales_Amount\" %in% names(df_imputed))\n",
    "Q1_sales <- quantile(df_imputed$Sales_Amount, 0.25, na.rm = TRUE)\n",
    "Q3_sales <- quantile(df_imputed$Sales_Amount, 0.75, na.rm = TRUE)\n",
    "IQR_sales <- Q3_sales - Q1_sales\n",
    "Q1_sales; Q3_sales; IQR_sales\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbae5a6",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "### TODO: Calculate quartiles and IQR for Sales_Amount\n",
    "Q1_sales <- # YOUR CODE HERE\n",
    "Q3_sales <- # YOUR CODE HERE  \n",
    "IQR_sales <- # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc30ca3c",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "### TODO: Calculate outlier thresholds\n",
    "upper_threshold <- # YOUR CODE HERE\n",
    "lower_threshold <- # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f782a224",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "### TODO: Identify outliers\n",
    "outliers <- # YOUR CODE HERE\n",
    "\n",
    "print(paste(\"Q1:\", Q1_sales))\n",
    "print(paste(\"Q3:\", Q3_sales))\n",
    "print(paste(\"IQR:\", IQR_sales))\n",
    "print(paste(\"Lower threshold:\", lower_threshold))\n",
    "print(paste(\"Upper threshold:\", upper_threshold))\n",
    "print(paste(\"Number of outliers found:\", nrow(outliers)))\n",
    "print(\"Outlier rows:\")\n",
    "print(outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41902067",
   "metadata": {},
   "source": [
    "### 3.2 Outlier Visualization\n",
    "\n",
    "Create a boxplot to visualize the outliers in Sales_Amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473e77cb",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "### TODO: Create a boxplot for Sales_Amount\n",
    "# Use ggplot2 to create a boxplot showing outliers\n",
    "boxplot_sales <- # YOUR CODE HERE\n",
    "\n",
    "# Display the plot\n",
    "print(boxplot_sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab78e27a",
   "metadata": {},
   "source": [
    "### 3.3 Outlier Treatment - Option A (Removal)\n",
    "\n",
    "Remove rows containing outliers and assess the impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8a1784",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# 3.2 â€” Boxplot for Sales_Amount (recomputes IQR thresholds)\n",
    "Q1  <- quantile(df_imputed$Sales_Amount, 0.25, na.rm = TRUE)\n",
    "Q3  <- quantile(df_imputed$Sales_Amount, 0.75, na.rm = TRUE)\n",
    "IQRv <- Q3 - Q1\n",
    "lower_threshold <- Q1 - 1.5 * IQRv\n",
    "upper_threshold <- Q3 + 1.5 * IQRv\n",
    "\n",
    "if (requireNamespace(\"ggplot2\", quietly = TRUE)) {\n",
    "  library(ggplot2)\n",
    "  boxplot_sales <- ggplot(df_imputed, aes(y = Sales_Amount)) +\n",
    "    geom_boxplot(outlier.alpha = 0.6) +\n",
    "    labs(title = \"Sales_Amount (imputed)\", y = \"Sales_Amount\")\n",
    "  print(boxplot_sales)\n",
    "} else {\n",
    "  # fallback: base R\n",
    "  boxplot_sales <- boxplot(df_imputed$Sales_Amount,\n",
    "                           main = \"Sale\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad26c10",
   "metadata": {},
   "source": [
    "### 3.4 Outlier Treatment - Option B (Capping)\n",
    "\n",
    "Apply capping/winsorization to handle outliers while preserving data points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d330f9",
   "metadata": {},
   "source": [
    "### 3.2 Outlier Visualization\n",
    "\n",
    "Create a boxplot to visualize the outliers in Sales_Amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf184da",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Create a boxplot for Sales_Amount\n",
    "# Use ggplot2 to create a boxplot showing outliers\n",
    "boxplot_sales <- # YOUR CODE HERE\n",
    "# Hint: ggplot(sales_imputed, aes(y = Sales_Amount)) + geom_boxplot() + ggtitle(\"Sales Amount Outliers\")\n",
    "\n",
    "# Display the plot\n",
    "print(boxplot_sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ed2ac7",
   "metadata": {},
   "source": [
    "### 3.3 Outlier Treatment - Option A (Removal)\n",
    "\n",
    "Remove rows containing outliers and assess the impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba04465",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# 3.3 â€” Remove rows with Sales_Amount outside IQR bounds\n",
    "keep <- df_imputed$Sales_Amount >= lower_threshold & df_imputed$Sales_Amount <= upper_threshold\n",
    "sales_outliers_removed <- df_imputed[keep, , drop = FALSE]\n",
    "\n",
    "cat(\"Removed\", sum(!keep), \"rows; kept\", nrow(sales_outliers_removed), \"rows\\n\")\n",
    "write.csv(sales_outliers_removed, \"clean_sales_amount_outliers_removed.csv\", row.names = FALSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f7e0cc",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "### TODO: Create a capped version of the dataset\n",
    "sales_outliers_capped <- sales_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cc8e4e",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "### TODO: Apply capping to Sales_Amount\n",
    "sales_outliers_capped$Sales_Amount <- # YOUR CODE HERE\n",
    "### Hint: Use ifelse() to replace values above/below thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fd1b2e",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "### Verify capping worked\n",
    "print(\"Sales_Amount range after capping:\")\n",
    "print(range(sales_outliers_capped$Sales_Amount, na.rm = TRUE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a935fdea",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "### Check for remaining outliers\n",
    "remaining_outliers <- # YOUR CODE HERE\n",
    "print(paste(\"Remaining outliers after capping:\", nrow(remaining_outliers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8911b91",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Final Data Quality Assessment and Decision Making\n",
    "\n",
    "Choose your final cleaned dataset and justify your decision based on the analysis you've completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668ceb90",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Choose your final cleaned dataset\n",
    "final_dataset <- # Choose one: messy_sales, sales_removed_na, sales_imputed, sales_outliers_removed, or sales_outliers_capped\n",
    "\n",
    "print(\"=== FINAL DATASET SUMMARY ===\")\n",
    "print(dim(final_dataset))\n",
    "summary(final_dataset$Sales_Amount)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2a573a",
   "metadata": {},
   "source": [
    "**Justification for Your Choice:**\n",
    "\n",
    "[Explain why you chose this particular cleaned dataset. Consider factors like:\n",
    "- Sample size preservation\n",
    "- Data quality improvements\n",
    "- Business impact\n",
    "- Analysis requirements]\n",
    "\n",
    "**YOUR JUSTIFICATION:**\n",
    "\n",
    "[Write your detailed reasoning here]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5025810",
   "metadata": {},
   "source": [
    "### 4.2 Create Comparison Summary\n",
    "\n",
    "Create a comprehensive comparison of your original and final datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22c2b0f",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Create comparison summary\n",
    "comparison_summary <- data.frame(\n",
    "  Metric = c(\"Number of Rows\", \"Missing Values\", \"Mean Sales_Amount\", \"Median Sales_Amount\", \"Outliers\"),\n",
    "  Original_Data = c(\n",
    "    nrow(messy_sales),\n",
    "    sum(is.na(messy_sales)),\n",
    "    round(mean(messy_sales$Sales_Amount, na.rm = TRUE), 2),\n",
    "    round(median(messy_sales$Sales_Amount, na.rm = TRUE), 2),\n",
    "    \"Check manually\" # TODO: Calculate this\n",
    "  ),\n",
    "  Final_Data = c(\n",
    "    nrow(final_dataset),\n",
    "    sum(is.na(final_dataset)),\n",
    "    round(mean(final_dataset$Sales_Amount, na.rm = TRUE), 2),\n",
    "    round(median(final_dataset$Sales_Amount, na.rm = TRUE), 2),\n",
    "    \"Check manually\" # TODO: Calculate this\n",
    "  )\n",
    ")\n",
    "\n",
    "print(\"=== DATA CLEANING COMPARISON ===\")\n",
    "print(comparison_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27aa62cf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Reflection Questions\n",
    "\n",
    "Answer the following questions to demonstrate your understanding of data cleaning concepts and their business implications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff8e4bb",
   "metadata": {},
   "source": [
    "### Question 1: Missing Value Strategy\n",
    "\n",
    "In what business scenarios would you prefer removing rows with missing values versus imputing them? Provide specific examples.\n",
    "\n",
    "**YOUR ANSWER:**\n",
    "\n",
    "[Write your detailed response here]\n",
    "\n",
    "### Question 2: Outlier Interpretation  \n",
    "\n",
    "You identified outliers in the Sales_Amount column. In a real business context, what could these outliers represent? Should they always be removed or treated? Explain your reasoning.\n",
    "\n",
    "**YOUR ANSWER:**\n",
    "\n",
    "[Write your detailed response here]\n",
    "\n",
    "### Question 3: Data Quality Impact\n",
    "\n",
    "How might the presence of missing values and outliers affect common business analytics tasks such as calculating average sales, identifying top-performing products, or forecasting future sales?\n",
    "\n",
    "**YOUR ANSWER:**\n",
    "\n",
    "[Write your detailed response here]\n",
    "\n",
    "### Question 4: Ethical Considerations\n",
    "\n",
    "What are the ethical implications of removing or modifying data during the cleaning process? How can analysts ensure transparency and maintain data integrity?\n",
    "\n",
    "**YOUR ANSWER:**\n",
    "\n",
    "[Write your detailed response here]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75413084",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Submission Checklist\n",
    "\n",
    "Before submitting, make sure you have:\n",
    "\n",
    "- [ ] **Part 1**: Created and inspected the messy dataset\n",
    "- [ ] **Part 2**: Completed missing value identification and treatment\n",
    "- [ ] **Part 3**: Detected and treated outliers using IQR method  \n",
    "- [ ] **Part 4**: Chosen and justified your final cleaned dataset\n",
    "- [ ] **Part 4**: Created comparison summary table\n",
    "- [ ] **Part 5**: Answered all reflection questions thoroughly\n",
    "- [ ] **Code Quality**: All TODO sections completed with working code\n",
    "- [ ] **Documentation**: Added your name and date at the top\n",
    "- [ ] **Testing**: Run all cells to verify output\n",
    "- [ ] **Submission**: Committed and pushed to GitHub\n",
    "\n",
    "**Great work mastering data cleaning techniques! ðŸ§¹âœ¨**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a83f963",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸš€ Ready to Submit?\n",
    "\n",
    "### Easy Submission Steps (No Command Line Required!):\n",
    "\n",
    "1. **Save this notebook** (Ctrl+S or File â†’ Save)\n",
    "\n",
    "2. **Use VS Code Source Control**:\n",
    "   - Click the **Source Control** icon in the left sidebar (tree branch symbol)\n",
    "   - Click the **\"+\"** button next to your notebook file\n",
    "   - Type a message: `Submit homework 2 - Data Cleaning - [Your Name]`\n",
    "   - Click **\"Commit\"** \n",
    "   - Click **\"Sync Changes\"** or **\"Push\"**\n",
    "\n",
    "3. **Verify on GitHub**: Go to your repository online and confirm your notebook appears with your completed work\n",
    "\n",
    "**ðŸ“– Need help?** See [GITHUB_CLASSROOM_SUBMISSION.md](../../GITHUB_CLASSROOM_SUBMISSION.md) for detailed instructions.\n",
    "\n",
    "**ðŸŽ‰ Congratulations on completing your data cleaning assignment!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
