{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Homework Assignment - Lesson 7: String Manipulation and Date/Time Data\n",
    "\n",
    "**Student Name:** Charles Moten-Lopez\n",
    "\n",
    "**Student ID:** @02126789     gan744\n",
    "\n",
    "**Date Submitted:** October 19th, 2025\n",
    "\n",
    "**Due Date:** October 12th, 2025\n",
    "\n",
    "---\n",
    "\n",
    "## Objective\n",
    "\n",
    "Master string manipulation with `stringr` and date/time operations with `lubridate` for real-world business data cleaning and analysis.\n",
    "\n",
    "## Learning Goals\n",
    "\n",
    "By completing this assignment, you will:\n",
    "- Clean and standardize messy text data using `stringr` functions\n",
    "- Parse and manipulate dates using `lubridate` functions\n",
    "- Extract information from text and dates for business insights\n",
    "- Combine string and date operations for customer segmentation\n",
    "- Create business-ready reports from raw data\n",
    "\n",
    "## Instructions\n",
    "\n",
    "- Complete all tasks in this notebook\n",
    "- Write your code in the designated TODO sections\n",
    "- Use the pipe operator (`%>%`) wherever possible\n",
    "- Add comments explaining your logic\n",
    "- Run all cells to verify your code works\n",
    "- Answer all reflection questions\n",
    "\n",
    "## Datasets\n",
    "\n",
    "You will work with three CSV files:\n",
    "- `customer_feedback.csv` - Customer reviews with messy text\n",
    "- `transaction_log.csv` - Transaction records with dates\n",
    "- `product_catalog.csv` - Product descriptions needing standardization\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part1_intro",
   "metadata": {},
   "source": [
    "## Part 1: Data Import and Initial Exploration\n",
    "\n",
    "**Business Context:** Before cleaning data, you must understand its structure and quality issues.\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Load required packages (`tidyverse` and `lubridate`)\n",
    "2. Import all three CSV files from the `data/` directory\n",
    "3. Examine the structure and identify data quality issues\n",
    "4. Display sample rows to understand the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "setup",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Packages loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Task 1.1: Load Required Packages\n",
    "# TODO: Load tidyverse (includes stringr)\n",
    "library(tidyverse)\n",
    "\n",
    "# TODO: Load lubridate\n",
    "library(lubridate)\n",
    "\n",
    "cat(\"✅ Packages loaded successfully!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "import_data",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data imported successfully!\n",
      "Feedback rows: 100 \n",
      "Transaction rows: 150 \n",
      "Product rows: 75 \n"
     ]
    }
   ],
   "source": [
    "# Task 1.2: Import Datasets\n",
    "# TODO: Import customer_feedback.csv into a variable called 'feedback'\n",
    "feedback <- read.csv(\"customer_feedback.csv\")\n",
    "\n",
    "# TODO: Import transaction_log.csv into a variable called 'transactions'\n",
    "transactions <- read.csv(\"transaction_log.csv\")\n",
    "\n",
    "# TODO: Import product_catalog.csv into a variable called 'products'\n",
    "products <- read.csv(\"product_catalog.csv\")\n",
    "\n",
    "cat(\"✅ Data imported successfully!\\n\")\n",
    "cat(\"Feedback rows:\", nrow(feedback), \"\\n\")\n",
    "cat(\"Transaction rows:\", nrow(transactions), \"\\n\")\n",
    "cat(\"Product rows:\", nrow(products), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "explore_data",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CUSTOMER FEEDBACK DATA ===\n",
      "'data.frame':\t100 obs. of  5 variables:\n",
      " $ FeedbackID   : int  1 2 3 4 5 6 7 8 9 10 ...\n",
      " $ CustomerID   : int  12 40 34 1 47 13 13 37 49 23 ...\n",
      " $ Feedback_Text: chr  \"Highly recommend this item\" \"   Excellent service   \" \"Poor quality control\" \"average product, nothing special\" ...\n",
      " $ Contact_Info : chr  \"bob.wilson@test.org\" \"555-123-4567\" \"jane_smith@company.com\" \"jane_smith@company.com\" ...\n",
      " $ Feedback_Date: chr  \"2024-02-23\" \"2024-01-21\" \"2023-09-02\" \"2023-08-21\" ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 5 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>FeedbackID</th><th scope=col>CustomerID</th><th scope=col>Feedback_Text</th><th scope=col>Contact_Info</th><th scope=col>Feedback_Date</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>1</td><td>12</td><td>Highly recommend this item      </td><td>bob.wilson@test.org   </td><td>2024-02-23</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>2</td><td>40</td><td>   Excellent service            </td><td>555-123-4567          </td><td>2024-01-21</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>3</td><td>34</td><td>Poor quality control            </td><td>jane_smith@company.com</td><td>2023-09-02</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>4</td><td> 1</td><td>average product, nothing special</td><td>jane_smith@company.com</td><td>2023-08-21</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>5</td><td>47</td><td>AMAZING customer support!!!     </td><td>555-123-4567          </td><td>2023-04-24</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 5 × 5\n",
       "\\begin{tabular}{r|lllll}\n",
       "  & FeedbackID & CustomerID & Feedback\\_Text & Contact\\_Info & Feedback\\_Date\\\\\n",
       "  & <int> & <int> & <chr> & <chr> & <chr>\\\\\n",
       "\\hline\n",
       "\t1 & 1 & 12 & Highly recommend this item       & bob.wilson@test.org    & 2024-02-23\\\\\n",
       "\t2 & 2 & 40 &    Excellent service             & 555-123-4567           & 2024-01-21\\\\\n",
       "\t3 & 3 & 34 & Poor quality control             & jane\\_smith@company.com & 2023-09-02\\\\\n",
       "\t4 & 4 &  1 & average product, nothing special & jane\\_smith@company.com & 2023-08-21\\\\\n",
       "\t5 & 5 & 47 & AMAZING customer support!!!      & 555-123-4567           & 2023-04-24\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 5 × 5\n",
       "\n",
       "| <!--/--> | FeedbackID &lt;int&gt; | CustomerID &lt;int&gt; | Feedback_Text &lt;chr&gt; | Contact_Info &lt;chr&gt; | Feedback_Date &lt;chr&gt; |\n",
       "|---|---|---|---|---|---|\n",
       "| 1 | 1 | 12 | Highly recommend this item       | bob.wilson@test.org    | 2024-02-23 |\n",
       "| 2 | 2 | 40 |    Excellent service             | 555-123-4567           | 2024-01-21 |\n",
       "| 3 | 3 | 34 | Poor quality control             | jane_smith@company.com | 2023-09-02 |\n",
       "| 4 | 4 |  1 | average product, nothing special | jane_smith@company.com | 2023-08-21 |\n",
       "| 5 | 5 | 47 | AMAZING customer support!!!      | 555-123-4567           | 2023-04-24 |\n",
       "\n"
      ],
      "text/plain": [
       "  FeedbackID CustomerID Feedback_Text                    Contact_Info          \n",
       "1 1          12         Highly recommend this item       bob.wilson@test.org   \n",
       "2 2          40            Excellent service             555-123-4567          \n",
       "3 3          34         Poor quality control             jane_smith@company.com\n",
       "4 4           1         average product, nothing special jane_smith@company.com\n",
       "5 5          47         AMAZING customer support!!!      555-123-4567          \n",
       "  Feedback_Date\n",
       "1 2024-02-23   \n",
       "2 2024-01-21   \n",
       "3 2023-09-02   \n",
       "4 2023-08-21   \n",
       "5 2023-04-24   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TRANSACTION DATA ===\n",
      "'data.frame':\t150 obs. of  5 variables:\n",
      " $ LogID               : int  1 2 3 4 5 6 7 8 9 10 ...\n",
      " $ CustomerID          : int  26 21 12 6 32 27 31 30 31 13 ...\n",
      " $ Transaction_DateTime: chr  \"4/5/24 14:30\" \"3/15/24 14:30\" \"3/15/24 14:30\" \"3/20/24 9:15\" ...\n",
      " $ Amount              : num  277 175 252 215 269 ...\n",
      " $ Status              : chr  \"Pending\" \"Pending\" \"Pending\" \"Pending\" ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 5 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>LogID</th><th scope=col>CustomerID</th><th scope=col>Transaction_DateTime</th><th scope=col>Amount</th><th scope=col>Status</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>1</td><td>26</td><td>4/5/24 14:30 </td><td>277.22</td><td>Pending  </td></tr>\n",
       "\t<tr><th scope=row>2</th><td>2</td><td>21</td><td>3/15/24 14:30</td><td>175.16</td><td>Pending  </td></tr>\n",
       "\t<tr><th scope=row>3</th><td>3</td><td>12</td><td>3/15/24 14:30</td><td>251.71</td><td>Pending  </td></tr>\n",
       "\t<tr><th scope=row>4</th><td>4</td><td> 6</td><td>3/20/24 9:15 </td><td>214.98</td><td>Pending  </td></tr>\n",
       "\t<tr><th scope=row>5</th><td>5</td><td>32</td><td>3/20/24 9:15 </td><td>268.91</td><td>Completed</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 5 × 5\n",
       "\\begin{tabular}{r|lllll}\n",
       "  & LogID & CustomerID & Transaction\\_DateTime & Amount & Status\\\\\n",
       "  & <int> & <int> & <chr> & <dbl> & <chr>\\\\\n",
       "\\hline\n",
       "\t1 & 1 & 26 & 4/5/24 14:30  & 277.22 & Pending  \\\\\n",
       "\t2 & 2 & 21 & 3/15/24 14:30 & 175.16 & Pending  \\\\\n",
       "\t3 & 3 & 12 & 3/15/24 14:30 & 251.71 & Pending  \\\\\n",
       "\t4 & 4 &  6 & 3/20/24 9:15  & 214.98 & Pending  \\\\\n",
       "\t5 & 5 & 32 & 3/20/24 9:15  & 268.91 & Completed\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 5 × 5\n",
       "\n",
       "| <!--/--> | LogID &lt;int&gt; | CustomerID &lt;int&gt; | Transaction_DateTime &lt;chr&gt; | Amount &lt;dbl&gt; | Status &lt;chr&gt; |\n",
       "|---|---|---|---|---|---|\n",
       "| 1 | 1 | 26 | 4/5/24 14:30  | 277.22 | Pending   |\n",
       "| 2 | 2 | 21 | 3/15/24 14:30 | 175.16 | Pending   |\n",
       "| 3 | 3 | 12 | 3/15/24 14:30 | 251.71 | Pending   |\n",
       "| 4 | 4 |  6 | 3/20/24 9:15  | 214.98 | Pending   |\n",
       "| 5 | 5 | 32 | 3/20/24 9:15  | 268.91 | Completed |\n",
       "\n"
      ],
      "text/plain": [
       "  LogID CustomerID Transaction_DateTime Amount Status   \n",
       "1 1     26         4/5/24 14:30         277.22 Pending  \n",
       "2 2     21         3/15/24 14:30        175.16 Pending  \n",
       "3 3     12         3/15/24 14:30        251.71 Pending  \n",
       "4 4      6         3/20/24 9:15         214.98 Pending  \n",
       "5 5     32         3/20/24 9:15         268.91 Completed"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PRODUCT CATALOG DATA ===\n",
      "'data.frame':\t75 obs. of  5 variables:\n",
      " $ ProductID          : int  1 2 3 4 5 6 7 8 9 10 ...\n",
      " $ Product_Description: chr  \"Apple iPhone 14 Pro - 128GB - Space Black\" \"samsung galaxy s23 ultra 256gb\" \"Apple iPhone 14 Pro - 128GB - Space Black\" \"Apple iPhone 14 Pro - 128GB - Space Black\" ...\n",
      " $ Category           : chr  \"TV\" \"TV\" \"Audio\" \"Shoes\" ...\n",
      " $ Price              : num  964 1817 853 649 586 ...\n",
      " $ In_Stock           : chr  \"Limited\" \"Yes\" \"Yes\" \"Yes\" ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 5 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>ProductID</th><th scope=col>Product_Description</th><th scope=col>Category</th><th scope=col>Price</th><th scope=col>In_Stock</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>1</td><td>Apple iPhone 14 Pro - 128GB - Space Black</td><td>TV         </td><td> 963.53</td><td>Limited</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>2</td><td>samsung galaxy s23 ultra 256gb           </td><td>TV         </td><td>1817.44</td><td>Yes    </td></tr>\n",
       "\t<tr><th scope=row>3</th><td>3</td><td>Apple iPhone 14 Pro - 128GB - Space Black</td><td>Audio      </td><td> 852.79</td><td>Yes    </td></tr>\n",
       "\t<tr><th scope=row>4</th><td>4</td><td>Apple iPhone 14 Pro - 128GB - Space Black</td><td>Shoes      </td><td> 648.58</td><td>Yes    </td></tr>\n",
       "\t<tr><th scope=row>5</th><td>5</td><td>samsung galaxy s23 ultra 256gb           </td><td>Electronics</td><td> 586.35</td><td>Limited</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 5 × 5\n",
       "\\begin{tabular}{r|lllll}\n",
       "  & ProductID & Product\\_Description & Category & Price & In\\_Stock\\\\\n",
       "  & <int> & <chr> & <chr> & <dbl> & <chr>\\\\\n",
       "\\hline\n",
       "\t1 & 1 & Apple iPhone 14 Pro - 128GB - Space Black & TV          &  963.53 & Limited\\\\\n",
       "\t2 & 2 & samsung galaxy s23 ultra 256gb            & TV          & 1817.44 & Yes    \\\\\n",
       "\t3 & 3 & Apple iPhone 14 Pro - 128GB - Space Black & Audio       &  852.79 & Yes    \\\\\n",
       "\t4 & 4 & Apple iPhone 14 Pro - 128GB - Space Black & Shoes       &  648.58 & Yes    \\\\\n",
       "\t5 & 5 & samsung galaxy s23 ultra 256gb            & Electronics &  586.35 & Limited\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 5 × 5\n",
       "\n",
       "| <!--/--> | ProductID &lt;int&gt; | Product_Description &lt;chr&gt; | Category &lt;chr&gt; | Price &lt;dbl&gt; | In_Stock &lt;chr&gt; |\n",
       "|---|---|---|---|---|---|\n",
       "| 1 | 1 | Apple iPhone 14 Pro - 128GB - Space Black | TV          |  963.53 | Limited |\n",
       "| 2 | 2 | samsung galaxy s23 ultra 256gb            | TV          | 1817.44 | Yes     |\n",
       "| 3 | 3 | Apple iPhone 14 Pro - 128GB - Space Black | Audio       |  852.79 | Yes     |\n",
       "| 4 | 4 | Apple iPhone 14 Pro - 128GB - Space Black | Shoes       |  648.58 | Yes     |\n",
       "| 5 | 5 | samsung galaxy s23 ultra 256gb            | Electronics |  586.35 | Limited |\n",
       "\n"
      ],
      "text/plain": [
       "  ProductID Product_Description                       Category    Price  \n",
       "1 1         Apple iPhone 14 Pro - 128GB - Space Black TV           963.53\n",
       "2 2         samsung galaxy s23 ultra 256gb            TV          1817.44\n",
       "3 3         Apple iPhone 14 Pro - 128GB - Space Black Audio        852.79\n",
       "4 4         Apple iPhone 14 Pro - 128GB - Space Black Shoes        648.58\n",
       "5 5         samsung galaxy s23 ultra 256gb            Electronics  586.35\n",
       "  In_Stock\n",
       "1 Limited \n",
       "2 Yes     \n",
       "3 Yes     \n",
       "4 Yes     \n",
       "5 Limited "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Task 1.3: Initial Data Exploration\n",
    "\n",
    "cat(\"=== CUSTOMER FEEDBACK DATA ===\\n\")\n",
    "# TODO: Display structure of feedback using str()\n",
    "str(feedback)\n",
    "\n",
    "# TODO: Display first 5 rows of feedback\n",
    "head(feedback, 5)\n",
    "\n",
    "cat(\"\\n=== TRANSACTION DATA ===\\n\")\n",
    "# TODO: Display structure of transactions\n",
    "str(transactions)\n",
    "\n",
    "# TODO: Display first 5 rows of transactions\n",
    "head(transactions, 5)\n",
    "\n",
    "cat(\"\\n=== PRODUCT CATALOG DATA ===\\n\")\n",
    "# TODO: Display structure of products\n",
    "str(products)\n",
    "\n",
    "# TODO: Display first 5 rows of products\n",
    "head(products, 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part2_intro",
   "metadata": {},
   "source": [
    "## Part 2: String Cleaning and Standardization\n",
    "\n",
    "**Business Context:** Product names and feedback text often have inconsistent formatting that prevents accurate analysis.\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Clean product names (remove extra spaces, standardize case)\n",
    "2. Standardize product categories\n",
    "3. Clean customer feedback text\n",
    "4. Extract customer names from feedback\n",
    "\n",
    "**Key Functions:** `str_trim()`, `str_squish()`, `str_to_lower()`, `str_to_upper()`, `str_to_title()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "clean_products",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product Name Cleaning Results:\n",
      "                         Product_Description\n",
      "1  Apple iPhone 14 Pro - 128GB - Space Black\n",
      "2             samsung galaxy s23 ultra 256gb\n",
      "3  Apple iPhone 14 Pro - 128GB - Space Black\n",
      "4  Apple iPhone 14 Pro - 128GB - Space Black\n",
      "5             samsung galaxy s23 ultra 256gb\n",
      "6  Apple iPhone 14 Pro - 128GB - Space Black\n",
      "7   DELL XPS 13 Laptop - Intel i7 - 16GB RAM\n",
      "8         hp envy printer - wireless - color\n",
      "9   Nike Air Max 270 - Size 10 - Black/White\n",
      "10         LG 55\" 4K Smart TV - OLED Display\n",
      "                          product_name_clean\n",
      "1  Apple Iphone 14 Pro - 128gb - Space Black\n",
      "2             Samsung Galaxy S23 Ultra 256gb\n",
      "3  Apple Iphone 14 Pro - 128gb - Space Black\n",
      "4  Apple Iphone 14 Pro - 128gb - Space Black\n",
      "5             Samsung Galaxy S23 Ultra 256gb\n",
      "6  Apple Iphone 14 Pro - 128gb - Space Black\n",
      "7   Dell Xps 13 Laptop - Intel I7 - 16gb Ram\n",
      "8         Hp Envy Printer - Wireless - Color\n",
      "9   Nike Air Max 270 - Size 10 - Black/White\n",
      "10         Lg 55\" 4k Smart Tv - Oled Display\n"
     ]
    }
   ],
   "source": [
    "# Task 2.1: Clean Product Names\n",
    "# TODO: Create a new column 'product_name_clean' that:\n",
    "#   - Removes leading/trailing whitespace using str_trim()\n",
    "#   - Converts to Title Case using str_to_title()\n",
    "\n",
    "products_clean <- products %>%\n",
    "  mutate(\n",
    "    product_name_clean = str_to_title(str_trim(Product_Description))\n",
    "    \n",
    "  )\n",
    "\n",
    "# Display before and after\n",
    "cat(\"Product Name Cleaning Results:\\n\")\n",
    "products_clean %>%\n",
    "  select(Product_Description, product_name_clean) %>%\n",
    "  head(10) %>%\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "clean_categories",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original categories:\n",
      "[1] \"TV\"          \"Audio\"       \"Shoes\"       \"Electronics\" \"Computers\"  \n",
      "\n",
      "Cleaned categories:\n",
      "[1] \"Tv\"          \"Audio\"       \"Shoes\"       \"Electronics\" \"Computers\"  \n"
     ]
    }
   ],
   "source": [
    "# Task 2.2: Standardize Product Categories\n",
    "# TODO: Create a new column 'category_clean' that:\n",
    "#   - Converts category to Title Case\n",
    "#   - Removes any extra whitespace\n",
    "\n",
    "products_clean <- products_clean %>%\n",
    "  mutate(\n",
    "    category_clean = str_to_title(str_trim(Category))\n",
    "  )\n",
    "\n",
    "# Show unique categories before and after\n",
    "cat(\"Original categories:\\n\")\n",
    "print(unique(products$Category))\n",
    "\n",
    "cat(\"\\nCleaned categories:\\n\")\n",
    "print(unique(products_clean$category_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f93757f6",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feedback Cleaning Sample:\n",
      "                     Feedback_Text                   feedback_clean\n",
      "1       Highly recommend this item       highly recommend this item\n",
      "2             Excellent service                   excellent service\n",
      "3             Poor quality control             poor quality control\n",
      "4 average product, nothing special average product, nothing special\n",
      "5      AMAZING customer support!!!      amazing customer support!!!\n"
     ]
    }
   ],
   "source": [
    "# Task 2.3: Clean Customer Feedback Text\n",
    "# TODO: Create a new column 'feedback_clean' that:\n",
    "#   - Converts text to lowercase using str_to_lower()\n",
    "#   - Removes extra whitespace using str_squish()\n",
    "\n",
    "feedback_clean <- feedback %>%\n",
    "  mutate(\n",
    "    feedback_clean = str_squish(str_to_lower(Feedback_Text))\n",
    "  )\n",
    "\n",
    "# Display sample\n",
    "cat(\"Feedback Cleaning Sample:\\n\")\n",
    "feedback_clean %>%\n",
    "    select(Feedback_Text, feedback_clean) %>%\n",
    "  head(5) %>%\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524fd4ce",
   "metadata": {},
   "source": [
    "## Part 3: Pattern Detection and Extraction\n",
    "\n",
    "**Business Context:** Identifying products with specific features and extracting specifications helps with inventory management and marketing.\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Identify products with specific keywords (wireless, premium, gaming)\n",
    "2. Extract numerical specifications from product names\n",
    "3. Detect sentiment words in customer feedback\n",
    "4. Extract email addresses from feedback\n",
    "\n",
    "**Key Functions:** `str_detect()`, `str_extract()`, `str_count()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detect_features",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product Feature Detection:\n",
      "                          product_name_clean is_wireless is_premium is_gaming\n",
      "1  Apple Iphone 14 Pro - 128gb - Space Black       FALSE       TRUE     FALSE\n",
      "2             Samsung Galaxy S23 Ultra 256gb       FALSE      FALSE     FALSE\n",
      "3  Apple Iphone 14 Pro - 128gb - Space Black       FALSE       TRUE     FALSE\n",
      "4  Apple Iphone 14 Pro - 128gb - Space Black       FALSE       TRUE     FALSE\n",
      "5             Samsung Galaxy S23 Ultra 256gb       FALSE      FALSE     FALSE\n",
      "6  Apple Iphone 14 Pro - 128gb - Space Black       FALSE       TRUE     FALSE\n",
      "7   Dell Xps 13 Laptop - Intel I7 - 16gb Ram       FALSE      FALSE     FALSE\n",
      "8         Hp Envy Printer - Wireless - Color        TRUE      FALSE     FALSE\n",
      "9   Nike Air Max 270 - Size 10 - Black/White       FALSE      FALSE     FALSE\n",
      "10         Lg 55\" 4k Smart Tv - Oled Display       FALSE      FALSE     FALSE\n",
      "\n",
      "Feature Summary:\n",
      "Wireless products: 17 \n",
      "Premium products: 13 \n",
      "Gaming products: 0 \n"
     ]
    }
   ],
   "source": [
    "# Task 3.1: Detect Product Features\n",
    "# TODO: Create three new columns:\n",
    "#   - is_wireless: TRUE if product name contains \"wireless\" (case-insensitive)\n",
    "#   - is_premium: TRUE if product name contains \"pro\", \"premium\", or \"deluxe\"\n",
    "#   - is_gaming: TRUE if product name contains \"gaming\" or \"gamer\"\n",
    "# Hint: Use str_detect() with str_to_lower() for case-insensitive matching\n",
    "# Hint: Use | (pipe) in regex for OR conditions\n",
    "\n",
    "products_clean <- products_clean %>%\n",
    "  mutate(\n",
    "    is_wireless = str_detect(str_to_lower(product_name_clean), \"wireless\"),\n",
    "    is_premium = str_detect(str_to_lower(product_name_clean), \"pro|premium|deluxe\"),\n",
    "    is_gaming = str_detect(str_to_lower(product_name_clean), \"gaming|gamer\")\n",
    "  )\n",
    "\n",
    "# Display results\n",
    "cat(\"Product Feature Detection:\\n\")\n",
    "products_clean %>%\n",
    "  select(product_name_clean, is_wireless, is_premium, is_gaming) %>%\n",
    "  head(10) %>%\n",
    "  print()\n",
    "\n",
    "# Summary statistics\n",
    "cat(\"\\nFeature Summary:\\n\")\n",
    "cat(\"Wireless products:\", sum(products_clean$is_wireless), \"\\n\")\n",
    "cat(\"Premium products:\", sum(products_clean$is_premium), \"\\n\")\n",
    "cat(\"Gaming products:\", sum(products_clean$is_gaming), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "extract_specs",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Product Specifications:\n",
      "                          product_name_clean size_number\n",
      "1  Apple Iphone 14 Pro - 128gb - Space Black          14\n",
      "2             Samsung Galaxy S23 Ultra 256gb          23\n",
      "3  Apple Iphone 14 Pro - 128gb - Space Black          14\n",
      "4  Apple Iphone 14 Pro - 128gb - Space Black          14\n",
      "5             Samsung Galaxy S23 Ultra 256gb          23\n",
      "6  Apple Iphone 14 Pro - 128gb - Space Black          14\n",
      "7   Dell Xps 13 Laptop - Intel I7 - 16gb Ram          13\n",
      "8   Nike Air Max 270 - Size 10 - Black/White         270\n",
      "9          Lg 55\" 4k Smart Tv - Oled Display          55\n",
      "10       Sony Wh-1000xm4 Wireless Headphones        1000\n"
     ]
    }
   ],
   "source": [
    "# Task 3.2: Extract Product Specifications\n",
    "# TODO: Create a new column 'size_number' that extracts the first number from product_name\n",
    "# Hint: Use str_extract() with pattern \"\\\\\\\\d+\" to match one or more digits\n",
    "\n",
    "products_clean <- products_clean %>%\n",
    "  mutate(\n",
    "    size_number = str_extract(Product_Description, \"\\\\d+\")\n",
    "  )\n",
    "\n",
    "# Display products with extracted sizes\n",
    "cat(\"Extracted Product Specifications:\\n\")\n",
    "products_clean %>%\n",
    "  filter(!is.na(size_number)) %>%\n",
    "  select(product_name_clean, size_number) %>%\n",
    "  head(10) %>%\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "sentiment_analysis",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Analysis Results:\n",
      "                     feedback_clean positive_words negative_words\n",
      "1        highly recommend this item              0              0\n",
      "2                 excellent service              1              0\n",
      "3              poor quality control              0              0\n",
      "4  average product, nothing special              0              0\n",
      "5       amazing customer support!!!              1              0\n",
      "6       amazing customer support!!!              1              0\n",
      "7  average product, nothing special              0              0\n",
      "8              good value for money              0              0\n",
      "9        highly recommend this item              0              0\n",
      "10       highly recommend this item              0              0\n",
      "   sentiment_score\n",
      "1                0\n",
      "2                1\n",
      "3                0\n",
      "4                0\n",
      "5                1\n",
      "6                1\n",
      "7                0\n",
      "8                0\n",
      "9                0\n",
      "10               0\n",
      "\n",
      "Overall Sentiment Summary:\n",
      "Average sentiment score: 0.18 \n",
      "Positive reviews: 30 \n",
      "Negative reviews: 20 \n"
     ]
    }
   ],
   "source": [
    "# Task 3.3: Simple Sentiment Analysis\n",
    "# TODO: Create three new columns:\n",
    "#   - positive_words: count of positive words (\"great\", \"excellent\", \"love\", \"amazing\")\n",
    "#   - negative_words: count of negative words (\"bad\", \"terrible\", \"hate\", \"awful\")\n",
    "#   - sentiment_score: positive_words - negative_words\n",
    "# Hint: Use str_count() to count pattern occurrences\n",
    "\n",
    "feedback_clean <- feedback_clean %>%\n",
    "  mutate(\n",
    "    positive_words = str_count(str_to_lower(feedback_clean), \"great|excellent|love|amazing\"),\n",
    "    negative_words = str_count(str_to_lower(feedback_clean), \"bad|terrible|hate|awful\"),\n",
    "    sentiment_score = positive_words - negative_words\n",
    "  )\n",
    "\n",
    "# Display sentiment analysis results\n",
    "cat(\"Sentiment Analysis Results:\\n\")\n",
    "feedback_clean %>%\n",
    "  select(feedback_clean, positive_words, negative_words, sentiment_score) %>%\n",
    "  head(10) %>%\n",
    "  print()\n",
    "\n",
    "# Summary\n",
    "cat(\"\\nOverall Sentiment Summary:\\n\")\n",
    "cat(\"Average sentiment score:\", mean(feedback_clean$sentiment_score), \"\\n\")\n",
    "cat(\"Positive reviews:\", sum(feedback_clean$sentiment_score > 0), \"\\n\")\n",
    "cat(\"Negative reviews:\", sum(feedback_clean$sentiment_score < 0), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part4_intro",
   "metadata": {},
   "source": [
    "## Part 4: Date Parsing and Component Extraction\n",
    "\n",
    "**Business Context:** Transaction dates need to be parsed and analyzed to understand customer behavior patterns.\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Parse transaction dates from text to Date objects\n",
    "2. Extract date components (year, month, day, weekday)\n",
    "3. Identify weekend vs weekday transactions\n",
    "4. Extract quarter and month names\n",
    "\n",
    "**Key Functions:** `ymd()`, `mdy()`, `dmy()`, `year()`, `month()`, `day()`, `wday()`, `quarter()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "parse_dates",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date Parsing Results:\n",
      "   Transaction_DateTime         date_parsed\n",
      "1          4/5/24 14:30 2024-04-05 14:30:00\n",
      "2         3/15/24 14:30 2024-03-15 14:30:00\n",
      "3         3/15/24 14:30 2024-03-15 14:30:00\n",
      "4          3/20/24 9:15 2024-03-20 09:15:00\n",
      "5          3/20/24 9:15 2024-03-20 09:15:00\n",
      "6          3/20/24 9:15 2024-03-20 09:15:00\n",
      "7          3/20/24 9:15 2024-03-20 09:15:00\n",
      "8         3/15/24 14:30 2024-03-15 14:30:00\n",
      "9   25-03-2024 16:45:30 2024-03-25 16:45:30\n",
      "10         4/5/24 14:30 2024-04-05 14:30:00\n"
     ]
    }
   ],
   "source": [
    "# Task 4.1: Parse Transaction Dates\n",
    "# TODO: Create a new column 'date_parsed' that parses the transaction_date column\n",
    "# Hint: Check the format of transaction_date first, then use ymd(), mdy(), or dmy()\n",
    "\n",
    "transactions_clean <- transactions %>%\n",
    "  mutate(\n",
    "    date_parsed = parse_date_time(Transaction_DateTime,\n",
    "    orders = c(\"mdy HM\", \"dmy HMS\",\"ymd HMS\"))\n",
    "    \n",
    "  )\n",
    "\n",
    "# Verify parsing worked\n",
    "cat(\"Date Parsing Results:\\n\")\n",
    "transactions_clean %>%\n",
    "  select(Transaction_DateTime, date_parsed) %>%\n",
    "  head(10) %>%\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "extract_components",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date Component Extraction:\n",
      "           date_parsed trans_month_name trans_weekday trans_quarter\n",
      "1  2024-04-05 14:30:00            April        Friday             2\n",
      "2  2024-03-15 14:30:00            March        Friday             1\n",
      "3  2024-03-15 14:30:00            March        Friday             1\n",
      "4  2024-03-20 09:15:00            March     Wednesday             1\n",
      "5  2024-03-20 09:15:00            March     Wednesday             1\n",
      "6  2024-03-20 09:15:00            March     Wednesday             1\n",
      "7  2024-03-20 09:15:00            March     Wednesday             1\n",
      "8  2024-03-15 14:30:00            March        Friday             1\n",
      "9  2024-03-25 16:45:30            March        Monday             1\n",
      "10 2024-04-05 14:30:00            April        Friday             2\n"
     ]
    }
   ],
   "source": [
    "# Task 4.2: Extract Date Components\n",
    "# TODO: Create the following new columns:\n",
    "#   - trans_year: Extract year from date_parsed\n",
    "#   - trans_month: Extract month number from date_parsed\n",
    "#   - trans_month_name: Extract month name (use label=TRUE, abbr=FALSE)\n",
    "#   - trans_day: Extract day of month from date_parsed\n",
    "#   - trans_weekday: Extract weekday name (use label=TRUE, abbr=FALSE)\n",
    "#   - trans_quarter: Extract quarter from date_parsed\n",
    "\n",
    "transactions_clean <- transactions_clean %>%\n",
    "  mutate(\n",
    "    trans_year = year(date_parsed), \n",
    "    trans_month = month(date_parsed),\n",
    "    trans_month_name = month(date_parsed, label = TRUE, abbr = FALSE), \n",
    "    trans_day = day(date_parsed),\n",
    "    trans_weekday = wday(date_parsed, label = TRUE, abbr = FALSE),\n",
    "    trans_quarter = quarter(date_parsed)\n",
    "  )\n",
    "\n",
    "# Display results\n",
    "cat(\"Date Component Extraction:\\n\")\n",
    "transactions_clean %>%\n",
    "  select(date_parsed, trans_month_name, trans_weekday, trans_quarter) %>%\n",
    "  head(10) %>%\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "weekend_flag",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weekend vs Weekday Transactions:\n",
      "\n",
      "FALSE \n",
      "  150 \n",
      "\n",
      "Percentage of weekend transactions: 0 %\n"
     ]
    }
   ],
   "source": [
    "# Task 4.3: Identify Weekend Transactions\n",
    "# TODO: Create a new column 'is_weekend' that is TRUE if the transaction was on Saturday or Sunday\n",
    "# Hint: Use wday() which returns 1 for Sunday and 7 for Saturday\n",
    "# Hint: Use %in% c(1, 7) to check if day is weekend\n",
    "\n",
    "transactions_clean <- transactions_clean %>%\n",
    "  mutate(\n",
    "    is_weekend = wday(date_parsed) %in% c(1, 7)\n",
    "    \n",
    "  )\n",
    "\n",
    "# Summary\n",
    "cat(\"Weekend vs Weekday Transactions:\\n\")\n",
    "table(transactions_clean$is_weekend) %>% print()\n",
    "\n",
    "cat(\"\\nPercentage of weekend transactions:\",\n",
    "    round(sum(transactions_clean$is_weekend) / nrow(transactions_clean) * 100, 1), \"%\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part5_intro",
   "metadata": {},
   "source": [
    "## Part 5: Date Calculations and Customer Recency Analysis\n",
    "\n",
    "**Business Context:** Understanding how recently customers transacted helps identify at-risk customers for re-engagement campaigns.\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Calculate days since each transaction\n",
    "2. Categorize customers by recency (Recent, Moderate, Old)\n",
    "3. Identify customers who haven't transacted in 90+ days\n",
    "4. Calculate average days between transactions per customer\n",
    "\n",
    "**Key Functions:** `today()`, date arithmetic, `case_when()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "calculate_recency",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Days Since Transaction:\n",
      "   CustomerID         date_parsed days_since\n",
      "1          21 2024-03-15 14:30:00        584\n",
      "2          12 2024-03-15 14:30:00        584\n",
      "3          30 2024-03-15 14:30:00        584\n",
      "4          45 2024-03-15 14:30:00        584\n",
      "5           2 2024-03-15 14:30:00        584\n",
      "6          18 2024-03-15 14:30:00        584\n",
      "7          34 2024-03-15 14:30:00        584\n",
      "8          48 2024-03-15 14:30:00        584\n",
      "9          28 2024-03-15 14:30:00        584\n",
      "10         30 2024-03-15 14:30:00        584\n"
     ]
    }
   ],
   "source": [
    "# Task 5.1: Calculate Days Since Transaction\n",
    "# TODO: Create a new column 'days_since' that calculates days from date_parsed to today()\n",
    "# Hint: Use as.numeric(today() - date_parsed)\n",
    "\n",
    "transactions_clean <- transactions_clean %>%\n",
    "  mutate(\n",
    "    days_since = as.numeric(today() - as_date(date_parsed))\n",
    "    \n",
    "  )\n",
    "\n",
    "# Display results\n",
    "cat(\"Days Since Transaction:\\n\")\n",
    "transactions_clean %>%\n",
    "  select(CustomerID, date_parsed, days_since) %>%\n",
    "  arrange(desc(days_since)) %>%\n",
    "  head(10) %>%\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "recency_categories",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recency Category Distribution:\n",
      "\n",
      "At Risk \n",
      "    150 \n",
      "\n",
      "At-Risk Customers (>90 days):\n",
      "    CustomerID         date_parsed days_since\n",
      "1           21 2024-03-15 14:30:00        584\n",
      "2           12 2024-03-15 14:30:00        584\n",
      "3           30 2024-03-15 14:30:00        584\n",
      "4           45 2024-03-15 14:30:00        584\n",
      "5            2 2024-03-15 14:30:00        584\n",
      "6           18 2024-03-15 14:30:00        584\n",
      "7           34 2024-03-15 14:30:00        584\n",
      "8           48 2024-03-15 14:30:00        584\n",
      "9           28 2024-03-15 14:30:00        584\n",
      "10          30 2024-03-15 14:30:00        584\n",
      "11          33 2024-03-15 14:30:00        584\n",
      "12          11 2024-03-15 14:30:00        584\n",
      "13          36 2024-03-15 14:30:00        584\n",
      "14           6 2024-03-15 14:30:00        584\n",
      "15           8 2024-03-15 14:30:00        584\n",
      "16          38 2024-03-15 14:30:00        584\n",
      "17          49 2024-03-15 14:30:00        584\n",
      "18          28 2024-03-15 14:30:00        584\n",
      "19          44 2024-03-15 14:30:00        584\n",
      "20          33 2024-03-15 14:30:00        584\n",
      "21          29 2024-03-15 14:30:00        584\n",
      "22          14 2024-03-15 14:30:00        584\n",
      "23          17 2024-03-15 14:30:00        584\n",
      "24          17 2024-03-15 14:30:00        584\n",
      "25          48 2024-03-15 14:30:00        584\n",
      "26          41 2024-03-15 14:30:00        584\n",
      "27          42 2024-03-15 14:30:00        584\n",
      "28           6 2024-03-20 09:15:00        579\n",
      "29          32 2024-03-20 09:15:00        579\n",
      "30          27 2024-03-20 09:15:00        579\n",
      "31          31 2024-03-20 09:15:00        579\n",
      "32          30 2024-03-20 09:15:00        579\n",
      "33          33 2024-03-20 09:15:00        579\n",
      "34          13 2024-03-20 09:15:00        579\n",
      "35           7 2024-03-20 09:15:00        579\n",
      "36          34 2024-03-20 09:15:00        579\n",
      "37           9 2024-03-20 09:15:00        579\n",
      "38          21 2024-03-20 09:15:00        579\n",
      "39           1 2024-03-20 09:15:00        579\n",
      "40          17 2024-03-20 09:15:00        579\n",
      "41          48 2024-03-20 09:15:00        579\n",
      "42           1 2024-03-20 09:15:00        579\n",
      "43          14 2024-03-20 09:15:00        579\n",
      "44          42 2024-03-20 09:15:00        579\n",
      "45          50 2024-03-20 09:15:00        579\n",
      "46           8 2024-03-20 09:15:00        579\n",
      "47          31 2024-03-20 09:15:00        579\n",
      "48          21 2024-03-20 09:15:00        579\n",
      "49          25 2024-03-20 09:15:00        579\n",
      "50          12 2024-03-20 09:15:00        579\n",
      "51          31 2024-03-20 09:15:00        579\n",
      "52          28 2024-03-20 09:15:00        579\n",
      "53           8 2024-03-20 09:15:00        579\n",
      "54          43 2024-03-20 09:15:00        579\n",
      "55          25 2024-03-20 09:15:00        579\n",
      "56          21 2024-03-20 09:15:00        579\n",
      "57          13 2024-03-20 09:15:00        579\n",
      "58          28 2024-03-20 09:15:00        579\n",
      "59          34 2024-03-20 09:15:00        579\n",
      "60          37 2024-03-20 09:15:00        579\n",
      "61          24 2024-03-20 09:15:00        579\n",
      "62          31 2024-03-25 16:45:30        574\n",
      "63          25 2024-03-25 16:45:30        574\n",
      "64          35 2024-03-25 16:45:30        574\n",
      "65          12 2024-03-25 16:45:30        574\n",
      "66          39 2024-03-25 16:45:30        574\n",
      "67           2 2024-03-25 16:45:30        574\n",
      "68          11 2024-03-25 16:45:30        574\n",
      "69          48 2024-03-25 16:45:30        574\n",
      "70          44 2024-03-25 16:45:30        574\n",
      "71           6 2024-03-25 16:45:30        574\n",
      "72           7 2024-03-25 16:45:30        574\n",
      "73          31 2024-03-25 16:45:30        574\n",
      "74          14 2024-03-25 16:45:30        574\n",
      "75          36 2024-03-25 16:45:30        574\n",
      "76           3 2024-03-25 16:45:30        574\n",
      "77          45 2024-03-25 16:45:30        574\n",
      "78          24 2024-03-25 16:45:30        574\n",
      "79           7 2024-03-25 16:45:30        574\n",
      "80          48 2024-03-25 16:45:30        574\n",
      "81          38 2024-03-25 16:45:30        574\n",
      "82          50 2024-03-25 16:45:30        574\n",
      "83          45 2024-03-25 16:45:30        574\n",
      "84          27 2024-03-25 16:45:30        574\n",
      "85           1 2024-03-25 16:45:30        574\n",
      "86           9 2024-03-25 16:45:30        574\n",
      "87          35 2024-03-25 16:45:30        574\n",
      "88          35 2024-03-25 16:45:30        574\n",
      "89          42 2024-03-25 16:45:30        574\n",
      "90          28 2024-04-01 10:30:00        567\n",
      "91           1 2024-04-01 10:30:00        567\n",
      "92          48 2024-04-01 10:30:00        567\n",
      "93          40 2024-04-01 10:30:00        567\n",
      "94          24 2024-04-01 10:30:00        567\n",
      "95           1 2024-04-01 10:30:00        567\n",
      "96          25 2024-04-01 10:30:00        567\n",
      "97          11 2024-04-01 10:30:00        567\n",
      "98          29 2024-04-01 10:30:00        567\n",
      "99           8 2024-04-01 10:30:00        567\n",
      "100         33 2024-04-01 10:30:00        567\n",
      "101         33 2024-04-01 10:30:00        567\n",
      "102         41 2024-04-01 10:30:00        567\n",
      "103         29 2024-04-01 10:30:00        567\n",
      "104         19 2024-04-01 10:30:00        567\n",
      "105         33 2024-04-01 10:30:00        567\n",
      "106         36 2024-04-01 10:30:00        567\n",
      "107         43 2024-04-01 10:30:00        567\n",
      "108         26 2024-04-01 10:30:00        567\n",
      "109          7 2024-04-01 10:30:00        567\n",
      "110         32 2024-04-01 10:30:00        567\n",
      "111         30 2024-04-01 10:30:00        567\n",
      "112         35 2024-04-01 10:30:00        567\n",
      "113         45 2024-04-01 10:30:00        567\n",
      "114          3 2024-04-01 10:30:00        567\n",
      "115          6 2024-04-01 10:30:00        567\n",
      "116         15 2024-04-01 10:30:00        567\n",
      "117         24 2024-04-01 10:30:00        567\n",
      "118         35 2024-04-01 10:30:00        567\n",
      "119         30 2024-04-01 10:30:00        567\n",
      "120         24 2024-04-01 10:30:00        567\n",
      "121         35 2024-04-01 10:30:00        567\n",
      "122         41 2024-04-01 10:30:00        567\n",
      "123         26 2024-04-05 14:30:00        563\n",
      "124         13 2024-04-05 14:30:00        563\n",
      "125         44 2024-04-05 14:30:00        563\n",
      "126         22 2024-04-05 14:30:00        563\n",
      "127         13 2024-04-05 14:30:00        563\n",
      "128         35 2024-04-05 14:30:00        563\n",
      "129         30 2024-04-05 14:30:00        563\n",
      "130         48 2024-04-05 14:30:00        563\n",
      "131          4 2024-04-05 14:30:00        563\n",
      "132         44 2024-04-05 14:30:00        563\n",
      "133          8 2024-04-05 14:30:00        563\n",
      "134         12 2024-04-05 14:30:00        563\n",
      "135         40 2024-04-05 14:30:00        563\n",
      "136         10 2024-04-05 14:30:00        563\n",
      "137         17 2024-04-05 14:30:00        563\n",
      "138         29 2024-04-05 14:30:00        563\n",
      "139          5 2024-04-05 14:30:00        563\n",
      "140         19 2024-04-05 14:30:00        563\n",
      "141          4 2024-04-05 14:30:00        563\n",
      "142         30 2024-04-05 14:30:00        563\n",
      "143         23 2024-04-05 14:30:00        563\n",
      "144         28 2024-04-05 14:30:00        563\n",
      "145         10 2024-04-05 14:30:00        563\n",
      "146         46 2024-04-05 14:30:00        563\n",
      "147         13 2024-04-05 14:30:00        563\n",
      "148         19 2024-04-05 14:30:00        563\n",
      "149         48 2024-04-05 14:30:00        563\n",
      "150         38 2024-04-05 14:30:00        563\n"
     ]
    }
   ],
   "source": [
    "# Task 5.2: Categorize by Recency\n",
    "# TODO: Create a new column 'recency_category' using case_when():\n",
    "#   - \"Recent\" if days_since <= 30\n",
    "#   - \"Moderate\" if days_since <= 90\n",
    "#   - \"At Risk\" if days_since > 90\n",
    "\n",
    "transactions_clean <- transactions_clean %>%\n",
    "  mutate(\n",
    "    recency_category = case_when(\n",
    "      days_since <= 30 ~ \"Recent\",\n",
    "      days_since <= 90 ~ \"Moderate\",\n",
    "      days_since > 90 ~ \"At Risk\"\n",
    "    )\n",
    "  )\n",
    "\n",
    "# Display distribution\n",
    "cat(\"Recency Category Distribution:\\n\")\n",
    "table(transactions_clean$recency_category) %>% print()\n",
    "\n",
    "# Show at-risk customers\n",
    "cat(\"\\nAt-Risk Customers (>90 days):\\n\")\n",
    "transactions_clean %>%\n",
    "  filter(recency_category == \"At Risk\") %>%\n",
    "  select(CustomerID, date_parsed, days_since) %>%\n",
    "  arrange(desc(days_since)) %>%\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part6_intro",
   "metadata": {},
   "source": [
    "## Part 6: Combined String and Date Operations\n",
    "\n",
    "**Business Context:** Create personalized customer outreach messages based on purchase recency.\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Extract first names from customer names\n",
    "2. Create personalized messages based on recency\n",
    "3. Analyze transaction patterns by weekday\n",
    "4. Identify best customers (recent + high value)\n",
    "\n",
    "**Key Functions:** Combine `str_extract()`, date calculations, `case_when()`, `group_by()`, `summarize()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "extract_names",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Personalized Customer Messages:\n",
      "   customer_name first_name days_since\n",
      "1    Customer 26   Customer        563\n",
      "2    Customer 21   Customer        584\n",
      "3    Customer 12   Customer        584\n",
      "4     Customer 6   Customer        579\n",
      "5    Customer 32   Customer        579\n",
      "6    Customer 27   Customer        579\n",
      "7    Customer 31   Customer        579\n",
      "8    Customer 30   Customer        584\n",
      "9    Customer 31   Customer        574\n",
      "10   Customer 13   Customer        563\n",
      "                                               personalized_message\n",
      "1  Hi Customer , it's been a while! Here's a special offer for you.\n",
      "2  Hi Customer , it's been a while! Here's a special offer for you.\n",
      "3  Hi Customer , it's been a while! Here's a special offer for you.\n",
      "4  Hi Customer , it's been a while! Here's a special offer for you.\n",
      "5  Hi Customer , it's been a while! Here's a special offer for you.\n",
      "6  Hi Customer , it's been a while! Here's a special offer for you.\n",
      "7  Hi Customer , it's been a while! Here's a special offer for you.\n",
      "8  Hi Customer , it's been a while! Here's a special offer for you.\n",
      "9  Hi Customer , it's been a while! Here's a special offer for you.\n",
      "10 Hi Customer , it's been a while! Here's a special offer for you.\n"
     ]
    }
   ],
   "source": [
    "# Task 6.1: Extract First Names and Create Personalized Messages\n",
    "# TODO: Create two new columns:\n",
    "#   - first_name: Extract first name from customer_name (everything before first space)\n",
    "#   - personalized_message: Create message based on recency_category\n",
    "#     * Recent: \"Hi [name]! Thanks for your recent purchase!\"\n",
    "#     * Moderate: \"Hi [name], we miss you! Check out our new products.\"\n",
    "#     * At Risk: \"Hi [name], it's been a while! Here's a special offer for you.\"\n",
    "# Hint: Use str_extract() with pattern \"^\\\\\\\\w+\" for first name\n",
    "# Hint: Use paste() to combine strings in case_when()\n",
    "\n",
    "customer_outreach <- transactions_clean %>%\n",
    "  mutate(\n",
    "    customer_name = paste(\"Customer\", CustomerID),\n",
    "    first_name = str_extract(customer_name, \"^\\\\w+\"),\n",
    "        personalized_message = case_when(\n",
    "      recency_category == \"Recent\" ~ paste(\"Hi\", first_name, \"! Thanks for your recent purchase!\"),\n",
    "      recency_category == \"Moderate\" ~ paste(\"Hi\", first_name, \", we miss you! Check out our new products.\"),\n",
    "      recency_category == \"At Risk\" ~ paste(\"Hi\", first_name, \", it's been a while! Here's a special offer for you.\")\n",
    "    )\n",
    "  )\n",
    "\n",
    "# Display personalized messages\n",
    "cat(\"Personalized Customer Messages:\\n\")\n",
    "customer_outreach %>%\n",
    "  select(customer_name, first_name, days_since, personalized_message) %>%\n",
    "  head(10) %>%\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "weekday_analysis",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transaction Patterns by Weekday:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90m# A tibble: 3 × 4\u001b[39m\n",
      "  trans_weekday transaction_count total_amount avg_amount\n",
      "  \u001b[3m\u001b[90m<ord>\u001b[39m\u001b[23m                     \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m        \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m      \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m Monday                       61       \u001b[4m1\u001b[24m\u001b[4m5\u001b[24m367.       252.\n",
      "\u001b[90m2\u001b[39m Friday                       55       \u001b[4m1\u001b[24m\u001b[4m4\u001b[24m789.       269.\n",
      "\u001b[90m3\u001b[39m Wednesday                    34        \u001b[4m7\u001b[24m578.       223.\n",
      "\n",
      "🔥 Busiest day: Monday \n"
     ]
    }
   ],
   "source": [
    "# Task 6.2: Analyze Transaction Patterns by Weekday\n",
    "# TODO: Group by trans_weekday and calculate:\n",
    "#   - transaction_count: number of transactions\n",
    "#   - total_amount: sum of amount (if available)\n",
    "#   - avg_amount: average amount per transaction\n",
    "# TODO: Arrange by transaction_count descending\n",
    "\n",
    "weekday_patterns <- transactions_clean %>%\n",
    "  group_by(trans_weekday) %>%\n",
    "  summarize(\n",
    "    transaction_count = n(),\n",
    "    total_amount = sum(Amount, na.rm = TRUE),\n",
    "    avg_amount = mean(Amount, na.rm = TRUE)\n",
    "  ) %>%\n",
    "  arrange(desc(transaction_count))\n",
    "\n",
    "# Display results\n",
    "cat(\"Transaction Patterns by Weekday:\\n\")\n",
    "print(weekday_patterns)\n",
    "\n",
    "# Identify busiest day\n",
    "busiest_day <- weekday_patterns$trans_weekday[1]\n",
    "cat(\"\\n🔥 Busiest day:\", as.character(busiest_day), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "monthly_analysis",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monthly Transaction Patterns:\n",
      "\u001b[90m# A tibble: 2 × 4\u001b[39m\n",
      "  trans_month_name trans_month transaction_count unique_customers\n",
      "  \u001b[3m\u001b[90m<ord>\u001b[39m\u001b[23m                  \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m             \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m            \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m March                      3                89               37\n",
      "\u001b[90m2\u001b[39m April                      4                61               34\n"
     ]
    }
   ],
   "source": [
    "# Task 6.3: Monthly Transaction Analysis\n",
    "# TODO: Group by trans_month_name and calculate:\n",
    "#   - transaction_count\n",
    "#   - unique_customers: use n_distinct(customer_name)\n",
    "# TODO: Arrange by trans_month (to show chronological order)\n",
    "\n",
    "monthly_patterns <- transactions_clean %>%\n",
    "  group_by(trans_month_name, trans_month)  %>%\n",
    "  summarize( \n",
    "    transaction_count = n(),\n",
    "    unique_customers = n_distinct(CustomerID),\n",
    "  .groups = \"drop\"\n",
    "  ) %>%\n",
    "  arrange(trans_month)\n",
    "# Display results\n",
    "cat(\"Monthly Transaction Patterns:\\n\")\n",
    "print(monthly_patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part7_intro",
   "metadata": {},
   "source": [
    "## Part 7: Business Intelligence Summary\n",
    "\n",
    "**Business Context:** Create an executive summary that combines all your analyses into actionable insights.\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Calculate key metrics across all datasets\n",
    "2. Identify top products and categories\n",
    "3. Summarize customer sentiment\n",
    "4. Provide data-driven recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "business_summary",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "         BUSINESS INTELLIGENCE SUMMARY\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "\n",
      "📦 PRODUCT ANALYSIS\n",
      "─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Products: 75 \n",
      "Wireless Products: 17 ( 22.7 %)\n",
      "Premium Products: 13 ( 17.3 %)\n",
      "Most Common Category: Electronics \n",
      "\n",
      "💬 CUSTOMER SENTIMENT\n",
      "─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ \n",
      "Total Feedback Entries: 100 \n",
      "Average Sentiment Score: 0.18 \n",
      "Positive Reviews: 30 ( 30 %)\n",
      "Negative Reviews: 20 ( 20 %)\n",
      "\n",
      "📊 TRANSACTION PATTERNS\n",
      "─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ \n",
      "Total Transactions: 150 \n",
      "Date Range: 2024-03-15 to 2024-04-05 \n",
      "Busiest Weekday: Monday \n",
      "Weekend Transactions: 0 %\n",
      "\n",
      "👥 CUSTOMER RECENCY\n",
      "─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ \n",
      "Recent Customers (under 30 days): 0 \n",
      "At-Risk Customers (over 90 days): 150 \n",
      "Customers Needing Re-engagement: 100 %\n"
     ]
    }
   ],
   "source": [
    "# Task 7.1: Create Business Intelligence Dashboard\n",
    "\n",
    "cat(\"\\n\", rep(\"=\", 60), \"\\n\")\n",
    "cat(\"         BUSINESS INTELLIGENCE SUMMARY\\n\")\n",
    "cat(rep(\"=\", 60), \"\\n\\n\")\n",
    "\n",
    "# Product Analysis\n",
    "cat(\"📦 PRODUCT ANALYSIS\\n\")\n",
    "cat(rep(\"─\", 30), \"\\n\")\n",
    "# TODO: Calculate and display:\n",
    "#   - Total number of products\n",
    "total_products <- nrow(products_clean)\n",
    "#   - Number of wireless products\n",
    "wireless_count <- sum(products_clean$is_wireless, na.rm = TRUE)\n",
    "#   - Number of premium products\n",
    "premium_count <- sum(products_clean$is_premium, na.rm = TRUE)\n",
    "#   - Most common category\n",
    "most_common_category <- names(sort(table(products_clean$Category), decreasing = TRUE))[1]\n",
    "\n",
    "cat(\"Total Products:\", total_products, \"\\n\")\n",
    "cat(\"Wireless Products:\", wireless_count, \"(\", round(wireless_count/total_products*100, 1), \"%)\\n\")\n",
    "cat(\"Premium Products:\", premium_count, \"(\", round(premium_count/total_products*100, 1), \"%)\\n\")\n",
    "cat(\"Most Common Category:\", most_common_category, \"\\n\")\n",
    "\n",
    "# Customer Sentiment\n",
    "cat(\"\\n💬 CUSTOMER SENTIMENT\\n\")\n",
    "cat(rep(\"─\", 30), \"\\n\")\n",
    "# TODO: Calculate and display:\n",
    "#   - Total feedback entries\n",
    "total_feedback <- nrow(feedback_clean)\n",
    "#   - Average sentiment score\n",
    "avg_sentiment <- mean(feedback_clean$sentiment_score, na.rm = TRUE)\n",
    "#   - Percentage of positive reviews\n",
    "positive_reviews <- sum(feedback_clean$sentiment_score > 0, na.rm = TRUE)\n",
    "pct_positive <- round(positive_reviews/total_feedback*100, 1)\n",
    "#   - Percentage of negative reviews\n",
    "negative_reviews <- sum(feedback_clean$sentiment_score < 0, na.rm = TRUE)\n",
    "pct_negative <- round(negative_reviews/total_feedback*100, 1)\n",
    "\n",
    "cat(\"Total Feedback Entries:\", total_feedback, \"\\n\")\n",
    "cat(\"Average Sentiment Score:\", avg_sentiment, \"\\n\")\n",
    "cat(\"Positive Reviews:\", positive_reviews, \"(\", pct_positive, \"%)\\n\")\n",
    "cat(\"Negative Reviews:\", negative_reviews, \"(\", pct_negative, \"%)\\n\")\n",
    "\n",
    "# Transaction Patterns\n",
    "cat(\"\\n📊 TRANSACTION PATTERNS\\n\")\n",
    "cat(rep(\"─\", 30), \"\\n\")\n",
    "# TODO: Calculate and display:\n",
    "#   - Total transactions\n",
    "total_transactions <- nrow(transactions_clean)\n",
    "#   - Date range (earliest to latest)\n",
    "earliest_date <- min(transactions_clean$date_parsed, na.rm = TRUE)\n",
    "latest_date <- max(transactions_clean$date_parsed, na.rm = TRUE)\n",
    "#   - Busiest weekday\n",
    "busiest_weekday <- as.character(busiest_day)\n",
    "\n",
    "#   - Weekend transaction percentage\n",
    "weekend_pct <- sum(transactions_clean$is_weekend, na.rm = TRUE) / total_transactions * 100\n",
    "\n",
    "cat(\"Total Transactions:\", total_transactions, \"\\n\")\n",
    "cat(\"Date Range:\", format(earliest_date, \"%Y-%m-%d\"), \"to\", format(latest_date, \"%Y-%m-%d\"), \"\\n\")\n",
    "cat(\"Busiest Weekday:\", busiest_weekday, \"\\n\")\n",
    "cat(\"Weekend Transactions:\", weekend_pct, \"%\\n\")\n",
    "\n",
    "# Customer Recency\n",
    "cat(\"\\n👥 CUSTOMER RECENCY\\n\")\n",
    "cat(rep(\"─\", 30), \"\\n\")\n",
    "# TODO: Calculate and display:\n",
    "#   - Number of recent customers (< 30 days)\n",
    "recent_customers <- sum(transactions_clean$days_since < 30, na.rm = TRUE)\n",
    "#   - Number of at-risk customers (> 90 days)\n",
    "at_risk_customers <- sum(transactions_clean$days_since > 90, na.rm = TRUE)\n",
    "#   - Percentage needing re-engagement\n",
    "pct_at_risk <- round(at_risk_customers/total_transactions*100, 1)\n",
    "\n",
    "cat(\"Recent Customers (under 30 days):\", recent_customers, \"\\n\")\n",
    "cat(\"At-Risk Customers (over 90 days):\", at_risk_customers, \"\\n\")\n",
    "cat(\"Customers Needing Re-engagement:\", pct_at_risk, \"%\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a561fd",
   "metadata": {},
   "source": [
    "add recommendations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "top_products",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Product Categories:\n",
      "\u001b[90m# A tibble: 5 × 2\u001b[39m\n",
      "  Category    product_count\n",
      "  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m               \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m Electronics            21\n",
      "\u001b[90m2\u001b[39m Computers              15\n",
      "\u001b[90m3\u001b[39m Audio                  14\n",
      "\u001b[90m4\u001b[39m TV                     14\n",
      "\u001b[90m5\u001b[39m Shoes                  11\n"
     ]
    }
   ],
   "source": [
    "# Task 7.2: Identify Top Products by Category\n",
    "# TODO: Group products by category_clean and count products in each\n",
    "# TODO: Arrange by count descending\n",
    "# TODO: Display top 5 categories\n",
    "\n",
    "top_categories <- products_clean %>%\n",
    "    group_by(Category) %>%\n",
    "  summarise(product_count = n()) %>%\n",
    "  arrange(desc(product_count)) %>%\n",
    "  head(5)\n",
    "  \n",
    "\n",
    "cat(\"Top Product Categories:\\n\")\n",
    "print(top_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part8_intro",
   "metadata": {},
   "source": [
    "## Part 8: Reflection Questions\n",
    "\n",
    "Answer the following questions based on your analysis. Write your answers in the markdown cells below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection1",
   "metadata": {},
   "source": [
    "### Question 8.1: Data Quality Impact\n",
    "\n",
    "**How did cleaning the text data (removing spaces, standardizing case) improve your ability to analyze the data? Provide specific examples from your homework.**\n",
    "\n",
    "Helps fix inconsistent formatting throughout the raw data using the str_trim() and str_to_title() functions to give consistent standardization for all product names. Without the cleaning step pattern matching would’ve failed and lead to missed insights. In Task 2.3 I standardized the feedback text using the code feedback_clean = str_squish(str_to_lower(Feedback_Text)) to convert all text lowercase and get rid of whitespace into the feedback_clean file. Then later in task 3.3 Sentiment analysis when using feedback_clean file using the str_count() on great, excellent, love, and amazing words. It allowed the function to count any of the words that were already put in lowercase in a previous step. It turned feedback with “AMAZING” to “amazing” and it allowed me to better analyze the feedback_clean file in sentiment analysis accuracy.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection2",
   "metadata": {},
   "source": [
    "### Question 8.2: Pattern Detection Value\n",
    "\n",
    "**What business insights did you gain from detecting patterns in product names (wireless, premium, gaming)? How could a business use this information?**\n",
    "\n",
    "Specific findings I found were 17 wireless products and 13 premium products but no gaming products. This insight reveals the strengths and gaps in purchased products and a business could use this insight to make marketing strategies. For example, create a bundling strategy for wireless products with items that can go together with gaming items with lower sales such as wireless headphones paired with an xbox. This would help tap into the gaming market paired with products that are already consistently being sold. In addition to this, customers who already have premium products could be sent recommendations to other high end products. This is due to the fact they’ve purchased higher end items and would be more likely to purchase more if receiving targeted promotions. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection3",
   "metadata": {},
   "source": [
    "### Question 8.3: Date Analysis Importance\n",
    "\n",
    "**Why is analyzing transaction dates by weekday and month important for business operations? Provide at least three specific business applications.**\n",
    "\n",
    "\n",
    "\n",
    "1. The busiest day of transactions was shown to take place on Monday with 61 transactions and slowest day on Wednesday with 34, this could affect the way a business would schedule staff. More staff would be required on mondays to deal with the more customer transactions taking place to ensure operations are taking place efficiently, and reduce staff on Wednesday to optimize labor cost by having a prediction on how many sales will take place on those days. \n",
    "\n",
    "2. March had 89 transactions which could require more sales events or product releases to use the momentum of sales to have better selling effectiveness. This could also require larger marketing budgets to get a better use on money spent on ads. On the other hand April had 61 transactions showing a drop in customers sales, for slower months like this a company could lower its marketing budget. Using discounts could help stimulate customers to help generate more sales during a slower month to help drive revenue. Instead of ads a company could use promotional emails to save money and help bring attention to customers about the discounts. \n",
    "\n",
    "3. Along with the High transactions in March, a business would need to make sure inventory is prepared and stocked before the high demand to make sure all transactions can be made. Then in the lower transactions in April could see a business reduce inventory to focus on clearing any remaining inventory from stocking in March and reducing any holding costs of unsold items. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection4",
   "metadata": {},
   "source": [
    "### Question 8.4: Customer Recency Strategy\n",
    "\n",
    "**Based on your recency analysis, what specific actions would you recommend for customers in each category (Recent, Moderate, At Risk)? How would you prioritize these actions?**\n",
    "\n",
    "All of the 150 customers are at risk and listed as at-risk customers with the last purchase taking place 563 days ago. This would require an aggressive business strategy for each category. Starting with customers that left positive reviews which are the most likely to make purchases again would be to launch targeted campaigns with personalized messaging. Next would be to address issues from negative reviews and send emails with discounts to encourage customers that have negative reviews to consider making future purchases. Long-term would be to keep customers re-engaged with automated messages once purchases are made to focus on customer retention. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection5",
   "metadata": {},
   "source": [
    "### Question 8.5: Sentiment Analysis Application\n",
    "\n",
    "**How could the sentiment analysis you performed be used to improve products or customer service? What are the limitations of this simple sentiment analysis approach?**\n",
    "\n",
    "Sentiment analysis could be used to improve customer services by tracking recurring negative reviews and address those issues such as quality control. Prioritizing products with negative feedback and combining with transaction data to better identify which products are generating negative reviews and improving the quality or supplier of those items. The limitation of sentiment analysis is it only counts specific words and can fail to give a full representation of how customers feel towards products. This could create limits to how quality control can be addressed.    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection6",
   "metadata": {},
   "source": [
    "### Question 8.6: Real-World Application\n",
    "\n",
    "**Describe a real business scenario where you would need to combine string manipulation and date analysis (like you did in this homework). What insights would you be trying to discover?**\n",
    "\n",
    "An online retailer could require a full string manipulation and data analysis to help create re-engagement for customers who haven’t purchased in a while. Having a data analysis could reveal an urgency to prioritize an outreach to customers based on how long since a purchase has been made. This would be more valuable to an online retailer opposed to an in-person location due to the fact that online customers are easier to lose interest because of no physical store customers are easier to turn away so customer retention is that much more valuable. An online retailer could create automated personalized messages to customers based on risk such as what was completed in the homework in Task 8.6. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## Summary and Submission\n",
    "\n",
    "### What You've Accomplished\n",
    "\n",
    "In this homework, you've successfully:\n",
    "- ✅ Cleaned and standardized messy text data using `stringr` functions\n",
    "- ✅ Detected patterns and extracted information from text\n",
    "- ✅ Parsed dates and extracted temporal components using `lubridate`\n",
    "- ✅ Calculated customer recency for segmentation\n",
    "- ✅ Analyzed transaction patterns by time periods\n",
    "- ✅ Combined string and date operations for business insights\n",
    "- ✅ Created personalized customer communications\n",
    "- ✅ Generated executive-ready business intelligence summaries\n",
    "\n",
    "### Key Skills Mastered\n",
    "\n",
    "**String Manipulation:**\n",
    "- `str_trim()`, `str_squish()` - Whitespace handling\n",
    "- `str_to_lower()`, `str_to_upper()`, `str_to_title()` - Case conversion\n",
    "- `str_detect()` - Pattern detection\n",
    "- `str_extract()` - Information extraction\n",
    "- `str_count()` - Pattern counting\n",
    "\n",
    "**Date/Time Operations:**\n",
    "- `ymd()`, `mdy()`, `dmy()` - Date parsing\n",
    "- `year()`, `month()`, `day()`, `wday()` - Component extraction\n",
    "- `quarter()` - Period extraction\n",
    "- `today()` - Current date\n",
    "- Date arithmetic - Calculating differences\n",
    "\n",
    "**Business Applications:**\n",
    "- Data cleaning and standardization\n",
    "- Customer segmentation by recency\n",
    "- Sentiment analysis\n",
    "- Pattern identification\n",
    "- Temporal trend analysis\n",
    "- Personalized communication\n",
    "\n",
    "### Submission Checklist\n",
    "\n",
    "Before submitting, ensure you have:\n",
    "- [ ] Entered your name, student ID, and date at the top\n",
    "- [ ] Completed all code tasks (Parts 1-7)\n",
    "- [ ] Run all cells successfully without errors\n",
    "- [ ] Answered all reflection questions (Part 8)\n",
    "- [ ] Used proper commenting in your code\n",
    "- [ ] Used the pipe operator (`%>%`) where appropriate\n",
    "- [ ] Verified your results make business sense\n",
    "- [ ] Checked for any remaining TODO comments\n",
    "\n",
    "### Grading Criteria\n",
    "\n",
    "Your homework will be evaluated on:\n",
    "- **Code Correctness (40%)**: All tasks completed correctly\n",
    "- **Code Quality (20%)**: Clean, well-commented, efficient code\n",
    "- **Business Understanding (20%)**: Demonstrates understanding of business applications\n",
    "- **Reflection Questions (15%)**: Thoughtful, complete answers\n",
    "- **Presentation (5%)**: Professional formatting and organization\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "In Lesson 8, you'll learn:\n",
    "- Advanced data wrangling with complex pipelines\n",
    "- Sophisticated conditional logic with `case_when()`\n",
    "- Data validation and quality checks\n",
    "- Creating reproducible analysis workflows\n",
    "- Professional best practices for business analytics\n",
    "\n",
    "**Great work on completing this assignment! 🎉**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
