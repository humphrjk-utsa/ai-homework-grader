{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# MIDTERM EXAM: Comprehensive R Data Wrangling Assessment\n",
    "\n",
    "**Student Name:** Tala Kamil\n",
    "\n",
    "**Student ID:** ocf664\n",
    "\n",
    "**Date:** 10-19-2025\n",
    "\n",
    "**Time Limit:** 4 hours\n",
    "\n",
    "---\n",
    "\n",
    "## Exam Overview\n",
    "\n",
    "This comprehensive midterm exam assesses your mastery of ALL R data wrangling skills covered in Lessons 1-8:\n",
    "\n",
    "- **Lesson 1:** R Basics and Data Import\n",
    "- **Lesson 2:** Data Cleaning (Missing Values & Outliers)\n",
    "- **Lesson 3:** Data Transformation Part 1 (select, filter, arrange)\n",
    "- **Lesson 4:** Data Transformation Part 2 (mutate, summarize, group_by)\n",
    "- **Lesson 5:** Data Reshaping (pivot_longer, pivot_wider)\n",
    "- **Lesson 6:** Combining Datasets (joins)\n",
    "- **Lesson 7:** String Manipulation & Date/Time\n",
    "- **Lesson 8:** Advanced Wrangling & Best Practices\n",
    "\n",
    "## Business Scenario\n",
    "\n",
    "You are a data analyst for a retail company. The executive team needs a comprehensive analysis of:\n",
    "- Sales performance across products and regions\n",
    "- Customer behavior and segmentation\n",
    "- Data quality issues and recommendations\n",
    "- Strategic insights for business growth\n",
    "\n",
    "## Instructions\n",
    "\n",
    "1. **Set your working directory** to where your data files are located\n",
    "2. Complete ALL tasks in order\n",
    "3. Write code in the TODO sections\n",
    "4. Use the pipe operator (%>%) to chain operations\n",
    "5. Add comments explaining your logic\n",
    "6. Run all cells to verify your code works\n",
    "7. Answer all reflection questions\n",
    "\n",
    "## Grading\n",
    "\n",
    "- **Code Correctness (40%)**: All tasks completed correctly\n",
    "- **Code Quality (20%)**: Clean, well-commented code\n",
    "- **Business Understanding (20%)**: Demonstrates understanding of context\n",
    "- **Analysis & Insights (15%)**: Meaningful insights and recommendations\n",
    "- **Reflection Questions (5%)**: Thoughtful answers\n",
    "\n",
    "## Academic Integrity\n",
    "\n",
    "This is an individual exam. You may use:\n",
    "- Course notes and lesson materials\n",
    "- R documentation and help files\n",
    "- Your previous homework assignments\n",
    "\n",
    "You may NOT:\n",
    "- Collaborate with other students\n",
    "- Use AI assistants or online forums\n",
    "- Share code or solutions\n",
    "\n",
    "---\n",
    "\n",
    "**Good luck! ðŸŽ“**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part1_intro",
   "metadata": {},
   "source": [
    "## Part 1: R Basics and Data Import (Lesson 1)\n",
    "\n",
    "**Skills Assessed:** Variables, data types, data import, working directory\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Set working directory\n",
    "2. Load required packages\n",
    "3. Import multiple datasets\n",
    "4. Examine data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "setup",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /workspaces/Data-Management-Assignment-1-Intro-to-R/data \n"
     ]
    }
   ],
   "source": [
    "# Task 1.1: Set Working Directory\n",
    "# TODO: Set your working directory to where your data files are located\n",
    "# IMPORTANT: Students must set their own path!\n",
    "# Example: setwd(\"/Users/yourname/GitHub/ai-homework-grader-clean/data\")\n",
    "\n",
    "# Your code here:\n",
    "setwd(\"/workspaces/Data-Management-Assignment-1-Intro-to-R/data\")    #used setwd to set working directory\n",
    "\n",
    "# Verify working directory\n",
    "cat(\"Current working directory:\", getwd(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "load_packages",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Packages loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Task 1.2: Load Required Packages\n",
    "# TODO: Load tidyverse (includes dplyr, tidyr, stringr, ggplot2)\n",
    "library(tidyverse)    # Load the tidyverse package collection, which includes several essential tools for data analysis:\n",
    "\n",
    "# TODO: Load lubridate for date operations\n",
    "library(lubridate)   # Load the lubridate package to work with dates and times (e.g., parsing, extracting months/weekdays)\n",
    "\n",
    "cat(\"âœ… Packages loaded successfully!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "import_data",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mRows: \u001b[22m\u001b[34m300\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m8\u001b[39m\n",
      "\u001b[36mâ”€â”€\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m  (3): Sales_Rep_Name, Region, Product_Category\n",
      "\u001b[32mdbl\u001b[39m  (4): TransactionID, Revenue, Cost, Units_Sold\n",
      "\u001b[34mdate\u001b[39m (1): Sale_Date\n",
      "\n",
      "\u001b[36mâ„¹\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mâ„¹\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
      "\u001b[1mRows: \u001b[22m\u001b[34m100\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m5\u001b[39m\n",
      "\u001b[36mâ”€â”€\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m  (3): Name, Email, City\n",
      "\u001b[32mdbl\u001b[39m  (1): CustomerID\n",
      "\u001b[34mdate\u001b[39m (1): Registration_Date\n",
      "\n",
      "\u001b[36mâ„¹\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mâ„¹\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
      "\u001b[1mRows: \u001b[22m\u001b[34m50\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m4\u001b[39m\n",
      "\u001b[36mâ”€â”€\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m (2): Product_Name, Category\n",
      "\u001b[32mdbl\u001b[39m (2): ProductID, Supplier_ID\n",
      "\n",
      "\u001b[36mâ„¹\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mâ„¹\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
      "\u001b[1mRows: \u001b[22m\u001b[34m250\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m4\u001b[39m\n",
      "\u001b[36mâ”€â”€\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[32mdbl\u001b[39m  (3): OrderID, CustomerID, Total_Amount\n",
      "\u001b[34mdate\u001b[39m (1): Order_Date\n",
      "\n",
      "\u001b[36mâ„¹\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mâ„¹\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
      "\u001b[1mRows: \u001b[22m\u001b[34m400\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m4\u001b[39m\n",
      "\u001b[36mâ”€â”€\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[32mdbl\u001b[39m (4): OrderID, ProductID, Quantity, Unit_Price\n",
      "\n",
      "\u001b[36mâ„¹\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mâ„¹\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data imported successfully!\n",
      "Sales data: 300 rows\n",
      "Customers: 100 rows\n",
      "Products: 50 rows\n",
      "Orders: 250 rows\n",
      "Order items: 400 rows\n"
     ]
    }
   ],
   "source": [
    "# Task 1.3: Import Datasets\n",
    "# TODO: Import the following CSV files using read_csv():\n",
    "#   - company_sales_data.csv -> sales_data\n",
    "#   - customers.csv -> customers\n",
    "#   - products.csv -> products\n",
    "#   - orders.csv -> orders\n",
    "#   - order_items.csv -> order_items\n",
    "\n",
    "# Your code here:\n",
    "\n",
    "# Import all company data files into R using read_csv()\n",
    "# Each dataset is stored in a separate variable for analysis\n",
    "\n",
    "library(readr)\n",
    "\n",
    "sales_data  <- read_csv(\"company_sales_data.csv\")  # Read main sales data file \n",
    "customers   <- read_csv(\"customers.csv\")   # Read customer information file\n",
    "products    <- read_csv(\"products.csv\")   # Read product details file\n",
    "orders      <- read_csv(\"orders.csv\")   # Read orders information file\n",
    "order_items <- read_csv(\"order_items.csv\")   # Read individual order items file (links products to orders)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Display import summary\n",
    "cat(\"âœ… Data imported successfully!\\n\")\n",
    "cat(\"Sales data:\", nrow(sales_data), \"rows\\n\")\n",
    "cat(\"Customers:\", nrow(customers), \"rows\\n\")\n",
    "cat(\"Products:\", nrow(products), \"rows\\n\")\n",
    "cat(\"Orders:\", nrow(orders), \"rows\\n\")\n",
    "cat(\"Order items:\", nrow(order_items), \"rows\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part2_intro",
   "metadata": {},
   "source": [
    "## Part 2: Data Cleaning - Missing Values & Outliers (Lesson 2)\n",
    "\n",
    "**Skills Assessed:** Identifying NAs, handling missing data, detecting outliers\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Check for missing values in sales_data\n",
    "2. Handle missing values appropriately\n",
    "3. Identify outliers in Revenue column\n",
    "4. Create a cleaned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "check_missing",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== MISSING VALUES SUMMARY ==========\n",
      "   TransactionID   Sales_Rep_Name           Region Product_Category \n",
      "               0                0                0                0 \n",
      "         Revenue             Cost       Units_Sold        Sale_Date \n",
      "               0                0                0                0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total missing values: 0 \n"
     ]
    }
   ],
   "source": [
    "# Task 2.1: Check for Missing Values\n",
    "# TODO: Create 'missing_summary' that shows count of NAs in each column of sales_data\n",
    "\n",
    "# Count the number of missing (NA) values in each column of the sales_data dataset.\n",
    "# This helps identify incomplete data that may need cleaning before analysis.\n",
    "missing_summary <- colSums(is.na(sales_data))\n",
    "\n",
    "\n",
    "cat(\"========== MISSING VALUES SUMMARY ==========\\n\")\n",
    "print(missing_summary)\n",
    "cat(\"\\nTotal missing values:\", sum(missing_summary), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "handle_missing",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== DATA CLEANING RESULTS ==========\n",
      "Original rows: 300 \n",
      "Cleaned rows: 300 \n",
      "Rows removed: 0 \n"
     ]
    }
   ],
   "source": [
    "# Task 2.2: Handle Missing Values\n",
    "# TODO: Create 'sales_clean' by removing rows with ANY missing values\n",
    "\n",
    "# Remove any rows in the sales_data dataset that contain missing (NA) values.\n",
    "# Creates a new cleaned dataset (sales_clean) with only complete records for accurate analysis.\n",
    "sales_clean <- na.omit(sales_data)\n",
    "\n",
    "\n",
    "cat(\"========== DATA CLEANING RESULTS ==========\\n\")\n",
    "cat(\"Original rows:\", nrow(sales_data), \"\\n\")\n",
    "cat(\"Cleaned rows:\", nrow(sales_clean), \"\\n\")\n",
    "cat(\"Rows removed:\", nrow(sales_data) - nrow(sales_clean), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "detect_outliers",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== OUTLIER ANALYSIS ==========\n",
      "       Metric     Value\n",
      "1          Q1  15034.29\n",
      "2          Q3  37707.71\n",
      "3         IQR  22673.42\n",
      "4 Lower Bound -18975.84\n",
      "5 Upper Bound  71717.84\n",
      "\n",
      "Number of outliers detected: 0 \n"
     ]
    }
   ],
   "source": [
    "# Task 2.3: Detect Outliers in Revenue\n",
    "# TODO: Calculate outlier thresholds using IQR method\n",
    "#   - Calculate Q1 (25th percentile) and Q3 (75th percentile) of Revenue\n",
    "#   - Calculate IQR = Q3 - Q1\n",
    "#   - Lower bound = Q1 - 1.5 * IQR\n",
    "#   - Upper bound = Q3 + 1.5 * IQR\n",
    "# TODO: Create 'outlier_analysis' dataframe with these values\n",
    "\n",
    "# Calculate the first quartile (Q1) â€” the 25th percentile of Revenue values\n",
    "Q1 <- quantile(sales_clean$Revenue, 0.25, na.rm = TRUE)\n",
    "\n",
    "# Calculate the third quartile (Q3) â€” the 75th percentile of Revenue values\n",
    "Q3 <- quantile(sales_clean$Revenue, 0.75, na.rm = TRUE)\n",
    "\n",
    "# Compute the Interquartile Range (IQR) â€” the middle 50% of the data (Q3 - Q1)\n",
    "IQR_value <- Q3 - Q1\n",
    "\n",
    "# Determine the lower bound for outliers using the IQR rule\n",
    "# Any value below this threshold is considered a potential low outlier\n",
    "lower_bound <- Q1 - 1.5 * IQR_value\n",
    "\n",
    "# Determine the upper bound for outliers using the IQR rule\n",
    "# Any value above this threshold is considered a potential high outlier\n",
    "upper_bound <- Q3 + 1.5 * IQR_value\n",
    "\n",
    "\n",
    "outlier_analysis <- data.frame(\n",
    "  Metric = c(\"Q1\", \"Q3\", \"IQR\", \"Lower Bound\", \"Upper Bound\"),\n",
    "  Value = c(Q1, Q3, IQR_value, lower_bound, upper_bound)\n",
    ")\n",
    "\n",
    "cat(\"========== OUTLIER ANALYSIS ==========\\n\")\n",
    "print(outlier_analysis)\n",
    "\n",
    "# Count outliers\n",
    "outlier_count <- sum(sales_clean$Revenue < lower_bound | sales_clean$Revenue > upper_bound)\n",
    "cat(\"\\nNumber of outliers detected:\", outlier_count, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part3_intro",
   "metadata": {},
   "source": [
    "## Part 3: Data Transformation Part 1 (Lesson 3)\n",
    "\n",
    "**Skills Assessed:** select(), filter(), arrange(), pipe operator\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Select specific columns\n",
    "2. Filter data by conditions\n",
    "3. Sort data\n",
    "4. Chain operations with pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "select_columns",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== SELECTED COLUMNS ==========\n",
      "Columns: Region Product_Category Revenue Units_Sold Sale_Date \n",
      "Rows: 300 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 5 Ã— 5</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>Region</th><th scope=col>Product_Category</th><th scope=col>Revenue</th><th scope=col>Units_Sold</th><th scope=col>Sale_Date</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;date&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>Latin America</td><td>Services</td><td>20750.92</td><td>78</td><td>2023-04-24</td></tr>\n",
       "\t<tr><td>Europe       </td><td>Hardware</td><td>32359.98</td><td>13</td><td>2023-06-09</td></tr>\n",
       "\t<tr><td>Europe       </td><td>Services</td><td>39268.40</td><td>34</td><td>2023-03-25</td></tr>\n",
       "\t<tr><td>Europe       </td><td>Hardware</td><td>28865.09</td><td>90</td><td>2023-04-11</td></tr>\n",
       "\t<tr><td>Latin America</td><td>Software</td><td> 3932.36</td><td>63</td><td>2023-08-26</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 5 Ã— 5\n",
       "\\begin{tabular}{lllll}\n",
       " Region & Product\\_Category & Revenue & Units\\_Sold & Sale\\_Date\\\\\n",
       " <chr> & <chr> & <dbl> & <dbl> & <date>\\\\\n",
       "\\hline\n",
       "\t Latin America & Services & 20750.92 & 78 & 2023-04-24\\\\\n",
       "\t Europe        & Hardware & 32359.98 & 13 & 2023-06-09\\\\\n",
       "\t Europe        & Services & 39268.40 & 34 & 2023-03-25\\\\\n",
       "\t Europe        & Hardware & 28865.09 & 90 & 2023-04-11\\\\\n",
       "\t Latin America & Software &  3932.36 & 63 & 2023-08-26\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 5 Ã— 5\n",
       "\n",
       "| Region &lt;chr&gt; | Product_Category &lt;chr&gt; | Revenue &lt;dbl&gt; | Units_Sold &lt;dbl&gt; | Sale_Date &lt;date&gt; |\n",
       "|---|---|---|---|---|\n",
       "| Latin America | Services | 20750.92 | 78 | 2023-04-24 |\n",
       "| Europe        | Hardware | 32359.98 | 13 | 2023-06-09 |\n",
       "| Europe        | Services | 39268.40 | 34 | 2023-03-25 |\n",
       "| Europe        | Hardware | 28865.09 | 90 | 2023-04-11 |\n",
       "| Latin America | Software |  3932.36 | 63 | 2023-08-26 |\n",
       "\n"
      ],
      "text/plain": [
       "  Region        Product_Category Revenue  Units_Sold Sale_Date \n",
       "1 Latin America Services         20750.92 78         2023-04-24\n",
       "2 Europe        Hardware         32359.98 13         2023-06-09\n",
       "3 Europe        Services         39268.40 34         2023-03-25\n",
       "4 Europe        Hardware         28865.09 90         2023-04-11\n",
       "5 Latin America Software          3932.36 63         2023-08-26"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Task 3.1: Select Specific Columns\n",
    "# TODO: Create 'sales_summary' with only these columns from sales_clean:\n",
    "#   Region, Product_Category, Revenue, Units_Sold, Sale_Date\n",
    "\n",
    "\n",
    "sales_summary <- sales_clean %>%\n",
    "  # Your code here:\n",
    "  # Select only the relevant columns needed for summary analysis:\n",
    "  # Region, Product_Category, Revenue, Units_Sold, and Sale_Date\n",
    "  select(Region, Product_Category, Revenue, Units_Sold, Sale_Date)\n",
    "\n",
    "cat(\"========== SELECTED COLUMNS ==========\\n\")\n",
    "cat(\"Columns:\", names(sales_summary), \"\\n\")\n",
    "cat(\"Rows:\", nrow(sales_summary), \"\\n\")\n",
    "head(sales_summary, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "filter_data",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== HIGH REVENUE SALES ==========\n",
      "Total high revenue transactions: 194 \n",
      "Total revenue from these sales: $ 6671906 \n"
     ]
    }
   ],
   "source": [
    "# Task 3.2: Filter High Revenue Sales\n",
    "# TODO: Create 'high_revenue_sales' by filtering sales_clean for Revenue > 20000\n",
    "\n",
    "\n",
    "high_revenue_sales <- sales_clean %>%\n",
    "  # Your code here:\n",
    "  # Filter the dataset to include only transactions where Revenue is greater than 20,000\n",
    "  # This isolates high-revenue sales for focused analysis\n",
    "  filter(Revenue > 20000)\n",
    "\n",
    "cat(\"========== HIGH REVENUE SALES ==========\\n\")\n",
    "cat(\"Total high revenue transactions:\", nrow(high_revenue_sales), \"\\n\")\n",
    "cat(\"Total revenue from these sales: $\", sum(high_revenue_sales$Revenue), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "sort_data",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== TOP 10 SALES ==========\n",
      "\u001b[90m# A tibble: 10 Ã— 4\u001b[39m\n",
      "   Region        Product_Category Revenue Units_Sold\n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m         \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m              \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m      \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m Asia Pacific  Consulting        \u001b[4m4\u001b[24m\u001b[4m9\u001b[24m956.         88\n",
      "\u001b[90m 2\u001b[39m Europe        Software          \u001b[4m4\u001b[24m\u001b[4m9\u001b[24m867.         96\n",
      "\u001b[90m 3\u001b[39m Europe        Consulting        \u001b[4m4\u001b[24m\u001b[4m9\u001b[24m857.          1\n",
      "\u001b[90m 4\u001b[39m Asia Pacific  Consulting        \u001b[4m4\u001b[24m\u001b[4m9\u001b[24m239.         72\n",
      "\u001b[90m 5\u001b[39m Asia Pacific  Hardware          \u001b[4m4\u001b[24m\u001b[4m8\u001b[24m997.         92\n",
      "\u001b[90m 6\u001b[39m North America Services          \u001b[4m4\u001b[24m\u001b[4m8\u001b[24m884.         62\n",
      "\u001b[90m 7\u001b[39m Europe        Software          \u001b[4m4\u001b[24m\u001b[4m8\u001b[24m794.         77\n",
      "\u001b[90m 8\u001b[39m North America Hardware          \u001b[4m4\u001b[24m\u001b[4m8\u001b[24m772.         16\n",
      "\u001b[90m 9\u001b[39m North America Consulting        \u001b[4m4\u001b[24m\u001b[4m8\u001b[24m748.         63\n",
      "\u001b[90m10\u001b[39m Europe        Consulting        \u001b[4m4\u001b[24m\u001b[4m8\u001b[24m572.         22\n"
     ]
    }
   ],
   "source": [
    "# Task 3.3: Sort by Revenue\n",
    "# TODO: Create 'top_sales' by arranging sales_clean by Revenue in descending order\n",
    "#       and keeping only the top 10 rows\n",
    "\n",
    "\n",
    "top_sales <- sales_clean %>%\n",
    "  # Your code here:\n",
    "  # Sort the cleaned sales data in descending order based on Revenue\n",
    "  # Then keep only the top 10 highest revenue transactions for quick comparison\n",
    "  arrange(desc(Revenue)) %>%\n",
    "  slice_head(n = 10)\n",
    "\n",
    "cat(\"========== TOP 10 SALES ==========\\n\")\n",
    "print(top_sales %>% select(Region, Product_Category, Revenue, Units_Sold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "chain_operations",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== REGIONAL TOP SALES ==========\n",
      "\u001b[90m# A tibble: 15 Ã— 3\u001b[39m\n",
      "   Region       Product_Category Revenue\n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m        \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m              \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m Asia Pacific Consulting        \u001b[4m4\u001b[24m\u001b[4m9\u001b[24m956.\n",
      "\u001b[90m 2\u001b[39m Asia Pacific Consulting        \u001b[4m4\u001b[24m\u001b[4m9\u001b[24m239.\n",
      "\u001b[90m 3\u001b[39m Asia Pacific Hardware          \u001b[4m4\u001b[24m\u001b[4m8\u001b[24m997.\n",
      "\u001b[90m 4\u001b[39m Asia Pacific Consulting        \u001b[4m4\u001b[24m\u001b[4m8\u001b[24m063.\n",
      "\u001b[90m 5\u001b[39m Asia Pacific Services          \u001b[4m4\u001b[24m\u001b[4m6\u001b[24m731.\n",
      "\u001b[90m 6\u001b[39m Asia Pacific Software          \u001b[4m4\u001b[24m\u001b[4m6\u001b[24m615.\n",
      "\u001b[90m 7\u001b[39m Asia Pacific Consulting        \u001b[4m4\u001b[24m\u001b[4m6\u001b[24m545.\n",
      "\u001b[90m 8\u001b[39m Asia Pacific Consulting        \u001b[4m4\u001b[24m\u001b[4m5\u001b[24m756.\n",
      "\u001b[90m 9\u001b[39m Asia Pacific Services          \u001b[4m4\u001b[24m\u001b[4m5\u001b[24m298.\n",
      "\u001b[90m10\u001b[39m Asia Pacific Services          \u001b[4m4\u001b[24m\u001b[4m4\u001b[24m624.\n",
      "\u001b[90m11\u001b[39m Asia Pacific Consulting        \u001b[4m4\u001b[24m\u001b[4m4\u001b[24m455.\n",
      "\u001b[90m12\u001b[39m Asia Pacific Consulting        \u001b[4m4\u001b[24m\u001b[4m4\u001b[24m364.\n",
      "\u001b[90m13\u001b[39m Asia Pacific Software          \u001b[4m4\u001b[24m\u001b[4m3\u001b[24m221.\n",
      "\u001b[90m14\u001b[39m Asia Pacific Software          \u001b[4m4\u001b[24m\u001b[4m2\u001b[24m063.\n",
      "\u001b[90m15\u001b[39m Asia Pacific Software          \u001b[4m4\u001b[24m\u001b[4m1\u001b[24m412.\n"
     ]
    }
   ],
   "source": [
    "# Task 3.4: Chain Multiple Operations\n",
    "# TODO: Create 'regional_top_sales' by:\n",
    "#   1. Filtering for Revenue > 15000\n",
    "#   2. Selecting: Region, Product_Category, Revenue\n",
    "#   3. Arranging by Region (ascending) then Revenue (descending)\n",
    "#   4. Keeping top 15 rows\n",
    "# Use the pipe operator to chain all operations\n",
    "\n",
    "regional_top_sales <- sales_clean %>%\n",
    "  # Your code here:\n",
    "  # Filter the dataset to include only sales with Revenue greater than 15,000\n",
    "  # Select key columns for analysis: Region, Product_Category, and Revenue\n",
    "  # Arrange the results first alphabetically by Region, then by Revenue in descending order\n",
    "  # Finally, keep only the top 15 records to highlight high-performing regional sales\n",
    "  filter(Revenue > 15000) %>%\n",
    "  select(Region, Product_Category, Revenue) %>%\n",
    "  arrange(Region, desc(Revenue)) %>%\n",
    "  slice_head(n = 15)\n",
    "\n",
    "cat(\"========== REGIONAL TOP SALES ==========\\n\")\n",
    "print(regional_top_sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part4_intro",
   "metadata": {},
   "source": [
    "## Part 4: Data Transformation Part 2 (Lesson 4)\n",
    "\n",
    "**Skills Assessed:** mutate(), summarize(), group_by()\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Create calculated columns with mutate()\n",
    "2. Calculate summary statistics\n",
    "3. Perform grouped analysis\n",
    "4. Generate business metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "mutate_columns",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== ENHANCED SALES DATA ==========\n",
      "New columns added: revenue_per_unit, high_value\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 5 Ã— 4</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>Revenue</th><th scope=col>Units_Sold</th><th scope=col>revenue_per_unit</th><th scope=col>high_value</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>20750.92</td><td>78</td><td> 266.03744</td><td>Yes</td></tr>\n",
       "\t<tr><td>32359.98</td><td>13</td><td>2489.22923</td><td>Yes</td></tr>\n",
       "\t<tr><td>39268.40</td><td>34</td><td>1154.95294</td><td>Yes</td></tr>\n",
       "\t<tr><td>28865.09</td><td>90</td><td> 320.72322</td><td>Yes</td></tr>\n",
       "\t<tr><td> 3932.36</td><td>63</td><td>  62.41841</td><td>No </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 5 Ã— 4\n",
       "\\begin{tabular}{llll}\n",
       " Revenue & Units\\_Sold & revenue\\_per\\_unit & high\\_value\\\\\n",
       " <dbl> & <dbl> & <dbl> & <chr>\\\\\n",
       "\\hline\n",
       "\t 20750.92 & 78 &  266.03744 & Yes\\\\\n",
       "\t 32359.98 & 13 & 2489.22923 & Yes\\\\\n",
       "\t 39268.40 & 34 & 1154.95294 & Yes\\\\\n",
       "\t 28865.09 & 90 &  320.72322 & Yes\\\\\n",
       "\t  3932.36 & 63 &   62.41841 & No \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 5 Ã— 4\n",
       "\n",
       "| Revenue &lt;dbl&gt; | Units_Sold &lt;dbl&gt; | revenue_per_unit &lt;dbl&gt; | high_value &lt;chr&gt; |\n",
       "|---|---|---|---|\n",
       "| 20750.92 | 78 |  266.03744 | Yes |\n",
       "| 32359.98 | 13 | 2489.22923 | Yes |\n",
       "| 39268.40 | 34 | 1154.95294 | Yes |\n",
       "| 28865.09 | 90 |  320.72322 | Yes |\n",
       "|  3932.36 | 63 |   62.41841 | No  |\n",
       "\n"
      ],
      "text/plain": [
       "  Revenue  Units_Sold revenue_per_unit high_value\n",
       "1 20750.92 78          266.03744       Yes       \n",
       "2 32359.98 13         2489.22923       Yes       \n",
       "3 39268.40 34         1154.95294       Yes       \n",
       "4 28865.09 90          320.72322       Yes       \n",
       "5  3932.36 63           62.41841       No        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Task 4.1: Create Calculated Columns\n",
    "# TODO: Add these new columns to sales_clean using mutate():\n",
    "#   - revenue_per_unit: Revenue / Units_Sold\n",
    "#   - high_value: \"Yes\" if Revenue > 20000, else \"No\"\n",
    "# Store result in 'sales_enhanced'\n",
    "\n",
    "sales_enhanced <- sales_clean %>%\n",
    "  mutate(\n",
    "    # Your code here:\n",
    "    # Calculate average revenue per unit sold for each transaction\n",
    "    revenue_per_unit = Revenue / Units_Sold,\n",
    "    # Create a new column to flag high-value transactions\n",
    "    # Label as \"Yes\" if Revenue exceeds 20,000, otherwise \"No\"\n",
    "    high_value = ifelse(Revenue > 20000, \"Yes\", \"No\")\n",
    "  )\n",
    "\n",
    "cat(\"========== ENHANCED SALES DATA ==========\\n\")\n",
    "cat(\"New columns added: revenue_per_unit, high_value\\n\")\n",
    "head(sales_enhanced %>% select(Revenue, Units_Sold, revenue_per_unit, high_value), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "summarize_data",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== OVERALL SUMMARY ==========\n",
      "\u001b[90m# A tibble: 1 Ã— 4\u001b[39m\n",
      "  total_revenue avg_revenue total_units transaction_count\n",
      "          \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m       \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m       \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m             \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m      7\u001b[4m7\u001b[24m\u001b[4m7\u001b[24m\u001b[4m1\u001b[24m711.      \u001b[4m2\u001b[24m\u001b[4m5\u001b[24m906.       \u001b[4m1\u001b[24m\u001b[4m6\u001b[24m169               300\n"
     ]
    }
   ],
   "source": [
    "# Task 4.2: Calculate Overall Summary Statistics\n",
    "# TODO: Create 'overall_summary' with these metrics from sales_enhanced:\n",
    "#   - total_revenue: sum of Revenue\n",
    "#   - avg_revenue: mean of Revenue\n",
    "#   - total_units: sum of Units_Sold\n",
    "#   - transaction_count: count using n()\n",
    "\n",
    "\n",
    "overall_summary <- sales_enhanced %>%\n",
    "  \n",
    "    # Your code here:\n",
    "   # Summarize key metrics from the enhanced sales dataset\n",
    "   # Calculate total revenue, average revenue, total units sold, and total transaction count\n",
    "\n",
    "summarise(\n",
    "  # Sum of all Revenue values (ignoring missing values)\n",
    "  total_revenue = sum(Revenue, na.rm = TRUE),\n",
    "  \n",
    "  # Average revenue per transaction (ignoring missing values)\n",
    "  avg_revenue = mean(Revenue, na.rm = TRUE),\n",
    "  \n",
    "  # Total number of units sold across all transactions\n",
    "  total_units = sum(Units_Sold, na.rm = TRUE),\n",
    "  \n",
    "  # Count total number of transactions (rows) in the dataset\n",
    "  transaction_count = n()\n",
    ")\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "cat(\"========== OVERALL SUMMARY ==========\\n\")\n",
    "print(overall_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "group_by_region",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== REGIONAL SUMMARY ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90m# A tibble: 4 Ã— 4\u001b[39m\n",
      "  Region        total_revenue avg_revenue transaction_count\n",
      "  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                 \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m       \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m             \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m Europe             2\u001b[4m2\u001b[24m\u001b[4m2\u001b[24m\u001b[4m4\u001b[24m182.      \u001b[4m2\u001b[24m\u001b[4m7\u001b[24m124.                82\n",
      "\u001b[90m2\u001b[39m Latin America      2\u001b[4m1\u001b[24m\u001b[4m1\u001b[24m\u001b[4m2\u001b[24m037.      \u001b[4m2\u001b[24m\u001b[4m5\u001b[24m446.                83\n",
      "\u001b[90m3\u001b[39m Asia Pacific       1\u001b[4m8\u001b[24m\u001b[4m0\u001b[24m\u001b[4m4\u001b[24m243.      \u001b[4m2\u001b[24m\u001b[4m6\u001b[24m929.                67\n",
      "\u001b[90m4\u001b[39m North America      1\u001b[4m6\u001b[24m\u001b[4m3\u001b[24m\u001b[4m1\u001b[24m248.      \u001b[4m2\u001b[24m\u001b[4m3\u001b[24m989.                68\n"
     ]
    }
   ],
   "source": [
    "# Task 4.3: Regional Performance Analysis\n",
    "# TODO: Create 'regional_summary' by grouping sales_enhanced by Region\n",
    "#       and calculating:\n",
    "#   - total_revenue: sum of Revenue\n",
    "#   - avg_revenue: mean of Revenue\n",
    "#   - transaction_count: count using n()\n",
    "# Then arrange by total_revenue descending\n",
    "# Hint: Use group_by() %>% summarize() %>% arrange()\n",
    "\n",
    "regional_summary <- sales_enhanced %>%\n",
    "  # Your code here:\n",
    " # Group the dataset by Region to analyze performance across different areas\n",
    "# For each region, calculate total revenue, average revenue, and total number of transactions\n",
    "# Then sort the results in descending order of total revenue to highlight the top-performing regions\n",
    "\n",
    "group_by(Region) %>%\n",
    "  summarise(\n",
    "    # Calculate total revenue for each region (ignore missing values)\n",
    "    total_revenue = sum(Revenue, na.rm = TRUE),\n",
    "    \n",
    "    # Compute the average revenue per transaction in each region\n",
    "    avg_revenue = mean(Revenue, na.rm = TRUE),\n",
    "    \n",
    "    # Count how many transactions occurred in each region\n",
    "    transaction_count = n()\n",
    "  ) %>%\n",
    "  # Arrange the summary so that the highest-revenue regions appear first\n",
    "  arrange(desc(total_revenue))\n",
    "\n",
    "\n",
    "\n",
    "cat(\"========== REGIONAL SUMMARY ==========\\n\")\n",
    "print(regional_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "group_by_category",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== CATEGORY SUMMARY ==========\n",
      "\u001b[90m# A tibble: 4 Ã— 4\u001b[39m\n",
      "  Product_Category total_revenue avg_revenue transaction_count\n",
      "  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                    \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m       \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m             \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m Consulting            1\u001b[4m9\u001b[24m\u001b[4m7\u001b[24m\u001b[4m8\u001b[24m840.      \u001b[4m2\u001b[24m\u001b[4m6\u001b[24m037.                76\n",
      "\u001b[90m2\u001b[39m Services              1\u001b[4m9\u001b[24m\u001b[4m6\u001b[24m\u001b[4m1\u001b[24m565.      \u001b[4m2\u001b[24m\u001b[4m7\u001b[24m244.                72\n",
      "\u001b[90m3\u001b[39m Hardware              1\u001b[4m9\u001b[24m\u001b[4m5\u001b[24m\u001b[4m1\u001b[24m325.      \u001b[4m2\u001b[24m\u001b[4m6\u001b[24m730.                73\n",
      "\u001b[90m4\u001b[39m Software              1\u001b[4m8\u001b[24m\u001b[4m7\u001b[24m\u001b[4m9\u001b[24m981.      \u001b[4m2\u001b[24m\u001b[4m3\u001b[24m797.                79\n"
     ]
    }
   ],
   "source": [
    "# Task 4.4: Product Category Analysis\n",
    "# TODO: Create 'category_summary' by grouping by Product_Category\n",
    "#       and calculating the same metrics as regional_summary\n",
    "#       Then arrange by total_revenue descending\n",
    "\n",
    "category_summary <- sales_enhanced %>%\n",
    "  # Your code here:\n",
    "# Group the dataset by Product_Category to compare performance across different product types\n",
    "# For each category, calculate total revenue, average revenue, and the number of transactions\n",
    "# Finally, sort the categories from highest to lowest total revenue to identify top-selling products\n",
    "\n",
    "group_by(Product_Category) %>%\n",
    "  summarise(\n",
    "    # Total revenue generated by each product category (ignoring missing values)\n",
    "    total_revenue = sum(Revenue, na.rm = TRUE),\n",
    "    \n",
    "    # Average revenue per transaction within each product category\n",
    "    avg_revenue = mean(Revenue, na.rm = TRUE),\n",
    "    \n",
    "    # Count of total transactions for each product category\n",
    "    transaction_count = n()\n",
    "  ) %>%\n",
    "  # Arrange results so that categories with the highest total revenue appear first\n",
    "  arrange(desc(total_revenue))\n",
    "\n",
    "\n",
    "cat(\"========== CATEGORY SUMMARY ==========\\n\")\n",
    "print(category_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part5_intro",
   "metadata": {},
   "source": [
    "## Part 5: Data Reshaping with tidyr (Lesson 5)\n",
    "\n",
    "**Skills Assessed:** pivot_longer(), pivot_wider(), tidy data principles\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Reshape data from wide to long format\n",
    "2. Reshape data from long to wide format\n",
    "3. Create analysis-ready datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "create_wide_data",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== REGION-CATEGORY DATA (LONG FORMAT) ==========\n",
      "\u001b[90m# A tibble: 10 Ã— 3\u001b[39m\n",
      "   Region        Product_Category total_revenue\n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m         \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                    \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m Asia Pacific  Consulting             \u001b[4m7\u001b[24m\u001b[4m5\u001b[24m\u001b[4m9\u001b[24m641.\n",
      "\u001b[90m 2\u001b[39m Asia Pacific  Hardware               \u001b[4m2\u001b[24m\u001b[4m7\u001b[24m\u001b[4m1\u001b[24m979.\n",
      "\u001b[90m 3\u001b[39m Asia Pacific  Services               \u001b[4m3\u001b[24m\u001b[4m3\u001b[24m\u001b[4m1\u001b[24m826.\n",
      "\u001b[90m 4\u001b[39m Asia Pacific  Software               \u001b[4m4\u001b[24m\u001b[4m4\u001b[24m\u001b[4m0\u001b[24m797.\n",
      "\u001b[90m 5\u001b[39m Europe        Consulting             \u001b[4m3\u001b[24m\u001b[4m9\u001b[24m\u001b[4m0\u001b[24m670.\n",
      "\u001b[90m 6\u001b[39m Europe        Hardware               \u001b[4m7\u001b[24m\u001b[4m7\u001b[24m\u001b[4m7\u001b[24m044.\n",
      "\u001b[90m 7\u001b[39m Europe        Services               \u001b[4m5\u001b[24m\u001b[4m1\u001b[24m\u001b[4m3\u001b[24m507.\n",
      "\u001b[90m 8\u001b[39m Europe        Software               \u001b[4m5\u001b[24m\u001b[4m4\u001b[24m\u001b[4m2\u001b[24m961.\n",
      "\u001b[90m 9\u001b[39m Latin America Consulting             \u001b[4m4\u001b[24m\u001b[4m3\u001b[24m\u001b[4m3\u001b[24m397.\n",
      "\u001b[90m10\u001b[39m Latin America Hardware               \u001b[4m4\u001b[24m\u001b[4m7\u001b[24m\u001b[4m4\u001b[24m257.\n"
     ]
    }
   ],
   "source": [
    "# Task 5.1: Create Wide Format Data\n",
    "# First, create a summary by Region and Product_Category\n",
    "region_category_revenue <- sales_enhanced %>%\n",
    "  group_by(Region, Product_Category) %>%\n",
    "  summarize(total_revenue = sum(Revenue), .groups = 'drop')\n",
    "\n",
    "cat(\"========== REGION-CATEGORY DATA (LONG FORMAT) ==========\\n\")\n",
    "print(head(region_category_revenue, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "pivot_wider",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== REVENUE DATA (WIDE FORMAT) ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90m# A tibble: 4 Ã— 5\u001b[39m\n",
      "  Region        Consulting Hardware Services Software\n",
      "  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m              \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m    \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m    \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m    \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m Asia Pacific     \u001b[4m7\u001b[24m\u001b[4m5\u001b[24m\u001b[4m9\u001b[24m641.  \u001b[4m2\u001b[24m\u001b[4m7\u001b[24m\u001b[4m1\u001b[24m979.  \u001b[4m3\u001b[24m\u001b[4m3\u001b[24m\u001b[4m1\u001b[24m826.  \u001b[4m4\u001b[24m\u001b[4m4\u001b[24m\u001b[4m0\u001b[24m797.\n",
      "\u001b[90m2\u001b[39m Europe           \u001b[4m3\u001b[24m\u001b[4m9\u001b[24m\u001b[4m0\u001b[24m670.  \u001b[4m7\u001b[24m\u001b[4m7\u001b[24m\u001b[4m7\u001b[24m044.  \u001b[4m5\u001b[24m\u001b[4m1\u001b[24m\u001b[4m3\u001b[24m507.  \u001b[4m5\u001b[24m\u001b[4m4\u001b[24m\u001b[4m2\u001b[24m961.\n",
      "\u001b[90m3\u001b[39m Latin America    \u001b[4m4\u001b[24m\u001b[4m3\u001b[24m\u001b[4m3\u001b[24m397.  \u001b[4m4\u001b[24m\u001b[4m7\u001b[24m\u001b[4m4\u001b[24m257.  \u001b[4m6\u001b[24m\u001b[4m4\u001b[24m\u001b[4m4\u001b[24m772.  \u001b[4m5\u001b[24m\u001b[4m5\u001b[24m\u001b[4m9\u001b[24m611.\n",
      "\u001b[90m4\u001b[39m North America    \u001b[4m3\u001b[24m\u001b[4m9\u001b[24m\u001b[4m5\u001b[24m132.  \u001b[4m4\u001b[24m\u001b[4m2\u001b[24m\u001b[4m8\u001b[24m046.  \u001b[4m4\u001b[24m\u001b[4m7\u001b[24m\u001b[4m1\u001b[24m460.  \u001b[4m3\u001b[24m\u001b[4m3\u001b[24m\u001b[4m6\u001b[24m611.\n"
     ]
    }
   ],
   "source": [
    "# Task 5.2: Reshape to Wide Format\n",
    "# TODO: Create 'revenue_wide' by pivoting region_category_revenue\n",
    "#       so that Product_Category values become column names\n",
    "#       with total_revenue as the values\n",
    "\n",
    "\n",
    "revenue_wide <- region_category_revenue %>%\n",
    "  # Your code here:\n",
    "# Reshape the summarized data from long format to wide format\n",
    "# Each unique Product_Category becomes a separate column\n",
    "# The total_revenue values are spread across these new category columns\n",
    "\n",
    "pivot_wider(\n",
    "  names_from = Product_Category,\n",
    "  values_from = total_revenue\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "cat(\"========== REVENUE DATA (WIDE FORMAT) ==========\\n\")\n",
    "print(revenue_wide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "pivot_longer",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== REVENUE DATA (BACK TO LONG FORMAT) ==========\n",
      "\u001b[90m# A tibble: 10 Ã— 3\u001b[39m\n",
      "   Region        Product_Category revenue\n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m         \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m              \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m Asia Pacific  Consulting       \u001b[4m7\u001b[24m\u001b[4m5\u001b[24m\u001b[4m9\u001b[24m641.\n",
      "\u001b[90m 2\u001b[39m Asia Pacific  Hardware         \u001b[4m2\u001b[24m\u001b[4m7\u001b[24m\u001b[4m1\u001b[24m979.\n",
      "\u001b[90m 3\u001b[39m Asia Pacific  Services         \u001b[4m3\u001b[24m\u001b[4m3\u001b[24m\u001b[4m1\u001b[24m826.\n",
      "\u001b[90m 4\u001b[39m Asia Pacific  Software         \u001b[4m4\u001b[24m\u001b[4m4\u001b[24m\u001b[4m0\u001b[24m797.\n",
      "\u001b[90m 5\u001b[39m Europe        Consulting       \u001b[4m3\u001b[24m\u001b[4m9\u001b[24m\u001b[4m0\u001b[24m670.\n",
      "\u001b[90m 6\u001b[39m Europe        Hardware         \u001b[4m7\u001b[24m\u001b[4m7\u001b[24m\u001b[4m7\u001b[24m044.\n",
      "\u001b[90m 7\u001b[39m Europe        Services         \u001b[4m5\u001b[24m\u001b[4m1\u001b[24m\u001b[4m3\u001b[24m507.\n",
      "\u001b[90m 8\u001b[39m Europe        Software         \u001b[4m5\u001b[24m\u001b[4m4\u001b[24m\u001b[4m2\u001b[24m961.\n",
      "\u001b[90m 9\u001b[39m Latin America Consulting       \u001b[4m4\u001b[24m\u001b[4m3\u001b[24m\u001b[4m3\u001b[24m397.\n",
      "\u001b[90m10\u001b[39m Latin America Hardware         \u001b[4m4\u001b[24m\u001b[4m7\u001b[24m\u001b[4m4\u001b[24m257.\n"
     ]
    }
   ],
   "source": [
    "# Task 5.3: Reshape Back to Long Format\n",
    "# TODO: Create 'revenue_long' by pivoting revenue_wide back to long format\n",
    "#       Column names (except Region) should go into 'Product_Category'\n",
    "#       Values should go into 'revenue'\n",
    "\n",
    "\n",
    "revenue_long <- revenue_wide %>%\n",
    "  # Your code here:\n",
    "# Reshape the dataset back from wide format to long format\n",
    "# Combine all product category columns into two new columns:\n",
    "# - 'Product_Category' stores the original column names\n",
    "# - 'revenue' stores their corresponding total revenue values\n",
    "# Exclude the 'Region' column from reshaping to keep it as an identifier\n",
    "\n",
    "pivot_longer(\n",
    "  cols = -Region,\n",
    "  names_to = \"Product_Category\",\n",
    "  values_to = \"revenue\"\n",
    ")\n",
    "\n",
    "\n",
    "cat(\"========== REVENUE DATA (BACK TO LONG FORMAT) ==========\\n\")\n",
    "print(head(revenue_long, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part6_intro",
   "metadata": {},
   "source": [
    "## Part 6: Combining Datasets with Joins (Lesson 6)\n",
    "\n",
    "**Skills Assessed:** left_join(), inner_join(), data integration\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Join customers with orders\n",
    "2. Join orders with order_items\n",
    "3. Create integrated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "join_customers_orders",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== CUSTOMER ORDERS ==========\n",
      "Total rows: 200 \n",
      "Columns: 8 \n"
     ]
    }
   ],
   "source": [
    "# Task 6.1: Join Customers and Orders\n",
    "# TODO: Create 'customer_orders' by left joining customers with orders\n",
    "#       Join on CustomerID\n",
    "\n",
    "\n",
    "customer_orders <- customers %>%\n",
    "left_join(orders, by = \"CustomerID\")\n",
    "\n",
    "\n",
    "cat(\"========== CUSTOMER ORDERS ==========\\n\")\n",
    "cat(\"Total rows:\", nrow(customer_orders), \"\\n\")\n",
    "cat(\"Columns:\", ncol(customer_orders), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "join_orders_items",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== ORDERS WITH ITEMS ==========\n",
      "Total rows: 400 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 5 Ã— 7</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>OrderID</th><th scope=col>CustomerID</th><th scope=col>Order_Date</th><th scope=col>Total_Amount</th><th scope=col>ProductID</th><th scope=col>Quantity</th><th scope=col>Unit_Price</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;date&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>1</td><td> 87</td><td>2023-08-30</td><td>424.30</td><td> 2</td><td>3</td><td>115.72</td></tr>\n",
       "\t<tr><td>1</td><td> 87</td><td>2023-08-30</td><td>424.30</td><td>22</td><td>5</td><td>206.62</td></tr>\n",
       "\t<tr><td>1</td><td> 87</td><td>2023-08-30</td><td>424.30</td><td>26</td><td>5</td><td> 61.75</td></tr>\n",
       "\t<tr><td>3</td><td> 37</td><td>2024-03-19</td><td>549.07</td><td>19</td><td>1</td><td>474.92</td></tr>\n",
       "\t<tr><td>6</td><td>101</td><td>2023-07-22</td><td>189.85</td><td>32</td><td>4</td><td>272.64</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 5 Ã— 7\n",
       "\\begin{tabular}{lllllll}\n",
       " OrderID & CustomerID & Order\\_Date & Total\\_Amount & ProductID & Quantity & Unit\\_Price\\\\\n",
       " <dbl> & <dbl> & <date> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 1 &  87 & 2023-08-30 & 424.30 &  2 & 3 & 115.72\\\\\n",
       "\t 1 &  87 & 2023-08-30 & 424.30 & 22 & 5 & 206.62\\\\\n",
       "\t 1 &  87 & 2023-08-30 & 424.30 & 26 & 5 &  61.75\\\\\n",
       "\t 3 &  37 & 2024-03-19 & 549.07 & 19 & 1 & 474.92\\\\\n",
       "\t 6 & 101 & 2023-07-22 & 189.85 & 32 & 4 & 272.64\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 5 Ã— 7\n",
       "\n",
       "| OrderID &lt;dbl&gt; | CustomerID &lt;dbl&gt; | Order_Date &lt;date&gt; | Total_Amount &lt;dbl&gt; | ProductID &lt;dbl&gt; | Quantity &lt;dbl&gt; | Unit_Price &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|\n",
       "| 1 |  87 | 2023-08-30 | 424.30 |  2 | 3 | 115.72 |\n",
       "| 1 |  87 | 2023-08-30 | 424.30 | 22 | 5 | 206.62 |\n",
       "| 1 |  87 | 2023-08-30 | 424.30 | 26 | 5 |  61.75 |\n",
       "| 3 |  37 | 2024-03-19 | 549.07 | 19 | 1 | 474.92 |\n",
       "| 6 | 101 | 2023-07-22 | 189.85 | 32 | 4 | 272.64 |\n",
       "\n"
      ],
      "text/plain": [
       "  OrderID CustomerID Order_Date Total_Amount ProductID Quantity Unit_Price\n",
       "1 1        87        2023-08-30 424.30        2        3        115.72    \n",
       "2 1        87        2023-08-30 424.30       22        5        206.62    \n",
       "3 1        87        2023-08-30 424.30       26        5         61.75    \n",
       "4 3        37        2024-03-19 549.07       19        1        474.92    \n",
       "5 6       101        2023-07-22 189.85       32        4        272.64    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Task 6.2: Join Orders and Order Items\n",
    "# TODO: Create 'orders_with_items' by inner joining orders with order_items\n",
    "#       Join on OrderID\n",
    "\n",
    "\n",
    "orders_with_items <- orders %>%\n",
    "inner_join(order_items, by = \"OrderID\")\n",
    "\n",
    "\n",
    "cat(\"========== ORDERS WITH ITEMS ==========\\n\")\n",
    "cat(\"Total rows:\", nrow(orders_with_items), \"\\n\")\n",
    "head(orders_with_items, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part7_intro",
   "metadata": {},
   "source": [
    "## Part 7: String Manipulation & Date/Time Operations (Lesson 7)\n",
    "\n",
    "**Skills Assessed:** stringr functions, lubridate functions\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Clean text data\n",
    "2. Parse dates\n",
    "3. Extract date components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "clean_text",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== CLEANED TEXT DATA ==========\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 5 Ã— 4</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>Region</th><th scope=col>region_clean</th><th scope=col>Product_Category</th><th scope=col>category_clean</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>Latin America</td><td>Latin America</td><td>Services</td><td>Services</td></tr>\n",
       "\t<tr><td>Europe       </td><td>Europe       </td><td>Hardware</td><td>Hardware</td></tr>\n",
       "\t<tr><td>Europe       </td><td>Europe       </td><td>Services</td><td>Services</td></tr>\n",
       "\t<tr><td>Europe       </td><td>Europe       </td><td>Hardware</td><td>Hardware</td></tr>\n",
       "\t<tr><td>Latin America</td><td>Latin America</td><td>Software</td><td>Software</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 5 Ã— 4\n",
       "\\begin{tabular}{llll}\n",
       " Region & region\\_clean & Product\\_Category & category\\_clean\\\\\n",
       " <chr> & <chr> & <chr> & <chr>\\\\\n",
       "\\hline\n",
       "\t Latin America & Latin America & Services & Services\\\\\n",
       "\t Europe        & Europe        & Hardware & Hardware\\\\\n",
       "\t Europe        & Europe        & Services & Services\\\\\n",
       "\t Europe        & Europe        & Hardware & Hardware\\\\\n",
       "\t Latin America & Latin America & Software & Software\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 5 Ã— 4\n",
       "\n",
       "| Region &lt;chr&gt; | region_clean &lt;chr&gt; | Product_Category &lt;chr&gt; | category_clean &lt;chr&gt; |\n",
       "|---|---|---|---|\n",
       "| Latin America | Latin America | Services | Services |\n",
       "| Europe        | Europe        | Hardware | Hardware |\n",
       "| Europe        | Europe        | Services | Services |\n",
       "| Europe        | Europe        | Hardware | Hardware |\n",
       "| Latin America | Latin America | Software | Software |\n",
       "\n"
      ],
      "text/plain": [
       "  Region        region_clean  Product_Category category_clean\n",
       "1 Latin America Latin America Services         Services      \n",
       "2 Europe        Europe        Hardware         Hardware      \n",
       "3 Europe        Europe        Services         Services      \n",
       "4 Europe        Europe        Hardware         Hardware      \n",
       "5 Latin America Latin America Software         Software      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Task 7.1: Clean Text Data\n",
    "# TODO: Add these columns to sales_enhanced using mutate():\n",
    "#   - region_clean: Region with trimmed whitespace and Title Case\n",
    "#   - category_clean: Product_Category with trimmed whitespace and Title Case\n",
    "\n",
    "\n",
    "sales_enhanced <- sales_enhanced %>%\n",
    "  mutate(\n",
    "    # Your code here:\n",
    "# Clean and standardize text data for Region and Product_Category columns\n",
    "# str_trim() removes extra spaces at the beginning or end of text\n",
    "# str_to_title() converts the text to Title Case (first letter uppercase for each word)\n",
    "\n",
    "region_clean = str_to_title(str_trim(Region)),\n",
    "category_clean = str_to_title(str_trim(Product_Category))\n",
    "\n",
    "  )\n",
    "\n",
    "cat(\"========== CLEANED TEXT DATA ==========\\n\")\n",
    "head(sales_enhanced %>% select(Region, region_clean, Product_Category, category_clean), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "parse_dates",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== DATE COMPONENTS ==========\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 5 Ã— 4</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>Sale_Date</th><th scope=col>date_parsed</th><th scope=col>sale_month</th><th scope=col>sale_weekday</th></tr>\n",
       "\t<tr><th scope=col>&lt;date&gt;</th><th scope=col>&lt;date&gt;</th><th scope=col>&lt;ord&gt;</th><th scope=col>&lt;ord&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>2023-04-24</td><td>2023-04-24</td><td>April </td><td>Monday  </td></tr>\n",
       "\t<tr><td>2023-06-09</td><td>2023-06-09</td><td>June  </td><td>Friday  </td></tr>\n",
       "\t<tr><td>2023-03-25</td><td>2023-03-25</td><td>March </td><td>Saturday</td></tr>\n",
       "\t<tr><td>2023-04-11</td><td>2023-04-11</td><td>April </td><td>Tuesday </td></tr>\n",
       "\t<tr><td>2023-08-26</td><td>2023-08-26</td><td>August</td><td>Saturday</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 5 Ã— 4\n",
       "\\begin{tabular}{llll}\n",
       " Sale\\_Date & date\\_parsed & sale\\_month & sale\\_weekday\\\\\n",
       " <date> & <date> & <ord> & <ord>\\\\\n",
       "\\hline\n",
       "\t 2023-04-24 & 2023-04-24 & April  & Monday  \\\\\n",
       "\t 2023-06-09 & 2023-06-09 & June   & Friday  \\\\\n",
       "\t 2023-03-25 & 2023-03-25 & March  & Saturday\\\\\n",
       "\t 2023-04-11 & 2023-04-11 & April  & Tuesday \\\\\n",
       "\t 2023-08-26 & 2023-08-26 & August & Saturday\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 5 Ã— 4\n",
       "\n",
       "| Sale_Date &lt;date&gt; | date_parsed &lt;date&gt; | sale_month &lt;ord&gt; | sale_weekday &lt;ord&gt; |\n",
       "|---|---|---|---|\n",
       "| 2023-04-24 | 2023-04-24 | April  | Monday   |\n",
       "| 2023-06-09 | 2023-06-09 | June   | Friday   |\n",
       "| 2023-03-25 | 2023-03-25 | March  | Saturday |\n",
       "| 2023-04-11 | 2023-04-11 | April  | Tuesday  |\n",
       "| 2023-08-26 | 2023-08-26 | August | Saturday |\n",
       "\n"
      ],
      "text/plain": [
       "  Sale_Date  date_parsed sale_month sale_weekday\n",
       "1 2023-04-24 2023-04-24  April      Monday      \n",
       "2 2023-06-09 2023-06-09  June       Friday      \n",
       "3 2023-03-25 2023-03-25  March      Saturday    \n",
       "4 2023-04-11 2023-04-11  April      Tuesday     \n",
       "5 2023-08-26 2023-08-26  August     Saturday    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Task 7.2: Parse Dates and Extract Components\n",
    "# TODO: Add these date-related columns using mutate():\n",
    "#   - date_parsed: Parse Sale_Date column (use ymd(), mdy(), or dmy() as appropriate)\n",
    "#   - sale_month: Extract month name from date_parsed\n",
    "#   - sale_weekday: Extract weekday name from date_parsed\n",
    "\n",
    "\n",
    "sales_enhanced <- sales_enhanced %>%\n",
    "  mutate(\n",
    "    # Your code here:\n",
    "# Parse and extract useful components from the Sale_Date column\n",
    "\n",
    "# Convert Sale_Date from text to a proper date format using ymd() (works for YYYY-MM-DD format)\n",
    "date_parsed = ymd(Sale_Date),\n",
    "\n",
    "# Extract the full month name from the parsed date (e.g., \"January\", \"February\")\n",
    "sale_month = month(date_parsed, label = TRUE, abbr = FALSE),\n",
    "\n",
    "# Extract the full weekday name from the parsed date (e.g., \"Monday\", \"Tuesday\")\n",
    "sale_weekday = wday(date_parsed, label = TRUE, abbr = FALSE)\n",
    "\n",
    "  )\n",
    "\n",
    "cat(\"========== DATE COMPONENTS ==========\\n\")\n",
    "head(sales_enhanced %>% select(Sale_Date, date_parsed, sale_month, sale_weekday), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part8_intro",
   "metadata": {},
   "source": [
    "## Part 8: Advanced Wrangling & Business Intelligence (Lesson 8)\n",
    "\n",
    "**Skills Assessed:** case_when(), complex logic, KPIs\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Create business categories with case_when()\n",
    "2. Calculate KPIs\n",
    "3. Generate executive summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "case_when_logic",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== PERFORMANCE TIERS ==========\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "  High    Low Medium \n",
       "   154     74     72 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Task 8.1: Create Performance Categories\n",
    "# TODO: Add 'performance_tier' column using case_when():\n",
    "#   - \"High\" if Revenue > 25000\n",
    "#   - \"Medium\" if Revenue > 15000\n",
    "#   - \"Low\" otherwise\n",
    "\n",
    "sales_enhanced <- sales_enhanced %>%\n",
    "  mutate(\n",
    "    performance_tier = case_when(\n",
    "      # Your code here:\n",
    "    # Create a new column that categorizes sales performance based on Revenue value\n",
    "# \"High\" for revenue above 25,000, \"Medium\" for revenue above 15,000, and \"Low\" for all others\n",
    "\n",
    "Revenue > 25000 ~ \"High\",      # High-performing sales\n",
    "Revenue > 15000 ~ \"Medium\",    # Medium-performing sales\n",
    "TRUE ~ \"Low\"                   # All other sales classified as Low\n",
    "\n",
    "    )\n",
    "  )\n",
    "\n",
    "cat(\"========== PERFORMANCE TIERS ==========\\n\")\n",
    "table(sales_enhanced$performance_tier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "calculate_kpis",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== BUSINESS KPIs ==========\n",
      "\u001b[90m# A tibble: 1 Ã— 4\u001b[39m\n",
      "  total_revenue total_transactions avg_transaction_value high_value_pct\n",
      "          \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m              \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m                 \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m          \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m      7\u001b[4m7\u001b[24m\u001b[4m7\u001b[24m\u001b[4m1\u001b[24m711.                300                \u001b[4m2\u001b[24m\u001b[4m5\u001b[24m906.           64.7\n"
     ]
    }
   ],
   "source": [
    "# Task 8.2: Calculate Business KPIs\n",
    "# TODO: Create 'business_kpis' with these metrics:\n",
    "#   - total_revenue: sum of Revenue\n",
    "#   - total_transactions: count of rows\n",
    "#   - avg_transaction_value: mean of Revenue\n",
    "#   - high_value_pct: percentage where high_value = \"Yes\"\n",
    "\n",
    "business_kpis <- sales_enhanced %>%\n",
    "  # Calculate key business performance indicators (KPIs) from the enhanced sales dataset\n",
    "\n",
    "summarize(\n",
    "  # Total revenue generated from all transactions (ignoring missing values)\n",
    "  total_revenue = sum(Revenue, na.rm = TRUE),\n",
    "  \n",
    "  # Total number of transactions recorded in the dataset\n",
    "  total_transactions = n(),\n",
    "  \n",
    "  # Average revenue per transaction, providing insight into typical sales size\n",
    "  avg_transaction_value = mean(Revenue, na.rm = TRUE),\n",
    "  \n",
    "  # Percentage of transactions classified as high-value sales (where high_value == \"Yes\")\n",
    "  high_value_pct = mean(high_value == \"Yes\") * 100\n",
    ")\n",
    "\n",
    "\n",
    "cat(\"========== BUSINESS KPIs ==========\\n\")\n",
    "print(business_kpis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection_intro",
   "metadata": {},
   "source": [
    "## Part 9: Reflection Questions\n",
    "\n",
    "Answer the following questions based on your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection1",
   "metadata": {},
   "source": [
    "### Question 9.1: Data Cleaning Impact\n",
    "\n",
    "**How did handling missing values and outliers affect your analysis? Why is data cleaning important before performing business analysis?**\n",
    "\n",
    "Your answer here:\n",
    "\n",
    "Handling missing values and outliers made the dataset much more reliable and easier to analyze. Before cleaning, there were gaps and extreme numbers that could have skewed averages or totals, giving a false impression of performance. After removing those issues, the patterns in revenue and sales became more realistic and consistent. Data cleaning is important because it ensures that the results you get actually reflect whatâ€™s happening in the business, not just errors or random noise in the data. Without cleaning, even the best analysis could lead to wrong decisions or misleading insights.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection2",
   "metadata": {},
   "source": [
    "### Question 9.2: Grouped Analysis Value\n",
    "\n",
    "**What insights did you gain from the regional and category summaries that you couldn't see in the raw data? How can businesses use this type of grouped analysis?**\n",
    "\n",
    "Your answer here:\n",
    "\n",
    "The regional and category summaries helped reveal trends that werenâ€™t obvious in the raw data. For example, I could see which regions consistently brought in the most revenue and which product categories were performing best overall. In the raw dataset, those patterns were buried in hundreds of individual transactions, but grouping made it clear where the business was strongest and where improvements were needed. Businesses can use this kind of grouped analysis to make data-driven decisionsâ€”like focusing marketing efforts on high-performing regions, adjusting pricing or inventory for weaker categories, and identifying growth opportunities based on regional demand patterns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection3",
   "metadata": {},
   "source": [
    "### Question 9.3: Data Reshaping Purpose\n",
    "\n",
    "**Why would you need to reshape data between wide and long formats? Provide a business scenario where each format would be useful.**\n",
    "\n",
    "Your answer here:\n",
    "\n",
    "Reshaping data between wide and long formats makes it easier to analyze or visualize information depending on the goal. The long format is better for detailed analysis and visualizations because each observation is stored in its own row, which works well with most R functions and plotting tools. The wide format is more useful for quick comparisons or creating summary reports, since all related values are side by side. For example, a business might use the wide format to create a sales dashboard that compares monthly revenue across regions, while the long format would be used when building a line chart showing sales trends over time for each product category. Switching between the two formats helps analysts look at the same data from different perspectives.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection4",
   "metadata": {},
   "source": [
    "### Question 9.4: Joining Datasets\n",
    "\n",
    "**What is the difference between left_join() and inner_join()? When would you use each one in a business context?**\n",
    "\n",
    "Your answer here:\n",
    "\n",
    "The main difference between left_join() and inner_join() is how they handle unmatched rows. A left_join() keeps all the records from the first dataset, even if thereâ€™s no matching data in the second oneâ€”missing matches just show up as blanks (NAs). An inner_join(), on the other hand, only keeps the rows that appear in both datasets. In a business context, youâ€™d use a left join if you want to keep your full customer list and see which ones have placed orders, making sure no customer is left out. Youâ€™d use an inner join if you only care about transactions that actually occurred, such as analyzing only customers who made a purchase.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection5",
   "metadata": {},
   "source": [
    "### Question 9.5: Skills Integration\n",
    "\n",
    "**Which R data wrangling skill (from Lessons 1-8) do you think is most valuable for business analytics? Why?**\n",
    "\n",
    "Your answer here:\n",
    "\n",
    "I think the most valuable R data wrangling skill for business analytics is using group_by() with summarize(). These functions make it easy to turn large, messy datasets into clear summaries that reveal important patternsâ€”like total sales by region or average revenue per product. In business, decisions often depend on understanding trends and comparisons, and grouped summaries provide exactly that insight. While importing, cleaning, and reshaping data are also essential, being able to quickly group and summarize data is what truly turns raw information into meaningful business intelligence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## Exam Complete!\n",
    "\n",
    "### What You've Demonstrated\n",
    "\n",
    "âœ… **Lesson 1:** R basics and data import\n",
    "âœ… **Lesson 2:** Data cleaning (missing values & outliers)\n",
    "âœ… **Lesson 3:** Data transformation (select, filter, arrange)\n",
    "âœ… **Lesson 4:** Advanced transformation (mutate, summarize, group_by)\n",
    "âœ… **Lesson 5:** Data reshaping (pivot_longer, pivot_wider)\n",
    "âœ… **Lesson 6:** Combining datasets (joins)\n",
    "âœ… **Lesson 7:** String manipulation & date/time operations\n",
    "âœ… **Lesson 8:** Advanced wrangling & business intelligence\n",
    "\n",
    "### Submission Checklist\n",
    "\n",
    "Before submitting, ensure:\n",
    "- [ ] All code cells run without errors\n",
    "- [ ] All TODO sections completed\n",
    "- [ ] All required dataframes created with correct names\n",
    "- [ ] All 5 reflection questions answered\n",
    "- [ ] Student name and ID filled in at top\n",
    "\n",
    "**Good work! ðŸŽ‰**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
