{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# MIDTERM EXAM: Comprehensive R Data Wrangling Assessment\n",
    "\n",
    "**Student Name:** Gavin Lara\n",
    "\n",
    "**Student ID:** 01985022\n",
    "\n",
    "**Date:** 10/19/2025\n",
    "\n",
    "**Time Limit:** 4 hours\n",
    "\n",
    "---\n",
    "\n",
    "## Exam Overview\n",
    "\n",
    "This comprehensive midterm exam assesses your mastery of ALL R data wrangling skills covered in Lessons 1-8:\n",
    "\n",
    "- **Lesson 1:** R Basics and Data Import\n",
    "- **Lesson 2:** Data Cleaning (Missing Values & Outliers)\n",
    "- **Lesson 3:** Data Transformation Part 1 (select, filter, arrange)\n",
    "- **Lesson 4:** Data Transformation Part 2 (mutate, summarize, group_by)\n",
    "- **Lesson 5:** Data Reshaping (pivot_longer, pivot_wider)\n",
    "- **Lesson 6:** Combining Datasets (joins)\n",
    "- **Lesson 7:** String Manipulation & Date/Time\n",
    "- **Lesson 8:** Advanced Wrangling & Best Practices\n",
    "\n",
    "## Business Scenario\n",
    "\n",
    "You are a data analyst for a retail company. The executive team needs a comprehensive analysis of:\n",
    "- Sales performance across products and regions\n",
    "- Customer behavior and segmentation\n",
    "- Data quality issues and recommendations\n",
    "- Strategic insights for business growth\n",
    "\n",
    "## Instructions\n",
    "\n",
    "1. **Set your working directory** to where your data files are located\n",
    "2. Complete ALL tasks in order\n",
    "3. Write code in the TODO sections\n",
    "4. Use the pipe operator (%>%) to chain operations\n",
    "5. Add comments explaining your logic\n",
    "6. Run all cells to verify your code works\n",
    "7. Answer all reflection questions\n",
    "\n",
    "## Grading\n",
    "\n",
    "- **Code Correctness (40%)**: All tasks completed correctly\n",
    "- **Code Quality (20%)**: Clean, well-commented code\n",
    "- **Business Understanding (20%)**: Demonstrates understanding of context\n",
    "- **Analysis & Insights (15%)**: Meaningful insights and recommendations\n",
    "- **Reflection Questions (5%)**: Thoughtful answers\n",
    "\n",
    "## Academic Integrity\n",
    "\n",
    "This is an individual exam. You may use:\n",
    "- Course notes and lesson materials\n",
    "- R documentation and help files\n",
    "- Your previous homework assignments\n",
    "\n",
    "You may NOT:\n",
    "- Collaborate with other students\n",
    "- Use AI assistants or online forums\n",
    "- Share code or solutions\n",
    "\n",
    "---\n",
    "\n",
    "**Good luck! ðŸŽ“**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part1_intro",
   "metadata": {},
   "source": [
    "## Part 1: R Basics and Data Import (Lesson 1)\n",
    "\n",
    "**Skills Assessed:** Variables, data types, data import, working directory\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Set working directory\n",
    "2. Load required packages\n",
    "3. Import multiple datasets\n",
    "4. Examine data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "setup",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /workspaces/assignment-1-version-3-Gavinlara1/assignment/Homework \n",
      "Files:\n",
      " [1] \"homework_lesson_3_data_transformation (3).ipynb\"                 \n",
      " [2] \"homework_lesson_4_data_transformation_part2.ipynb\"               \n",
      " [3] \"Lara_Gavin homework_lesson_3.ipynb\"                              \n",
      " [4] \"Lara_Gavin_homework_lesson_4_data_transformation_part2 (1).ipynb\"\n",
      " [5] \"Lara_Gavin_homework_lesson_5_data_reshaping.ipynb\"               \n",
      " [6] \"Lara_Gavin_homework_lesson_6_joins.ipynb\"                        \n",
      " [7] \"Lara_Gavin_homework_lesson_7_string_datetime.ipynb\"              \n",
      " [8] \"MIDTERM_EXAM_COMPREHENSIVE (1).ipynb\"                            \n",
      " [9] \"MIDTERM_EXAM_COMPREHENSIVE (2).ipynb\"                            \n",
      "[10] \"README.md\"                                                       \n",
      "Files:\n",
      " [1] \"homework_lesson_3_data_transformation (3).ipynb\"                 \n",
      " [2] \"homework_lesson_4_data_transformation_part2.ipynb\"               \n",
      " [3] \"Lara_Gavin homework_lesson_3.ipynb\"                              \n",
      " [4] \"Lara_Gavin_homework_lesson_4_data_transformation_part2 (1).ipynb\"\n",
      " [5] \"Lara_Gavin_homework_lesson_5_data_reshaping.ipynb\"               \n",
      " [6] \"Lara_Gavin_homework_lesson_6_joins.ipynb\"                        \n",
      " [7] \"Lara_Gavin_homework_lesson_7_string_datetime.ipynb\"              \n",
      " [8] \"MIDTERM_EXAM_COMPREHENSIVE (1).ipynb\"                            \n",
      " [9] \"MIDTERM_EXAM_COMPREHENSIVE (2).ipynb\"                            \n",
      "[10] \"README.md\"                                                       \n"
     ]
    }
   ],
   "source": [
    "# Task 1.1: Set Working Directory\n",
    "# TODO: Set your working directory to where your data files are located\n",
    "# IMPORTANT: Students must set their own path!\n",
    "# Example: setwd(\"/Users/yourname/GitHub/ai-homework-grader-clean/data\")\n",
    "\n",
    "# Your code here: \n",
    "\n",
    "# Task 1.1: Set Working Directory\n",
    "\n",
    "data_dir <- \"/workspaces/assignment-1-version-3-Gavinlara1/assignment/Homework\"  # replace with your path\n",
    "\n",
    "if (!dir.exists(data_dir)) stop(paste(\"Path not found:\", data_dir))\n",
    "setwd(data_dir)\n",
    "\n",
    "# Verify\n",
    "cat(\"Current working directory:\", getwd(), \"\\n\")\n",
    "cat(\"Files:\\n\"); print(list.files())\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "load_packages",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Packages loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Task 1.2: Load Required Packages\n",
    "# TODO: Load tidyverse (includes dplyr, tidyr, stringr, ggplot2)\n",
    "# TODO: Load lubridate for date operations\n",
    "\n",
    "required_pkgs <- c(\"tidyverse\", \"lubridate\")\n",
    "to_install <- setdiff(required_pkgs, rownames(installed.packages()))\n",
    "if (length(to_install) > 0) {\n",
    "  install.packages(to_install, repos = \"https://cloud.r-project.org\", quiet = TRUE)\n",
    "}\n",
    "\n",
    "suppressPackageStartupMessages({\n",
    "  library(tidyverse)\n",
    "  library(lubridate)\n",
    "})\n",
    "\n",
    "cat(\"âœ… Packages loaded successfully!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "import_data",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Imported datasets:\n",
      "- sales_data: 300 rows, 8 cols\n",
      "- customers: 100 rows, 5 cols\n",
      "- products: 50 rows, 4 cols\n",
      "- orders: 250 rows, 4 cols\n",
      "- order_items: 400 rows, 4 cols\n",
      "\n",
      "Preview of sales_data:\n",
      "- sales_data: 300 rows, 8 cols\n",
      "- customers: 100 rows, 5 cols\n",
      "- products: 50 rows, 4 cols\n",
      "- orders: 250 rows, 4 cols\n",
      "- order_items: 400 rows, 4 cols\n",
      "\n",
      "Preview of sales_data:\n",
      "\u001b[90m# A tibble: 5 Ã— 8\u001b[39m\n",
      "  TransactionID Sales_Rep_Name Region Product_Category Revenue   Cost Units_Sold\n",
      "          \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m          \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m              \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m  \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m      \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m             1 Carol Davis    Latinâ€¦ Services          \u001b[4m2\u001b[24m\u001b[4m0\u001b[24m751. \u001b[4m1\u001b[24m\u001b[4m2\u001b[24m253.         78\n",
      "\u001b[90m2\u001b[39m             2 Carol Davis    Europe Hardware          \u001b[4m3\u001b[24m\u001b[4m2\u001b[24m360. \u001b[4m2\u001b[24m\u001b[4m4\u001b[24m595.         13\n",
      "\u001b[90m3\u001b[39m             3 Carol Davis    Europe Services          \u001b[4m3\u001b[24m\u001b[4m9\u001b[24m268. \u001b[4m2\u001b[24m\u001b[4m3\u001b[24m291.         34\n",
      "\u001b[90m4\u001b[39m             4 Bob Smith      Europe Hardware          \u001b[4m2\u001b[24m\u001b[4m8\u001b[24m865. \u001b[4m1\u001b[24m\u001b[4m2\u001b[24m429.         90\n",
      "\u001b[90m5\u001b[39m             5 Frank Miller   Latinâ€¦ Software           \u001b[4m3\u001b[24m932.  \u001b[4m1\u001b[24m778.         63\n",
      "\u001b[90m# â„¹ 1 more variable: Sale_Date <date>\u001b[39m\n",
      "\u001b[90m# A tibble: 5 Ã— 8\u001b[39m\n",
      "  TransactionID Sales_Rep_Name Region Product_Category Revenue   Cost Units_Sold\n",
      "          \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m          \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m              \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m  \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m      \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m             1 Carol Davis    Latinâ€¦ Services          \u001b[4m2\u001b[24m\u001b[4m0\u001b[24m751. \u001b[4m1\u001b[24m\u001b[4m2\u001b[24m253.         78\n",
      "\u001b[90m2\u001b[39m             2 Carol Davis    Europe Hardware          \u001b[4m3\u001b[24m\u001b[4m2\u001b[24m360. \u001b[4m2\u001b[24m\u001b[4m4\u001b[24m595.         13\n",
      "\u001b[90m3\u001b[39m             3 Carol Davis    Europe Services          \u001b[4m3\u001b[24m\u001b[4m9\u001b[24m268. \u001b[4m2\u001b[24m\u001b[4m3\u001b[24m291.         34\n",
      "\u001b[90m4\u001b[39m             4 Bob Smith      Europe Hardware          \u001b[4m2\u001b[24m\u001b[4m8\u001b[24m865. \u001b[4m1\u001b[24m\u001b[4m2\u001b[24m429.         90\n",
      "\u001b[90m5\u001b[39m             5 Frank Miller   Latinâ€¦ Software           \u001b[4m3\u001b[24m932.  \u001b[4m1\u001b[24m778.         63\n",
      "\u001b[90m# â„¹ 1 more variable: Sale_Date <date>\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "# Task 1.3: Import Datasets\n",
    "# TODO: Import the following CSV files using read_csv():\n",
    "#   - company_sales_data.csv -> sales_data\n",
    "#   - customers.csv -> customers\n",
    "#   - products.csv -> products\n",
    "#   - orders.csv -> orders\n",
    "#   - order_items.csv -> order_items\n",
    "\n",
    "# Your code here:\n",
    "files <- c(\n",
    "  sales_data  = \"company_sales_data.csv\",\n",
    "  customers   = \"customers.csv\",\n",
    "  products    = \"products.csv\",\n",
    "  orders      = \"orders.csv\",\n",
    "  order_items = \"order_items.csv\"\n",
    ")\n",
    "\n",
    "# Try locations in this order: working dir, ./data subfolder, data_dir (if defined),\n",
    "# plus parent-level data folders and the repo-level data folder if present.\n",
    "repo_data_path <- '/workspaces/assignment-1-version-3-Gavinlara1/data'\n",
    "parent1 <- dirname(getwd())\n",
    "parent2 <- dirname(parent1)\n",
    "locs <- unique(c(\n",
    "  getwd(),\n",
    "  file.path(getwd(), 'data'),\n",
    "  if (exists('data_dir')) normalizePath(data_dir, mustWork = FALSE) else NULL,\n",
    "  file.path(parent1, 'data'),\n",
    "  file.path(parent2, 'data'),\n",
    "  repo_data_path\n",
    "))\n",
    "\n",
    "found_paths <- sapply(files, function(fname) {\n",
    "  candidates <- file.path(locs, fname)\n",
    "  candidates <- candidates[!is.na(candidates) & nzchar(candidates)]\n",
    "  hit <- candidates[file.exists(candidates)]\n",
    "  if (length(hit) > 0) return(hit[1])\n",
    "  NA_character_\n",
    "})\n",
    "\n",
    "missing <- names(found_paths)[is.na(found_paths)]\n",
    "if (length(missing) > 0) {\n",
    "  cat(\"Files in current directory:\\n\"); print(list.files())\n",
    "  if (dir.exists(\"data\")) { cat(\"\\nFiles in ./data directory:\\n\"); print(list.files(\"data\")) }\n",
    "  if (exists(\"data_dir\")) { cat(\"\\nFiles in data_dir (\", data_dir, \"):\\n\"); print(list.files(data_dir)) }\n",
    "  stop(paste(\"Missing required file(s):\", paste(missing, collapse = \", \")))\n",
    "}\n",
    "\n",
    "suppressMessages({\n",
    "  sales_data  <- readr::read_csv(found_paths[\"sales_data\"],  show_col_types = FALSE)\n",
    "  customers   <- readr::read_csv(found_paths[\"customers\"],   show_col_types = FALSE)\n",
    "  products    <- readr::read_csv(found_paths[\"products\"],    show_col_types = FALSE)\n",
    "  orders      <- readr::read_csv(found_paths[\"orders\"],      show_col_types = FALSE)\n",
    "  order_items <- readr::read_csv(found_paths[\"order_items\"], show_col_types = FALSE)\n",
    "})\n",
    "\n",
    "cat(\"âœ… Imported datasets:\\n\")\n",
    "datasets <- list(sales_data = sales_data, customers = customers, products = products, orders = orders, order_items = order_items)\n",
    "for (nm in names(datasets)) {\n",
    "  df <- datasets[[nm]]\n",
    "  cat(sprintf(\"- %s: %d rows, %d cols\\n\", nm, nrow(df), ncol(df)))\n",
    "}\n",
    "\n",
    "cat(\"\\nPreview of sales_data:\\n\")\n",
    "print(utils::head(sales_data, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part2_intro",
   "metadata": {},
   "source": [
    "## Part 2: Data Cleaning - Missing Values & Outliers (Lesson 2)\n",
    "\n",
    "**Skills Assessed:** Identifying NAs, handling missing data, detecting outliers\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Check for missing values in sales_data\n",
    "2. Handle missing values appropriately\n",
    "3. Identify outliers in Revenue column\n",
    "4. Create a cleaned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "check_missing",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== MISSING VALUES SUMMARY ==========\n",
      "                           column missing_count missing_pct\n",
      "TransactionID       TransactionID             0           0\n",
      "Sales_Rep_Name     Sales_Rep_Name             0           0\n",
      "Region                     Region             0           0\n",
      "Product_Category Product_Category             0           0\n",
      "Revenue                   Revenue             0           0\n",
      "Cost                         Cost             0           0\n",
      "Units_Sold             Units_Sold             0           0\n",
      "Sale_Date               Sale_Date             0           0\n",
      "\n",
      "Total missing values: 0  (  0 )% of all cells\n",
      "                           column missing_count missing_pct\n",
      "TransactionID       TransactionID             0           0\n",
      "Sales_Rep_Name     Sales_Rep_Name             0           0\n",
      "Region                     Region             0           0\n",
      "Product_Category Product_Category             0           0\n",
      "Revenue                   Revenue             0           0\n",
      "Cost                         Cost             0           0\n",
      "Units_Sold             Units_Sold             0           0\n",
      "Sale_Date               Sale_Date             0           0\n",
      "\n",
      "Total missing values: 0  (  0 )% of all cells\n"
     ]
    }
   ],
   "source": [
    "# Task 2.1: Check for Missing Values\n",
    "# TODO: Create 'missing_summary' that shows count of NAs in each column of sales_data\n",
    "\n",
    "# Calculate missing values per column (works for data.frames and tibbles)\n",
    "missing_summary <- sapply(sales_data, function(x) sum(is.na(x)))\n",
    "# Also compute percent missing for convenience\n",
    "missing_pct <- round(100 * missing_summary / nrow(sales_data), 2)\n",
    "missing_df <- data.frame(column = names(missing_summary), missing_count = as.integer(missing_summary), missing_pct = missing_pct, stringsAsFactors = FALSE)\n",
    "missing_df <- missing_df[order(-missing_df$missing_count), ]\n",
    "\n",
    "cat(\"========== MISSING VALUES SUMMARY ==========\\n\")\n",
    "print(missing_df)\n",
    "cat(\"\\nTotal missing values:\", sum(missing_summary), \" ( \", sum(missing_summary) / (nrow(sales_data) * ncol(sales_data)) * 100, \")% of all cells\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "handle_missing",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== DATA CLEANING RESULTS ==========\n",
      "Original rows: 300 \n",
      "Cleaned rows: 300 \n",
      "Rows removed: 0  ( 0 % )\n",
      "Original rows: 300 \n",
      "Cleaned rows: 300 \n",
      "Rows removed: 0  ( 0 % )\n",
      "\u001b[90m# A tibble: 5 Ã— 8\u001b[39m\n",
      "  TransactionID Sales_Rep_Name Region Product_Category Revenue   Cost Units_Sold\n",
      "          \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m          \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m              \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m  \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m      \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m             1 Carol Davis    Latinâ€¦ Services          \u001b[4m2\u001b[24m\u001b[4m0\u001b[24m751. \u001b[4m1\u001b[24m\u001b[4m2\u001b[24m253.         78\n",
      "\u001b[90m2\u001b[39m             2 Carol Davis    Europe Hardware          \u001b[4m3\u001b[24m\u001b[4m2\u001b[24m360. \u001b[4m2\u001b[24m\u001b[4m4\u001b[24m595.         13\n",
      "\u001b[90m3\u001b[39m             3 Carol Davis    Europe Services          \u001b[4m3\u001b[24m\u001b[4m9\u001b[24m268. \u001b[4m2\u001b[24m\u001b[4m3\u001b[24m291.         34\n",
      "\u001b[90m4\u001b[39m             4 Bob Smith      Europe Hardware          \u001b[4m2\u001b[24m\u001b[4m8\u001b[24m865. \u001b[4m1\u001b[24m\u001b[4m2\u001b[24m429.         90\n",
      "\u001b[90m5\u001b[39m             5 Frank Miller   Latinâ€¦ Software           \u001b[4m3\u001b[24m932.  \u001b[4m1\u001b[24m778.         63\n",
      "\u001b[90m# â„¹ 1 more variable: Sale_Date <date>\u001b[39m\n",
      "\u001b[90m# A tibble: 5 Ã— 8\u001b[39m\n",
      "  TransactionID Sales_Rep_Name Region Product_Category Revenue   Cost Units_Sold\n",
      "          \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m          \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m              \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m  \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m      \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m             1 Carol Davis    Latinâ€¦ Services          \u001b[4m2\u001b[24m\u001b[4m0\u001b[24m751. \u001b[4m1\u001b[24m\u001b[4m2\u001b[24m253.         78\n",
      "\u001b[90m2\u001b[39m             2 Carol Davis    Europe Hardware          \u001b[4m3\u001b[24m\u001b[4m2\u001b[24m360. \u001b[4m2\u001b[24m\u001b[4m4\u001b[24m595.         13\n",
      "\u001b[90m3\u001b[39m             3 Carol Davis    Europe Services          \u001b[4m3\u001b[24m\u001b[4m9\u001b[24m268. \u001b[4m2\u001b[24m\u001b[4m3\u001b[24m291.         34\n",
      "\u001b[90m4\u001b[39m             4 Bob Smith      Europe Hardware          \u001b[4m2\u001b[24m\u001b[4m8\u001b[24m865. \u001b[4m1\u001b[24m\u001b[4m2\u001b[24m429.         90\n",
      "\u001b[90m5\u001b[39m             5 Frank Miller   Latinâ€¦ Software           \u001b[4m3\u001b[24m932.  \u001b[4m1\u001b[24m778.         63\n",
      "\u001b[90m# â„¹ 1 more variable: Sale_Date <date>\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "# Task 2.2: Handle Missing Values\n",
    "# TODO: Create 'sales_clean' by removing rows with ANY missing values\n",
    "\n",
    "# Remove rows that contain any NA in any column (use tidyr::drop_na)\n",
    "sales_clean <- tidyr::drop_na(sales_data)\n",
    "\n",
    "# Sanity checks and summary\n",
    "original_rows <- nrow(sales_data)\n",
    "cleaned_rows  <- nrow(sales_clean)\n",
    "rows_removed  <- original_rows - cleaned_rows\n",
    "pct_removed   <- if (original_rows > 0) round(100 * rows_removed / original_rows, 2) else 0\n",
    "\n",
    "cat(\"========== DATA CLEANING RESULTS ==========\\n\")\n",
    "cat(\"Original rows:\", original_rows, \"\\n\")\n",
    "cat(\"Cleaned rows:\", cleaned_rows, \"\\n\")\n",
    "cat(\"Rows removed:\", rows_removed, \" (\", pct_removed, \"% )\\n\")\n",
    "\n",
    "# Display a small sample of cleaned data to confirm\n",
    "print(utils::head(sales_clean, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "detect_outliers",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== OUTLIER ANALYSIS ==========\n",
      "       Metric     Value\n",
      "1          Q1  15034.29\n",
      "2          Q3  37707.71\n",
      "3         IQR  22673.42\n",
      "4 Lower Bound -18975.84\n",
      "5 Upper Bound  71717.84\n",
      "\n",
      "Number of outliers detected: 0 \n",
      "\n",
      "No outliers detected using the IQR method.\n",
      "       Metric     Value\n",
      "1          Q1  15034.29\n",
      "2          Q3  37707.71\n",
      "3         IQR  22673.42\n",
      "4 Lower Bound -18975.84\n",
      "5 Upper Bound  71717.84\n",
      "\n",
      "Number of outliers detected: 0 \n",
      "\n",
      "No outliers detected using the IQR method.\n"
     ]
    }
   ],
   "source": [
    "# Task 2.3: Detect Outliers in Revenue\n",
    "# Calculate outlier thresholds using the IQR method\n",
    "#   - Calculate Q1 (25th percentile) and Q3 (75th percentile) of Revenue\n",
    "#   - Calculate IQR = Q3 - Q1\n",
    "#   - Lower bound = Q1 - 1.5 * IQR\n",
    "#   - Upper bound = Q3 + 1.5 * IQR\n",
    "# Create 'outlier_analysis' dataframe with these values and identify outlier rows\n",
    "\n",
    "# Ensure Revenue is numeric and remove NA values for the calculation\n",
    "revenue_vec <- as.numeric(sales_clean$Revenue)\n",
    "revenue_vec <- revenue_vec[!is.na(revenue_vec)]\n",
    "\n",
    "if (length(revenue_vec) == 0) {\n",
    "  stop('Revenue column has no numeric values after removing NAs; cannot compute outliers')\n",
    "}\n",
    "\n",
    "Q1 <- as.numeric(quantile(revenue_vec, probs = 0.25, na.rm = TRUE, type = 7))\n",
    "Q3 <- as.numeric(quantile(revenue_vec, probs = 0.75, na.rm = TRUE, type = 7))\n",
    "IQR_value <- Q3 - Q1\n",
    "lower_bound <- Q1 - 1.5 * IQR_value\n",
    "upper_bound <- Q3 + 1.5 * IQR_value\n",
    "\n",
    "outlier_analysis <- data.frame(\n",
    "  Metric = c(\"Q1\", \"Q3\", \"IQR\", \"Lower Bound\", \"Upper Bound\"),\n",
    "  Value = c(Q1, Q3, IQR_value, lower_bound, upper_bound)\n",
    ")\n",
    "\n",
    "cat(\"========== OUTLIER ANALYSIS ==========\\n\")\n",
    "print(outlier_analysis)\n",
    "\n",
    "# Identify outlier rows in sales_clean (using original sales_clean to preserve rows)\n",
    "is_outlier <- !is.na(sales_clean$Revenue) & (as.numeric(sales_clean$Revenue) < lower_bound | as.numeric(sales_clean$Revenue) > upper_bound)\n",
    "outlier_count <- sum(is_outlier, na.rm = TRUE)\n",
    "cat(\"\\nNumber of outliers detected:\", outlier_count, \"\\n\")\n",
    "\n",
    "# Show a small sample of outliers if any\n",
    "if (outlier_count > 0) {\n",
    "  cat(\"\\nSample outlier rows:\\n\")\n",
    "  print(head(sales_clean[which(is_outlier), ], 10))\n",
    "} else {\n",
    "  cat(\"\\nNo outliers detected using the IQR method.\\n\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part3_intro",
   "metadata": {},
   "source": [
    "## Part 3: Data Transformation Part 1 (Lesson 3)\n",
    "\n",
    "**Skills Assessed:** select(), filter(), arrange(), pipe operator\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Select specific columns\n",
    "2. Filter data by conditions\n",
    "3. Sort data\n",
    "4. Chain operations with pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "select_columns",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== SELECTED COLUMNS ==========\n",
      "Columns: Region, Product_Category, Revenue, Units_Sold, Sale_Date \n",
      "Rows: 300 \n",
      "Columns: Region, Product_Category, Revenue, Units_Sold, Sale_Date \n",
      "Rows: 300 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 5 Ã— 5</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>Region</th><th scope=col>Product_Category</th><th scope=col>Revenue</th><th scope=col>Units_Sold</th><th scope=col>Sale_Date</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;date&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>Latin America</td><td>Services</td><td>20750.92</td><td>78</td><td>2023-04-24</td></tr>\n",
       "\t<tr><td>Europe       </td><td>Hardware</td><td>32359.98</td><td>13</td><td>2023-06-09</td></tr>\n",
       "\t<tr><td>Europe       </td><td>Services</td><td>39268.40</td><td>34</td><td>2023-03-25</td></tr>\n",
       "\t<tr><td>Europe       </td><td>Hardware</td><td>28865.09</td><td>90</td><td>2023-04-11</td></tr>\n",
       "\t<tr><td>Latin America</td><td>Software</td><td> 3932.36</td><td>63</td><td>2023-08-26</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 5 Ã— 5\n",
       "\\begin{tabular}{lllll}\n",
       " Region & Product\\_Category & Revenue & Units\\_Sold & Sale\\_Date\\\\\n",
       " <chr> & <chr> & <dbl> & <dbl> & <date>\\\\\n",
       "\\hline\n",
       "\t Latin America & Services & 20750.92 & 78 & 2023-04-24\\\\\n",
       "\t Europe        & Hardware & 32359.98 & 13 & 2023-06-09\\\\\n",
       "\t Europe        & Services & 39268.40 & 34 & 2023-03-25\\\\\n",
       "\t Europe        & Hardware & 28865.09 & 90 & 2023-04-11\\\\\n",
       "\t Latin America & Software &  3932.36 & 63 & 2023-08-26\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 5 Ã— 5\n",
       "\n",
       "| Region &lt;chr&gt; | Product_Category &lt;chr&gt; | Revenue &lt;dbl&gt; | Units_Sold &lt;dbl&gt; | Sale_Date &lt;date&gt; |\n",
       "|---|---|---|---|---|\n",
       "| Latin America | Services | 20750.92 | 78 | 2023-04-24 |\n",
       "| Europe        | Hardware | 32359.98 | 13 | 2023-06-09 |\n",
       "| Europe        | Services | 39268.40 | 34 | 2023-03-25 |\n",
       "| Europe        | Hardware | 28865.09 | 90 | 2023-04-11 |\n",
       "| Latin America | Software |  3932.36 | 63 | 2023-08-26 |\n",
       "\n"
      ],
      "text/plain": [
       "  Region        Product_Category Revenue  Units_Sold Sale_Date \n",
       "1 Latin America Services         20750.92 78         2023-04-24\n",
       "2 Europe        Hardware         32359.98 13         2023-06-09\n",
       "3 Europe        Services         39268.40 34         2023-03-25\n",
       "4 Europe        Hardware         28865.09 90         2023-04-11\n",
       "5 Latin America Software          3932.36 63         2023-08-26"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Task 3.1: Select Specific Columns\n",
    "# Create 'sales_summary' with only these columns from sales_clean:\n",
    "#   Region, Product_Category, Revenue, Units_Sold, Sale_Date\n",
    "\n",
    "# Robust selection: handle minor column-name variations (e.g., Sale_Date vs SaleDate)\n",
    "required_cols <- c('Region', 'Product_Category', 'Revenue', 'Units_Sold', 'Sale_Date')\n",
    "available_cols <- names(sales_clean)\n",
    "\n",
    "# Helper to find best match for a desired column name\n",
    "find_col <- function(name, candidates) {\n",
    "  if (name %in% candidates) return(name)\n",
    "  # try common variants\n",
    "  variants <- c(name, gsub('_', '', name), gsub('_', '', tolower(name)), tolower(name))\n",
    "  hit <- variants[variants %in% candidates]\n",
    "  if (length(hit) > 0) return(hit[1])\n",
    "  NA_character_\n",
    "}\n",
    "\n",
    "mapped <- sapply(required_cols, find_col, candidates = available_cols, USE.NAMES = FALSE)\n",
    "missing <- required_cols[is.na(mapped)]\n",
    "if (length(missing) > 0) stop(paste('Missing required columns in sales_clean:', paste(missing, collapse = ', ')))\n",
    "\n",
    "# Build sales_summary by selecting the mapped columns in the requested order\n",
    "sales_summary <- sales_clean %>% dplyr::select(all_of(mapped))\n",
    "\n",
    "cat(\"========== SELECTED COLUMNS ==========\\n\")\n",
    "cat(\"Columns:\", paste(names(sales_summary), collapse = ', '), \"\\n\")\n",
    "cat(\"Rows:\", nrow(sales_summary), \"\\n\")\n",
    "head(sales_summary, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "filter_data",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== HIGH REVENUE SALES ==========\n",
      "Total high revenue transactions: 194 \n",
      "Total revenue from these sales: $ 6671906 \n",
      "Total high revenue transactions: 194 \n",
      "Total revenue from these sales: $ 6671906 \n",
      "\u001b[90m# A tibble: 5 Ã— 8\u001b[39m\n",
      "  TransactionID Sales_Rep_Name Region Product_Category Revenue   Cost Units_Sold\n",
      "          \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m          \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m              \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m  \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m      \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m           230 Alice Johnson  Asia â€¦ Consulting        \u001b[4m4\u001b[24m\u001b[4m9\u001b[24m956. \u001b[4m2\u001b[24m\u001b[4m1\u001b[24m741.         88\n",
      "\u001b[90m2\u001b[39m           284 David Wilson   Europe Software          \u001b[4m4\u001b[24m\u001b[4m9\u001b[24m867. \u001b[4m1\u001b[24m\u001b[4m9\u001b[24m117.         96\n",
      "\u001b[90m3\u001b[39m             8 Alice Johnson  Europe Consulting        \u001b[4m4\u001b[24m\u001b[4m9\u001b[24m857. \u001b[4m3\u001b[24m\u001b[4m7\u001b[24m119.          1\n",
      "\u001b[90m4\u001b[39m           119 Eva Brown      Asia â€¦ Consulting        \u001b[4m4\u001b[24m\u001b[4m9\u001b[24m239. \u001b[4m2\u001b[24m\u001b[4m4\u001b[24m051.         72\n",
      "\u001b[90m5\u001b[39m            12 Alice Johnson  Asia â€¦ Hardware          \u001b[4m4\u001b[24m\u001b[4m8\u001b[24m997. \u001b[4m2\u001b[24m\u001b[4m6\u001b[24m135.         92\n",
      "\u001b[90m# â„¹ 1 more variable: Sale_Date <date>\u001b[39m\n",
      "\u001b[90m# A tibble: 5 Ã— 8\u001b[39m\n",
      "  TransactionID Sales_Rep_Name Region Product_Category Revenue   Cost Units_Sold\n",
      "          \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m          \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m              \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m  \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m      \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m           230 Alice Johnson  Asia â€¦ Consulting        \u001b[4m4\u001b[24m\u001b[4m9\u001b[24m956. \u001b[4m2\u001b[24m\u001b[4m1\u001b[24m741.         88\n",
      "\u001b[90m2\u001b[39m           284 David Wilson   Europe Software          \u001b[4m4\u001b[24m\u001b[4m9\u001b[24m867. \u001b[4m1\u001b[24m\u001b[4m9\u001b[24m117.         96\n",
      "\u001b[90m3\u001b[39m             8 Alice Johnson  Europe Consulting        \u001b[4m4\u001b[24m\u001b[4m9\u001b[24m857. \u001b[4m3\u001b[24m\u001b[4m7\u001b[24m119.          1\n",
      "\u001b[90m4\u001b[39m           119 Eva Brown      Asia â€¦ Consulting        \u001b[4m4\u001b[24m\u001b[4m9\u001b[24m239. \u001b[4m2\u001b[24m\u001b[4m4\u001b[24m051.         72\n",
      "\u001b[90m5\u001b[39m            12 Alice Johnson  Asia â€¦ Hardware          \u001b[4m4\u001b[24m\u001b[4m8\u001b[24m997. \u001b[4m2\u001b[24m\u001b[4m6\u001b[24m135.         92\n",
      "\u001b[90m# â„¹ 1 more variable: Sale_Date <date>\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "# Task 3.2: Filter High Revenue Sales\n",
    "# Create 'high_revenue_sales' by filtering sales_clean for Revenue > 20000\n",
    "\n",
    "# Ensure Revenue is numeric for comparison (coerce safely)\n",
    "sales_clean <- sales_clean %>% dplyr::mutate(Revenue = as.numeric(Revenue))\n",
    "\n",
    "high_revenue_sales <- sales_clean %>%\n",
    "  dplyr::filter(!is.na(Revenue) & Revenue > 20000)\n",
    "\n",
    "cat(\"========== HIGH REVENUE SALES ==========\\n\")\n",
    "cat(\"Total high revenue transactions:\", nrow(high_revenue_sales), \"\\n\")\n",
    "cat(\"Total revenue from these sales: $\", sum(high_revenue_sales$Revenue, na.rm = TRUE), \"\\n\")\n",
    "\n",
    "# Show top 5 high revenue transactions for quick inspection\n",
    "print(head(high_revenue_sales %>% dplyr::arrange(desc(Revenue)), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "sort_data",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== TOP 10 SALES ==========\n",
      "\u001b[90m# A tibble: 10 Ã— 4\u001b[39m\n",
      "   Region        Product_Category Revenue Units_Sold\n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m         \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m              \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m      \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m Asia Pacific  Consulting        \u001b[4m4\u001b[24m\u001b[4m9\u001b[24m956.         88\n",
      "\u001b[90m 2\u001b[39m Europe        Software          \u001b[4m4\u001b[24m\u001b[4m9\u001b[24m867.         96\n",
      "\u001b[90m 3\u001b[39m Europe        Consulting        \u001b[4m4\u001b[24m\u001b[4m9\u001b[24m857.          1\n",
      "\u001b[90m 4\u001b[39m Asia Pacific  Consulting        \u001b[4m4\u001b[24m\u001b[4m9\u001b[24m239.         72\n",
      "\u001b[90m 5\u001b[39m Asia Pacific  Hardware          \u001b[4m4\u001b[24m\u001b[4m8\u001b[24m997.         92\n",
      "\u001b[90m 6\u001b[39m North America Services          \u001b[4m4\u001b[24m\u001b[4m8\u001b[24m884.         62\n",
      "\u001b[90m 7\u001b[39m Europe        Software          \u001b[4m4\u001b[24m\u001b[4m8\u001b[24m794.         77\n",
      "\u001b[90m 8\u001b[39m North America Hardware          \u001b[4m4\u001b[24m\u001b[4m8\u001b[24m772.         16\n",
      "\u001b[90m 9\u001b[39m North America Consulting        \u001b[4m4\u001b[24m\u001b[4m8\u001b[24m748.         63\n",
      "\u001b[90m10\u001b[39m Europe        Consulting        \u001b[4m4\u001b[24m\u001b[4m8\u001b[24m572.         22\n",
      "\u001b[90m# A tibble: 10 Ã— 4\u001b[39m\n",
      "   Region        Product_Category Revenue Units_Sold\n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m         \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m              \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m      \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m Asia Pacific  Consulting        \u001b[4m4\u001b[24m\u001b[4m9\u001b[24m956.         88\n",
      "\u001b[90m 2\u001b[39m Europe        Software          \u001b[4m4\u001b[24m\u001b[4m9\u001b[24m867.         96\n",
      "\u001b[90m 3\u001b[39m Europe        Consulting        \u001b[4m4\u001b[24m\u001b[4m9\u001b[24m857.          1\n",
      "\u001b[90m 4\u001b[39m Asia Pacific  Consulting        \u001b[4m4\u001b[24m\u001b[4m9\u001b[24m239.         72\n",
      "\u001b[90m 5\u001b[39m Asia Pacific  Hardware          \u001b[4m4\u001b[24m\u001b[4m8\u001b[24m997.         92\n",
      "\u001b[90m 6\u001b[39m North America Services          \u001b[4m4\u001b[24m\u001b[4m8\u001b[24m884.         62\n",
      "\u001b[90m 7\u001b[39m Europe        Software          \u001b[4m4\u001b[24m\u001b[4m8\u001b[24m794.         77\n",
      "\u001b[90m 8\u001b[39m North America Hardware          \u001b[4m4\u001b[24m\u001b[4m8\u001b[24m772.         16\n",
      "\u001b[90m 9\u001b[39m North America Consulting        \u001b[4m4\u001b[24m\u001b[4m8\u001b[24m748.         63\n",
      "\u001b[90m10\u001b[39m Europe        Consulting        \u001b[4m4\u001b[24m\u001b[4m8\u001b[24m572.         22\n"
     ]
    }
   ],
   "source": [
    "# Task 3.3: Sort by Revenue\n",
    "# Create 'top_sales' by arranging sales_clean by Revenue in descending order\n",
    "# and keeping only the top 10 rows\n",
    "\n",
    "# Ensure Revenue is numeric (should already be from Task 3.2, but coerce again to be safe)\n",
    "sales_clean <- sales_clean %>% dplyr::mutate(Revenue = as.numeric(Revenue))\n",
    "\n",
    "top_sales <- sales_clean %>%\n",
    "  dplyr::arrange(dplyr::desc(Revenue)) %>%\n",
    "  dplyr::slice_head(n = 10)\n",
    "\n",
    "cat(\"========== TOP 10 SALES ==========\\n\")\n",
    "print(top_sales %>% dplyr::select(Region, Product_Category, Revenue, Units_Sold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "chain_operations",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== REGIONAL TOP SALES ==========\n",
      "\u001b[90m# A tibble: 15 Ã— 3\u001b[39m\n",
      "   Region       Product_Category Revenue\n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m        \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m              \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m Asia Pacific Consulting        \u001b[4m4\u001b[24m\u001b[4m9\u001b[24m956.\n",
      "\u001b[90m 2\u001b[39m Asia Pacific Consulting        \u001b[4m4\u001b[24m\u001b[4m9\u001b[24m239.\n",
      "\u001b[90m 3\u001b[39m Asia Pacific Hardware          \u001b[4m4\u001b[24m\u001b[4m8\u001b[24m997.\n",
      "\u001b[90m 4\u001b[39m Asia Pacific Consulting        \u001b[4m4\u001b[24m\u001b[4m8\u001b[24m063.\n",
      "\u001b[90m 5\u001b[39m Asia Pacific Services          \u001b[4m4\u001b[24m\u001b[4m6\u001b[24m731.\n",
      "\u001b[90m 6\u001b[39m Asia Pacific Software          \u001b[4m4\u001b[24m\u001b[4m6\u001b[24m615.\n",
      "\u001b[90m 7\u001b[39m Asia Pacific Consulting        \u001b[4m4\u001b[24m\u001b[4m6\u001b[24m545.\n",
      "\u001b[90m 8\u001b[39m Asia Pacific Consulting        \u001b[4m4\u001b[24m\u001b[4m5\u001b[24m756.\n",
      "\u001b[90m 9\u001b[39m Asia Pacific Services          \u001b[4m4\u001b[24m\u001b[4m5\u001b[24m298.\n",
      "\u001b[90m10\u001b[39m Asia Pacific Services          \u001b[4m4\u001b[24m\u001b[4m4\u001b[24m624.\n",
      "\u001b[90m11\u001b[39m Asia Pacific Consulting        \u001b[4m4\u001b[24m\u001b[4m4\u001b[24m455.\n",
      "\u001b[90m12\u001b[39m Asia Pacific Consulting        \u001b[4m4\u001b[24m\u001b[4m4\u001b[24m364.\n",
      "\u001b[90m13\u001b[39m Asia Pacific Software          \u001b[4m4\u001b[24m\u001b[4m3\u001b[24m221.\n",
      "\u001b[90m14\u001b[39m Asia Pacific Software          \u001b[4m4\u001b[24m\u001b[4m2\u001b[24m063.\n",
      "\u001b[90m15\u001b[39m Asia Pacific Software          \u001b[4m4\u001b[24m\u001b[4m1\u001b[24m412.\n",
      "\u001b[90m# A tibble: 15 Ã— 3\u001b[39m\n",
      "   Region       Product_Category Revenue\n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m        \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m              \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m Asia Pacific Consulting        \u001b[4m4\u001b[24m\u001b[4m9\u001b[24m956.\n",
      "\u001b[90m 2\u001b[39m Asia Pacific Consulting        \u001b[4m4\u001b[24m\u001b[4m9\u001b[24m239.\n",
      "\u001b[90m 3\u001b[39m Asia Pacific Hardware          \u001b[4m4\u001b[24m\u001b[4m8\u001b[24m997.\n",
      "\u001b[90m 4\u001b[39m Asia Pacific Consulting        \u001b[4m4\u001b[24m\u001b[4m8\u001b[24m063.\n",
      "\u001b[90m 5\u001b[39m Asia Pacific Services          \u001b[4m4\u001b[24m\u001b[4m6\u001b[24m731.\n",
      "\u001b[90m 6\u001b[39m Asia Pacific Software          \u001b[4m4\u001b[24m\u001b[4m6\u001b[24m615.\n",
      "\u001b[90m 7\u001b[39m Asia Pacific Consulting        \u001b[4m4\u001b[24m\u001b[4m6\u001b[24m545.\n",
      "\u001b[90m 8\u001b[39m Asia Pacific Consulting        \u001b[4m4\u001b[24m\u001b[4m5\u001b[24m756.\n",
      "\u001b[90m 9\u001b[39m Asia Pacific Services          \u001b[4m4\u001b[24m\u001b[4m5\u001b[24m298.\n",
      "\u001b[90m10\u001b[39m Asia Pacific Services          \u001b[4m4\u001b[24m\u001b[4m4\u001b[24m624.\n",
      "\u001b[90m11\u001b[39m Asia Pacific Consulting        \u001b[4m4\u001b[24m\u001b[4m4\u001b[24m455.\n",
      "\u001b[90m12\u001b[39m Asia Pacific Consulting        \u001b[4m4\u001b[24m\u001b[4m4\u001b[24m364.\n",
      "\u001b[90m13\u001b[39m Asia Pacific Software          \u001b[4m4\u001b[24m\u001b[4m3\u001b[24m221.\n",
      "\u001b[90m14\u001b[39m Asia Pacific Software          \u001b[4m4\u001b[24m\u001b[4m2\u001b[24m063.\n",
      "\u001b[90m15\u001b[39m Asia Pacific Software          \u001b[4m4\u001b[24m\u001b[4m1\u001b[24m412.\n"
     ]
    }
   ],
   "source": [
    "# Task 3.4: Chain Multiple Operations\n",
    "# TODO: Create 'regional_top_sales' by:\n",
    "#   1. Filtering for Revenue > 15000\n",
    "#   2. Selecting: Region, Product_Category, Revenue\n",
    "#   3. Arranging by Region (ascending) then Revenue (descending)\n",
    "#   4. Keeping top 15 rows\n",
    "# Use the pipe operator to chain all operations\n",
    "\n",
    "regional_top_sales <- sales_clean %>%\n",
    "  dplyr::mutate(Revenue = as.numeric(Revenue)) %>%\n",
    "  dplyr::filter(!is.na(Revenue) & Revenue > 15000) %>%\n",
    "  dplyr::select(Region, Product_Category, Revenue) %>%\n",
    "  dplyr::arrange(Region, dplyr::desc(Revenue)) %>%\n",
    "  dplyr::slice_head(n = 15)\n",
    "\n",
    "cat(\"========== REGIONAL TOP SALES ==========\\n\")\n",
    "print(regional_top_sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part4_intro",
   "metadata": {},
   "source": [
    "## Part 4: Data Transformation Part 2 (Lesson 4)\n",
    "\n",
    "**Skills Assessed:** mutate(), summarize(), group_by()\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Create calculated columns with mutate()\n",
    "2. Calculate summary statistics\n",
    "3. Perform grouped analysis\n",
    "4. Generate business metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "mutate_columns",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== ENHANCED SALES DATA ==========\n",
      "New columns added: revenue_per_unit, high_value\n",
      "New columns added: revenue_per_unit, high_value\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 5 Ã— 4</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>Revenue</th><th scope=col>Units_Sold</th><th scope=col>revenue_per_unit</th><th scope=col>high_value</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>20750.92</td><td>78</td><td> 266.03744</td><td>Yes</td></tr>\n",
       "\t<tr><td>32359.98</td><td>13</td><td>2489.22923</td><td>Yes</td></tr>\n",
       "\t<tr><td>39268.40</td><td>34</td><td>1154.95294</td><td>Yes</td></tr>\n",
       "\t<tr><td>28865.09</td><td>90</td><td> 320.72322</td><td>Yes</td></tr>\n",
       "\t<tr><td> 3932.36</td><td>63</td><td>  62.41841</td><td>No </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 5 Ã— 4\n",
       "\\begin{tabular}{llll}\n",
       " Revenue & Units\\_Sold & revenue\\_per\\_unit & high\\_value\\\\\n",
       " <dbl> & <dbl> & <dbl> & <chr>\\\\\n",
       "\\hline\n",
       "\t 20750.92 & 78 &  266.03744 & Yes\\\\\n",
       "\t 32359.98 & 13 & 2489.22923 & Yes\\\\\n",
       "\t 39268.40 & 34 & 1154.95294 & Yes\\\\\n",
       "\t 28865.09 & 90 &  320.72322 & Yes\\\\\n",
       "\t  3932.36 & 63 &   62.41841 & No \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 5 Ã— 4\n",
       "\n",
       "| Revenue &lt;dbl&gt; | Units_Sold &lt;dbl&gt; | revenue_per_unit &lt;dbl&gt; | high_value &lt;chr&gt; |\n",
       "|---|---|---|---|\n",
       "| 20750.92 | 78 |  266.03744 | Yes |\n",
       "| 32359.98 | 13 | 2489.22923 | Yes |\n",
       "| 39268.40 | 34 | 1154.95294 | Yes |\n",
       "| 28865.09 | 90 |  320.72322 | Yes |\n",
       "|  3932.36 | 63 |   62.41841 | No  |\n",
       "\n"
      ],
      "text/plain": [
       "  Revenue  Units_Sold revenue_per_unit high_value\n",
       "1 20750.92 78          266.03744       Yes       \n",
       "2 32359.98 13         2489.22923       Yes       \n",
       "3 39268.40 34         1154.95294       Yes       \n",
       "4 28865.09 90          320.72322       Yes       \n",
       "5  3932.36 63           62.41841       No        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Task 4.1: Create Calculated Columns\n",
    "# TODO: Add these new columns to sales_clean using mutate():\n",
    "#   - revenue_per_unit: Revenue / Units_Sold\n",
    "#   - high_value: \"Yes\" if Revenue > 20000, else \"No\"\n",
    "# Store result in 'sales_enhanced'\n",
    "\n",
    "# Ensure numeric columns before calculations\n",
    "sales_enhanced <- sales_clean %>%\n",
    "  dplyr::mutate(\n",
    "    Revenue = as.numeric(Revenue),\n",
    "    Units_Sold = as.numeric(Units_Sold),\n",
    "    revenue_per_unit = ifelse(!is.na(Units_Sold) & Units_Sold != 0, Revenue / Units_Sold, NA_real_),\n",
    "    high_value = ifelse(!is.na(Revenue) & Revenue > 20000, 'Yes', 'No')\n",
    "  )\n",
    "\n",
    "cat(\"========== ENHANCED SALES DATA ==========\\n\")\n",
    "cat(\"New columns added: revenue_per_unit, high_value\\n\")\n",
    "head(sales_enhanced %>% dplyr::select(Revenue, Units_Sold, revenue_per_unit, high_value), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "summarize_data",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== OVERALL SUMMARY ==========\n",
      "\u001b[90m# A tibble: 1 Ã— 4\u001b[39m\n",
      "  total_revenue avg_revenue total_units transaction_count\n",
      "          \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m       \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m       \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m             \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m      7\u001b[4m7\u001b[24m\u001b[4m7\u001b[24m\u001b[4m1\u001b[24m711.      \u001b[4m2\u001b[24m\u001b[4m5\u001b[24m906.       \u001b[4m1\u001b[24m\u001b[4m6\u001b[24m169               300\n",
      "\u001b[90m# A tibble: 1 Ã— 4\u001b[39m\n",
      "  total_revenue avg_revenue total_units transaction_count\n",
      "          \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m       \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m       \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m             \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m      7\u001b[4m7\u001b[24m\u001b[4m7\u001b[24m\u001b[4m1\u001b[24m711.      \u001b[4m2\u001b[24m\u001b[4m5\u001b[24m906.       \u001b[4m1\u001b[24m\u001b[4m6\u001b[24m169               300\n"
     ]
    }
   ],
   "source": [
    "# Task 4.2: Calculate Overall Summary Statistics\n",
    "# Create 'overall_summary' with these metrics from sales_enhanced:\n",
    "#   - total_revenue: sum of Revenue\n",
    "#   - avg_revenue: mean of Revenue\n",
    "#   - total_units: sum of Units_Sold\n",
    "#   - transaction_count: count using n()\n",
    "\n",
    "overall_summary <- sales_enhanced %>%\n",
    "  dplyr::summarize(\n",
    "    total_revenue = sum(Revenue, na.rm = TRUE),\n",
    "    avg_revenue = mean(Revenue, na.rm = TRUE),\n",
    "    total_units = sum(Units_Sold, na.rm = TRUE),\n",
    "    transaction_count = dplyr::n()\n",
    "  )\n",
    "\n",
    "cat(\"========== OVERALL SUMMARY ==========\\n\")\n",
    "print(overall_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "group_by_region",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== REGIONAL SUMMARY ==========\n",
      "\u001b[90m# A tibble: 4 Ã— 4\u001b[39m\n",
      "  Region        total_revenue avg_revenue transaction_count\n",
      "  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                 \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m       \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m             \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m Europe             2\u001b[4m2\u001b[24m\u001b[4m2\u001b[24m\u001b[4m4\u001b[24m182.      \u001b[4m2\u001b[24m\u001b[4m7\u001b[24m124.                82\n",
      "\u001b[90m2\u001b[39m Latin America      2\u001b[4m1\u001b[24m\u001b[4m1\u001b[24m\u001b[4m2\u001b[24m037.      \u001b[4m2\u001b[24m\u001b[4m5\u001b[24m446.                83\n",
      "\u001b[90m3\u001b[39m Asia Pacific       1\u001b[4m8\u001b[24m\u001b[4m0\u001b[24m\u001b[4m4\u001b[24m243.      \u001b[4m2\u001b[24m\u001b[4m6\u001b[24m929.                67\n",
      "\u001b[90m4\u001b[39m North America      1\u001b[4m6\u001b[24m\u001b[4m3\u001b[24m\u001b[4m1\u001b[24m248.      \u001b[4m2\u001b[24m\u001b[4m3\u001b[24m989.                68\n",
      "\u001b[90m# A tibble: 4 Ã— 4\u001b[39m\n",
      "  Region        total_revenue avg_revenue transaction_count\n",
      "  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                 \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m       \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m             \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m Europe             2\u001b[4m2\u001b[24m\u001b[4m2\u001b[24m\u001b[4m4\u001b[24m182.      \u001b[4m2\u001b[24m\u001b[4m7\u001b[24m124.                82\n",
      "\u001b[90m2\u001b[39m Latin America      2\u001b[4m1\u001b[24m\u001b[4m1\u001b[24m\u001b[4m2\u001b[24m037.      \u001b[4m2\u001b[24m\u001b[4m5\u001b[24m446.                83\n",
      "\u001b[90m3\u001b[39m Asia Pacific       1\u001b[4m8\u001b[24m\u001b[4m0\u001b[24m\u001b[4m4\u001b[24m243.      \u001b[4m2\u001b[24m\u001b[4m6\u001b[24m929.                67\n",
      "\u001b[90m4\u001b[39m North America      1\u001b[4m6\u001b[24m\u001b[4m3\u001b[24m\u001b[4m1\u001b[24m248.      \u001b[4m2\u001b[24m\u001b[4m3\u001b[24m989.                68\n"
     ]
    }
   ],
   "source": [
    "# Task 4.3: Regional Performance Analysis\n",
    "# TODO: Create 'regional_summary' by grouping sales_enhanced by Region\n",
    "#       and calculating:\n",
    "#   - total_revenue: sum of Revenue\n",
    "#   - avg_revenue: mean of Revenue\n",
    "#   - transaction_count: count using n()\n",
    "# Then arrange by total_revenue descending\n",
    "# Hint: Use group_by() %>% summarize() %>% arrange()\n",
    "\n",
    "regional_summary <- sales_enhanced %>%\n",
    "  dplyr::mutate(Revenue = as.numeric(Revenue)) %>%\n",
    "  dplyr::group_by(Region) %>%\n",
    "  dplyr::summarize(\n",
    "    total_revenue = sum(Revenue, na.rm = TRUE),\n",
    "    avg_revenue = mean(Revenue, na.rm = TRUE),\n",
    "    transaction_count = dplyr::n(),\n",
    "    .groups = 'drop'\n",
    "  ) %>%\n",
    "  dplyr::arrange(dplyr::desc(total_revenue))\n",
    "\n",
    "cat(\"========== REGIONAL SUMMARY ==========\\n\")\n",
    "print(regional_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "group_by_category",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== CATEGORY SUMMARY ==========\n",
      "\u001b[90m# A tibble: 4 Ã— 4\u001b[39m\n",
      "  Product_Category total_revenue avg_revenue transaction_count\n",
      "  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                    \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m       \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m             \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m Consulting            1\u001b[4m9\u001b[24m\u001b[4m7\u001b[24m\u001b[4m8\u001b[24m840.      \u001b[4m2\u001b[24m\u001b[4m6\u001b[24m037.                76\n",
      "\u001b[90m2\u001b[39m Services              1\u001b[4m9\u001b[24m\u001b[4m6\u001b[24m\u001b[4m1\u001b[24m565.      \u001b[4m2\u001b[24m\u001b[4m7\u001b[24m244.                72\n",
      "\u001b[90m3\u001b[39m Hardware              1\u001b[4m9\u001b[24m\u001b[4m5\u001b[24m\u001b[4m1\u001b[24m325.      \u001b[4m2\u001b[24m\u001b[4m6\u001b[24m730.                73\n",
      "\u001b[90m4\u001b[39m Software              1\u001b[4m8\u001b[24m\u001b[4m7\u001b[24m\u001b[4m9\u001b[24m981.      \u001b[4m2\u001b[24m\u001b[4m3\u001b[24m797.                79\n",
      "\u001b[90m# A tibble: 4 Ã— 4\u001b[39m\n",
      "  Product_Category total_revenue avg_revenue transaction_count\n",
      "  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                    \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m       \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m             \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m Consulting            1\u001b[4m9\u001b[24m\u001b[4m7\u001b[24m\u001b[4m8\u001b[24m840.      \u001b[4m2\u001b[24m\u001b[4m6\u001b[24m037.                76\n",
      "\u001b[90m2\u001b[39m Services              1\u001b[4m9\u001b[24m\u001b[4m6\u001b[24m\u001b[4m1\u001b[24m565.      \u001b[4m2\u001b[24m\u001b[4m7\u001b[24m244.                72\n",
      "\u001b[90m3\u001b[39m Hardware              1\u001b[4m9\u001b[24m\u001b[4m5\u001b[24m\u001b[4m1\u001b[24m325.      \u001b[4m2\u001b[24m\u001b[4m6\u001b[24m730.                73\n",
      "\u001b[90m4\u001b[39m Software              1\u001b[4m8\u001b[24m\u001b[4m7\u001b[24m\u001b[4m9\u001b[24m981.      \u001b[4m2\u001b[24m\u001b[4m3\u001b[24m797.                79\n"
     ]
    }
   ],
   "source": [
    "# Task 4.4: Product Category Analysis\n",
    "# TODO: Create 'category_summary' by grouping by Product_Category\n",
    "#       and calculating the same metrics as regional_summary\n",
    "#       Then arrange by total_revenue descending\n",
    "\n",
    "category_summary <- sales_enhanced %>%\n",
    "  dplyr::mutate(Revenue = as.numeric(Revenue)) %>%\n",
    "  dplyr::group_by(Product_Category) %>%\n",
    "  dplyr::summarize(\n",
    "    total_revenue = sum(Revenue, na.rm = TRUE),\n",
    "    avg_revenue = mean(Revenue, na.rm = TRUE),\n",
    "    transaction_count = dplyr::n(),\n",
    "    .groups = 'drop'\n",
    "  ) %>%\n",
    "  dplyr::arrange(dplyr::desc(total_revenue))\n",
    "\n",
    "cat(\"========== CATEGORY SUMMARY ==========\\n\")\n",
    "print(category_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part5_intro",
   "metadata": {},
   "source": [
    "## Part 5: Data Reshaping with tidyr (Lesson 5)\n",
    "\n",
    "**Skills Assessed:** pivot_longer(), pivot_wider(), tidy data principles\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Reshape data from wide to long format\n",
    "2. Reshape data from long to wide format\n",
    "3. Create analysis-ready datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "create_wide_data",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== REGION-CATEGORY DATA (LONG FORMAT) ==========\n",
      "\u001b[90m# A tibble: 10 Ã— 3\u001b[39m\n",
      "   Region        Product_Category total_revenue\n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m         \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                    \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m Asia Pacific  Consulting             \u001b[4m7\u001b[24m\u001b[4m5\u001b[24m\u001b[4m9\u001b[24m641.\n",
      "\u001b[90m 2\u001b[39m Asia Pacific  Hardware               \u001b[4m2\u001b[24m\u001b[4m7\u001b[24m\u001b[4m1\u001b[24m979.\n",
      "\u001b[90m 3\u001b[39m Asia Pacific  Services               \u001b[4m3\u001b[24m\u001b[4m3\u001b[24m\u001b[4m1\u001b[24m826.\n",
      "\u001b[90m 4\u001b[39m Asia Pacific  Software               \u001b[4m4\u001b[24m\u001b[4m4\u001b[24m\u001b[4m0\u001b[24m797.\n",
      "\u001b[90m 5\u001b[39m Europe        Consulting             \u001b[4m3\u001b[24m\u001b[4m9\u001b[24m\u001b[4m0\u001b[24m670.\n",
      "\u001b[90m 6\u001b[39m Europe        Hardware               \u001b[4m7\u001b[24m\u001b[4m7\u001b[24m\u001b[4m7\u001b[24m044.\n",
      "\u001b[90m 7\u001b[39m Europe        Services               \u001b[4m5\u001b[24m\u001b[4m1\u001b[24m\u001b[4m3\u001b[24m507.\n",
      "\u001b[90m 8\u001b[39m Europe        Software               \u001b[4m5\u001b[24m\u001b[4m4\u001b[24m\u001b[4m2\u001b[24m961.\n",
      "\u001b[90m 9\u001b[39m Latin America Consulting             \u001b[4m4\u001b[24m\u001b[4m3\u001b[24m\u001b[4m3\u001b[24m397.\n",
      "\u001b[90m10\u001b[39m Latin America Hardware               \u001b[4m4\u001b[24m\u001b[4m7\u001b[24m\u001b[4m4\u001b[24m257.\n",
      "\u001b[90m# A tibble: 10 Ã— 3\u001b[39m\n",
      "   Region        Product_Category total_revenue\n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m         \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                    \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m Asia Pacific  Consulting             \u001b[4m7\u001b[24m\u001b[4m5\u001b[24m\u001b[4m9\u001b[24m641.\n",
      "\u001b[90m 2\u001b[39m Asia Pacific  Hardware               \u001b[4m2\u001b[24m\u001b[4m7\u001b[24m\u001b[4m1\u001b[24m979.\n",
      "\u001b[90m 3\u001b[39m Asia Pacific  Services               \u001b[4m3\u001b[24m\u001b[4m3\u001b[24m\u001b[4m1\u001b[24m826.\n",
      "\u001b[90m 4\u001b[39m Asia Pacific  Software               \u001b[4m4\u001b[24m\u001b[4m4\u001b[24m\u001b[4m0\u001b[24m797.\n",
      "\u001b[90m 5\u001b[39m Europe        Consulting             \u001b[4m3\u001b[24m\u001b[4m9\u001b[24m\u001b[4m0\u001b[24m670.\n",
      "\u001b[90m 6\u001b[39m Europe        Hardware               \u001b[4m7\u001b[24m\u001b[4m7\u001b[24m\u001b[4m7\u001b[24m044.\n",
      "\u001b[90m 7\u001b[39m Europe        Services               \u001b[4m5\u001b[24m\u001b[4m1\u001b[24m\u001b[4m3\u001b[24m507.\n",
      "\u001b[90m 8\u001b[39m Europe        Software               \u001b[4m5\u001b[24m\u001b[4m4\u001b[24m\u001b[4m2\u001b[24m961.\n",
      "\u001b[90m 9\u001b[39m Latin America Consulting             \u001b[4m4\u001b[24m\u001b[4m3\u001b[24m\u001b[4m3\u001b[24m397.\n",
      "\u001b[90m10\u001b[39m Latin America Hardware               \u001b[4m4\u001b[24m\u001b[4m7\u001b[24m\u001b[4m4\u001b[24m257.\n"
     ]
    }
   ],
   "source": [
    "# Task 5.1: Create Wide Format Data\n",
    "# First, create a summary by Region and Product_Category\n",
    "region_category_revenue <- sales_enhanced %>%\n",
    "  group_by(Region, Product_Category) %>%\n",
    "  summarize(total_revenue = sum(Revenue), .groups = 'drop')\n",
    "\n",
    "cat(\"========== REGION-CATEGORY DATA (LONG FORMAT) ==========\\n\")\n",
    "print(head(region_category_revenue, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "pivot_wider",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== REVENUE DATA (WIDE FORMAT) ==========\n",
      "\u001b[90m# A tibble: 4 Ã— 5\u001b[39m\n",
      "  Region        Consulting Hardware Services Software\n",
      "  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m              \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m    \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m    \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m    \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m Asia Pacific     \u001b[4m7\u001b[24m\u001b[4m5\u001b[24m\u001b[4m9\u001b[24m641.  \u001b[4m2\u001b[24m\u001b[4m7\u001b[24m\u001b[4m1\u001b[24m979.  \u001b[4m3\u001b[24m\u001b[4m3\u001b[24m\u001b[4m1\u001b[24m826.  \u001b[4m4\u001b[24m\u001b[4m4\u001b[24m\u001b[4m0\u001b[24m797.\n",
      "\u001b[90m2\u001b[39m Europe           \u001b[4m3\u001b[24m\u001b[4m9\u001b[24m\u001b[4m0\u001b[24m670.  \u001b[4m7\u001b[24m\u001b[4m7\u001b[24m\u001b[4m7\u001b[24m044.  \u001b[4m5\u001b[24m\u001b[4m1\u001b[24m\u001b[4m3\u001b[24m507.  \u001b[4m5\u001b[24m\u001b[4m4\u001b[24m\u001b[4m2\u001b[24m961.\n",
      "\u001b[90m3\u001b[39m Latin America    \u001b[4m4\u001b[24m\u001b[4m3\u001b[24m\u001b[4m3\u001b[24m397.  \u001b[4m4\u001b[24m\u001b[4m7\u001b[24m\u001b[4m4\u001b[24m257.  \u001b[4m6\u001b[24m\u001b[4m4\u001b[24m\u001b[4m4\u001b[24m772.  \u001b[4m5\u001b[24m\u001b[4m5\u001b[24m\u001b[4m9\u001b[24m611.\n",
      "\u001b[90m4\u001b[39m North America    \u001b[4m3\u001b[24m\u001b[4m9\u001b[24m\u001b[4m5\u001b[24m132.  \u001b[4m4\u001b[24m\u001b[4m2\u001b[24m\u001b[4m8\u001b[24m046.  \u001b[4m4\u001b[24m\u001b[4m7\u001b[24m\u001b[4m1\u001b[24m460.  \u001b[4m3\u001b[24m\u001b[4m3\u001b[24m\u001b[4m6\u001b[24m611.\n",
      "\u001b[90m# A tibble: 4 Ã— 5\u001b[39m\n",
      "  Region        Consulting Hardware Services Software\n",
      "  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m              \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m    \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m    \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m    \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m Asia Pacific     \u001b[4m7\u001b[24m\u001b[4m5\u001b[24m\u001b[4m9\u001b[24m641.  \u001b[4m2\u001b[24m\u001b[4m7\u001b[24m\u001b[4m1\u001b[24m979.  \u001b[4m3\u001b[24m\u001b[4m3\u001b[24m\u001b[4m1\u001b[24m826.  \u001b[4m4\u001b[24m\u001b[4m4\u001b[24m\u001b[4m0\u001b[24m797.\n",
      "\u001b[90m2\u001b[39m Europe           \u001b[4m3\u001b[24m\u001b[4m9\u001b[24m\u001b[4m0\u001b[24m670.  \u001b[4m7\u001b[24m\u001b[4m7\u001b[24m\u001b[4m7\u001b[24m044.  \u001b[4m5\u001b[24m\u001b[4m1\u001b[24m\u001b[4m3\u001b[24m507.  \u001b[4m5\u001b[24m\u001b[4m4\u001b[24m\u001b[4m2\u001b[24m961.\n",
      "\u001b[90m3\u001b[39m Latin America    \u001b[4m4\u001b[24m\u001b[4m3\u001b[24m\u001b[4m3\u001b[24m397.  \u001b[4m4\u001b[24m\u001b[4m7\u001b[24m\u001b[4m4\u001b[24m257.  \u001b[4m6\u001b[24m\u001b[4m4\u001b[24m\u001b[4m4\u001b[24m772.  \u001b[4m5\u001b[24m\u001b[4m5\u001b[24m\u001b[4m9\u001b[24m611.\n",
      "\u001b[90m4\u001b[39m North America    \u001b[4m3\u001b[24m\u001b[4m9\u001b[24m\u001b[4m5\u001b[24m132.  \u001b[4m4\u001b[24m\u001b[4m2\u001b[24m\u001b[4m8\u001b[24m046.  \u001b[4m4\u001b[24m\u001b[4m7\u001b[24m\u001b[4m1\u001b[24m460.  \u001b[4m3\u001b[24m\u001b[4m3\u001b[24m\u001b[4m6\u001b[24m611.\n"
     ]
    }
   ],
   "source": [
    "# Task 5.2: Reshape to Wide Format\n",
    "# TODO: Create 'revenue_wide' by pivoting region_category_revenue\n",
    "#       so that Product_Category values become column names\n",
    "#       with total_revenue as the values\n",
    "\n",
    "\n",
    "revenue_wide <- region_category_revenue %>%\n",
    "  tidyr::pivot_wider(\n",
    "    names_from = Product_Category,\n",
    "    values_from = total_revenue,\n",
    "    values_fill = list(total_revenue = 0)\n",
    "  ) %>%\n",
    "  # Make column names safe (optional)\n",
    "  dplyr::rename_with(~ make.names(., unique = TRUE))\n",
    "\n",
    "cat(\"========== REVENUE DATA (WIDE FORMAT) ==========\\n\")\n",
    "print(revenue_wide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "pivot_longer",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== REVENUE DATA (BACK TO LONG FORMAT) ==========\n",
      "\u001b[90m# A tibble: 10 Ã— 3\u001b[39m\n",
      "   Region        Product_Category revenue\n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m         \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m              \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m Asia Pacific  Consulting       \u001b[4m7\u001b[24m\u001b[4m5\u001b[24m\u001b[4m9\u001b[24m641.\n",
      "\u001b[90m 2\u001b[39m Asia Pacific  Software         \u001b[4m4\u001b[24m\u001b[4m4\u001b[24m\u001b[4m0\u001b[24m797.\n",
      "\u001b[90m 3\u001b[39m Asia Pacific  Services         \u001b[4m3\u001b[24m\u001b[4m3\u001b[24m\u001b[4m1\u001b[24m826.\n",
      "\u001b[90m 4\u001b[39m Asia Pacific  Hardware         \u001b[4m2\u001b[24m\u001b[4m7\u001b[24m\u001b[4m1\u001b[24m979.\n",
      "\u001b[90m 5\u001b[39m Europe        Hardware         \u001b[4m7\u001b[24m\u001b[4m7\u001b[24m\u001b[4m7\u001b[24m044.\n",
      "\u001b[90m 6\u001b[39m Europe        Software         \u001b[4m5\u001b[24m\u001b[4m4\u001b[24m\u001b[4m2\u001b[24m961.\n",
      "\u001b[90m 7\u001b[39m Europe        Services         \u001b[4m5\u001b[24m\u001b[4m1\u001b[24m\u001b[4m3\u001b[24m507.\n",
      "\u001b[90m 8\u001b[39m Europe        Consulting       \u001b[4m3\u001b[24m\u001b[4m9\u001b[24m\u001b[4m0\u001b[24m670.\n",
      "\u001b[90m 9\u001b[39m Latin America Services         \u001b[4m6\u001b[24m\u001b[4m4\u001b[24m\u001b[4m4\u001b[24m772.\n",
      "\u001b[90m10\u001b[39m Latin America Software         \u001b[4m5\u001b[24m\u001b[4m5\u001b[24m\u001b[4m9\u001b[24m611.\n",
      "\u001b[90m# A tibble: 10 Ã— 3\u001b[39m\n",
      "   Region        Product_Category revenue\n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m         \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m              \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m Asia Pacific  Consulting       \u001b[4m7\u001b[24m\u001b[4m5\u001b[24m\u001b[4m9\u001b[24m641.\n",
      "\u001b[90m 2\u001b[39m Asia Pacific  Software         \u001b[4m4\u001b[24m\u001b[4m4\u001b[24m\u001b[4m0\u001b[24m797.\n",
      "\u001b[90m 3\u001b[39m Asia Pacific  Services         \u001b[4m3\u001b[24m\u001b[4m3\u001b[24m\u001b[4m1\u001b[24m826.\n",
      "\u001b[90m 4\u001b[39m Asia Pacific  Hardware         \u001b[4m2\u001b[24m\u001b[4m7\u001b[24m\u001b[4m1\u001b[24m979.\n",
      "\u001b[90m 5\u001b[39m Europe        Hardware         \u001b[4m7\u001b[24m\u001b[4m7\u001b[24m\u001b[4m7\u001b[24m044.\n",
      "\u001b[90m 6\u001b[39m Europe        Software         \u001b[4m5\u001b[24m\u001b[4m4\u001b[24m\u001b[4m2\u001b[24m961.\n",
      "\u001b[90m 7\u001b[39m Europe        Services         \u001b[4m5\u001b[24m\u001b[4m1\u001b[24m\u001b[4m3\u001b[24m507.\n",
      "\u001b[90m 8\u001b[39m Europe        Consulting       \u001b[4m3\u001b[24m\u001b[4m9\u001b[24m\u001b[4m0\u001b[24m670.\n",
      "\u001b[90m 9\u001b[39m Latin America Services         \u001b[4m6\u001b[24m\u001b[4m4\u001b[24m\u001b[4m4\u001b[24m772.\n",
      "\u001b[90m10\u001b[39m Latin America Software         \u001b[4m5\u001b[24m\u001b[4m5\u001b[24m\u001b[4m9\u001b[24m611.\n"
     ]
    }
   ],
   "source": [
    "# Task 5.3: Reshape Back to Long Format\n",
    "# TODO: Create 'revenue_long' by pivoting revenue_wide back to long format\n",
    "#       Column names (except Region) should go into 'Product_Category'\n",
    "#       Values should go into 'revenue'\n",
    "\n",
    "\n",
    "revenue_long <- revenue_wide %>%\n",
    "  tidyr::pivot_longer(\n",
    "    cols = -Region,\n",
    "    names_to = 'Product_Category',\n",
    "    values_to = 'revenue'\n",
    "  ) %>%\n",
    "  # If column names were made syntactic, reverse make.names() effects where possible\n",
    "  dplyr::mutate(\n",
    "    Product_Category = gsub('.', ' ', Product_Category, fixed = TRUE),\n",
    "    revenue = as.numeric(revenue)\n",
    "  ) %>%\n",
    "  dplyr::arrange(Region, dplyr::desc(revenue))\n",
    "\n",
    "cat(\"========== REVENUE DATA (BACK TO LONG FORMAT) ==========\\n\")\n",
    "print(head(revenue_long, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part6_intro",
   "metadata": {},
   "source": [
    "## Part 6: Combining Datasets with Joins (Lesson 6)\n",
    "\n",
    "**Skills Assessed:** left_join(), inner_join(), data integration\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Join customers with orders\n",
    "2. Join orders with order_items\n",
    "3. Create integrated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "join_customers_orders",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== CUSTOMER ORDERS ==========\n",
      "Detected join keys -> customers: CustomerID , orders: CustomerID \n",
      "Total rows (customer_orders): 200 \n",
      "Columns (customer_orders): 8 \n",
      "Detected join keys -> customers: CustomerID , orders: CustomerID \n",
      "Total rows (customer_orders): 200 \n",
      "Columns (customer_orders): 8 \n",
      "\u001b[90m# A tibble: 5 Ã— 8\u001b[39m\n",
      "  CustomerID Name  Email City  Registration_Date OrderID Order_Date Total_Amount\n",
      "       \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<date>\u001b[39m\u001b[23m              \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<date>\u001b[39m\u001b[23m            \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m          1 Custâ€¦ custâ€¦ Phoeâ€¦ 2020-10-03             87 2023-03-28         716.\n",
      "\u001b[90m2\u001b[39m          1 Custâ€¦ custâ€¦ Phoeâ€¦ 2020-10-03            214 2023-09-12        \u001b[4m1\u001b[24m344.\n",
      "\u001b[90m3\u001b[39m          2 Custâ€¦ custâ€¦ Los â€¦ 2020-06-02            173 2024-02-25         160.\n",
      "\u001b[90m4\u001b[39m          2 Custâ€¦ custâ€¦ Los â€¦ 2020-06-02            190 2023-04-19        \u001b[4m1\u001b[24m503.\n",
      "\u001b[90m5\u001b[39m          3 Custâ€¦ custâ€¦ Chicâ€¦ 2021-04-20             29 2023-03-07         441.\n",
      "\u001b[90m# A tibble: 5 Ã— 8\u001b[39m\n",
      "  CustomerID Name  Email City  Registration_Date OrderID Order_Date Total_Amount\n",
      "       \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<date>\u001b[39m\u001b[23m              \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<date>\u001b[39m\u001b[23m            \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m          1 Custâ€¦ custâ€¦ Phoeâ€¦ 2020-10-03             87 2023-03-28         716.\n",
      "\u001b[90m2\u001b[39m          1 Custâ€¦ custâ€¦ Phoeâ€¦ 2020-10-03            214 2023-09-12        \u001b[4m1\u001b[24m344.\n",
      "\u001b[90m3\u001b[39m          2 Custâ€¦ custâ€¦ Los â€¦ 2020-06-02            173 2024-02-25         160.\n",
      "\u001b[90m4\u001b[39m          2 Custâ€¦ custâ€¦ Los â€¦ 2020-06-02            190 2023-04-19        \u001b[4m1\u001b[24m503.\n",
      "\u001b[90m5\u001b[39m          3 Custâ€¦ custâ€¦ Chicâ€¦ 2021-04-20             29 2023-03-07         441.\n"
     ]
    }
   ],
   "source": [
    "# Task 6.1: Join Customers and Orders\n",
    "# Create 'customer_orders' by left joining customers with orders\n",
    "# Robust join: try common key name variants (CustomerID, customer_id, CustomerId)\n",
    "\n",
    "# Detect possible join keys in each dataframe\n",
    "cust_keys <- tolower(names(customers))\n",
    "order_keys <- tolower(names(orders))\n",
    "possible_keys <- c('customerid', 'customer_id', 'customerid', 'customerid')\n",
    "join_key <- NULL\n",
    "order_key <- NULL\n",
    "for (k in possible_keys) {\n",
    "  if (k %in% cust_keys && k %in% order_keys) {\n",
    "    # use the original column names as present in dataframes\n",
    "    join_key <- names(customers)[which(cust_keys == k)[1]]\n",
    "    order_key <- names(orders)[which(order_keys == k)[1]]\n",
    "    break\n",
    "  }\n",
    "}\n",
    "if (is.null(join_key)) {\n",
    "  stop('Could not find a common Customer key in customers and orders dataframes')\n",
    "}\n",
    "\n",
    "# Perform left join using the detected keys (allow differing names)\n",
    "customer_orders <- dplyr::left_join(customers, orders, by = setNames(order_key, join_key))\n",
    "\n",
    "cat(\"========== CUSTOMER ORDERS ==========\\n\")\n",
    "cat(\"Detected join keys -> customers:\", join_key, \", orders:\", order_key, \"\\n\")\n",
    "cat(\"Total rows (customer_orders):\", nrow(customer_orders), \"\\n\")\n",
    "cat(\"Columns (customer_orders):\", ncol(customer_orders), \"\\n\")\n",
    "# show a small sample to validate the join\n",
    "print(head(customer_orders, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "join_orders_items",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== ORDERS WITH ITEMS ==========\n",
      "Detected order join keys -> orders: OrderID , order_items: OrderID \n",
      "Total rows (orders_with_items): 400 \n",
      "Columns (orders_with_items): 7 \n",
      "Detected order join keys -> orders: OrderID , order_items: OrderID \n",
      "Total rows (orders_with_items): 400 \n",
      "Columns (orders_with_items): 7 \n",
      "\u001b[90m# A tibble: 5 Ã— 7\u001b[39m\n",
      "  OrderID CustomerID Order_Date Total_Amount ProductID Quantity Unit_Price\n",
      "    \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m      \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<date>\u001b[39m\u001b[23m            \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m     \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m    \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m      \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m       1         87 2023-08-30         424.         2        3      116. \n",
      "\u001b[90m2\u001b[39m       1         87 2023-08-30         424.        22        5      207. \n",
      "\u001b[90m3\u001b[39m       1         87 2023-08-30         424.        26        5       61.8\n",
      "\u001b[90m4\u001b[39m       3         37 2024-03-19         549.        19        1      475. \n",
      "\u001b[90m5\u001b[39m       6        101 2023-07-22         190.        32        4      273. \n",
      "\u001b[90m# A tibble: 5 Ã— 7\u001b[39m\n",
      "  OrderID CustomerID Order_Date Total_Amount ProductID Quantity Unit_Price\n",
      "    \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m      \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<date>\u001b[39m\u001b[23m            \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m     \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m    \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m      \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m       1         87 2023-08-30         424.         2        3      116. \n",
      "\u001b[90m2\u001b[39m       1         87 2023-08-30         424.        22        5      207. \n",
      "\u001b[90m3\u001b[39m       1         87 2023-08-30         424.        26        5       61.8\n",
      "\u001b[90m4\u001b[39m       3         37 2024-03-19         549.        19        1      475. \n",
      "\u001b[90m5\u001b[39m       6        101 2023-07-22         190.        32        4      273. \n"
     ]
    }
   ],
   "source": [
    "# Task 6.2: Join Orders and Order Items\n",
    "# Create 'orders_with_items' by inner joining orders with order_items\n",
    "# Robust join: detect common Order key variants (OrderID, order_id, OrderId)\n",
    "\n",
    "order_keys_orders <- tolower(names(orders))\n",
    "order_keys_items  <- tolower(names(order_items))\n",
    "possible_order_keys <- c('orderid', 'order_id', 'orderid', 'orderid')\n",
    "order_join_key <- NULL\n",
    "order_item_key <- NULL\n",
    "for (k in possible_order_keys) {\n",
    "  if (k %in% order_keys_orders && k %in% order_keys_items) {\n",
    "    order_join_key <- names(orders)[which(order_keys_orders == k)[1]]\n",
    "    order_item_key <- names(order_items)[which(order_keys_items == k)[1]]\n",
    "    break\n",
    "  }\n",
    "}\n",
    "if (is.null(order_join_key)) {\n",
    "  stop('Could not find a common Order key in orders and order_items dataframes')\n",
    "}\n",
    "\n",
    "# Perform inner join (orders -> order_items)\n",
    "orders_with_items <- dplyr::inner_join(orders, order_items, by = setNames(order_item_key, order_join_key))\n",
    "\n",
    "cat(\"========== ORDERS WITH ITEMS ==========\\n\")\n",
    "cat(\"Detected order join keys -> orders:\", order_join_key, \", order_items:\", order_item_key, \"\\n\")\n",
    "cat(\"Total rows (orders_with_items):\", nrow(orders_with_items), \"\\n\")\n",
    "cat(\"Columns (orders_with_items):\", ncol(orders_with_items), \"\\n\")\n",
    "print(head(orders_with_items, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part7_intro",
   "metadata": {},
   "source": [
    "## Part 7: String Manipulation & Date/Time Operations (Lesson 7)\n",
    "\n",
    "**Skills Assessed:** stringr functions, lubridate functions\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Clean text data\n",
    "2. Parse dates\n",
    "3. Extract date components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "clean_text",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== CLEANED TEXT DATA ==========\n",
      "\u001b[90m# A tibble: 5 Ã— 4\u001b[39m\n",
      "  Region        region_clean  Product_Category category_clean\n",
      "  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m         \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m         \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m            \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m         \n",
      "\u001b[90m1\u001b[39m Latin America Latin America Services         Services      \n",
      "\u001b[90m2\u001b[39m Europe        Europe        Hardware         Hardware      \n",
      "\u001b[90m3\u001b[39m Europe        Europe        Services         Services      \n",
      "\u001b[90m4\u001b[39m Europe        Europe        Hardware         Hardware      \n",
      "\u001b[90m5\u001b[39m Latin America Latin America Software         Software      \n",
      "\u001b[90m# A tibble: 5 Ã— 4\u001b[39m\n",
      "  Region        region_clean  Product_Category category_clean\n",
      "  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m         \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m         \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m            \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m         \n",
      "\u001b[90m1\u001b[39m Latin America Latin America Services         Services      \n",
      "\u001b[90m2\u001b[39m Europe        Europe        Hardware         Hardware      \n",
      "\u001b[90m3\u001b[39m Europe        Europe        Services         Services      \n",
      "\u001b[90m4\u001b[39m Europe        Europe        Hardware         Hardware      \n",
      "\u001b[90m5\u001b[39m Latin America Latin America Software         Software      \n"
     ]
    }
   ],
   "source": [
    "# Task 7.1: Clean Text Data\n",
    "# TODO: Add these columns to sales_enhanced using mutate():\n",
    "#   - region_clean: Region with trimmed whitespace and Title Case\n",
    "#   - category_clean: Product_Category with trimmed whitespace and Title Case\n",
    "\n",
    "\n",
    "sales_enhanced <- sales_enhanced %>%\n",
    "  dplyr::mutate(\n",
    "    # Trim whitespace and convert to Title Case for consistency\n",
    "    region_clean = stringr::str_to_title(stringr::str_squish(as.character(Region))),\n",
    "    category_clean = stringr::str_to_title(stringr::str_squish(as.character(Product_Category)))\n",
    "  )\n",
    "\n",
    "cat(\"========== CLEANED TEXT DATA ==========\\n\")\n",
    "print(head(sales_enhanced %>% dplyr::select(Region, region_clean, Product_Category, category_clean), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "parse_dates",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== DATE COMPONENTS ==========\n",
      "\u001b[90m# A tibble: 5 Ã— 5\u001b[39m\n",
      "  Sale_Date  raw_sale_date date_parsed   sale_month sale_weekday\n",
      "  \u001b[3m\u001b[90m<date>\u001b[39m\u001b[23m     \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m         \u001b[3m\u001b[90m<date>\u001b[39m\u001b[23m        \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m      \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m       \n",
      "\u001b[90m1\u001b[39m 2023-04-24 2023-04-24    4607935-08-18 August     Sunday      \n",
      "\u001b[90m2\u001b[39m 2023-06-09 2023-06-09    4618817-03-01 March      Wednesday   \n",
      "\u001b[90m3\u001b[39m 2023-03-25 2023-03-25    4600838-12-21 December   Tuesday     \n",
      "\u001b[90m4\u001b[39m 2023-04-11 2023-04-11    4604860-05-29 May        Saturday    \n",
      "\u001b[90m5\u001b[39m 2023-08-26 2023-08-26    4637268-06-19 June       Tuesday     \n",
      "\u001b[90m# A tibble: 5 Ã— 5\u001b[39m\n",
      "  Sale_Date  raw_sale_date date_parsed   sale_month sale_weekday\n",
      "  \u001b[3m\u001b[90m<date>\u001b[39m\u001b[23m     \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m         \u001b[3m\u001b[90m<date>\u001b[39m\u001b[23m        \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m      \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m       \n",
      "\u001b[90m1\u001b[39m 2023-04-24 2023-04-24    4607935-08-18 August     Sunday      \n",
      "\u001b[90m2\u001b[39m 2023-06-09 2023-06-09    4618817-03-01 March      Wednesday   \n",
      "\u001b[90m3\u001b[39m 2023-03-25 2023-03-25    4600838-12-21 December   Tuesday     \n",
      "\u001b[90m4\u001b[39m 2023-04-11 2023-04-11    4604860-05-29 May        Saturday    \n",
      "\u001b[90m5\u001b[39m 2023-08-26 2023-08-26    4637268-06-19 June       Tuesday     \n"
     ]
    }
   ],
   "source": [
    "# Task 7.2: Parse Dates and Extract Components\n",
    "# TODO: Add these date-related columns using mutate():\n",
    "#   - date_parsed: Parse Sale_Date column (use ymd(), mdy(), or dmy() as appropriate)\n",
    "#   - sale_month: Extract month name from date_parsed\n",
    "#   - sale_weekday: Extract weekday name from date_parsed\n",
    "\n",
    "\n",
    "# We'll attempt robust parsing using lubridate::parse_date_time\n",
    "# Accept common formats: 'Ymd', 'mdY', 'dmy', with separators\n",
    "sales_enhanced <- sales_enhanced %>%\n",
    "  dplyr::mutate(\n",
    "    raw_sale_date = as.character(Sale_Date),\n",
    "    date_parsed = lubridate::parse_date_time(raw_sale_date, orders = c('Ymd', 'ymd', 'mdy', 'dmy', 'Y-m-d', 'm/d/Y', 'd/m/Y'), tz = 'UTC'),\n",
    "    # If parse_date_time returned NA for some rows, try ymd() fallback on numeric-looking strings\n",
    "    # use a safe numeric-only test (no backslash escapes that R will misinterpret)\n",
    "    date_parsed = ifelse(is.na(date_parsed) & grepl('^[0-9]+$', raw_sale_date), lubridate::ymd(raw_sale_date), date_parsed),\n",
    "    # Ensure date_parsed is a Date object (not POSIXct) for easier month/week extraction\n",
    "    date_parsed = as.Date(date_parsed),\n",
    "    sale_month = ifelse(!is.na(date_parsed), format(date_parsed, '%B'), NA_character_),\n",
    "    sale_weekday = ifelse(!is.na(date_parsed), format(date_parsed, '%A'), NA_character_)\n",
    "  )\n",
    "\n",
    "cat(\"========== DATE COMPONENTS ==========\\n\")\n",
    "print(head(sales_enhanced %>% dplyr::select(Sale_Date, raw_sale_date, date_parsed, sale_month, sale_weekday), 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part8_intro",
   "metadata": {},
   "source": [
    "## Part 8: Advanced Wrangling & Business Intelligence (Lesson 8)\n",
    "\n",
    "**Skills Assessed:** case_when(), complex logic, KPIs\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Create business categories with case_when()\n",
    "2. Calculate KPIs\n",
    "3. Generate executive summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "case_when_logic",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== PERFORMANCE TIERS ==========\n",
      "\u001b[90m# A tibble: 3 Ã— 2\u001b[39m\n",
      "  performance_tier     n\n",
      "  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m            \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m High               154\n",
      "\u001b[90m2\u001b[39m Low                 74\n",
      "\u001b[90m3\u001b[39m Medium              72\n",
      "\u001b[90m# A tibble: 3 Ã— 2\u001b[39m\n",
      "  performance_tier     n\n",
      "  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m            \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m High               154\n",
      "\u001b[90m2\u001b[39m Low                 74\n",
      "\u001b[90m3\u001b[39m Medium              72\n"
     ]
    }
   ],
   "source": [
    "# Task 8.1: Create Performance Categories\n",
    "# TODO: Add 'performance_tier' column using case_when():\n",
    "#   - \"High\" if Revenue > 25000\n",
    "#   - \"Medium\" if Revenue > 15000\n",
    "#   - \"Low\" otherwise\n",
    "\n",
    "# Ensure Revenue is numeric before applying thresholds\n",
    "sales_enhanced <- sales_enhanced %>%\n",
    "  dplyr::mutate(Revenue = as.numeric(Revenue)) %>%\n",
    "  dplyr::mutate(\n",
    "    performance_tier = dplyr::case_when(\n",
    "      !is.na(Revenue) & Revenue > 25000 ~ 'High',\n",
    "      !is.na(Revenue) & Revenue > 15000 ~ 'Medium',\n",
    "      !is.na(Revenue) ~ 'Low',\n",
    "      TRUE ~ NA_character_\n",
    "    )\n",
    "  )\n",
    "\n",
    "cat(\"========== PERFORMANCE TIERS ==========\\n\")\n",
    "print(dplyr::count(sales_enhanced, performance_tier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "calculate_kpis",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Business KPIs are shown below:\n",
      "\u001b[90m# A tibble: 1 Ã— 4\u001b[39m\n",
      "  total_revenue total_transactions avg_transaction_value high_value_pct\n",
      "          \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m              \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m                 \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m          \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m      7\u001b[4m7\u001b[24m\u001b[4m7\u001b[24m\u001b[4m1\u001b[24m711.                300                \u001b[4m2\u001b[24m\u001b[4m5\u001b[24m906.           64.7\n",
      "\u001b[90m# A tibble: 1 Ã— 4\u001b[39m\n",
      "  total_revenue total_transactions avg_transaction_value high_value_pct\n",
      "          \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m              \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m                 \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m          \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m      7\u001b[4m7\u001b[24m\u001b[4m7\u001b[24m\u001b[4m1\u001b[24m711.                300                \u001b[4m2\u001b[24m\u001b[4m5\u001b[24m906.           64.7\n"
     ]
    }
   ],
   "source": [
    "# Task 8.2: Calculate Business KPIs\n",
    "# TODO: Create 'business_kpis' with these metrics:\n",
    "#   - total_revenue: sum of Revenue\n",
    "#   - total_transactions: count of rows\n",
    "#   - avg_transaction_value: mean of Revenue\n",
    "#   - high_value_pct: percentage where high_value = \"Yes\"\n",
    "\n",
    "# Compute business KPIs from sales_enhanced\n",
    "business_kpis <- sales_enhanced %>%\n",
    "  dplyr::summarize(\n",
    "    total_revenue = sum(as.numeric(Revenue), na.rm = TRUE),\n",
    "    total_transactions = dplyr::n(),\n",
    "    avg_transaction_value = mean(as.numeric(Revenue), na.rm = TRUE),\n",
    "    high_value_pct = 100 * mean(ifelse(tolower(as.character(high_value)) == 'yes', 1, 0), na.rm = TRUE)\n",
    "  )\n",
    "\n",
    "cat(\"Business KPIs are shown below:\\n\")\n",
    "print(business_kpis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection_intro",
   "metadata": {},
   "source": [
    "## Part 9: Reflection Questions\n",
    "\n",
    "Answer the following questions based on your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection1",
   "metadata": {},
   "source": [
    "### Question 9.1: Data Cleaning Impact\n",
    "\n",
    "**How did handling missing values and outliers affect your analysis? Why is data cleaning important before performing business analysis?**\n",
    "\n",
    "Answer:\n",
    "- Removing missing values and flagging outliers ensures summary metrics (like totals and averages) reflect valid transactions and arenâ€™t skewed by bad or incomplete data.\n",
    "- This improves the reliability of KPIs and supports better business decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection2",
   "metadata": {},
   "source": [
    "### Question 9.2: Grouped Analysis Value\n",
    "\n",
    "**What insights did you gain from the regional and category summaries that you couldn't see in the raw data? How can businesses use this type of grouped analysis?**\n",
    "\n",
    "Your answer:\n",
    "\n",
    "- Grouped summaries reveal which regions or product categories drive most revenue and which have higher average transaction values, insights that are not obvious from raw rows.\n",
    "- Businesses can use these results to target promotions, allocate inventory, and set regional sales strategies based on high-performing segments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection3",
   "metadata": {},
   "source": [
    "### Question 9.3: Data Reshaping Purpose\n",
    "\n",
    "**Why would you need to reshape data between wide and long formats? Provide a business scenario where each format would be useful.**\n",
    "\n",
    "Your answer:\n",
    "\n",
    "- Wide format is useful for summary tables or dashboards where each product or category is a column (e.g., a regional sales dashboard showing revenue by category across columns).\n",
    "- Long format is best for analysis and modeling, and for functions that expect tidy data (e.g., a time series plotting or grouped aggregation where Product_Category is a variable rather than separate columns)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection4",
   "metadata": {},
   "source": [
    "### Question 9.4: Joining Datasets\n",
    "\n",
    "**What is the difference between left_join() and inner_join()? When would you use each one in a business context?**\n",
    "\n",
    "Your answer:\n",
    "\n",
    "- `left_join()` keeps all rows from the left table and brings matching rows from the right; use it when you want to retain all customers and attach orders (even if some customers have no orders).\n",
    "- `inner_join()` keeps only rows with matches in both tables so use it when you need only complete order-item records (e.g., computing metrics only for orders that have line items)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection5",
   "metadata": {},
   "source": [
    "### Question 9.5: Skills Integration\n",
    "\n",
    "**Which R data wrangling skill (from Lessons 1-8) do you think is most valuable for business analytics? Why?**\n",
    "\n",
    "Suggested answer:\n",
    "\n",
    "- Data transformation with dplyr is the most valuable skill because it lets you clean, reshape, and summarize data efficiently for analysis and reportin.\n",
    "- These functions are versatile, fast, and compose well with pipes, making them central to nearly every business analytics workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## Exam Complete!\n",
    "\n",
    "### What You've Demonstrated\n",
    "\n",
    "âœ… **Lesson 1:** R basics and data import\n",
    "âœ… **Lesson 2:** Data cleaning (missing values & outliers)\n",
    "âœ… **Lesson 3:** Data transformation (select, filter, arrange)\n",
    "âœ… **Lesson 4:** Advanced transformation (mutate, summarize, group_by)\n",
    "âœ… **Lesson 5:** Data reshaping (pivot_longer, pivot_wider)\n",
    "âœ… **Lesson 6:** Combining datasets (joins)\n",
    "âœ… **Lesson 7:** String manipulation & date/time operations\n",
    "âœ… **Lesson 8:** Advanced wrangling & business intelligence\n",
    "\n",
    "### Submission Checklist\n",
    "\n",
    "Before submitting, ensure:\n",
    "- [ ] All code cells run without errors\n",
    "- [ ] All TODO sections completed\n",
    "- [ ] All required dataframes created with correct names\n",
    "- [ ] All 5 reflection questions answered\n",
    "- [ ] Student name and ID filled in at top\n",
    "\n",
    "**Good work! ðŸŽ‰**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
