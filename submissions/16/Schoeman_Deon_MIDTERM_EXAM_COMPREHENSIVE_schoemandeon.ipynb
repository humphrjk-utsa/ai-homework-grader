{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# MIDTERM EXAM: Comprehensive R Data Wrangling Assessment\n",
    "\n",
    "**Student Name:** [Deon Schoeman]\n",
    "\n",
    "**Student ID:** [MCH616]\n",
    "\n",
    "**Date:** [10/19/2025]\n",
    "\n",
    "**Time Limit:** 4 hours\n",
    "\n",
    "---\n",
    "\n",
    "## Exam Overview\n",
    "\n",
    "This comprehensive midterm exam assesses your mastery of ALL R data wrangling skills covered in Lessons 1-8:\n",
    "\n",
    "- **Lesson 1:** R Basics and Data Import\n",
    "- **Lesson 2:** Data Cleaning (Missing Values & Outliers)\n",
    "- **Lesson 3:** Data Transformation Part 1 (select, filter, arrange)\n",
    "- **Lesson 4:** Data Transformation Part 2 (mutate, summarize, group_by)\n",
    "- **Lesson 5:** Data Reshaping (pivot_longer, pivot_wider)\n",
    "- **Lesson 6:** Combining Datasets (joins)\n",
    "- **Lesson 7:** String Manipulation & Date/Time\n",
    "- **Lesson 8:** Advanced Wrangling & Best Practices\n",
    "\n",
    "## Business Scenario\n",
    "\n",
    "You are a data analyst for a retail company. The executive team needs a comprehensive analysis of:\n",
    "- Sales performance across products and regions\n",
    "- Customer behavior and segmentation\n",
    "- Data quality issues and recommendations\n",
    "- Strategic insights for business growth\n",
    "\n",
    "## Instructions\n",
    "\n",
    "1. **Set your working directory** to where your data files are located\n",
    "2. Complete ALL tasks in order\n",
    "3. Write code in the TODO sections\n",
    "4. Use the pipe operator (%>%) to chain operations\n",
    "5. Add comments explaining your logic\n",
    "6. Run all cells to verify your code works\n",
    "7. Answer all reflection questions\n",
    "\n",
    "## Grading\n",
    "\n",
    "- **Code Correctness (40%)**: All tasks completed correctly\n",
    "- **Code Quality (20%)**: Clean, well-commented code\n",
    "- **Business Understanding (20%)**: Demonstrates understanding of context\n",
    "- **Analysis & Insights (15%)**: Meaningful insights and recommendations\n",
    "- **Reflection Questions (5%)**: Thoughtful answers\n",
    "\n",
    "## Academic Integrity\n",
    "\n",
    "This is an individual exam. You may use:\n",
    "- Course notes and lesson materials\n",
    "- R documentation and help files\n",
    "- Your previous homework assignments\n",
    "\n",
    "You may NOT:\n",
    "- Collaborate with other students\n",
    "- Use AI assistants or online forums\n",
    "- Share code or solutions\n",
    "\n",
    "---\n",
    "\n",
    "**Good luck! ðŸŽ“**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part1_intro",
   "metadata": {},
   "source": [
    "## Part 1: R Basics and Data Import (Lesson 1)\n",
    "\n",
    "**Skills Assessed:** Variables, data types, data import, working directory\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Set working directory\n",
    "2. Load required packages\n",
    "3. Import multiple datasets\n",
    "4. Examine data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "setup",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /workspaces/Assignment-3-Data-Transformation-with-dplyr---Part-1/data \n"
     ]
    }
   ],
   "source": [
    "# Task 1.1: Set Working Directory\n",
    "# TODO: Set your working directory to where your data files are located\n",
    "# IMPORTANT: Students must set their own path!\n",
    "# Example: setwd(\"/Users/yourname/GitHub/ai-homework-grader-clean/data\")\n",
    "\n",
    "# Sets the working directory to the data folder in the repostitory.\n",
    "setwd(\"/workspaces/Assignment-3-Data-Transformation-with-dplyr---Part-1/data/\")\n",
    "\n",
    "\n",
    "# Verify working directory\n",
    "cat(\"Current working directory:\", getwd(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "load_packages",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Packages loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Task 1.2: Load Required Packages\n",
    "# TODO: Load tidyverse (includes dplyr, tidyr, stringr, ggplot2)\n",
    "\n",
    "# Loads tidyverse for data manipulation and visualization\n",
    "library(tidyverse)\n",
    "\n",
    "\n",
    "# TODO: Load lubridate for date operations\n",
    "# Loads lubridate for date operations\n",
    "library(lubridate)\n",
    "\n",
    "\n",
    "cat(\"âœ… Packages loaded successfully!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "import_data",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data imported successfully!\n",
      "Sales data: 300 rows\n",
      "Customers: 100 rows\n",
      "Products: 50 rows\n",
      "Orders: 250 rows\n",
      "Order items: 400 rows\n"
     ]
    }
   ],
   "source": [
    "# Task 1.3: Import Datasets\n",
    "# TODO: Import the following CSV files using read_csv():\n",
    "#   - company_sales_data.csv -> sales_data\n",
    "#   - customers.csv -> customers\n",
    "#   - products.csv -> products\n",
    "#   - orders.csv -> orders\n",
    "#   - order_items.csv -> order_items\n",
    "\n",
    "# Your code here:\n",
    "\n",
    "# Assigns each CSV file to a variable.\n",
    "sales_data <- read.csv(\"company_sales_data.csv\")\n",
    "\n",
    "customers <- read.csv(\"customers.csv\")\n",
    "\n",
    "products <- read.csv(\"products.csv\")\n",
    "\n",
    "orders <- read.csv(\"orders.csv\")\n",
    "\n",
    "order_items <- read.csv(\"order_items.csv\")\n",
    "\n",
    "\n",
    "# Display import summary\n",
    "cat(\"âœ… Data imported successfully!\\n\")\n",
    "cat(\"Sales data:\", nrow(sales_data), \"rows\\n\")\n",
    "cat(\"Customers:\", nrow(customers), \"rows\\n\")\n",
    "cat(\"Products:\", nrow(products), \"rows\\n\")\n",
    "cat(\"Orders:\", nrow(orders), \"rows\\n\")\n",
    "cat(\"Order items:\", nrow(order_items), \"rows\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part2_intro",
   "metadata": {},
   "source": [
    "## Part 2: Data Cleaning - Missing Values & Outliers (Lesson 2)\n",
    "\n",
    "**Skills Assessed:** Identifying NAs, handling missing data, detecting outliers\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Check for missing values in sales_data\n",
    "2. Handle missing values appropriately\n",
    "3. Identify outliers in Revenue column\n",
    "4. Create a cleaned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "check_missing",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== MISSING VALUES SUMMARY ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TransactionID   Sales_Rep_Name           Region Product_Category \n",
      "               0                0                0                0 \n",
      "         Revenue             Cost       Units_Sold        Sale_Date \n",
      "               0                0                0                0 \n",
      "\n",
      "Total missing values: 0 \n"
     ]
    }
   ],
   "source": [
    "# Task 2.1: Check for Missing Values\n",
    "# TODO: Create 'missing_summary' that shows count of NAs in each column of sales_data\n",
    "\n",
    "# Used sapply to count NAs in each column of sales_data. And according to the result there are no missing values in the dataset.\n",
    "# I verified this by checking the excel file as well.\n",
    "missing_summary <- sapply(sales_data, function(x) sum(is.na(x)))\n",
    "\n",
    "\n",
    "cat(\"========== MISSING VALUES SUMMARY ==========\\n\")\n",
    "print(missing_summary)\n",
    "cat(\"\\nTotal missing values:\", sum(missing_summary), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "handle_missing",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== DATA CLEANING RESULTS ==========\n",
      "Original rows: 300 \n",
      "Cleaned rows: 300 \n",
      "Rows removed: 0 \n"
     ]
    }
   ],
   "source": [
    "# Task 2.2: Handle Missing Values\n",
    "# TODO: Create 'sales_clean' by removing rows with ANY missing values\n",
    "\n",
    "# Removed rows with any missing values from sales_data by using na.omit().\n",
    "sales_clean <- na.omit(sales_data)\n",
    "\n",
    "\n",
    "cat(\"========== DATA CLEANING RESULTS ==========\\n\")\n",
    "cat(\"Original rows:\", nrow(sales_data), \"\\n\")\n",
    "cat(\"Cleaned rows:\", nrow(sales_clean), \"\\n\")\n",
    "cat(\"Rows removed:\", nrow(sales_data) - nrow(sales_clean), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "detect_outliers",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== OUTLIER ANALYSIS ==========\n",
      "       Metric     Value\n",
      "1          Q1  15034.29\n",
      "2          Q3  37707.71\n",
      "3         IQR  22673.42\n",
      "4 Lower Bound -18975.84\n",
      "5 Upper Bound  71717.84\n",
      "\n",
      "Number of outliers detected: 0 \n"
     ]
    }
   ],
   "source": [
    "# Task 2.3: Detect Outliers in Revenue\n",
    "# TODO: Calculate outlier thresholds using IQR method\n",
    "#   - Calculate Q1 (25th percentile) and Q3 (75th percentile) of Revenue\n",
    "#   - Calculate IQR = Q3 - Q1\n",
    "#   - Lower bound = Q1 - 1.5 * IQR\n",
    "#   - Upper bound = Q3 + 1.5 * IQR\n",
    "# TODO: Create 'outlier_analysis' dataframe with these values\n",
    "\n",
    "# Quantile is used to calculate Q1 and Q3. na.rm = true is not needed due to previous cleaning of data set.\n",
    "# $ is used to access the Revenue column in sales_clean dataframe.\n",
    "Q1 <- quantile(sales_clean$Revenue, 0.25)\n",
    "Q3 <- quantile(sales_clean$Revenue, 0.75)\n",
    "# Quartile 3 minus Quartile 1 gives the IQR value.\n",
    "IQR_value <- Q3 - Q1\n",
    "# Lower and upper bounds are calculated using the IQR method.\n",
    "lower_bound <- Q1 - 1.5 * IQR_value\n",
    "upper_bound <- Q3 + 1.5 * IQR_value\n",
    "\n",
    "outlier_analysis <- data.frame(\n",
    "  Metric = c(\"Q1\", \"Q3\", \"IQR\", \"Lower Bound\", \"Upper Bound\"),\n",
    "  Value = c(Q1, Q3, IQR_value, lower_bound, upper_bound)\n",
    ")\n",
    "\n",
    "cat(\"========== OUTLIER ANALYSIS ==========\\n\")\n",
    "print(outlier_analysis)\n",
    "\n",
    "# Count outliers\n",
    "outlier_count <- sum(sales_clean$Revenue < lower_bound | sales_clean$Revenue > upper_bound)\n",
    "cat(\"\\nNumber of outliers detected:\", outlier_count, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part3_intro",
   "metadata": {},
   "source": [
    "## Part 3: Data Transformation Part 1 (Lesson 3)\n",
    "\n",
    "**Skills Assessed:** select(), filter(), arrange(), pipe operator\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Select specific columns\n",
    "2. Filter data by conditions\n",
    "3. Sort data\n",
    "4. Chain operations with pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "select_columns",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== SELECTED COLUMNS ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: Region Product_Category Revenue Units_Sold Sale_Date \n",
      "Rows: 300 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 5 Ã— 5</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Region</th><th scope=col>Product_Category</th><th scope=col>Revenue</th><th scope=col>Units_Sold</th><th scope=col>Sale_Date</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>Latin America</td><td>Services</td><td>20750.92</td><td>78</td><td>2023-04-24</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>Europe       </td><td>Hardware</td><td>32359.98</td><td>13</td><td>2023-06-09</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>Europe       </td><td>Services</td><td>39268.40</td><td>34</td><td>2023-03-25</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>Europe       </td><td>Hardware</td><td>28865.09</td><td>90</td><td>2023-04-11</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>Latin America</td><td>Software</td><td> 3932.36</td><td>63</td><td>2023-08-26</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 5 Ã— 5\n",
       "\\begin{tabular}{r|lllll}\n",
       "  & Region & Product\\_Category & Revenue & Units\\_Sold & Sale\\_Date\\\\\n",
       "  & <chr> & <chr> & <dbl> & <int> & <chr>\\\\\n",
       "\\hline\n",
       "\t1 & Latin America & Services & 20750.92 & 78 & 2023-04-24\\\\\n",
       "\t2 & Europe        & Hardware & 32359.98 & 13 & 2023-06-09\\\\\n",
       "\t3 & Europe        & Services & 39268.40 & 34 & 2023-03-25\\\\\n",
       "\t4 & Europe        & Hardware & 28865.09 & 90 & 2023-04-11\\\\\n",
       "\t5 & Latin America & Software &  3932.36 & 63 & 2023-08-26\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 5 Ã— 5\n",
       "\n",
       "| <!--/--> | Region &lt;chr&gt; | Product_Category &lt;chr&gt; | Revenue &lt;dbl&gt; | Units_Sold &lt;int&gt; | Sale_Date &lt;chr&gt; |\n",
       "|---|---|---|---|---|---|\n",
       "| 1 | Latin America | Services | 20750.92 | 78 | 2023-04-24 |\n",
       "| 2 | Europe        | Hardware | 32359.98 | 13 | 2023-06-09 |\n",
       "| 3 | Europe        | Services | 39268.40 | 34 | 2023-03-25 |\n",
       "| 4 | Europe        | Hardware | 28865.09 | 90 | 2023-04-11 |\n",
       "| 5 | Latin America | Software |  3932.36 | 63 | 2023-08-26 |\n",
       "\n"
      ],
      "text/plain": [
       "  Region        Product_Category Revenue  Units_Sold Sale_Date \n",
       "1 Latin America Services         20750.92 78         2023-04-24\n",
       "2 Europe        Hardware         32359.98 13         2023-06-09\n",
       "3 Europe        Services         39268.40 34         2023-03-25\n",
       "4 Europe        Hardware         28865.09 90         2023-04-11\n",
       "5 Latin America Software          3932.36 63         2023-08-26"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Task 3.1: Select Specific Columns\n",
    "# TODO: Create 'sales_summary' with only these columns from sales_clean:\n",
    "#   Region, Product_Category, Revenue, Units_Sold, Sale_Date\n",
    "\n",
    "\n",
    "# Used the select() to only show the columns Region, Product_Category, Revenue, Units_Sold, and Sale_Date in the sales_summary variable.\n",
    "# The pipe operator is used to pass the information on to the next argument. It helps with readability of the code\n",
    "sales_summary <- sales_clean %>%\n",
    "  select(Region, Product_Category, Revenue, Units_Sold, Sale_Date)\n",
    "  \n",
    "\n",
    "cat(\"========== SELECTED COLUMNS ==========\\n\")\n",
    "cat(\"Columns:\", names(sales_summary), \"\\n\")\n",
    "cat(\"Rows:\", nrow(sales_summary), \"\\n\")\n",
    "head(sales_summary, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "filter_data",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== HIGH REVENUE SALES ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total high revenue transactions: 194 \n",
      "Total revenue from these sales: $ 6671906 \n"
     ]
    }
   ],
   "source": [
    "# Task 3.2: Filter High Revenue Sales\n",
    "# TODO: Create 'high_revenue_sales' by filtering sales_clean for Revenue > 20000\n",
    "\n",
    "#Used filter() to filter Revenue to greater than 20k.\n",
    "high_revenue_sales <- sales_clean %>%\n",
    "  filter(Revenue > 20000)\n",
    "  \n",
    "\n",
    "cat(\"========== HIGH REVENUE SALES ==========\\n\")\n",
    "cat(\"Total high revenue transactions:\", nrow(high_revenue_sales), \"\\n\")\n",
    "cat(\"Total revenue from these sales: $\", sum(high_revenue_sales$Revenue), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "sort_data",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== TOP 10 SALES ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Region Product_Category  Revenue Units_Sold\n",
      "1   Asia Pacific       Consulting 49956.01         88\n",
      "2         Europe         Software 49866.51         96\n",
      "3         Europe       Consulting 49856.54          1\n",
      "4   Asia Pacific       Consulting 49238.97         72\n",
      "5   Asia Pacific         Hardware 48997.22         92\n",
      "6  North America         Services 48884.31         62\n",
      "7         Europe         Software 48793.64         77\n",
      "8  North America         Hardware 48771.67         16\n",
      "9  North America       Consulting 48747.95         63\n",
      "10        Europe       Consulting 48571.74         22\n"
     ]
    }
   ],
   "source": [
    "# Task 3.3: Sort by Revenue\n",
    "# TODO: Create 'top_sales' by arranging sales_clean by Revenue in descending order\n",
    "#       and keeping only the top 10 rows\n",
    "\n",
    "#Used arrange with desc on Revenue to order the top_sales in descending order.\n",
    "#Then used head to show only the first 10 rows in the descending order.\n",
    "top_sales <- sales_clean %>%\n",
    "  arrange(desc(Revenue)) %>%\n",
    "  head(10)\n",
    "  \n",
    "\n",
    "cat(\"========== TOP 10 SALES ==========\\n\")\n",
    "print(top_sales %>% select(Region, Product_Category, Revenue, Units_Sold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "chain_operations",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== REGIONAL TOP SALES ==========\n",
      "         Region Product_Category  Revenue\n",
      "1  Asia Pacific       Consulting 49956.01\n",
      "2  Asia Pacific       Consulting 49238.97\n",
      "3  Asia Pacific         Hardware 48997.22\n",
      "4  Asia Pacific       Consulting 48063.17\n",
      "5  Asia Pacific         Services 46731.05\n",
      "6  Asia Pacific         Software 46615.43\n",
      "7  Asia Pacific       Consulting 46544.57\n",
      "8  Asia Pacific       Consulting 45755.79\n",
      "9  Asia Pacific         Services 45298.38\n",
      "10 Asia Pacific         Services 44624.16\n",
      "11 Asia Pacific       Consulting 44454.58\n",
      "12 Asia Pacific       Consulting 44364.40\n",
      "13 Asia Pacific         Software 43221.14\n",
      "14 Asia Pacific         Software 42062.52\n",
      "15 Asia Pacific         Software 41411.58\n"
     ]
    }
   ],
   "source": [
    "# Task 3.4: Chain Multiple Operations\n",
    "# TODO: Create 'regional_top_sales' by:\n",
    "#   1. Filtering for Revenue > 15000\n",
    "#   2. Selecting: Region, Product_Category, Revenue\n",
    "#   3. Arranging by Region (ascending) then Revenue (descending)\n",
    "#   4. Keeping top 15 rows\n",
    "# Use the pipe operator to chain all operations\n",
    "\n",
    "#Used the pipe operator to chain arguments make the code clean and more readable by connecting filter -> select -> arrange -> head.\n",
    "regional_top_sales <- sales_clean %>%\n",
    "  filter(Revenue > 15000) %>%\n",
    "  select(Region, Product_Category, Revenue) %>%\n",
    "  arrange(Region, desc(Revenue)) %>%\n",
    "  head(15)\n",
    "  \n",
    "\n",
    "cat(\"========== REGIONAL TOP SALES ==========\\n\")\n",
    "print(regional_top_sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part4_intro",
   "metadata": {},
   "source": [
    "## Part 4: Data Transformation Part 2 (Lesson 4)\n",
    "\n",
    "**Skills Assessed:** mutate(), summarize(), group_by()\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Create calculated columns with mutate()\n",
    "2. Calculate summary statistics\n",
    "3. Perform grouped analysis\n",
    "4. Generate business metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "mutate_columns",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== ENHANCED SALES DATA ==========\n",
      "New columns added: revenue_per_unit, high_value\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 5 Ã— 4</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Revenue</th><th scope=col>Units_Sold</th><th scope=col>revenue_per_unit</th><th scope=col>high_value</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>20750.92</td><td>78</td><td> 266.04</td><td>Yes</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>32359.98</td><td>13</td><td>2489.23</td><td>Yes</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>39268.40</td><td>34</td><td>1154.95</td><td>Yes</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>28865.09</td><td>90</td><td> 320.72</td><td>Yes</td></tr>\n",
       "\t<tr><th scope=row>5</th><td> 3932.36</td><td>63</td><td>  62.42</td><td>No </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 5 Ã— 4\n",
       "\\begin{tabular}{r|llll}\n",
       "  & Revenue & Units\\_Sold & revenue\\_per\\_unit & high\\_value\\\\\n",
       "  & <dbl> & <int> & <dbl> & <chr>\\\\\n",
       "\\hline\n",
       "\t1 & 20750.92 & 78 &  266.04 & Yes\\\\\n",
       "\t2 & 32359.98 & 13 & 2489.23 & Yes\\\\\n",
       "\t3 & 39268.40 & 34 & 1154.95 & Yes\\\\\n",
       "\t4 & 28865.09 & 90 &  320.72 & Yes\\\\\n",
       "\t5 &  3932.36 & 63 &   62.42 & No \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 5 Ã— 4\n",
       "\n",
       "| <!--/--> | Revenue &lt;dbl&gt; | Units_Sold &lt;int&gt; | revenue_per_unit &lt;dbl&gt; | high_value &lt;chr&gt; |\n",
       "|---|---|---|---|---|\n",
       "| 1 | 20750.92 | 78 |  266.04 | Yes |\n",
       "| 2 | 32359.98 | 13 | 2489.23 | Yes |\n",
       "| 3 | 39268.40 | 34 | 1154.95 | Yes |\n",
       "| 4 | 28865.09 | 90 |  320.72 | Yes |\n",
       "| 5 |  3932.36 | 63 |   62.42 | No  |\n",
       "\n"
      ],
      "text/plain": [
       "  Revenue  Units_Sold revenue_per_unit high_value\n",
       "1 20750.92 78          266.04          Yes       \n",
       "2 32359.98 13         2489.23          Yes       \n",
       "3 39268.40 34         1154.95          Yes       \n",
       "4 28865.09 90          320.72          Yes       \n",
       "5  3932.36 63           62.42          No        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Task 4.1: Create Calculated Columns\n",
    "# TODO: Add these new columns to sales_clean using mutate():\n",
    "#   - revenue_per_unit: Revenue / Units_Sold\n",
    "#   - high_value: \"Yes\" if Revenue > 20000, else \"No\"\n",
    "# Store result in 'sales_enhanced'\n",
    "\n",
    "#Created new column for revenue_per_unit also rounded the decimal places to clean the numbers up.\n",
    "#Also created a new column for high_value and using case_when to flag yes when revenue is above 20k other wise its not high_value.\n",
    "sales_enhanced <- sales_clean %>%\n",
    "  mutate(\n",
    "    revenue_per_unit = round(Revenue / Units_Sold, 2),\n",
    "    high_value = case_when(\n",
    "      Revenue > 20000 ~ \"Yes\",\n",
    "      TRUE ~ \"No\"\n",
    "    )\n",
    "    \n",
    "  )\n",
    "\n",
    "cat(\"========== ENHANCED SALES DATA ==========\\n\")\n",
    "cat(\"New columns added: revenue_per_unit, high_value\\n\")\n",
    "head(sales_enhanced %>% select(Revenue, Units_Sold, revenue_per_unit, high_value), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "summarize_data",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== OVERALL SUMMARY ==========\n",
      "  total_revenue avg_revenue total_units transaction_count\n",
      "1       7771711     25905.7       16169               300\n"
     ]
    }
   ],
   "source": [
    "# Task 4.2: Calculate Overall Summary Statistics\n",
    "# TODO: Create 'overall_summary' with these metrics from sales_enhanced:\n",
    "#   - total_revenue: sum of Revenue\n",
    "#   - avg_revenue: mean of Revenue\n",
    "#   - total_units: sum of Units_Sold\n",
    "#   - transaction_count: count using n()\n",
    "\n",
    "#Used summarize to create a summary of metrics from sales_enhanced.\n",
    "#Metrics created - total_revenue = sum of Revenue, avg_revenue = mean of Revenue\n",
    "#Continued, total_units = sum of Units_Sold, transaction_count = count of each transaction\n",
    "\n",
    "overall_summary <- sales_enhanced %>%\n",
    "    summarize(\n",
    "        total_revenue = sum(Revenue),\n",
    "        avg_revenue = mean(Revenue),\n",
    "        total_units = sum(Units_Sold),\n",
    "        transaction_count = n()\n",
    "    )\n",
    "\n",
    "cat(\"========== OVERALL SUMMARY ==========\\n\")\n",
    "print(overall_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "group_by_region",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== REGIONAL SUMMARY ==========\n",
      "\u001b[90m# A tibble: 4 Ã— 4\u001b[39m\n",
      "  Region        total_revenue avg_revenue transaction_count\n",
      "  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                 \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m       \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m             \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m Europe             2\u001b[4m2\u001b[24m\u001b[4m2\u001b[24m\u001b[4m4\u001b[24m182.      \u001b[4m2\u001b[24m\u001b[4m7\u001b[24m124.                82\n",
      "\u001b[90m2\u001b[39m Latin America      2\u001b[4m1\u001b[24m\u001b[4m1\u001b[24m\u001b[4m2\u001b[24m037.      \u001b[4m2\u001b[24m\u001b[4m5\u001b[24m446.                83\n",
      "\u001b[90m3\u001b[39m Asia Pacific       1\u001b[4m8\u001b[24m\u001b[4m0\u001b[24m\u001b[4m4\u001b[24m243.      \u001b[4m2\u001b[24m\u001b[4m6\u001b[24m929.                67\n",
      "\u001b[90m4\u001b[39m North America      1\u001b[4m6\u001b[24m\u001b[4m3\u001b[24m\u001b[4m1\u001b[24m248.      \u001b[4m2\u001b[24m\u001b[4m3\u001b[24m989.                68\n"
     ]
    }
   ],
   "source": [
    "# Task 4.3: Regional Performance Analysis\n",
    "# TODO: Create 'regional_summary' by grouping sales_enhanced by Region\n",
    "#       and calculating:\n",
    "#   - total_revenue: sum of Revenue\n",
    "#   - avg_revenue: mean of Revenue\n",
    "#   - transaction_count: count using n()\n",
    "# Then arrange by total_revenue descending\n",
    "# Hint: Use group_by() %>% summarize() %>% arrange()\n",
    "\n",
    "#Grouped by Region then used pipe operator to chain arguments together.\n",
    "#Metrics created are total_revenue, avg_revenue, and transaction_count.\n",
    "# .groups = \"drop\" removes further grouping.\n",
    "#Arranged the data in descending order of total_revenue.\n",
    "\n",
    "regional_summary <- sales_enhanced %>%\n",
    "  group_by(Region) %>%\n",
    "  summarize(\n",
    "    total_revenue = sum(Revenue),\n",
    "    avg_revenue = mean(Revenue),\n",
    "    transaction_count = n(),\n",
    "    .groups = \"drop\"\n",
    "  ) %>%\n",
    "  arrange(desc(total_revenue))\n",
    "\n",
    "cat(\"========== REGIONAL SUMMARY ==========\\n\")\n",
    "print(regional_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "group_by_category",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== CATEGORY SUMMARY ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90m# A tibble: 4 Ã— 4\u001b[39m\n",
      "  Product_Category total_revenue avg_revenue transaction_count\n",
      "  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                    \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m       \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m             \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m Consulting            1\u001b[4m9\u001b[24m\u001b[4m7\u001b[24m\u001b[4m8\u001b[24m840.      \u001b[4m2\u001b[24m\u001b[4m6\u001b[24m037.                76\n",
      "\u001b[90m2\u001b[39m Services              1\u001b[4m9\u001b[24m\u001b[4m6\u001b[24m\u001b[4m1\u001b[24m565.      \u001b[4m2\u001b[24m\u001b[4m7\u001b[24m244.                72\n",
      "\u001b[90m3\u001b[39m Hardware              1\u001b[4m9\u001b[24m\u001b[4m5\u001b[24m\u001b[4m1\u001b[24m325.      \u001b[4m2\u001b[24m\u001b[4m6\u001b[24m730.                73\n",
      "\u001b[90m4\u001b[39m Software              1\u001b[4m8\u001b[24m\u001b[4m7\u001b[24m\u001b[4m9\u001b[24m981.      \u001b[4m2\u001b[24m\u001b[4m3\u001b[24m797.                79\n"
     ]
    }
   ],
   "source": [
    "# Task 4.4: Product Category Analysis\n",
    "# TODO: Create 'category_summary' by grouping by Product_Category\n",
    "#       and calculating the same metrics as regional_summary\n",
    "#       Then arrange by total_revenue descending\n",
    "\n",
    "#Grouped by Product_Category then used pipe operator to chain arguments together.\n",
    "#Metrics created are total_revenue, avg_revenue, and transaction_count. The same as regional_summary.\n",
    "#Arranged the data in descending order of total_revenue. The same as regional_summary.\n",
    "category_summary <- sales_enhanced %>%\n",
    "  group_by(Product_Category) %>%\n",
    "  summarize(\n",
    "    total_revenue = sum(Revenue),\n",
    "    avg_revenue = mean(Revenue),\n",
    "    transaction_count = n(),\n",
    "    .groups = \"drop\"\n",
    "  ) %>%\n",
    "  arrange(desc(total_revenue))\n",
    "\n",
    "cat(\"========== CATEGORY SUMMARY ==========\\n\")\n",
    "print(category_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part5_intro",
   "metadata": {},
   "source": [
    "## Part 5: Data Reshaping with tidyr (Lesson 5)\n",
    "\n",
    "**Skills Assessed:** pivot_longer(), pivot_wider(), tidy data principles\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Reshape data from wide to long format\n",
    "2. Reshape data from long to wide format\n",
    "3. Create analysis-ready datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "create_wide_data",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== REGION-CATEGORY DATA (LONG FORMAT) ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90m# A tibble: 10 Ã— 3\u001b[39m\n",
      "   Region        Product_Category total_revenue\n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m         \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                    \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m Asia Pacific  Consulting             \u001b[4m7\u001b[24m\u001b[4m5\u001b[24m\u001b[4m9\u001b[24m641.\n",
      "\u001b[90m 2\u001b[39m Asia Pacific  Hardware               \u001b[4m2\u001b[24m\u001b[4m7\u001b[24m\u001b[4m1\u001b[24m979.\n",
      "\u001b[90m 3\u001b[39m Asia Pacific  Services               \u001b[4m3\u001b[24m\u001b[4m3\u001b[24m\u001b[4m1\u001b[24m826.\n",
      "\u001b[90m 4\u001b[39m Asia Pacific  Software               \u001b[4m4\u001b[24m\u001b[4m4\u001b[24m\u001b[4m0\u001b[24m797.\n",
      "\u001b[90m 5\u001b[39m Europe        Consulting             \u001b[4m3\u001b[24m\u001b[4m9\u001b[24m\u001b[4m0\u001b[24m670.\n",
      "\u001b[90m 6\u001b[39m Europe        Hardware               \u001b[4m7\u001b[24m\u001b[4m7\u001b[24m\u001b[4m7\u001b[24m044.\n",
      "\u001b[90m 7\u001b[39m Europe        Services               \u001b[4m5\u001b[24m\u001b[4m1\u001b[24m\u001b[4m3\u001b[24m507.\n",
      "\u001b[90m 8\u001b[39m Europe        Software               \u001b[4m5\u001b[24m\u001b[4m4\u001b[24m\u001b[4m2\u001b[24m961.\n",
      "\u001b[90m 9\u001b[39m Latin America Consulting             \u001b[4m4\u001b[24m\u001b[4m3\u001b[24m\u001b[4m3\u001b[24m397.\n",
      "\u001b[90m10\u001b[39m Latin America Hardware               \u001b[4m4\u001b[24m\u001b[4m7\u001b[24m\u001b[4m4\u001b[24m257.\n"
     ]
    }
   ],
   "source": [
    "# Task 5.1: Create Wide Format Data\n",
    "# First, create a summary by Region and Product_Category\n",
    "\n",
    "region_category_revenue <- sales_enhanced %>%\n",
    "  group_by(Region, Product_Category) %>%\n",
    "  summarize(total_revenue = sum(Revenue), .groups = 'drop')\n",
    "\n",
    "cat(\"========== REGION-CATEGORY DATA (LONG FORMAT) ==========\\n\")\n",
    "print(head(region_category_revenue, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "pivot_wider",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== REVENUE DATA (WIDE FORMAT) ==========\n",
      "\u001b[90m# A tibble: 4 Ã— 5\u001b[39m\n",
      "  Region        Consulting Hardware Services Software\n",
      "  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m              \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m    \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m    \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m    \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m Asia Pacific     \u001b[4m7\u001b[24m\u001b[4m5\u001b[24m\u001b[4m9\u001b[24m641.  \u001b[4m2\u001b[24m\u001b[4m7\u001b[24m\u001b[4m1\u001b[24m979.  \u001b[4m3\u001b[24m\u001b[4m3\u001b[24m\u001b[4m1\u001b[24m826.  \u001b[4m4\u001b[24m\u001b[4m4\u001b[24m\u001b[4m0\u001b[24m797.\n",
      "\u001b[90m2\u001b[39m Europe           \u001b[4m3\u001b[24m\u001b[4m9\u001b[24m\u001b[4m0\u001b[24m670.  \u001b[4m7\u001b[24m\u001b[4m7\u001b[24m\u001b[4m7\u001b[24m044.  \u001b[4m5\u001b[24m\u001b[4m1\u001b[24m\u001b[4m3\u001b[24m507.  \u001b[4m5\u001b[24m\u001b[4m4\u001b[24m\u001b[4m2\u001b[24m961.\n",
      "\u001b[90m3\u001b[39m Latin America    \u001b[4m4\u001b[24m\u001b[4m3\u001b[24m\u001b[4m3\u001b[24m397.  \u001b[4m4\u001b[24m\u001b[4m7\u001b[24m\u001b[4m4\u001b[24m257.  \u001b[4m6\u001b[24m\u001b[4m4\u001b[24m\u001b[4m4\u001b[24m772.  \u001b[4m5\u001b[24m\u001b[4m5\u001b[24m\u001b[4m9\u001b[24m611.\n",
      "\u001b[90m4\u001b[39m North America    \u001b[4m3\u001b[24m\u001b[4m9\u001b[24m\u001b[4m5\u001b[24m132.  \u001b[4m4\u001b[24m\u001b[4m2\u001b[24m\u001b[4m8\u001b[24m046.  \u001b[4m4\u001b[24m\u001b[4m7\u001b[24m\u001b[4m1\u001b[24m460.  \u001b[4m3\u001b[24m\u001b[4m3\u001b[24m\u001b[4m6\u001b[24m611.\n"
     ]
    }
   ],
   "source": [
    "# Task 5.2: Reshape to Wide Format\n",
    "# TODO: Create 'revenue_wide' by pivoting region_category_revenue\n",
    "#       so that Product_Category values become column names\n",
    "#       with total_revenue as the values\n",
    "\n",
    "#Used pivot_wider to separate product category into thier respective new columns with values from total_revenue.\n",
    "revenue_wide <- region_category_revenue %>%\n",
    "  pivot_wider(\n",
    "    names_from = Product_Category,\n",
    "    values_from = total_revenue\n",
    "  )\n",
    "  \n",
    "\n",
    "cat(\"========== REVENUE DATA (WIDE FORMAT) ==========\\n\")\n",
    "print(revenue_wide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "pivot_longer",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== REVENUE DATA (BACK TO LONG FORMAT) ==========\n",
      "\u001b[90m# A tibble: 10 Ã— 3\u001b[39m\n",
      "   Region        Product_Category revenue\n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m         \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m              \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m Asia Pacific  Consulting       \u001b[4m7\u001b[24m\u001b[4m5\u001b[24m\u001b[4m9\u001b[24m641.\n",
      "\u001b[90m 2\u001b[39m Asia Pacific  Hardware         \u001b[4m2\u001b[24m\u001b[4m7\u001b[24m\u001b[4m1\u001b[24m979.\n",
      "\u001b[90m 3\u001b[39m Asia Pacific  Services         \u001b[4m3\u001b[24m\u001b[4m3\u001b[24m\u001b[4m1\u001b[24m826.\n",
      "\u001b[90m 4\u001b[39m Asia Pacific  Software         \u001b[4m4\u001b[24m\u001b[4m4\u001b[24m\u001b[4m0\u001b[24m797.\n",
      "\u001b[90m 5\u001b[39m Europe        Consulting       \u001b[4m3\u001b[24m\u001b[4m9\u001b[24m\u001b[4m0\u001b[24m670.\n",
      "\u001b[90m 6\u001b[39m Europe        Hardware         \u001b[4m7\u001b[24m\u001b[4m7\u001b[24m\u001b[4m7\u001b[24m044.\n",
      "\u001b[90m 7\u001b[39m Europe        Services         \u001b[4m5\u001b[24m\u001b[4m1\u001b[24m\u001b[4m3\u001b[24m507.\n",
      "\u001b[90m 8\u001b[39m Europe        Software         \u001b[4m5\u001b[24m\u001b[4m4\u001b[24m\u001b[4m2\u001b[24m961.\n",
      "\u001b[90m 9\u001b[39m Latin America Consulting       \u001b[4m4\u001b[24m\u001b[4m3\u001b[24m\u001b[4m3\u001b[24m397.\n",
      "\u001b[90m10\u001b[39m Latin America Hardware         \u001b[4m4\u001b[24m\u001b[4m7\u001b[24m\u001b[4m4\u001b[24m257.\n"
     ]
    }
   ],
   "source": [
    "# Task 5.3: Reshape Back to Long Format\n",
    "# TODO: Create 'revenue_long' by pivoting revenue_wide back to long format\n",
    "#       Column names (except Region) should go into 'Product_Category'\n",
    "#       Values should go into 'revenue'\n",
    "\n",
    "#Used pivot_longer to put consulting, hardware, services, and software back under Product_Category column.\n",
    "#The new column also got assigned its respective values under revenue.\n",
    "\n",
    "revenue_long <- revenue_wide %>%\n",
    "  pivot_longer(\n",
    "    cols = c(Consulting, Hardware, Services, Software),\n",
    "    names_to = \"Product_Category\",\n",
    "    values_to = \"revenue\"\n",
    "  )\n",
    "\n",
    "cat(\"========== REVENUE DATA (BACK TO LONG FORMAT) ==========\\n\")\n",
    "print(head(revenue_long, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part6_intro",
   "metadata": {},
   "source": [
    "## Part 6: Combining Datasets with Joins (Lesson 6)\n",
    "\n",
    "**Skills Assessed:** left_join(), inner_join(), data integration\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Join customers with orders\n",
    "2. Join orders with order_items\n",
    "3. Create integrated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "join_customers_orders",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== CUSTOMER ORDERS ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 200 \n",
      "Columns: 8 \n"
     ]
    }
   ],
   "source": [
    "# Task 6.1: Join Customers and Orders\n",
    "# TODO: Create 'customer_orders' by left joining customers with orders\n",
    "#       Join on CustomerID\n",
    "\n",
    "#left_join to left join customers with orders by CustomerID.\n",
    "#The Left Join uses the complete left table and then only uses matching data for the right table.\n",
    "\n",
    "customer_orders <- left_join(customers, orders, by = \"CustomerID\")\n",
    "\n",
    "\n",
    "cat(\"========== CUSTOMER ORDERS ==========\\n\")\n",
    "cat(\"Total rows:\", nrow(customer_orders), \"\\n\")\n",
    "cat(\"Columns:\", ncol(customer_orders), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "join_orders_items",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== ORDERS WITH ITEMS ==========\n",
      "Total rows: 400 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 5 Ã— 7</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>OrderID</th><th scope=col>CustomerID</th><th scope=col>Order_Date</th><th scope=col>Total_Amount</th><th scope=col>ProductID</th><th scope=col>Quantity</th><th scope=col>Unit_Price</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>1</td><td> 87</td><td>2023-08-30</td><td>424.30</td><td> 2</td><td>3</td><td>115.72</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>1</td><td> 87</td><td>2023-08-30</td><td>424.30</td><td>22</td><td>5</td><td>206.62</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>1</td><td> 87</td><td>2023-08-30</td><td>424.30</td><td>26</td><td>5</td><td> 61.75</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>3</td><td> 37</td><td>2024-03-19</td><td>549.07</td><td>19</td><td>1</td><td>474.92</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>6</td><td>101</td><td>2023-07-22</td><td>189.85</td><td>32</td><td>4</td><td>272.64</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 5 Ã— 7\n",
       "\\begin{tabular}{r|lllllll}\n",
       "  & OrderID & CustomerID & Order\\_Date & Total\\_Amount & ProductID & Quantity & Unit\\_Price\\\\\n",
       "  & <int> & <int> & <chr> & <dbl> & <int> & <int> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 & 1 &  87 & 2023-08-30 & 424.30 &  2 & 3 & 115.72\\\\\n",
       "\t2 & 1 &  87 & 2023-08-30 & 424.30 & 22 & 5 & 206.62\\\\\n",
       "\t3 & 1 &  87 & 2023-08-30 & 424.30 & 26 & 5 &  61.75\\\\\n",
       "\t4 & 3 &  37 & 2024-03-19 & 549.07 & 19 & 1 & 474.92\\\\\n",
       "\t5 & 6 & 101 & 2023-07-22 & 189.85 & 32 & 4 & 272.64\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 5 Ã— 7\n",
       "\n",
       "| <!--/--> | OrderID &lt;int&gt; | CustomerID &lt;int&gt; | Order_Date &lt;chr&gt; | Total_Amount &lt;dbl&gt; | ProductID &lt;int&gt; | Quantity &lt;int&gt; | Unit_Price &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|\n",
       "| 1 | 1 |  87 | 2023-08-30 | 424.30 |  2 | 3 | 115.72 |\n",
       "| 2 | 1 |  87 | 2023-08-30 | 424.30 | 22 | 5 | 206.62 |\n",
       "| 3 | 1 |  87 | 2023-08-30 | 424.30 | 26 | 5 |  61.75 |\n",
       "| 4 | 3 |  37 | 2024-03-19 | 549.07 | 19 | 1 | 474.92 |\n",
       "| 5 | 6 | 101 | 2023-07-22 | 189.85 | 32 | 4 | 272.64 |\n",
       "\n"
      ],
      "text/plain": [
       "  OrderID CustomerID Order_Date Total_Amount ProductID Quantity Unit_Price\n",
       "1 1        87        2023-08-30 424.30        2        3        115.72    \n",
       "2 1        87        2023-08-30 424.30       22        5        206.62    \n",
       "3 1        87        2023-08-30 424.30       26        5         61.75    \n",
       "4 3        37        2024-03-19 549.07       19        1        474.92    \n",
       "5 6       101        2023-07-22 189.85       32        4        272.64    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Task 6.2: Join Orders and Order Items\n",
    "# TODO: Create 'orders_with_items' by inner joining orders with order_items\n",
    "#       Join on OrderID\n",
    "\n",
    "#Used inner_join to inner join orders and order_items by OrderID.\n",
    "#Inner Join only uses matching data between the two data sets.\n",
    "\n",
    "orders_with_items <- inner_join(orders, order_items, by = \"OrderID\")\n",
    "\n",
    "\n",
    "cat(\"========== ORDERS WITH ITEMS ==========\\n\")\n",
    "cat(\"Total rows:\", nrow(orders_with_items), \"\\n\")\n",
    "head(orders_with_items, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part7_intro",
   "metadata": {},
   "source": [
    "## Part 7: String Manipulation & Date/Time Operations (Lesson 7)\n",
    "\n",
    "**Skills Assessed:** stringr functions, lubridate functions\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Clean text data\n",
    "2. Parse dates\n",
    "3. Extract date components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "clean_text",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== CLEANED TEXT DATA ==========\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 5 Ã— 4</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Region</th><th scope=col>region_clean</th><th scope=col>Product_Category</th><th scope=col>category_clean</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>Latin America</td><td>Latin America</td><td>Services</td><td>Services</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>Europe       </td><td>Europe       </td><td>Hardware</td><td>Hardware</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>Europe       </td><td>Europe       </td><td>Services</td><td>Services</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>Europe       </td><td>Europe       </td><td>Hardware</td><td>Hardware</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>Latin America</td><td>Latin America</td><td>Software</td><td>Software</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 5 Ã— 4\n",
       "\\begin{tabular}{r|llll}\n",
       "  & Region & region\\_clean & Product\\_Category & category\\_clean\\\\\n",
       "  & <chr> & <chr> & <chr> & <chr>\\\\\n",
       "\\hline\n",
       "\t1 & Latin America & Latin America & Services & Services\\\\\n",
       "\t2 & Europe        & Europe        & Hardware & Hardware\\\\\n",
       "\t3 & Europe        & Europe        & Services & Services\\\\\n",
       "\t4 & Europe        & Europe        & Hardware & Hardware\\\\\n",
       "\t5 & Latin America & Latin America & Software & Software\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 5 Ã— 4\n",
       "\n",
       "| <!--/--> | Region &lt;chr&gt; | region_clean &lt;chr&gt; | Product_Category &lt;chr&gt; | category_clean &lt;chr&gt; |\n",
       "|---|---|---|---|---|\n",
       "| 1 | Latin America | Latin America | Services | Services |\n",
       "| 2 | Europe        | Europe        | Hardware | Hardware |\n",
       "| 3 | Europe        | Europe        | Services | Services |\n",
       "| 4 | Europe        | Europe        | Hardware | Hardware |\n",
       "| 5 | Latin America | Latin America | Software | Software |\n",
       "\n"
      ],
      "text/plain": [
       "  Region        region_clean  Product_Category category_clean\n",
       "1 Latin America Latin America Services         Services      \n",
       "2 Europe        Europe        Hardware         Hardware      \n",
       "3 Europe        Europe        Services         Services      \n",
       "4 Europe        Europe        Hardware         Hardware      \n",
       "5 Latin America Latin America Software         Software      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Task 7.1: Clean Text Data\n",
    "# TODO: Add these columns to sales_enhanced using mutate():\n",
    "#   - region_clean: Region with trimmed whitespace and Title Case\n",
    "#   - category_clean: Product_Category with trimmed whitespace and Title Case\n",
    "\n",
    "#Used str_trim to clean up white space and used str_to_title to Title Case both region_clean and category_clean.\n",
    "sales_enhanced <- sales_enhanced %>%\n",
    "  mutate(\n",
    "    region_clean = str_trim(Region),\n",
    "    region_clean = str_to_title(region_clean),\n",
    "    category_clean = str_trim(Product_Category),\n",
    "    category_clean = str_to_title(category_clean)\n",
    "  )\n",
    "\n",
    "cat(\"========== CLEANED TEXT DATA ==========\\n\")\n",
    "head(sales_enhanced %>% select(Region, region_clean, Product_Category, category_clean), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "parse_dates",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== DATE COMPONENTS ==========\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 5 Ã— 4</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Sale_Date</th><th scope=col>date_parsed</th><th scope=col>sale_month</th><th scope=col>sale_weekday</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;date&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;ord&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>2023-04-24</td><td>2023-04-24</td><td>4</td><td>Monday  </td></tr>\n",
       "\t<tr><th scope=row>2</th><td>2023-06-09</td><td>2023-06-09</td><td>6</td><td>Friday  </td></tr>\n",
       "\t<tr><th scope=row>3</th><td>2023-03-25</td><td>2023-03-25</td><td>3</td><td>Saturday</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>2023-04-11</td><td>2023-04-11</td><td>4</td><td>Tuesday </td></tr>\n",
       "\t<tr><th scope=row>5</th><td>2023-08-26</td><td>2023-08-26</td><td>8</td><td>Saturday</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 5 Ã— 4\n",
       "\\begin{tabular}{r|llll}\n",
       "  & Sale\\_Date & date\\_parsed & sale\\_month & sale\\_weekday\\\\\n",
       "  & <chr> & <date> & <dbl> & <ord>\\\\\n",
       "\\hline\n",
       "\t1 & 2023-04-24 & 2023-04-24 & 4 & Monday  \\\\\n",
       "\t2 & 2023-06-09 & 2023-06-09 & 6 & Friday  \\\\\n",
       "\t3 & 2023-03-25 & 2023-03-25 & 3 & Saturday\\\\\n",
       "\t4 & 2023-04-11 & 2023-04-11 & 4 & Tuesday \\\\\n",
       "\t5 & 2023-08-26 & 2023-08-26 & 8 & Saturday\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 5 Ã— 4\n",
       "\n",
       "| <!--/--> | Sale_Date &lt;chr&gt; | date_parsed &lt;date&gt; | sale_month &lt;dbl&gt; | sale_weekday &lt;ord&gt; |\n",
       "|---|---|---|---|---|\n",
       "| 1 | 2023-04-24 | 2023-04-24 | 4 | Monday   |\n",
       "| 2 | 2023-06-09 | 2023-06-09 | 6 | Friday   |\n",
       "| 3 | 2023-03-25 | 2023-03-25 | 3 | Saturday |\n",
       "| 4 | 2023-04-11 | 2023-04-11 | 4 | Tuesday  |\n",
       "| 5 | 2023-08-26 | 2023-08-26 | 8 | Saturday |\n",
       "\n"
      ],
      "text/plain": [
       "  Sale_Date  date_parsed sale_month sale_weekday\n",
       "1 2023-04-24 2023-04-24  4          Monday      \n",
       "2 2023-06-09 2023-06-09  6          Friday      \n",
       "3 2023-03-25 2023-03-25  3          Saturday    \n",
       "4 2023-04-11 2023-04-11  4          Tuesday     \n",
       "5 2023-08-26 2023-08-26  8          Saturday    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Task 7.2: Parse Dates and Extract Components\n",
    "# TODO: Add these date-related columns using mutate():\n",
    "#   - date_parsed: Parse Sale_Date column (use ymd(), mdy(), or dmy() as appropriate)\n",
    "#   - sale_month: Extract month name from date_parsed\n",
    "#   - sale_weekday: Extract weekday name from date_parsed\n",
    "\n",
    "#Used ymd for the correct format to parse sale date. Then used month() to get the month from date_parsed.\n",
    "#Then I used wday() with label = true to give a String name instead of a  value for weekday and abbr as false to not abbreviate the weekday name.\n",
    "sales_enhanced <- sales_enhanced %>%\n",
    "  mutate(\n",
    "    date_parsed = ymd(Sale_Date),\n",
    "    sale_month = month(date_parsed),\n",
    "    sale_weekday = wday(date_parsed, label = TRUE, abbr = FALSE)\n",
    "  )\n",
    "\n",
    "cat(\"========== DATE COMPONENTS ==========\\n\")\n",
    "head(sales_enhanced %>% select(Sale_Date, date_parsed, sale_month, sale_weekday), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part8_intro",
   "metadata": {},
   "source": [
    "## Part 8: Advanced Wrangling & Business Intelligence (Lesson 8)\n",
    "\n",
    "**Skills Assessed:** case_when(), complex logic, KPIs\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Create business categories with case_when()\n",
    "2. Calculate KPIs\n",
    "3. Generate executive summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "case_when_logic",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== PERFORMANCE TIERS ==========\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "  High    Low Medium \n",
       "   154     74     72 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Task 8.1: Create Performance Categories\n",
    "# TODO: Add 'performance_tier' column using case_when():\n",
    "#   - \"High\" if Revenue > 25000\n",
    "#   - \"Medium\" if Revenue > 15000\n",
    "#   - \"Low\" otherwise\n",
    "\n",
    "#Used mutate with case_when to create a new column called performance_tier to sort between high, medium and low revenue.\n",
    "sales_enhanced <- sales_enhanced %>%\n",
    "  mutate(\n",
    "    performance_tier = case_when(\n",
    "      Revenue > 25000 ~ \"High\",\n",
    "      Revenue > 15000 ~ \"Medium\",\n",
    "      TRUE ~ \"Low\"\n",
    "    )\n",
    "  )\n",
    "\n",
    "cat(\"========== PERFORMANCE TIERS ==========\\n\")\n",
    "table(sales_enhanced$performance_tier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "calculate_kpis",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== BUSINESS KPIs ==========\n",
      "  total_revenue total_transactions avg_transaction_value high_value_pct\n",
      "1       7771711                300               25905.7          51.33\n"
     ]
    }
   ],
   "source": [
    "# Task 8.2: Calculate Business KPIs\n",
    "# TODO: Create 'business_kpis' with these metrics:\n",
    "#   - total_revenue: sum of Revenue\n",
    "#   - total_transactions: count of rows\n",
    "#   - avg_transaction_value: mean of Revenue\n",
    "#   - high_value_pct: percentage where high_value = \"Yes\"\n",
    "\n",
    "business_kpis <- sales_enhanced %>%\n",
    "  summarize(\n",
    "    total_revenue = sum(Revenue),\n",
    "    total_transactions = n(),\n",
    "    avg_transaction_value = mean(Revenue),\n",
    "    high_value_pct = round(154 / 300 * 100, 2)\n",
    "  )\n",
    "cat(\"========== BUSINESS KPIs ==========\\n\")\n",
    "print(business_kpis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection_intro",
   "metadata": {},
   "source": [
    "## Part 9: Reflection Questions\n",
    "\n",
    "Answer the following questions based on your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection1",
   "metadata": {},
   "source": [
    "### Question 9.1: Data Cleaning Impact\n",
    "\n",
    "**How did handling missing values and outliers affect your analysis? Why is data cleaning important before performing business analysis?**\n",
    "\n",
    "Your answer here: The data set did not have outliers or missing values. Fortunately, that meant the data did not affect the analysis very much. However, if there were outliers or missing values they would have affected the averages and percentiles.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection2",
   "metadata": {},
   "source": [
    "### Question 9.2: Grouped Analysis Value\n",
    "\n",
    "**What insights did you gain from the regional and category summaries that you couldn't see in the raw data? How can businesses use this type of grouped analysis?**\n",
    "\n",
    "Your answer here: It was easier to see who the top selling regions were which were. Initially it looked like Asia Pacific was on top due to having the highest individual revenue; however, after some arranging of the data. It showed that Latin America and Europe was on top. Also the top revenue producing categories were Consulting and Services. Just looking at the raw data it would have been very difficult to come to these answers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection3",
   "metadata": {},
   "source": [
    "### Question 9.3: Data Reshaping Purpose\n",
    "\n",
    "**Why would you need to reshape data between wide and long formats? Provide a business scenario where each format would be useful.**\n",
    "\n",
    "Your answer here: For breaking things into wider format. I can think of a scenario where a category is really long and it would be beneficial to break it further down into sub-categories to make it easier for a user to read and understand a wider table. As for making it into a longer table it would be easier to run computer calculations on longer tables.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection4",
   "metadata": {},
   "source": [
    "### Question 9.4: Joining Datasets\n",
    "\n",
    "**What is the difference between left_join() and inner_join()? When would you use each one in a business context?**\n",
    "\n",
    "Your answer here: In a left join the complete table on the left is kept and only matching data from the right table is joined with the left table. This may end up with some NA fields in the data. In an inner join only matching data between both data sets is joined, and no NA fields occurs. For a left join business context: If a company is merging data with a company it bought, and it wants to retain all its current data, but wants to join what it can from the new company. Inner_Join would be useful when trying to run analysis on suppliers data and the product data the company sells. Since the only information the company wants to look at is the matching products. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection5",
   "metadata": {},
   "source": [
    "### Question 9.5: Skills Integration\n",
    "\n",
    "**Which R data wrangling skill (from Lessons 1-8) do you think is most valuable for business analytics? Why?**\n",
    "\n",
    "Your answer here: I think they are all very important to run any kind of analysis, but being able to mutate, summarize, and group by data is really valuable. Take for example mutating, being able to create new columns with existing information and being able analyze a regions total sales or units sold. Or take for example being able to summarize data set by creating KPI's to quickly and easily see the performance metrics from a data set. I think they are very powerful tools that can help focus the answers in a data set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## Exam Complete!\n",
    "\n",
    "### What You've Demonstrated\n",
    "\n",
    "âœ… **Lesson 1:** R basics and data import\n",
    "âœ… **Lesson 2:** Data cleaning (missing values & outliers)\n",
    "âœ… **Lesson 3:** Data transformation (select, filter, arrange)\n",
    "âœ… **Lesson 4:** Advanced transformation (mutate, summarize, group_by)\n",
    "âœ… **Lesson 5:** Data reshaping (pivot_longer, pivot_wider)\n",
    "âœ… **Lesson 6:** Combining datasets (joins)\n",
    "âœ… **Lesson 7:** String manipulation & date/time operations\n",
    "âœ… **Lesson 8:** Advanced wrangling & business intelligence\n",
    "\n",
    "### Submission Checklist\n",
    "\n",
    "Before submitting, ensure:\n",
    "- [ ] All code cells run without errors\n",
    "- [ ] All TODO sections completed\n",
    "- [ ] All required dataframes created with correct names\n",
    "- [ ] All 5 reflection questions answered\n",
    "- [ ] Student name and ID filled in at top\n",
    "\n",
    "**Good work! ðŸŽ‰**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
