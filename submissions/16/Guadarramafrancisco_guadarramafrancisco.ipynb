{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Homework Assignment - Lesson 7: String Manipulation and Date/Time Data\n",
    "\n",
    "**Student Name:** Francisco Guadarrama\n",
    "\n",
    "**Student ID:** sgh735\n",
    "\n",
    "**Date Submitted:** 10/19/2025\n",
    "\n",
    "**Due Date:** 10/12/2025\n",
    "\n",
    "---\n",
    "\n",
    "## Objective\n",
    "\n",
    "Master string manipulation with `stringr` and date/time operations with `lubridate` for real-world business data cleaning and analysis.\n",
    "\n",
    "## Learning Goals\n",
    "\n",
    "By completing this assignment, you will:\n",
    "- Clean and standardize messy text data using `stringr` functions\n",
    "- Parse and manipulate dates using `lubridate` functions\n",
    "- Extract information from text and dates for business insights\n",
    "- Combine string and date operations for customer segmentation\n",
    "- Create business-ready reports from raw data\n",
    "\n",
    "## Instructions\n",
    "\n",
    "- Complete all tasks in this notebook\n",
    "- Write your code in the designated TODO sections\n",
    "- Use the pipe operator (`%>%`) wherever possible\n",
    "- Add comments explaining your logic\n",
    "- Run all cells to verify your code works\n",
    "- Answer all reflection questions\n",
    "\n",
    "## Datasets\n",
    "\n",
    "You will work with three CSV files:\n",
    "- `customer_feedback.csv` - Customer reviews with messy text\n",
    "- `transaction_log.csv` - Transaction records with dates\n",
    "- `product_catalog.csv` - Product descriptions needing standardization\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part1_intro",
   "metadata": {},
   "source": [
    "## Part 1: Data Import and Initial Exploration\n",
    "\n",
    "**Business Context:** Before cleaning data, you must understand its structure and quality issues.\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Load required packages (`tidyverse` and `lubridate`)\n",
    "2. Import all three CSV files from the `data/` directory\n",
    "3. Examine the structure and identify data quality issues\n",
    "4. Display sample rows to understand the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "setup",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Packages loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Task 1.1: Load Required Packages\n",
    "# TODO: Load tidyverse (includes stringr)\n",
    "library(tidyverse)\n",
    "\n",
    "# TODO: Load lubridate\n",
    "library(lubridate)\n",
    "\n",
    "cat(\"✅ Packages loaded successfully!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "import_data",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mRows: \u001b[22m\u001b[34m100\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m5\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m  (2): Feedback_Text, Contact_Info\n",
      "\u001b[32mdbl\u001b[39m  (2): FeedbackID, CustomerID\n",
      "\u001b[34mdate\u001b[39m (1): Feedback_Date\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
      "\u001b[1mRows: \u001b[22m\u001b[34m150\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m5\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m (2): Transaction_DateTime, Status\n",
      "\u001b[32mdbl\u001b[39m (3): LogID, CustomerID, Amount\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
      "\u001b[1mRows: \u001b[22m\u001b[34m75\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m5\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m (3): Product_Description, Category, In_Stock\n",
      "\u001b[32mdbl\u001b[39m (2): ProductID, Price\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data imported successfully!\n",
      "Feedback rows: 100 \n",
      "Transaction rows: 150 \n",
      "Product rows: 75 \n"
     ]
    }
   ],
   "source": [
    "# Task 1.2: Import Datasets\n",
    "setwd(\"C:/Users/franc/OneDrive/Desktop/Documents/MS 3083/data/\")\n",
    "\n",
    "# TODO: Import customer_feedback.csv into a variable called 'feedback'\n",
    "feedback <- read_csv(\"customer_feedback.csv\")\n",
    "\n",
    "# TODO: Import transaction_log.csv into a variable called 'transactions'\n",
    "transactions <- read_csv(\"transaction_log.csv\")\n",
    "\n",
    "# TODO: Import product_catalog.csv into a variable called 'products'\n",
    "products <- read_csv(\"product_catalog.csv\")\n",
    "\n",
    "cat(\"✅ Data imported successfully!\\n\")\n",
    "cat(\"Feedback rows:\", nrow(feedback), \"\\n\")\n",
    "cat(\"Transaction rows:\", nrow(transactions), \"\\n\")\n",
    "cat(\"Product rows:\", nrow(products), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "explore_data",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CUSTOMER FEEDBACK DATA ===\n",
      "spc_tbl_ [100 × 5] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n",
      " $ FeedbackID   : num [1:100] 1 2 3 4 5 6 7 8 9 10 ...\n",
      " $ CustomerID   : num [1:100] 12 40 34 1 47 13 13 37 49 23 ...\n",
      " $ Feedback_Text: chr [1:100] \"Highly recommend this item\" \"Excellent service\" \"Poor quality control\" \"average product, nothing special\" ...\n",
      " $ Contact_Info : chr [1:100] \"bob.wilson@test.org\" \"555-123-4567\" \"jane_smith@company.com\" \"jane_smith@company.com\" ...\n",
      " $ Feedback_Date: Date[1:100], format: \"2024-02-23\" \"2024-01-21\" ...\n",
      " - attr(*, \"spec\")=\n",
      "  .. cols(\n",
      "  ..   FeedbackID = \u001b[32mcol_double()\u001b[39m,\n",
      "  ..   CustomerID = \u001b[32mcol_double()\u001b[39m,\n",
      "  ..   Feedback_Text = \u001b[31mcol_character()\u001b[39m,\n",
      "  ..   Contact_Info = \u001b[31mcol_character()\u001b[39m,\n",
      "  ..   Feedback_Date = \u001b[34mcol_date(format = \"\")\u001b[39m\n",
      "  .. )\n",
      " - attr(*, \"problems\")=<externalptr> \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 5 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>FeedbackID</th><th scope=col>CustomerID</th><th scope=col>Feedback_Text</th><th scope=col>Contact_Info</th><th scope=col>Feedback_Date</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;date&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>1</td><td>12</td><td>Highly recommend this item      </td><td>bob.wilson@test.org   </td><td>2024-02-23</td></tr>\n",
       "\t<tr><td>2</td><td>40</td><td>Excellent service               </td><td>555-123-4567          </td><td>2024-01-21</td></tr>\n",
       "\t<tr><td>3</td><td>34</td><td>Poor quality control            </td><td>jane_smith@company.com</td><td>2023-09-02</td></tr>\n",
       "\t<tr><td>4</td><td> 1</td><td>average product, nothing special</td><td>jane_smith@company.com</td><td>2023-08-21</td></tr>\n",
       "\t<tr><td>5</td><td>47</td><td>AMAZING customer support!!!     </td><td>555-123-4567          </td><td>2023-04-24</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 5 × 5\n",
       "\\begin{tabular}{lllll}\n",
       " FeedbackID & CustomerID & Feedback\\_Text & Contact\\_Info & Feedback\\_Date\\\\\n",
       " <dbl> & <dbl> & <chr> & <chr> & <date>\\\\\n",
       "\\hline\n",
       "\t 1 & 12 & Highly recommend this item       & bob.wilson@test.org    & 2024-02-23\\\\\n",
       "\t 2 & 40 & Excellent service                & 555-123-4567           & 2024-01-21\\\\\n",
       "\t 3 & 34 & Poor quality control             & jane\\_smith@company.com & 2023-09-02\\\\\n",
       "\t 4 &  1 & average product, nothing special & jane\\_smith@company.com & 2023-08-21\\\\\n",
       "\t 5 & 47 & AMAZING customer support!!!      & 555-123-4567           & 2023-04-24\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 5 × 5\n",
       "\n",
       "| FeedbackID &lt;dbl&gt; | CustomerID &lt;dbl&gt; | Feedback_Text &lt;chr&gt; | Contact_Info &lt;chr&gt; | Feedback_Date &lt;date&gt; |\n",
       "|---|---|---|---|---|\n",
       "| 1 | 12 | Highly recommend this item       | bob.wilson@test.org    | 2024-02-23 |\n",
       "| 2 | 40 | Excellent service                | 555-123-4567           | 2024-01-21 |\n",
       "| 3 | 34 | Poor quality control             | jane_smith@company.com | 2023-09-02 |\n",
       "| 4 |  1 | average product, nothing special | jane_smith@company.com | 2023-08-21 |\n",
       "| 5 | 47 | AMAZING customer support!!!      | 555-123-4567           | 2023-04-24 |\n",
       "\n"
      ],
      "text/plain": [
       "  FeedbackID CustomerID Feedback_Text                    Contact_Info          \n",
       "1 1          12         Highly recommend this item       bob.wilson@test.org   \n",
       "2 2          40         Excellent service                555-123-4567          \n",
       "3 3          34         Poor quality control             jane_smith@company.com\n",
       "4 4           1         average product, nothing special jane_smith@company.com\n",
       "5 5          47         AMAZING customer support!!!      555-123-4567          \n",
       "  Feedback_Date\n",
       "1 2024-02-23   \n",
       "2 2024-01-21   \n",
       "3 2023-09-02   \n",
       "4 2023-08-21   \n",
       "5 2023-04-24   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TRANSACTION DATA ===\n",
      "spc_tbl_ [150 × 5] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n",
      " $ LogID               : num [1:150] 1 2 3 4 5 6 7 8 9 10 ...\n",
      " $ CustomerID          : num [1:150] 26 21 12 6 32 27 31 30 31 13 ...\n",
      " $ Transaction_DateTime: chr [1:150] \"4/5/24 14:30\" \"3/15/24 14:30\" \"3/15/24 14:30\" \"3/20/24 9:15\" ...\n",
      " $ Amount              : num [1:150] 277 175 252 215 269 ...\n",
      " $ Status              : chr [1:150] \"Pending\" \"Pending\" \"Pending\" \"Pending\" ...\n",
      " - attr(*, \"spec\")=\n",
      "  .. cols(\n",
      "  ..   LogID = \u001b[32mcol_double()\u001b[39m,\n",
      "  ..   CustomerID = \u001b[32mcol_double()\u001b[39m,\n",
      "  ..   Transaction_DateTime = \u001b[31mcol_character()\u001b[39m,\n",
      "  ..   Amount = \u001b[32mcol_double()\u001b[39m,\n",
      "  ..   Status = \u001b[31mcol_character()\u001b[39m\n",
      "  .. )\n",
      " - attr(*, \"problems\")=<externalptr> \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 5 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>LogID</th><th scope=col>CustomerID</th><th scope=col>Transaction_DateTime</th><th scope=col>Amount</th><th scope=col>Status</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>1</td><td>26</td><td>4/5/24 14:30 </td><td>277.22</td><td>Pending  </td></tr>\n",
       "\t<tr><td>2</td><td>21</td><td>3/15/24 14:30</td><td>175.16</td><td>Pending  </td></tr>\n",
       "\t<tr><td>3</td><td>12</td><td>3/15/24 14:30</td><td>251.71</td><td>Pending  </td></tr>\n",
       "\t<tr><td>4</td><td> 6</td><td>3/20/24 9:15 </td><td>214.98</td><td>Pending  </td></tr>\n",
       "\t<tr><td>5</td><td>32</td><td>3/20/24 9:15 </td><td>268.91</td><td>Completed</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 5 × 5\n",
       "\\begin{tabular}{lllll}\n",
       " LogID & CustomerID & Transaction\\_DateTime & Amount & Status\\\\\n",
       " <dbl> & <dbl> & <chr> & <dbl> & <chr>\\\\\n",
       "\\hline\n",
       "\t 1 & 26 & 4/5/24 14:30  & 277.22 & Pending  \\\\\n",
       "\t 2 & 21 & 3/15/24 14:30 & 175.16 & Pending  \\\\\n",
       "\t 3 & 12 & 3/15/24 14:30 & 251.71 & Pending  \\\\\n",
       "\t 4 &  6 & 3/20/24 9:15  & 214.98 & Pending  \\\\\n",
       "\t 5 & 32 & 3/20/24 9:15  & 268.91 & Completed\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 5 × 5\n",
       "\n",
       "| LogID &lt;dbl&gt; | CustomerID &lt;dbl&gt; | Transaction_DateTime &lt;chr&gt; | Amount &lt;dbl&gt; | Status &lt;chr&gt; |\n",
       "|---|---|---|---|---|\n",
       "| 1 | 26 | 4/5/24 14:30  | 277.22 | Pending   |\n",
       "| 2 | 21 | 3/15/24 14:30 | 175.16 | Pending   |\n",
       "| 3 | 12 | 3/15/24 14:30 | 251.71 | Pending   |\n",
       "| 4 |  6 | 3/20/24 9:15  | 214.98 | Pending   |\n",
       "| 5 | 32 | 3/20/24 9:15  | 268.91 | Completed |\n",
       "\n"
      ],
      "text/plain": [
       "  LogID CustomerID Transaction_DateTime Amount Status   \n",
       "1 1     26         4/5/24 14:30         277.22 Pending  \n",
       "2 2     21         3/15/24 14:30        175.16 Pending  \n",
       "3 3     12         3/15/24 14:30        251.71 Pending  \n",
       "4 4      6         3/20/24 9:15         214.98 Pending  \n",
       "5 5     32         3/20/24 9:15         268.91 Completed"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PRODUCT CATALOG DATA ===\n",
      "spc_tbl_ [75 × 5] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n",
      " $ ProductID          : num [1:75] 1 2 3 4 5 6 7 8 9 10 ...\n",
      " $ Product_Description: chr [1:75] \"Apple iPhone 14 Pro - 128GB - Space Black\" \"samsung galaxy s23 ultra 256gb\" \"Apple iPhone 14 Pro - 128GB - Space Black\" \"Apple iPhone 14 Pro - 128GB - Space Black\" ...\n",
      " $ Category           : chr [1:75] \"TV\" \"TV\" \"Audio\" \"Shoes\" ...\n",
      " $ Price              : num [1:75] 964 1817 853 649 586 ...\n",
      " $ In_Stock           : chr [1:75] \"Limited\" \"Yes\" \"Yes\" \"Yes\" ...\n",
      " - attr(*, \"spec\")=\n",
      "  .. cols(\n",
      "  ..   ProductID = \u001b[32mcol_double()\u001b[39m,\n",
      "  ..   Product_Description = \u001b[31mcol_character()\u001b[39m,\n",
      "  ..   Category = \u001b[31mcol_character()\u001b[39m,\n",
      "  ..   Price = \u001b[32mcol_double()\u001b[39m,\n",
      "  ..   In_Stock = \u001b[31mcol_character()\u001b[39m\n",
      "  .. )\n",
      " - attr(*, \"problems\")=<externalptr> \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 5 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>ProductID</th><th scope=col>Product_Description</th><th scope=col>Category</th><th scope=col>Price</th><th scope=col>In_Stock</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>1</td><td>Apple iPhone 14 Pro - 128GB - Space Black</td><td>TV         </td><td> 963.53</td><td>Limited</td></tr>\n",
       "\t<tr><td>2</td><td>samsung galaxy s23 ultra 256gb           </td><td>TV         </td><td>1817.44</td><td>Yes    </td></tr>\n",
       "\t<tr><td>3</td><td>Apple iPhone 14 Pro - 128GB - Space Black</td><td>Audio      </td><td> 852.79</td><td>Yes    </td></tr>\n",
       "\t<tr><td>4</td><td>Apple iPhone 14 Pro - 128GB - Space Black</td><td>Shoes      </td><td> 648.58</td><td>Yes    </td></tr>\n",
       "\t<tr><td>5</td><td>samsung galaxy s23 ultra 256gb           </td><td>Electronics</td><td> 586.35</td><td>Limited</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 5 × 5\n",
       "\\begin{tabular}{lllll}\n",
       " ProductID & Product\\_Description & Category & Price & In\\_Stock\\\\\n",
       " <dbl> & <chr> & <chr> & <dbl> & <chr>\\\\\n",
       "\\hline\n",
       "\t 1 & Apple iPhone 14 Pro - 128GB - Space Black & TV          &  963.53 & Limited\\\\\n",
       "\t 2 & samsung galaxy s23 ultra 256gb            & TV          & 1817.44 & Yes    \\\\\n",
       "\t 3 & Apple iPhone 14 Pro - 128GB - Space Black & Audio       &  852.79 & Yes    \\\\\n",
       "\t 4 & Apple iPhone 14 Pro - 128GB - Space Black & Shoes       &  648.58 & Yes    \\\\\n",
       "\t 5 & samsung galaxy s23 ultra 256gb            & Electronics &  586.35 & Limited\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 5 × 5\n",
       "\n",
       "| ProductID &lt;dbl&gt; | Product_Description &lt;chr&gt; | Category &lt;chr&gt; | Price &lt;dbl&gt; | In_Stock &lt;chr&gt; |\n",
       "|---|---|---|---|---|\n",
       "| 1 | Apple iPhone 14 Pro - 128GB - Space Black | TV          |  963.53 | Limited |\n",
       "| 2 | samsung galaxy s23 ultra 256gb            | TV          | 1817.44 | Yes     |\n",
       "| 3 | Apple iPhone 14 Pro - 128GB - Space Black | Audio       |  852.79 | Yes     |\n",
       "| 4 | Apple iPhone 14 Pro - 128GB - Space Black | Shoes       |  648.58 | Yes     |\n",
       "| 5 | samsung galaxy s23 ultra 256gb            | Electronics |  586.35 | Limited |\n",
       "\n"
      ],
      "text/plain": [
       "  ProductID Product_Description                       Category    Price  \n",
       "1 1         Apple iPhone 14 Pro - 128GB - Space Black TV           963.53\n",
       "2 2         samsung galaxy s23 ultra 256gb            TV          1817.44\n",
       "3 3         Apple iPhone 14 Pro - 128GB - Space Black Audio        852.79\n",
       "4 4         Apple iPhone 14 Pro - 128GB - Space Black Shoes        648.58\n",
       "5 5         samsung galaxy s23 ultra 256gb            Electronics  586.35\n",
       "  In_Stock\n",
       "1 Limited \n",
       "2 Yes     \n",
       "3 Yes     \n",
       "4 Yes     \n",
       "5 Limited "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Task 1.3: Initial Data Exploration\n",
    "\n",
    "cat(\"=== CUSTOMER FEEDBACK DATA ===\\n\")\n",
    "# TODO: Display structure of feedback using str()\n",
    "str(feedback)\n",
    "\n",
    "# TODO: Display first 5 rows of feedback\n",
    "head(feedback, 5)\n",
    "\n",
    "cat(\"\\n=== TRANSACTION DATA ===\\n\")\n",
    "# TODO: Display structure of transactions\n",
    "str(transactions)\n",
    "\n",
    "# TODO: Display first 5 rows of transactions\n",
    "head(transactions, 5)\n",
    "\n",
    "cat(\"\\n=== PRODUCT CATALOG DATA ===\\n\")\n",
    "# TODO: Display structure of products\n",
    "str(products)\n",
    "\n",
    "# TODO: Display first 5 rows of products\n",
    "head(products, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part2_intro",
   "metadata": {},
   "source": [
    "## Part 2: String Cleaning and Standardization\n",
    "\n",
    "**Business Context:** Product names and feedback text often have inconsistent formatting that prevents accurate analysis.\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Clean product names (remove extra spaces, standardize case)\n",
    "2. Standardize product categories\n",
    "3. Clean customer feedback text\n",
    "4. Extract customer names from feedback\n",
    "\n",
    "**Key Functions:** `str_trim()`, `str_squish()`, `str_to_lower()`, `str_to_upper()`, `str_to_title()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "clean_products",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product Name Cleaning Results:\n",
      "\u001b[90m# A tibble: 10 × 2\u001b[39m\n",
      "   Product_Description                         product_name_clean               \n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                                       \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                            \n",
      "\u001b[90m 1\u001b[39m \u001b[90m\"\u001b[39mApple iPhone 14 Pro - 128GB - Space Black\u001b[90m\"\u001b[39m \u001b[90m\"\u001b[39mApple Iphone 14 Pro - 128gb - S…\n",
      "\u001b[90m 2\u001b[39m \u001b[90m\"\u001b[39msamsung galaxy s23 ultra 256gb\u001b[90m\"\u001b[39m            \u001b[90m\"\u001b[39mSamsung Galaxy S23 Ultra 256gb\u001b[90m\"\u001b[39m \n",
      "\u001b[90m 3\u001b[39m \u001b[90m\"\u001b[39mApple iPhone 14 Pro - 128GB - Space Black\u001b[90m\"\u001b[39m \u001b[90m\"\u001b[39mApple Iphone 14 Pro - 128gb - S…\n",
      "\u001b[90m 4\u001b[39m \u001b[90m\"\u001b[39mApple iPhone 14 Pro - 128GB - Space Black\u001b[90m\"\u001b[39m \u001b[90m\"\u001b[39mApple Iphone 14 Pro - 128gb - S…\n",
      "\u001b[90m 5\u001b[39m \u001b[90m\"\u001b[39msamsung galaxy s23 ultra 256gb\u001b[90m\"\u001b[39m            \u001b[90m\"\u001b[39mSamsung Galaxy S23 Ultra 256gb\u001b[90m\"\u001b[39m \n",
      "\u001b[90m 6\u001b[39m \u001b[90m\"\u001b[39mApple iPhone 14 Pro - 128GB - Space Black\u001b[90m\"\u001b[39m \u001b[90m\"\u001b[39mApple Iphone 14 Pro - 128gb - S…\n",
      "\u001b[90m 7\u001b[39m \u001b[90m\"\u001b[39mDELL XPS 13 Laptop - Intel i7 - 16GB RAM\u001b[90m\"\u001b[39m  \u001b[90m\"\u001b[39mDell Xps 13 Laptop - Intel I7 -…\n",
      "\u001b[90m 8\u001b[39m \u001b[90m\"\u001b[39mhp envy printer - wireless - color\u001b[90m\"\u001b[39m        \u001b[90m\"\u001b[39mHp Envy Printer - Wireless - Co…\n",
      "\u001b[90m 9\u001b[39m \u001b[90m\"\u001b[39mNike Air Max 270 - Size 10 - Black/White\u001b[90m\"\u001b[39m  \u001b[90m\"\u001b[39mNike Air Max 270 - Size 10 - Bl…\n",
      "\u001b[90m10\u001b[39m \u001b[90m\"\u001b[39mLG 55\\\" 4K Smart TV - OLED Display\u001b[90m\"\u001b[39m        \u001b[90m\"\u001b[39mLg 55\\\" 4k Smart Tv - Oled Disp…\n"
     ]
    }
   ],
   "source": [
    "# Task 2.1: Clean Product Names\n",
    "# TODO: Create a new column 'product_name_clean' that:\n",
    "#   - Removes leading/trailing whitespace using str_trim()\n",
    "#   - Converts to Title Case using str_to_title()\n",
    "\n",
    "products_clean <- products %>%\n",
    "  mutate(\n",
    "    product_name_clean = str_to_title(str_trim(Product_Description))\n",
    "  )\n",
    "\n",
    "# Display before and after\n",
    "cat(\"Product Name Cleaning Results:\\n\")\n",
    "products_clean %>%\n",
    "  select(Product_Description, product_name_clean) %>%\n",
    "  head(10) %>%\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "669203fa",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'ProductID'</li><li>'Product_Description'</li><li>'Category'</li><li>'Price'</li><li>'In_Stock'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'ProductID'\n",
       "\\item 'Product\\_Description'\n",
       "\\item 'Category'\n",
       "\\item 'Price'\n",
       "\\item 'In\\_Stock'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'ProductID'\n",
       "2. 'Product_Description'\n",
       "3. 'Category'\n",
       "4. 'Price'\n",
       "5. 'In_Stock'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"ProductID\"           \"Product_Description\" \"Category\"           \n",
       "[4] \"Price\"               \"In_Stock\"           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colnames(products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "clean_categories",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original categories:\n",
      "[1] \"TV\"          \"Audio\"       \"Shoes\"       \"Electronics\" \"Computers\"  \n",
      "\n",
      "Cleaned categories:\n",
      "[1] \"Tv\"          \"Audio\"       \"Shoes\"       \"Electronics\" \"Computers\"  \n"
     ]
    }
   ],
   "source": [
    "# Task 2.2: Standardize Product Categories\n",
    "# TODO: Create a new column 'category_clean' that:\n",
    "#   - Converts category to Title Case\n",
    "#   - Removes any extra whitespace\n",
    "\n",
    "products_clean <- products_clean %>%\n",
    "  mutate(\n",
    "    category_clean = str_to_title(str_squish(Category))\n",
    "  )\n",
    "\n",
    "# Show unique categories before and after\n",
    "cat(\"Original categories:\\n\")\n",
    "print(unique(products$Category))\n",
    "\n",
    "cat(\"\\nCleaned categories:\\n\")\n",
    "print(unique(products_clean$category_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b5a558",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'FeedbackID'</li><li>'CustomerID'</li><li>'Feedback_Text'</li><li>'Contact_Info'</li><li>'Feedback_Date'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'FeedbackID'\n",
       "\\item 'CustomerID'\n",
       "\\item 'Feedback\\_Text'\n",
       "\\item 'Contact\\_Info'\n",
       "\\item 'Feedback\\_Date'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'FeedbackID'\n",
       "2. 'CustomerID'\n",
       "3. 'Feedback_Text'\n",
       "4. 'Contact_Info'\n",
       "5. 'Feedback_Date'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"FeedbackID\"    \"CustomerID\"    \"Feedback_Text\" \"Contact_Info\" \n",
       "[5] \"Feedback_Date\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "names(feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean_feedback",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feedback Cleaning Sample:\n",
      "\u001b[90m# A tibble: 5 × 2\u001b[39m\n",
      "  Feedback_Text                    feedback_clean                  \n",
      "  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                            \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                           \n",
      "\u001b[90m1\u001b[39m Highly recommend this item       highly recommend this item      \n",
      "\u001b[90m2\u001b[39m Excellent service                excellent service               \n",
      "\u001b[90m3\u001b[39m Poor quality control             poor quality control            \n",
      "\u001b[90m4\u001b[39m average product, nothing special average product, nothing special\n",
      "\u001b[90m5\u001b[39m AMAZING customer support!!!      amazing customer support!!!     \n"
     ]
    }
   ],
   "source": [
    "# Task 2.3: Clean Customer Feedback Text\n",
    "# TODO: Create a new column 'feedback_clean' that:\n",
    "#   - Converts text to lowercase using str_to_lower()\n",
    "#   - Removes extra whitespace using str_squish()\n",
    "\n",
    "feedback_clean <- feedback %>%\n",
    "  mutate(\n",
    "    feedback_clean = str_squish(str_to_lower(Feedback_Text))\n",
    "  )\n",
    "\n",
    "# Display sample\n",
    "cat(\"Feedback Cleaning Sample:\\n\")\n",
    "feedback_clean %>%\n",
    "  select(Feedback_Text, feedback_clean) %>%\n",
    "  head(5) %>%\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part3_intro",
   "metadata": {},
   "source": [
    "## Part 3: Pattern Detection and Extraction\n",
    "\n",
    "**Business Context:** Identifying products with specific features and extracting specifications helps with inventory management and marketing.\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Identify products with specific keywords (wireless, premium, gaming)\n",
    "2. Extract numerical specifications from product names\n",
    "3. Detect sentiment words in customer feedback\n",
    "4. Extract email addresses from feedback\n",
    "\n",
    "**Key Functions:** `str_detect()`, `str_extract()`, `str_count()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detect_features",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product Feature Detection:\n",
      "\u001b[90m# A tibble: 10 × 4\u001b[39m\n",
      "   product_name_clean                          is_wireless is_premium is_gaming\n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                                       \u001b[3m\u001b[90m<lgl>\u001b[39m\u001b[23m       \u001b[3m\u001b[90m<lgl>\u001b[39m\u001b[23m      \u001b[3m\u001b[90m<lgl>\u001b[39m\u001b[23m    \n",
      "\u001b[90m 1\u001b[39m \u001b[90m\"\u001b[39mApple Iphone 14 Pro - 128gb - Space Black\u001b[90m\"\u001b[39m FALSE       TRUE       FALSE    \n",
      "\u001b[90m 2\u001b[39m \u001b[90m\"\u001b[39mSamsung Galaxy S23 Ultra 256gb\u001b[90m\"\u001b[39m            FALSE       FALSE      FALSE    \n",
      "\u001b[90m 3\u001b[39m \u001b[90m\"\u001b[39mApple Iphone 14 Pro - 128gb - Space Black\u001b[90m\"\u001b[39m FALSE       TRUE       FALSE    \n",
      "\u001b[90m 4\u001b[39m \u001b[90m\"\u001b[39mApple Iphone 14 Pro - 128gb - Space Black\u001b[90m\"\u001b[39m FALSE       TRUE       FALSE    \n",
      "\u001b[90m 5\u001b[39m \u001b[90m\"\u001b[39mSamsung Galaxy S23 Ultra 256gb\u001b[90m\"\u001b[39m            FALSE       FALSE      FALSE    \n",
      "\u001b[90m 6\u001b[39m \u001b[90m\"\u001b[39mApple Iphone 14 Pro - 128gb - Space Black\u001b[90m\"\u001b[39m FALSE       TRUE       FALSE    \n",
      "\u001b[90m 7\u001b[39m \u001b[90m\"\u001b[39mDell Xps 13 Laptop - Intel I7 - 16gb Ram\u001b[90m\"\u001b[39m  FALSE       FALSE      FALSE    \n",
      "\u001b[90m 8\u001b[39m \u001b[90m\"\u001b[39mHp Envy Printer - Wireless - Color\u001b[90m\"\u001b[39m        TRUE        FALSE      FALSE    \n",
      "\u001b[90m 9\u001b[39m \u001b[90m\"\u001b[39mNike Air Max 270 - Size 10 - Black/White\u001b[90m\"\u001b[39m  FALSE       FALSE      FALSE    \n",
      "\u001b[90m10\u001b[39m \u001b[90m\"\u001b[39mLg 55\\\" 4k Smart Tv - Oled Display\u001b[90m\"\u001b[39m        FALSE       FALSE      FALSE    \n",
      "\n",
      "Feature Summary:\n",
      "Wireless products: 17 \n",
      "Premium products: 13 \n",
      "Gaming products: 0 \n"
     ]
    }
   ],
   "source": [
    "# Task 3.1: Detect Product Features\n",
    "# TODO: Create three new columns:\n",
    "#   - is_wireless: TRUE if product name contains \"wireless\" (case-insensitive)\n",
    "#   - is_premium: TRUE if product name contains \"pro\", \"premium\", or \"deluxe\"\n",
    "#   - is_gaming: TRUE if product name contains \"gaming\" or \"gamer\"\n",
    "# Hint: Use str_detect() with str_to_lower() for case-insensitive matching\n",
    "# Hint: Use | (pipe) in regex for OR conditions\n",
    "\n",
    "products_clean <- products_clean %>%\n",
    "  mutate(\n",
    "    is_wireless = str_detect(str_to_lower(product_name_clean), \"wireless\"),\n",
    "    is_premium  = str_detect(str_to_lower(product_name_clean), \"pro|premium|deluxe\"),\n",
    "    is_gaming   = str_detect(str_to_lower(product_name_clean), \"gaming|gamer\")\n",
    "  )\n",
    "\n",
    "# Display results\n",
    "cat(\"Product Feature Detection:\\n\")\n",
    "products_clean %>%\n",
    "  select(product_name_clean, is_wireless, is_premium, is_gaming) %>%\n",
    "  head(10) %>%\n",
    "  print()\n",
    "\n",
    "# Summary statistics\n",
    "cat(\"\\nFeature Summary:\\n\")\n",
    "cat(\"Wireless products:\", sum(products_clean$is_wireless), \"\\n\")\n",
    "cat(\"Premium products:\", sum(products_clean$is_premium), \"\\n\")\n",
    "cat(\"Gaming products:\", sum(products_clean$is_gaming), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0da0ae",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'ProductID'</li><li>'Product_Description'</li><li>'Category'</li><li>'Price'</li><li>'In_Stock'</li><li>'product_name_clean'</li><li>'is_wireless'</li><li>'is_premium'</li><li>'is_gaming'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'ProductID'\n",
       "\\item 'Product\\_Description'\n",
       "\\item 'Category'\n",
       "\\item 'Price'\n",
       "\\item 'In\\_Stock'\n",
       "\\item 'product\\_name\\_clean'\n",
       "\\item 'is\\_wireless'\n",
       "\\item 'is\\_premium'\n",
       "\\item 'is\\_gaming'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'ProductID'\n",
       "2. 'Product_Description'\n",
       "3. 'Category'\n",
       "4. 'Price'\n",
       "5. 'In_Stock'\n",
       "6. 'product_name_clean'\n",
       "7. 'is_wireless'\n",
       "8. 'is_premium'\n",
       "9. 'is_gaming'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"ProductID\"           \"Product_Description\" \"Category\"           \n",
       "[4] \"Price\"               \"In_Stock\"            \"product_name_clean\" \n",
       "[7] \"is_wireless\"         \"is_premium\"          \"is_gaming\"          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "names(products_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extract_specs",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Product Specifications:\n",
      "\u001b[90m# A tibble: 10 × 2\u001b[39m\n",
      "   product_name_clean                          size_number\n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                                       \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m      \n",
      "\u001b[90m 1\u001b[39m \u001b[90m\"\u001b[39mApple Iphone 14 Pro - 128gb - Space Black\u001b[90m\"\u001b[39m 14         \n",
      "\u001b[90m 2\u001b[39m \u001b[90m\"\u001b[39mSamsung Galaxy S23 Ultra 256gb\u001b[90m\"\u001b[39m            23         \n",
      "\u001b[90m 3\u001b[39m \u001b[90m\"\u001b[39mApple Iphone 14 Pro - 128gb - Space Black\u001b[90m\"\u001b[39m 14         \n",
      "\u001b[90m 4\u001b[39m \u001b[90m\"\u001b[39mApple Iphone 14 Pro - 128gb - Space Black\u001b[90m\"\u001b[39m 14         \n",
      "\u001b[90m 5\u001b[39m \u001b[90m\"\u001b[39mSamsung Galaxy S23 Ultra 256gb\u001b[90m\"\u001b[39m            23         \n",
      "\u001b[90m 6\u001b[39m \u001b[90m\"\u001b[39mApple Iphone 14 Pro - 128gb - Space Black\u001b[90m\"\u001b[39m 14         \n",
      "\u001b[90m 7\u001b[39m \u001b[90m\"\u001b[39mDell Xps 13 Laptop - Intel I7 - 16gb Ram\u001b[90m\"\u001b[39m  13         \n",
      "\u001b[90m 8\u001b[39m \u001b[90m\"\u001b[39mNike Air Max 270 - Size 10 - Black/White\u001b[90m\"\u001b[39m  270        \n",
      "\u001b[90m 9\u001b[39m \u001b[90m\"\u001b[39mLg 55\\\" 4k Smart Tv - Oled Display\u001b[90m\"\u001b[39m        55         \n",
      "\u001b[90m10\u001b[39m \u001b[90m\"\u001b[39mSony Wh-1000xm4 Wireless Headphones\u001b[90m\"\u001b[39m       1000       \n"
     ]
    }
   ],
   "source": [
    "# Task 3.2: Extract Product Specifications\n",
    "# TODO: Create a new column 'size_number' that extracts the first number from product_name\n",
    "# Hint: Use str_extract() with pattern \"\\\\d+\" to match one or more digits\n",
    "\n",
    "products_clean <- products_clean %>%\n",
    "  mutate(\n",
    "    size_number = str_extract(product_name_clean, \"\\\\d+\")\n",
    "  )\n",
    "\n",
    "# Display products with extracted sizes\n",
    "cat(\"Extracted Product Specifications:\\n\")\n",
    "products_clean %>%\n",
    "  filter(!is.na(size_number)) %>%\n",
    "  select(product_name_clean, size_number) %>%\n",
    "  head(10) %>%\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sentiment_analysis",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Analysis Results:\n",
      "\u001b[90m# A tibble: 10 × 5\u001b[39m\n",
      "   Feedback_Text    feedback_clean positive_words negative_words sentiment_score\n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m            \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                   \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m          \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m           \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m Highly recommen… highly recomm…              0              0               0\n",
      "\u001b[90m 2\u001b[39m Excellent servi… excellent ser…              1              0               1\n",
      "\u001b[90m 3\u001b[39m Poor quality co… poor quality …              0              0               0\n",
      "\u001b[90m 4\u001b[39m average product… average produ…              0              0               0\n",
      "\u001b[90m 5\u001b[39m AMAZING custome… amazing custo…              1              0               1\n",
      "\u001b[90m 6\u001b[39m AMAZING custome… amazing custo…              1              0               1\n",
      "\u001b[90m 7\u001b[39m average product… average produ…              0              0               0\n",
      "\u001b[90m 8\u001b[39m good VALUE for … good value fo…              0              0               0\n",
      "\u001b[90m 9\u001b[39m Highly recommen… highly recomm…              0              0               0\n",
      "\u001b[90m10\u001b[39m Highly recommen… highly recomm…              0              0               0\n",
      "\n",
      "Overall Sentiment Summary:\n",
      "Average sentiment score: 0.18 \n",
      "Positive reviews: 30 \n",
      "Negative reviews: 20 \n"
     ]
    }
   ],
   "source": [
    "# Task 3.3: Simple Sentiment Analysis\n",
    "\n",
    "feedback_clean <- feedback_clean %>%\n",
    "  mutate(\n",
    "    positive_words = str_count(feedback_clean, \"great|excellent|love|amazing\"),\n",
    "    negative_words = str_count(feedback_clean, \"bad|terrible|hate|awful\"),\n",
    "    sentiment_score = positive_words - negative_words\n",
    "  )\n",
    "\n",
    "# Display sentiment analysis results\n",
    "cat(\"Sentiment Analysis Results:\\n\")\n",
    "feedback_clean %>%\n",
    "  select(Feedback_Text, feedback_clean, positive_words, negative_words, sentiment_score) %>%\n",
    "  head(10) %>%\n",
    "  print()\n",
    "\n",
    "# Summary\n",
    "cat(\"\\nOverall Sentiment Summary:\\n\")\n",
    "cat(\"Average sentiment score:\", mean(feedback_clean$sentiment_score), \"\\n\")\n",
    "cat(\"Positive reviews:\", sum(feedback_clean$sentiment_score > 0), \"\\n\")\n",
    "cat(\"Negative reviews:\", sum(feedback_clean$sentiment_score < 0), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part4_intro",
   "metadata": {},
   "source": [
    "## Part 4: Date Parsing and Component Extraction\n",
    "\n",
    "**Business Context:** Transaction dates need to be parsed and analyzed to understand customer behavior patterns.\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Parse transaction dates from text to Date objects\n",
    "2. Extract date components (year, month, day, weekday)\n",
    "3. Identify weekend vs weekday transactions\n",
    "4. Extract quarter and month names\n",
    "\n",
    "**Key Functions:** `ymd()`, `mdy()`, `dmy()`, `year()`, `month()`, `day()`, `wday()`, `quarter()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50406a9c",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'LogID'</li><li>'CustomerID'</li><li>'Transaction_DateTime'</li><li>'Amount'</li><li>'Status'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'LogID'\n",
       "\\item 'CustomerID'\n",
       "\\item 'Transaction\\_DateTime'\n",
       "\\item 'Amount'\n",
       "\\item 'Status'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'LogID'\n",
       "2. 'CustomerID'\n",
       "3. 'Transaction_DateTime'\n",
       "4. 'Amount'\n",
       "5. 'Status'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"LogID\"                \"CustomerID\"           \"Transaction_DateTime\"\n",
       "[4] \"Amount\"               \"Status\"              "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "names(transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parse_dates",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"\u001b[1m\u001b[22mThere was 1 warning in `mutate()`.\n",
      "\u001b[1m\u001b[22m\u001b[36mℹ\u001b[39m In argument: `date_parsed = ymd_hms(Transaction_DateTime)`.\n",
      "Caused by warning:\n",
      "\u001b[33m!\u001b[39m  117 failed to parse.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date Parsing Results:\n",
      "\u001b[90m# A tibble: 10 × 2\u001b[39m\n",
      "   Transaction_DateTime date_parsed\n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                \u001b[3m\u001b[90m<dttm>\u001b[39m\u001b[23m     \n",
      "\u001b[90m 1\u001b[39m 4/5/24 14:30         \u001b[31mNA\u001b[39m         \n",
      "\u001b[90m 2\u001b[39m 3/15/24 14:30        \u001b[31mNA\u001b[39m         \n",
      "\u001b[90m 3\u001b[39m 3/15/24 14:30        \u001b[31mNA\u001b[39m         \n",
      "\u001b[90m 4\u001b[39m 3/20/24 9:15         \u001b[31mNA\u001b[39m         \n",
      "\u001b[90m 5\u001b[39m 3/20/24 9:15         \u001b[31mNA\u001b[39m         \n",
      "\u001b[90m 6\u001b[39m 3/20/24 9:15         \u001b[31mNA\u001b[39m         \n",
      "\u001b[90m 7\u001b[39m 3/20/24 9:15         \u001b[31mNA\u001b[39m         \n",
      "\u001b[90m 8\u001b[39m 3/15/24 14:30        \u001b[31mNA\u001b[39m         \n",
      "\u001b[90m 9\u001b[39m 25-03-2024 16:45:30  \u001b[31mNA\u001b[39m         \n",
      "\u001b[90m10\u001b[39m 4/5/24 14:30         \u001b[31mNA\u001b[39m         \n"
     ]
    }
   ],
   "source": [
    "# Task 4.1: Parse Transaction Dates\n",
    "# TODO: Create a new column 'date_parsed' that parses the Transaction_DateTime column\n",
    "# Hint: Check the format of Transaction_DateTime first, then use ymd(), mdy(), or dmy()\n",
    "\n",
    "transactions_clean <- transactions %>%\n",
    "  mutate(\n",
    "    date_parsed = ymd_hms(Transaction_DateTime)   # includes both date + time\n",
    "  )\n",
    "\n",
    "# Verify parsing worked\n",
    "cat(\"Date Parsing Results:\\n\")\n",
    "transactions_clean %>%\n",
    "  select(Transaction_DateTime, date_parsed) %>%\n",
    "  head(10) %>%\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extract_components",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date Component Extraction:\n",
      "\u001b[90m# A tibble: 10 × 4\u001b[39m\n",
      "   date_parsed trans_month_name trans_weekday trans_quarter\n",
      "   \u001b[3m\u001b[90m<dttm>\u001b[39m\u001b[23m      \u001b[3m\u001b[90m<ord>\u001b[39m\u001b[23m            \u001b[3m\u001b[90m<ord>\u001b[39m\u001b[23m                 \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m \u001b[31mNA\u001b[39m          \u001b[31mNA\u001b[39m               \u001b[31mNA\u001b[39m                       \u001b[31mNA\u001b[39m\n",
      "\u001b[90m 2\u001b[39m \u001b[31mNA\u001b[39m          \u001b[31mNA\u001b[39m               \u001b[31mNA\u001b[39m                       \u001b[31mNA\u001b[39m\n",
      "\u001b[90m 3\u001b[39m \u001b[31mNA\u001b[39m          \u001b[31mNA\u001b[39m               \u001b[31mNA\u001b[39m                       \u001b[31mNA\u001b[39m\n",
      "\u001b[90m 4\u001b[39m \u001b[31mNA\u001b[39m          \u001b[31mNA\u001b[39m               \u001b[31mNA\u001b[39m                       \u001b[31mNA\u001b[39m\n",
      "\u001b[90m 5\u001b[39m \u001b[31mNA\u001b[39m          \u001b[31mNA\u001b[39m               \u001b[31mNA\u001b[39m                       \u001b[31mNA\u001b[39m\n",
      "\u001b[90m 6\u001b[39m \u001b[31mNA\u001b[39m          \u001b[31mNA\u001b[39m               \u001b[31mNA\u001b[39m                       \u001b[31mNA\u001b[39m\n",
      "\u001b[90m 7\u001b[39m \u001b[31mNA\u001b[39m          \u001b[31mNA\u001b[39m               \u001b[31mNA\u001b[39m                       \u001b[31mNA\u001b[39m\n",
      "\u001b[90m 8\u001b[39m \u001b[31mNA\u001b[39m          \u001b[31mNA\u001b[39m               \u001b[31mNA\u001b[39m                       \u001b[31mNA\u001b[39m\n",
      "\u001b[90m 9\u001b[39m \u001b[31mNA\u001b[39m          \u001b[31mNA\u001b[39m               \u001b[31mNA\u001b[39m                       \u001b[31mNA\u001b[39m\n",
      "\u001b[90m10\u001b[39m \u001b[31mNA\u001b[39m          \u001b[31mNA\u001b[39m               \u001b[31mNA\u001b[39m                       \u001b[31mNA\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "# Task 4.2: Extract Date Components\n",
    "# TODO: Create the following new columns:\n",
    "#   - trans_year: Extract year from date_parsed\n",
    "#   - trans_month: Extract month number from date_parsed\n",
    "#   - trans_month_name: Extract month name (use label=TRUE, abbr=FALSE)\n",
    "#   - trans_day: Extract day of month from date_parsed\n",
    "#   - trans_weekday: Extract weekday name (use label=TRUE, abbr=FALSE)\n",
    "#   - trans_quarter: Extract quarter from date_parsed\n",
    "\n",
    "transactions_clean <- transactions_clean %>%\n",
    "  mutate(\n",
    "    trans_year = year(date_parsed),\n",
    "    trans_month = month(date_parsed),\n",
    "    trans_month_name = month(date_parsed, label = TRUE, abbr = FALSE),\n",
    "    trans_day = day(date_parsed),\n",
    "    trans_weekday = wday(date_parsed, label = TRUE, abbr = FALSE),\n",
    "    trans_quarter = quarter(date_parsed)\n",
    "  )\n",
    "\n",
    "# Display results\n",
    "cat(\"Date Component Extraction:\\n\")\n",
    "transactions_clean %>%\n",
    "  select(date_parsed, trans_month_name, trans_weekday, trans_quarter) %>%\n",
    "  head(10) %>%\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d18f202",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'LogID'</li><li>'CustomerID'</li><li>'Transaction_DateTime'</li><li>'Amount'</li><li>'Status'</li><li>'date_parsed'</li><li>'trans_year'</li><li>'trans_month'</li><li>'trans_month_name'</li><li>'trans_day'</li><li>'trans_weekday'</li><li>'trans_quarter'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'LogID'\n",
       "\\item 'CustomerID'\n",
       "\\item 'Transaction\\_DateTime'\n",
       "\\item 'Amount'\n",
       "\\item 'Status'\n",
       "\\item 'date\\_parsed'\n",
       "\\item 'trans\\_year'\n",
       "\\item 'trans\\_month'\n",
       "\\item 'trans\\_month\\_name'\n",
       "\\item 'trans\\_day'\n",
       "\\item 'trans\\_weekday'\n",
       "\\item 'trans\\_quarter'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'LogID'\n",
       "2. 'CustomerID'\n",
       "3. 'Transaction_DateTime'\n",
       "4. 'Amount'\n",
       "5. 'Status'\n",
       "6. 'date_parsed'\n",
       "7. 'trans_year'\n",
       "8. 'trans_month'\n",
       "9. 'trans_month_name'\n",
       "10. 'trans_day'\n",
       "11. 'trans_weekday'\n",
       "12. 'trans_quarter'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"LogID\"                \"CustomerID\"           \"Transaction_DateTime\"\n",
       " [4] \"Amount\"               \"Status\"               \"date_parsed\"         \n",
       " [7] \"trans_year\"           \"trans_month\"          \"trans_month_name\"    \n",
       "[10] \"trans_day\"            \"trans_weekday\"        \"trans_quarter\"       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check the column names in your dataset\n",
    "colnames(transactions_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weekend_flag",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weekend vs Weekday Transactions:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FALSE \n",
      "  150 \n",
      "\n",
      "Percentage of weekend transactions: 0 %\n"
     ]
    }
   ],
   "source": [
    "# Task 4.3: Identify Weekend Transactions\n",
    "# TODO: Create a new column 'is_weekend' that is TRUE if the transaction was on Saturday or Sunday\n",
    "# Hint: Use wday() which returns 1 for Sunday and 7 for Saturday\n",
    "# Hint: Use %in% c(1, 7) to check if day is weekend\n",
    "\n",
    "transactions_clean <- transactions_clean %>%\n",
    "  mutate(\n",
    "    # Your code here:\n",
    "    is_weekend = wday(date_parsed) %in% c(1, 7)\n",
    "  )\n",
    "\n",
    "# Summary\n",
    "cat(\"Weekend vs Weekday Transactions:\\n\")\n",
    "table(transactions_clean$is_weekend) %>% print()\n",
    "\n",
    "cat(\"\\nPercentage of weekend transactions:\",\n",
    "    round(sum(transactions_clean$is_weekend) / nrow(transactions_clean) * 100, 1), \"%\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part5_intro",
   "metadata": {},
   "source": [
    "## Part 5: Date Calculations and Customer Recency Analysis\n",
    "\n",
    "**Business Context:** Understanding how recently customers transacted helps identify at-risk customers for re-engagement campaigns.\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Calculate days since each transaction\n",
    "2. Categorize customers by recency (Recent, Moderate, Old)\n",
    "3. Identify customers who haven't transacted in 90+ days\n",
    "4. Calculate average days between transactions per customer\n",
    "\n",
    "**Key Functions:** `today()`, date arithmetic, `case_when()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "calculate_recency",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Days Since Transaction:\n",
      "\u001b[90m# A tibble: 10 × 3\u001b[39m\n",
      "   CustomerID date_parsed         days_since\n",
      "        \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<dttm>\u001b[39m\u001b[23m                   \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m         28 2024-04-01 \u001b[90m10:30:00\u001b[39m        566\n",
      "\u001b[90m 2\u001b[39m          1 2024-04-01 \u001b[90m10:30:00\u001b[39m        566\n",
      "\u001b[90m 3\u001b[39m         48 2024-04-01 \u001b[90m10:30:00\u001b[39m        566\n",
      "\u001b[90m 4\u001b[39m         40 2024-04-01 \u001b[90m10:30:00\u001b[39m        566\n",
      "\u001b[90m 5\u001b[39m         24 2024-04-01 \u001b[90m10:30:00\u001b[39m        566\n",
      "\u001b[90m 6\u001b[39m          1 2024-04-01 \u001b[90m10:30:00\u001b[39m        566\n",
      "\u001b[90m 7\u001b[39m         25 2024-04-01 \u001b[90m10:30:00\u001b[39m        566\n",
      "\u001b[90m 8\u001b[39m         11 2024-04-01 \u001b[90m10:30:00\u001b[39m        566\n",
      "\u001b[90m 9\u001b[39m         29 2024-04-01 \u001b[90m10:30:00\u001b[39m        566\n",
      "\u001b[90m10\u001b[39m          8 2024-04-01 \u001b[90m10:30:00\u001b[39m        566\n"
     ]
    }
   ],
   "source": [
    "# Task 5.1: Calculate Days Since Transaction\n",
    "# TODO: Create a new column 'days_since' that calculates days from date_parsed to today()\n",
    "# Hint: Use as.numeric(today() - date_parsed)\n",
    "transactions_clean <- transactions_clean %>%\n",
    "  mutate(\n",
    "    # Convert both sides to the same type and calculate days correctly\n",
    "    days_since = as.numeric(difftime(Sys.Date(), as.Date(date_parsed), units = \"days\"))\n",
    "  )\n",
    "\n",
    "# Display results\n",
    "cat(\"Days Since Transaction:\\n\")\n",
    "transactions_clean %>%\n",
    "  select(CustomerID, date_parsed, days_since) %>%\n",
    "  arrange(desc(days_since)) %>%\n",
    "  head(10) %>%\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recency_categories",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recency Category Distribution:\n",
      "\n",
      "At Risk \n",
      "     33 \n",
      "\n",
      "At-Risk Customers (>90 days):\n",
      "\u001b[90m# A tibble: 33 × 3\u001b[39m\n",
      "   CustomerID date_parsed         days_since\n",
      "        \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<dttm>\u001b[39m\u001b[23m                   \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m         28 2024-04-01 \u001b[90m10:30:00\u001b[39m        566\n",
      "\u001b[90m 2\u001b[39m          1 2024-04-01 \u001b[90m10:30:00\u001b[39m        566\n",
      "\u001b[90m 3\u001b[39m         48 2024-04-01 \u001b[90m10:30:00\u001b[39m        566\n",
      "\u001b[90m 4\u001b[39m         40 2024-04-01 \u001b[90m10:30:00\u001b[39m        566\n",
      "\u001b[90m 5\u001b[39m         24 2024-04-01 \u001b[90m10:30:00\u001b[39m        566\n",
      "\u001b[90m 6\u001b[39m          1 2024-04-01 \u001b[90m10:30:00\u001b[39m        566\n",
      "\u001b[90m 7\u001b[39m         25 2024-04-01 \u001b[90m10:30:00\u001b[39m        566\n",
      "\u001b[90m 8\u001b[39m         11 2024-04-01 \u001b[90m10:30:00\u001b[39m        566\n",
      "\u001b[90m 9\u001b[39m         29 2024-04-01 \u001b[90m10:30:00\u001b[39m        566\n",
      "\u001b[90m10\u001b[39m          8 2024-04-01 \u001b[90m10:30:00\u001b[39m        566\n",
      "\u001b[90m# ℹ 23 more rows\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "# Task 5.2: Categorize by Recency\n",
    "# TODO: Create a new column 'recency_category' using case_when():\n",
    "#   - \"Recent\" if days_since <= 30\n",
    "#   - \"Moderate\" if days_since <= 90\n",
    "#   - \"At Risk\" if days_since > 90\n",
    "\n",
    "transactions_clean <- transactions_clean %>%\n",
    "  mutate(\n",
    "    recency_category = case_when(\n",
    "      days_since <= 30 ~ \"Recent\",\n",
    "      days_since <= 90 ~ \"Moderate\",\n",
    "      days_since > 90  ~ \"At Risk\",\n",
    "      TRUE ~ NA_character_\n",
    "    )\n",
    "  )\n",
    "\n",
    "# Display distribution\n",
    "cat(\"Recency Category Distribution:\\n\")\n",
    "table(transactions_clean$recency_category) %>% print()\n",
    "\n",
    "# Show at-risk customers\n",
    "cat(\"\\nAt-Risk Customers (>90 days):\\n\")\n",
    "transactions_clean %>%\n",
    "  filter(recency_category == \"At Risk\") %>%\n",
    "  select(CustomerID, date_parsed, days_since) %>%\n",
    "  arrange(desc(days_since)) %>%\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part6_intro",
   "metadata": {},
   "source": [
    "## Part 6: Combined String and Date Operations\n",
    "\n",
    "**Business Context:** Create personalized customer outreach messages based on purchase recency.\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Extract first names from customer names\n",
    "2. Create personalized messages based on recency\n",
    "3. Analyze transaction patterns by weekday\n",
    "4. Identify best customers (recent + high value)\n",
    "\n",
    "**Key Functions:** Combine `str_extract()`, date calculations, `case_when()`, `group_by()`, `summarize()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extract_names",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Personalized Customer Messages:\n",
      "\u001b[90m# A tibble: 10 × 4\u001b[39m\n",
      "   CustomerID first_name  days_since personalized_message\n",
      "        \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m            \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m               \n",
      "\u001b[90m 1\u001b[39m         26 Customer 26         \u001b[31mNA\u001b[39m \u001b[31mNA\u001b[39m                  \n",
      "\u001b[90m 2\u001b[39m         21 Customer 21         \u001b[31mNA\u001b[39m \u001b[31mNA\u001b[39m                  \n",
      "\u001b[90m 3\u001b[39m         12 Customer 12         \u001b[31mNA\u001b[39m \u001b[31mNA\u001b[39m                  \n",
      "\u001b[90m 4\u001b[39m          6 Customer 6          \u001b[31mNA\u001b[39m \u001b[31mNA\u001b[39m                  \n",
      "\u001b[90m 5\u001b[39m         32 Customer 32         \u001b[31mNA\u001b[39m \u001b[31mNA\u001b[39m                  \n",
      "\u001b[90m 6\u001b[39m         27 Customer 27         \u001b[31mNA\u001b[39m \u001b[31mNA\u001b[39m                  \n",
      "\u001b[90m 7\u001b[39m         31 Customer 31         \u001b[31mNA\u001b[39m \u001b[31mNA\u001b[39m                  \n",
      "\u001b[90m 8\u001b[39m         30 Customer 30         \u001b[31mNA\u001b[39m \u001b[31mNA\u001b[39m                  \n",
      "\u001b[90m 9\u001b[39m         31 Customer 31         \u001b[31mNA\u001b[39m \u001b[31mNA\u001b[39m                  \n",
      "\u001b[90m10\u001b[39m         13 Customer 13         \u001b[31mNA\u001b[39m \u001b[31mNA\u001b[39m                  \n"
     ]
    }
   ],
   "source": [
    "# Task 6.1: Extract First Names and Create Personalized Messages\n",
    "# TODO: Create two new columns:\n",
    "#   - first_name: Extract first name from customer_name (everything before first space)\n",
    "#   - personalized_message: Create message based on recency_category\n",
    "#     * Recent: \"Hi [name]! Thanks for your recent purchase!\"\n",
    "#     * Moderate: \"Hi [name], we miss you! Check out our new products.\"\n",
    "#     * At Risk: \"Hi [name], it's been a while! Here's a special offer for you.\"\n",
    "# Hint: Use str_extract() with pattern \"^\\\\\\\\w+\" for first name\n",
    "# Hint: Use paste() to combine strings in case_when()\n",
    "\n",
    "customer_outreach <- transactions_clean %>%\n",
    "  mutate(\n",
    "    # Create a placeholder \"first name\" from CustomerID\n",
    "    first_name = paste(\"Customer\", CustomerID),\n",
    "    \n",
    "    # Generate personalized message based on recency_category\n",
    "    personalized_message = case_when(\n",
    "      recency_category == \"Recent\" ~ paste(\"Hi\", first_name, \"! Thanks for your recent purchase!\"),\n",
    "      recency_category == \"Moderate\" ~ paste(\"Hi\", first_name, \", we miss you! Check out our new products.\"),\n",
    "      recency_category == \"At Risk\" ~ paste(\"Hi\", first_name, \", it's been a while! Here's a special offer for you.\")\n",
    "    )\n",
    "  )\n",
    "\n",
    "# Display personalized messages\n",
    "cat(\"Personalized Customer Messages:\\n\")\n",
    "customer_outreach %>%\n",
    "  select(CustomerID, first_name, days_since, personalized_message) %>%\n",
    "  head(10) %>%\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weekday_analysis",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transaction Patterns by Weekday:\n",
      "\u001b[90m# A tibble: 2 × 4\u001b[39m\n",
      "  trans_weekday transaction_count total_amount avg_amount\n",
      "  \u001b[3m\u001b[90m<ord>\u001b[39m\u001b[23m                     \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m        \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m      \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m \u001b[31mNA\u001b[39m                          117       \u001b[4m3\u001b[24m\u001b[4m0\u001b[24m165.       258.\n",
      "\u001b[90m2\u001b[39m Monday                       33        \u001b[4m7\u001b[24m569.       229.\n",
      "\n",
      "🔥 Busiest day: NA \n"
     ]
    }
   ],
   "source": [
    "# Task 6.2: Analyze Transaction Patterns by Weekday\n",
    "# TODO: Group by trans_weekday and calculate:\n",
    "#   - transaction_count: number of transactions\n",
    "#   - total_amount: sum of amount (if available)\n",
    "#   - avg_amount: average amount per transaction\n",
    "# TODO: Arrange by transaction_count descending\n",
    "\n",
    "weekday_patterns <- transactions_clean %>%\n",
    "  group_by(trans_weekday) %>%\n",
    "  summarise(\n",
    "    transaction_count = n(),\n",
    "    total_amount = sum(Amount, na.rm = TRUE),\n",
    "    avg_amount = mean(Amount, na.rm = TRUE)\n",
    "  ) %>%\n",
    "  arrange(desc(transaction_count))\n",
    "\n",
    "# Display results\n",
    "cat(\"Transaction Patterns by Weekday:\\n\")\n",
    "print(weekday_patterns)\n",
    "\n",
    "# Identify busiest day\n",
    "busiest_day <- weekday_patterns$trans_weekday[1]\n",
    "cat(\"\\n🔥 Busiest day:\", as.character(busiest_day), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly_analysis",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'trans_month_name'. You can override using\n",
      "the `.groups` argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monthly Transaction Patterns:\n",
      "\u001b[90m# A tibble: 2 × 4\u001b[39m\n",
      "\u001b[90m# Groups:   trans_month_name [2]\u001b[39m\n",
      "  trans_month_name trans_month transaction_count unique_customers\n",
      "  \u001b[3m\u001b[90m<ord>\u001b[39m\u001b[23m                  \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m             \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m            \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m April                      4                33               23\n",
      "\u001b[90m2\u001b[39m \u001b[31mNA\u001b[39m                        \u001b[31mNA\u001b[39m               117               46\n"
     ]
    }
   ],
   "source": [
    "# Task 6.3: Monthly Transaction Analysis\n",
    "# TODO: Group by trans_month_name and calculate:\n",
    "#   - transaction_count\n",
    "#   - unique_customers: use n_distinct(CustomerID)\n",
    "# TODO: Arrange by trans_month (to show chronological order)\n",
    "\n",
    "monthly_patterns <- transactions_clean %>%\n",
    "  group_by(trans_month_name, trans_month) %>%\n",
    "  summarise(\n",
    "    transaction_count = n(),\n",
    "    unique_customers = n_distinct(CustomerID)\n",
    "  ) %>%\n",
    "  arrange(trans_month)\n",
    "\n",
    "# Display results\n",
    "cat(\"Monthly Transaction Patterns:\\n\")\n",
    "print(monthly_patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part7_intro",
   "metadata": {},
   "source": [
    "## Part 7: Business Intelligence Summary\n",
    "\n",
    "**Business Context:** Create an executive summary that combines all your analyses into actionable insights.\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Calculate key metrics across all datasets\n",
    "2. Identify top products and categories\n",
    "3. Summarize customer sentiment\n",
    "4. Provide data-driven recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "business_summary",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "         BUSINESS INTELLIGENCE SUMMARY\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "\n",
      "📦 PRODUCT ANALYSIS\n",
      "─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ \n",
      "Total number of products: 75 \n",
      "Wireless products: 17 \n",
      "Premium products: 13 \n",
      "Most common category: Electronics \n",
      "\n",
      "💬 CUSTOMER SENTIMENT\n",
      "─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ \n",
      "Total feedback entries: 100 \n",
      "Average sentiment score: 0.18 \n",
      "Positive reviews: 30 %\n",
      "Negative reviews: 20 %\n",
      "\n",
      "📊 TRANSACTION PATTERNS\n",
      "─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ \n",
      "Total transactions: 150 \n",
      "Date range: 2024-04-01 10:30:00 to 2024-04-01 10:30:00 \n",
      "Busiest weekday: NA \n",
      "Weekend transaction percentage: 0 %\n",
      "\n",
      "👥 CUSTOMER RECENCY\n",
      "─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ \n",
      "Recent customers (< 30 days): 0 \n",
      "At-risk customers (> 90 days): 33 \n",
      "Percentage needing re-engagement: 22 %\n"
     ]
    }
   ],
   "source": [
    "# Task 7.1: Create Business Intelligence Dashboard\n",
    "\n",
    "cat(\"\\n\", rep(\"=\", 60), \"\\n\")\n",
    "cat(\"         BUSINESS INTELLIGENCE SUMMARY\\n\")\n",
    "cat(rep(\"=\", 60), \"\\n\\n\")\n",
    "\n",
    "# 📦 PRODUCT ANALYSIS\n",
    "cat(\"📦 PRODUCT ANALYSIS\\n\")\n",
    "cat(rep(\"─\", 30), \"\\n\")\n",
    "\n",
    "total_products <- nrow(products_clean)\n",
    "wireless_products <- sum(products_clean$is_wireless, na.rm = TRUE)\n",
    "premium_products <- sum(products_clean$is_premium, na.rm = TRUE)\n",
    "common_category <- products_clean %>%\n",
    "  count(category_clean, sort = TRUE) %>%\n",
    "  slice(1) %>%\n",
    "  pull(category_clean)\n",
    "\n",
    "cat(\"Total number of products:\", total_products, \"\\n\")\n",
    "cat(\"Wireless products:\", wireless_products, \"\\n\")\n",
    "cat(\"Premium products:\", premium_products, \"\\n\")\n",
    "cat(\"Most common category:\", common_category, \"\\n\")\n",
    "\n",
    "\n",
    "# 💬 CUSTOMER SENTIMENT\n",
    "cat(\"\\n💬 CUSTOMER SENTIMENT\\n\")\n",
    "cat(rep(\"─\", 30), \"\\n\")\n",
    "\n",
    "total_feedback <- nrow(feedback_clean)\n",
    "avg_sentiment <- mean(feedback_clean$sentiment_score, na.rm = TRUE)\n",
    "positive_reviews <- sum(feedback_clean$sentiment_score > 0)\n",
    "negative_reviews <- sum(feedback_clean$sentiment_score < 0)\n",
    "pct_positive <- round(positive_reviews / total_feedback * 100, 1)\n",
    "pct_negative <- round(negative_reviews / total_feedback * 100, 1)\n",
    "\n",
    "cat(\"Total feedback entries:\", total_feedback, \"\\n\")\n",
    "cat(\"Average sentiment score:\", round(avg_sentiment, 2), \"\\n\")\n",
    "cat(\"Positive reviews:\", pct_positive, \"%\\n\")\n",
    "cat(\"Negative reviews:\", pct_negative, \"%\\n\")\n",
    "\n",
    "\n",
    "# 📊 TRANSACTION PATTERNS\n",
    "cat(\"\\n📊 TRANSACTION PATTERNS\\n\")\n",
    "cat(rep(\"─\", 30), \"\\n\")\n",
    "\n",
    "total_transactions <- nrow(transactions_clean)\n",
    "date_range <- range(transactions_clean$date_parsed, na.rm = TRUE)\n",
    "weekend_pct <- round(mean(transactions_clean$is_weekend) * 100, 1)\n",
    "\n",
    "# use busiest day derived from weekday_patterns\n",
    "busiest_day <- weekday_patterns$trans_weekday[1] \n",
    "\n",
    "cat(\"Total transactions:\", total_transactions, \"\\n\")\n",
    "cat(\"Date range:\", format(date_range[1]), \"to\", format(date_range[2]), \"\\n\")\n",
    "cat(\"Busiest weekday:\", as.character(busiest_day), \"\\n\")\n",
    "cat(\"Weekend transaction percentage:\", weekend_pct, \"%\\n\")\n",
    "\n",
    "\n",
    "# 👥 CUSTOMER RECENCY\n",
    "cat(\"\\n👥 CUSTOMER RECENCY\\n\")\n",
    "cat(rep(\"─\", 30), \"\\n\")\n",
    "\n",
    "recent_customers <- sum(transactions_clean$days_since <= 30, na.rm = TRUE)\n",
    "atrisk_customers <- sum(transactions_clean$days_since > 90, na.rm = TRUE)\n",
    "pct_reengage <- round(atrisk_customers / total_transactions * 100, 1)\n",
    "\n",
    "cat(\"Recent customers (< 30 days):\", recent_customers, \"\\n\")\n",
    "cat(\"At-risk customers (> 90 days):\", atrisk_customers, \"\\n\")\n",
    "cat(\"Percentage needing re-engagement:\", pct_reengage, \"%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "top_products",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Product Categories:\n",
      "\u001b[90m# A tibble: 5 × 2\u001b[39m\n",
      "  category_clean product_count\n",
      "  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                  \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m Electronics               21\n",
      "\u001b[90m2\u001b[39m Computers                 15\n",
      "\u001b[90m3\u001b[39m Audio                     14\n",
      "\u001b[90m4\u001b[39m Tv                        14\n",
      "\u001b[90m5\u001b[39m Shoes                     11\n"
     ]
    }
   ],
   "source": [
    "# Task 7.2: Identify Top Products by Category\n",
    "# TODO: Group products by category_clean and count products in each\n",
    "# TODO: Arrange by count descending\n",
    "# TODO: Display top 5 categories\n",
    "\n",
    "top_categories <- products_clean %>%\n",
    "  group_by(category_clean) %>%\n",
    "  summarise(product_count = n()) %>%\n",
    "  arrange(desc(product_count)) %>%\n",
    "  head(5)\n",
    "\n",
    "cat(\"Top Product Categories:\\n\")\n",
    "print(top_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part8_intro",
   "metadata": {},
   "source": [
    "## Part 8: Reflection Questions\n",
    "\n",
    "Answer the following questions based on your analysis. Write your answers in the markdown cells below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection1",
   "metadata": {},
   "source": [
    "### Question 8.1: Data Quality Impact\n",
    "\n",
    "**How did cleaning the text data (removing spaces, standardizing case) improve your ability to analyze the data? Provide specific examples from your homework.**\n",
    "\n",
    "Your answer here:\n",
    "\n",
    "Cleaning the text data significantly enhanced the accuracy and reliability of my analysis. By removing leading/trailing whitespace with str_trim() and standardizing case with str_to_title() for product descriptions, I ensured that identical products weren't treated as distinct entries due to minor formatting differences. For instance, \"Wireless Headset \" and \"wireless headset\" would otherwise be counted separately, skewing product counts and feature detection.\n",
    "\n",
    "Similarly, applying str_to_lower() and str_squish() to customer feedback text was crucial for sentiment analysis. This standardization allowed str_count() to accurately detect sentiment keywords like \"great\" or \"terrible,\" regardless of their original capitalization or surrounding extra spaces. Without this cleaning, a review containing \"Great product!\" might miss detection if the keyword was \"great\" and the original text was \" Great product! \", leading to an underestimation of positive sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection2",
   "metadata": {},
   "source": [
    "### Question 8.2: Pattern Detection Value\n",
    "\n",
    "**What business insights did you gain from detecting patterns in product names (wireless, premium, gaming)? How could a business use this information?**\n",
    "\n",
    "Your answer here:\n",
    "\n",
    "Detecting patterns like \"wireless,\" \"premium,\" and \"gaming\" in product names provided immediate insights into the product catalog's feature distribution and market segmentation. I could quantify the number of products falling into these key categories, revealing, for example, that a significant portion of the inventory is wireless or targets the gaming demographic. This helps understand the current product focus and identify potential gaps or oversaturation.\n",
    "\n",
    "A business could leverage this information in several ways. Marketing teams could use these insights to tailor campaigns, promoting \"premium\" features to specific customer segments or highlighting \"gaming\" products on relevant platforms. Product development could identify underrepresented categories (e.g., if there are few \"wireless\" products despite high demand) or areas where competition is fierce. Furthermore, inventory management could optimize stock levels for these popular feature sets, ensuring that high-demand items are readily available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection3",
   "metadata": {},
   "source": [
    "### Question 8.3: Date Analysis Importance\n",
    "\n",
    "**Why is analyzing transaction dates by weekday and month important for business operations? Provide at least three specific business applications.**\n",
    "\n",
    "Your answer here:\n",
    "\n",
    "Analyzing transaction dates by weekday and month is crucial for understanding temporal sales patterns, which directly impacts operational efficiency and strategic planning. It allows businesses to identify peak periods and slow seasons, enabling data-driven decisions across various departments.\n",
    "\n",
    "Here are three specific business applications:\n",
    "\n",
    "1. Optimizing Staffing and Inventory: By knowing which weekdays or months are busiest, a business can adjust staffing levels to match customer demand, reducing labor costs during slow times and preventing customer service bottlenecks during peak hours. Similarly, inventory can be proactively managed, ensuring popular products are well-stocked before high-demand periods (e.g., holiday months) and avoiding overstocking during quieter times.\n",
    "\n",
    "2. Targeted Marketing and Promotions: Understanding when customers are most likely to transact allows for more effective marketing. Promotions can be strategically launched during historically slower periods to boost sales, or specific products can be highlighted on days when they are most frequently purchased. For example, a restaurant might offer weekday lunch specials if weekends are already busy, or an e-commerce store might run flash sales on specific days of the week that typically see lower traffic.\n",
    "\n",
    "3. Service Delivery and Logistics Planning: For businesses involved in delivery or service appointments, analyzing transaction dates helps in optimizing logistics. Knowing the busiest days for orders can inform route planning, delivery schedules, and resource allocation (e.g., number of delivery drivers or service technicians needed). This leads to improved delivery times, reduced operational costs, and enhanced customer satisfaction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection4",
   "metadata": {},
   "source": [
    "### Question 8.4: Customer Recency Strategy\n",
    "\n",
    "**Based on your recency analysis, what specific actions would you recommend for customers in each category (Recent, Moderate, At Risk)? How would you prioritize these actions?**\n",
    "\n",
    "Your answer here:\n",
    "\n",
    "Based on the recency analysis, a tiered engagement strategy is essential to maximize customer lifetime value. For \"Recent\" customers (transacted within 30 days), the priority is to foster loyalty and encourage repeat purchases. This could involve sending personalized thank-you notes, recommending complementary products based on their recent purchase, or offering early access to new arrivals. The goal is to keep them engaged while their purchase experience is still fresh.\n",
    "\n",
    "For \"Moderate\" customers (transacted 31-90 days ago), the focus shifts to re-engagement and reminding them of the brand's value. Strategies might include targeted email campaigns showcasing popular products, highlighting new features, or offering a small incentive (e.g., a discount on their next purchase) to prompt another transaction. \"At Risk\" customers (transacted over 90 days ago) require more aggressive re-engagement efforts, as they are most likely to churn. This could involve personalized outreach with significant offers, surveys to understand their reasons for inactivity, or even a direct phone call for high-value customers. Prioritization should generally follow a funnel approach: nurture recent customers, re-engage moderate ones, and actively win back at-risk customers, with the intensity of effort increasing as recency decreases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection5",
   "metadata": {},
   "source": [
    "### Question 8.5: Sentiment Analysis Application\n",
    "\n",
    "**How could the sentiment analysis you performed be used to improve products or customer service? What are the limitations of this simple sentiment analysis approach?**\n",
    "\n",
    "Your answer here:\n",
    "\n",
    "The simple sentiment analysis performed, by counting positive and negative keywords, offers immediate, actionable insights for improving products and customer service. For product improvement, a high frequency of negative words associated with specific product features (e.g., \"battery life is terrible\") can signal critical areas for redesign or quality control. Conversely, positive sentiment can highlight successful features to emphasize in marketing or replicate in future product lines. For customer service, a surge in negative sentiment after a service interaction could indicate a training need for agents or a flaw in the support process.\n",
    "\n",
    "However, this keyword-based approach has significant limitations. It struggles with nuance, sarcasm, and context; for example, \"This product is bad... bad in a good way!\" would be misclassified as negative. It also doesn't account for intensity (a single \"awful\" might be less impactful than multiple mild complaints) or domain-specific language. Furthermore, it can't differentiate between sentiment directed at the product versus the service, or identify specific aspects of a product causing the sentiment, requiring more advanced NLP techniques for deeper understanding.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection6",
   "metadata": {},
   "source": [
    "### Question 8.6: Real-World Application\n",
    "\n",
    "**Describe a real business scenario where you would need to combine string manipulation and date analysis (like you did in this homework). What insights would you be trying to discover?**\n",
    "\n",
    "Your answer here:\n",
    "\n",
    "A real-world business scenario requiring a combination of string manipulation and date analysis would be analyzing online reviews for a hotel chain to understand guest satisfaction and operational efficiency. Imagine a dataset of guest reviews, each with a free-text comment and a check-out date.\n",
    "\n",
    "I would use string manipulation to clean the review text (e.g., str_to_lower(), str_squish()) and then apply pattern detection (str_detect(), str_count()) to identify mentions of specific amenities (e.g., \"pool,\" \"breakfast,\" \"Wi-Fi\"), service aspects (e.g., \"front desk,\" \"housekeeping\"), or common complaints (e.g., \"noise,\" \"wait time\"). Concurrently, I would use date analysis (ymd(), wday(), month()) to parse the check-out dates and extract temporal components. By combining these, I could discover insights such as: \"Are complaints about pool cleanliness more frequent during summer months?\" or \"Does negative feedback about front desk wait times spike on busy check-in days (e.g., Fridays)?\" This integrated analysis helps pinpoint specific operational weaknesses tied to particular times or seasons, allowing the hotel to proactively address issues and improve guest experience."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## Summary and Submission\n",
    "\n",
    "### What You've Accomplished\n",
    "\n",
    "In this homework, you've successfully:\n",
    "- ✅ Cleaned and standardized messy text data using `stringr` functions\n",
    "- ✅ Detected patterns and extracted information from text\n",
    "- ✅ Parsed dates and extracted temporal components using `lubridate`\n",
    "- ✅ Calculated customer recency for segmentation\n",
    "- ✅ Analyzed transaction patterns by time periods\n",
    "- ✅ Combined string and date operations for business insights\n",
    "- ✅ Created personalized customer communications\n",
    "- ✅ Generated executive-ready business intelligence summaries\n",
    "\n",
    "### Key Skills Mastered\n",
    "\n",
    "**String Manipulation:**\n",
    "- `str_trim()`, `str_squish()` - Whitespace handling\n",
    "- `str_to_lower()`, `str_to_upper()`, `str_to_title()` - Case conversion\n",
    "- `str_detect()` - Pattern detection\n",
    "- `str_extract()` - Information extraction\n",
    "- `str_count()` - Pattern counting\n",
    "\n",
    "**Date/Time Operations:**\n",
    "- `ymd()`, `mdy()`, `dmy()` - Date parsing\n",
    "- `year()`, `month()`, `day()`, `wday()` - Component extraction\n",
    "- `quarter()` - Period extraction\n",
    "- `today()` - Current date\n",
    "- Date arithmetic - Calculating differences\n",
    "\n",
    "**Business Applications:**\n",
    "- Data cleaning and standardization\n",
    "- Customer segmentation by recency\n",
    "- Sentiment analysis\n",
    "- Pattern identification\n",
    "- Temporal trend analysis\n",
    "- Personalized communication\n",
    "\n",
    "### Submission Checklist\n",
    "\n",
    "Before submitting, ensure you have:\n",
    "- [ ] Entered your name, student ID, and date at the top\n",
    "- [ ] Completed all code tasks (Parts 1-7)\n",
    "- [ ] Run all cells successfully without errors\n",
    "- [ ] Answered all reflection questions (Part 8)\n",
    "- [ ] Used proper commenting in your code\n",
    "- [ ] Used the pipe operator (`%>%`) where appropriate\n",
    "- [ ] Verified your results make business sense\n",
    "- [ ] Checked for any remaining TODO comments\n",
    "\n",
    "### Grading Criteria\n",
    "\n",
    "Your homework will be evaluated on:\n",
    "- **Code Correctness (40%)**: All tasks completed correctly\n",
    "- **Code Quality (20%)**: Clean, well-commented, efficient code\n",
    "- **Business Understanding (20%)**: Demonstrates understanding of business applications\n",
    "- **Reflection Questions (15%)**: Thoughtful, complete answers\n",
    "- **Presentation (5%)**: Professional formatting and organization\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "In Lesson 8, you'll learn:\n",
    "- Advanced data wrangling with complex pipelines\n",
    "- Sophisticated conditional logic with `case_when()`\n",
    "- Data validation and quality checks\n",
    "- Creating reproducible analysis workflows\n",
    "- Professional best practices for business analytics\n",
    "\n",
    "**Great work on completing this assignment! 🎉**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
