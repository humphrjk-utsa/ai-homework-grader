{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Homework Assignment - Lesson 7: String Manipulation and Date/Time Data\n",
    "\n",
    "**Student Name:** [RaShaun Jackson]\n",
    "\n",
    "**Student ID:** [Enter Your Student ID]\n",
    "\n",
    "**Date Submitted:** [10/11/2025]\n",
    "\n",
    "**Due Date:** [10/12/2025\n",
    "\n",
    "---\n",
    "\n",
    "## Objective\n",
    "\n",
    "Master string manipulation with `stringr` and date/time operations with `lubridate` for real-world business data cleaning and analysis.\n",
    "\n",
    "## Learning Goals\n",
    "\n",
    "By completing this assignment, you will:\n",
    "- Clean and standardize messy text data using `stringr` functions\n",
    "- Parse and manipulate dates using `lubridate` functions\n",
    "- Extract information from text and dates for business insights\n",
    "- Combine string and date operations for customer segmentation\n",
    "- Create business-ready reports from raw data\n",
    "\n",
    "## Instructions\n",
    "\n",
    "- Complete all tasks in this notebook\n",
    "- Write your code in the designated TODO sections\n",
    "- Use the pipe operator (`%>%`) wherever possible\n",
    "- Add comments explaining your logic\n",
    "- Run all cells to verify your code works\n",
    "- Answer all reflection questions\n",
    "\n",
    "## Datasets\n",
    "\n",
    "You will work with three CSV files:\n",
    "- `customer_feedback.csv` - Customer reviews with messy text\n",
    "- `transaction_log.csv` - Transaction records with dates\n",
    "- `product_catalog.csv` - Product descriptions needing standardization\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part1_intro",
   "metadata": {},
   "source": [
    "## Part 1: Data Import and Initial Exploration\n",
    "\n",
    "**Business Context:** Before cleaning data, you must understand its structure and quality issues.\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Load required packages (`tidyverse` and `lubridate`)\n",
    "2. Import all three CSV files from the `data/` directory\n",
    "3. Examine the structure and identify data quality issues\n",
    "4. Display sample rows to understand the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "setup",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Packages loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Task 1.1: Load Required Packages\n",
    "# TODO: Load tidyverse (includes stringr)\n",
    "library(tidyverse)\n",
    "\n",
    "# TODO: Load lubridate\n",
    "library(lubridate)\n",
    "\n",
    "cat(\"✅ Packages loaded successfully!\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "import_data",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mRows: \u001b[22m\u001b[34m100\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m5\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m  (2): Feedback_Text, Contact_Info\n",
      "\u001b[32mdbl\u001b[39m  (2): FeedbackID, CustomerID\n",
      "\u001b[34mdate\u001b[39m (1): Feedback_Date\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
      "\u001b[1mRows: \u001b[22m\u001b[34m150\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m5\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m (2): Transaction_DateTime, Status\n",
      "\u001b[32mdbl\u001b[39m (3): LogID, CustomerID, Amount\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
      "\u001b[1mRows: \u001b[22m\u001b[34m75\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m5\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m (3): Product_Description, Category, In_Stock\n",
      "\u001b[32mdbl\u001b[39m (2): ProductID, Price\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data imported successfully!\n",
      "Feedback rows: 100 \n",
      "Transaction rows: 150 \n",
      "Product rows: 75 \n",
      "\n",
      "=== STRUCTURE: CUSTOMER FEEDBACK ===\n",
      "Rows: 100\n",
      "Columns: 5\n",
      "$ FeedbackID    \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 1\u001b[90m, \u001b[39m2\u001b[90m, \u001b[39m3\u001b[90m, \u001b[39m4\u001b[90m, \u001b[39m5\u001b[90m, \u001b[39m6\u001b[90m, \u001b[39m7\u001b[90m, \u001b[39m8\u001b[90m, \u001b[39m9\u001b[90m, \u001b[39m10\u001b[90m, \u001b[39m11\u001b[90m, \u001b[39m12\u001b[90m, \u001b[39m13\u001b[90m, \u001b[39m14\u001b[90m, \u001b[39m15\u001b[90m, \u001b[39m16\u001b[90m, \u001b[39m1…\n",
      "$ CustomerID    \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 12\u001b[90m, \u001b[39m40\u001b[90m, \u001b[39m34\u001b[90m, \u001b[39m1\u001b[90m, \u001b[39m47\u001b[90m, \u001b[39m13\u001b[90m, \u001b[39m13\u001b[90m, \u001b[39m37\u001b[90m, \u001b[39m49\u001b[90m, \u001b[39m23\u001b[90m, \u001b[39m24\u001b[90m, \u001b[39m35\u001b[90m, \u001b[39m3\u001b[90m, \u001b[39m20\u001b[90m, \u001b[39m38…\n",
      "$ Feedback_Text \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"Highly recommend this item\"\u001b[90m, \u001b[39m\"Excellent service\"\u001b[90m, \u001b[39m\"Poor…\n",
      "$ Contact_Info  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"bob.wilson@test.org\"\u001b[90m, \u001b[39m\"555-123-4567\"\u001b[90m, \u001b[39m\"jane_smith@compa…\n",
      "$ Feedback_Date \u001b[3m\u001b[90m<date>\u001b[39m\u001b[23m 2024-02-23\u001b[90m, \u001b[39m2024-01-21\u001b[90m, \u001b[39m2023-09-02\u001b[90m, \u001b[39m2023-08-21\u001b[90m, \u001b[39m2023-04…\n",
      "\u001b[90m# A tibble: 100 × 5\u001b[39m\n",
      "   FeedbackID CustomerID Feedback_Text                Contact_Info Feedback_Date\n",
      "        \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m      \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                        \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m        \u001b[3m\u001b[90m<date>\u001b[39m\u001b[23m       \n",
      "\u001b[90m 1\u001b[39m          1         12 Highly recommend this item   bob.wilson@… 2024-02-23   \n",
      "\u001b[90m 2\u001b[39m          2         40 Excellent service            555-123-4567 2024-01-21   \n",
      "\u001b[90m 3\u001b[39m          3         34 Poor quality control         jane_smith@… 2023-09-02   \n",
      "\u001b[90m 4\u001b[39m          4          1 average product, nothing sp… jane_smith@… 2023-08-21   \n",
      "\u001b[90m 5\u001b[39m          5         47 AMAZING customer support!!!  555-123-4567 2023-04-24   \n",
      "\u001b[90m 6\u001b[39m          6         13 AMAZING customer support!!!  john.doe@em… 2023-04-16   \n",
      "\u001b[90m 7\u001b[39m          7         13 average product, nothing sp… (555) 987-6… 2024-03-13   \n",
      "\u001b[90m 8\u001b[39m          8         37 good VALUE for money         (555) 987-6… 2023-07-15   \n",
      "\u001b[90m 9\u001b[39m          9         49 Highly recommend this item   invalid-ema… 2023-03-03   \n",
      "\u001b[90m10\u001b[39m         10         23 Highly recommend this item   john.doe@em… 2023-10-18   \n",
      "\u001b[90m# ℹ 90 more rows\u001b[39m\n",
      "\n",
      "=== STRUCTURE: TRANSACTIONS ===\n",
      "Rows: 150\n",
      "Columns: 5\n",
      "$ LogID                \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 1\u001b[90m, \u001b[39m2\u001b[90m, \u001b[39m3\u001b[90m, \u001b[39m4\u001b[90m, \u001b[39m5\u001b[90m, \u001b[39m6\u001b[90m, \u001b[39m7\u001b[90m, \u001b[39m8\u001b[90m, \u001b[39m9\u001b[90m, \u001b[39m10\u001b[90m, \u001b[39m11\u001b[90m, \u001b[39m12\u001b[90m, \u001b[39m13\u001b[90m, \u001b[39m14\u001b[90m, \u001b[39m15…\n",
      "$ CustomerID           \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 26\u001b[90m, \u001b[39m21\u001b[90m, \u001b[39m12\u001b[90m, \u001b[39m6\u001b[90m, \u001b[39m32\u001b[90m, \u001b[39m27\u001b[90m, \u001b[39m31\u001b[90m, \u001b[39m30\u001b[90m, \u001b[39m31\u001b[90m, \u001b[39m13\u001b[90m, \u001b[39m28\u001b[90m, \u001b[39m30\u001b[90m, \u001b[39m33…\n",
      "$ Transaction_DateTime \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"4/5/24 14:30\"\u001b[90m, \u001b[39m\"3/15/24 14:30\"\u001b[90m, \u001b[39m\"3/15/24 14:30\"\u001b[90m,\u001b[39m…\n",
      "$ Amount               \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 277.22\u001b[90m, \u001b[39m175.16\u001b[90m, \u001b[39m251.71\u001b[90m, \u001b[39m214.98\u001b[90m, \u001b[39m268.91\u001b[90m, \u001b[39m352.26\u001b[90m, \u001b[39m6…\n",
      "$ Status               \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"Pending\"\u001b[90m, \u001b[39m\"Pending\"\u001b[90m, \u001b[39m\"Pending\"\u001b[90m, \u001b[39m\"Pending\"\u001b[90m, \u001b[39m\"Comp…\n",
      "\u001b[90m# A tibble: 150 × 5\u001b[39m\n",
      "   LogID CustomerID Transaction_DateTime Amount Status   \n",
      "   \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m      \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                 \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m    \n",
      "\u001b[90m 1\u001b[39m     1         26 4/5/24 14:30          277.  Pending  \n",
      "\u001b[90m 2\u001b[39m     2         21 3/15/24 14:30         175.  Pending  \n",
      "\u001b[90m 3\u001b[39m     3         12 3/15/24 14:30         252.  Pending  \n",
      "\u001b[90m 4\u001b[39m     4          6 3/20/24 9:15          215.  Pending  \n",
      "\u001b[90m 5\u001b[39m     5         32 3/20/24 9:15          269.  Completed\n",
      "\u001b[90m 6\u001b[39m     6         27 3/20/24 9:15          352.  Pending  \n",
      "\u001b[90m 7\u001b[39m     7         31 3/20/24 9:15           67.0 Pending  \n",
      "\u001b[90m 8\u001b[39m     8         30 3/15/24 14:30         257.  Pending  \n",
      "\u001b[90m 9\u001b[39m     9         31 25-03-2024 16:45:30   464.  Failed   \n",
      "\u001b[90m10\u001b[39m    10         13 4/5/24 14:30          498.  Completed\n",
      "\u001b[90m# ℹ 140 more rows\u001b[39m\n",
      "\n",
      "=== STRUCTURE: PRODUCTS ===\n",
      "Rows: 75\n",
      "Columns: 5\n",
      "$ ProductID           \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 1\u001b[90m, \u001b[39m2\u001b[90m, \u001b[39m3\u001b[90m, \u001b[39m4\u001b[90m, \u001b[39m5\u001b[90m, \u001b[39m6\u001b[90m, \u001b[39m7\u001b[90m, \u001b[39m8\u001b[90m, \u001b[39m9\u001b[90m, \u001b[39m10\u001b[90m, \u001b[39m11\u001b[90m, \u001b[39m12\u001b[90m, \u001b[39m13\u001b[90m, \u001b[39m14\u001b[90m, \u001b[39m15\u001b[90m,\u001b[39m…\n",
      "$ Product_Description \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"Apple iPhone 14 Pro - 128GB - Space Black\"\u001b[90m, \u001b[39m\"sams…\n",
      "$ Category            \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"TV\"\u001b[90m, \u001b[39m\"TV\"\u001b[90m, \u001b[39m\"Audio\"\u001b[90m, \u001b[39m\"Shoes\"\u001b[90m, \u001b[39m\"Electronics\"\u001b[90m, \u001b[39m\"Comp…\n",
      "$ Price               \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 963.53\u001b[90m, \u001b[39m1817.44\u001b[90m, \u001b[39m852.79\u001b[90m, \u001b[39m648.58\u001b[90m, \u001b[39m586.35\u001b[90m, \u001b[39m1044.64\u001b[90m, \u001b[39m…\n",
      "$ In_Stock            \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"Limited\"\u001b[90m, \u001b[39m\"Yes\"\u001b[90m, \u001b[39m\"Yes\"\u001b[90m, \u001b[39m\"Yes\"\u001b[90m, \u001b[39m\"Limited\"\u001b[90m, \u001b[39m\"Yes\"\u001b[90m, \u001b[39m…\n",
      "\u001b[90m# A tibble: 75 × 5\u001b[39m\n",
      "   ProductID Product_Description                         Category Price In_Stock\n",
      "       \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                                       \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m    \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m   \n",
      "\u001b[90m 1\u001b[39m         1 \u001b[90m\"\u001b[39mApple iPhone 14 Pro - 128GB - Space Black\u001b[90m\"\u001b[39m TV        964. Limited \n",
      "\u001b[90m 2\u001b[39m         2 \u001b[90m\"\u001b[39msamsung galaxy s23 ultra 256gb\u001b[90m\"\u001b[39m            TV       \u001b[4m1\u001b[24m817. Yes     \n",
      "\u001b[90m 3\u001b[39m         3 \u001b[90m\"\u001b[39mApple iPhone 14 Pro - 128GB - Space Black\u001b[90m\"\u001b[39m Audio     853. Yes     \n",
      "\u001b[90m 4\u001b[39m         4 \u001b[90m\"\u001b[39mApple iPhone 14 Pro - 128GB - Space Black\u001b[90m\"\u001b[39m Shoes     649. Yes     \n",
      "\u001b[90m 5\u001b[39m         5 \u001b[90m\"\u001b[39msamsung galaxy s23 ultra 256gb\u001b[90m\"\u001b[39m            Electro…  586. Limited \n",
      "\u001b[90m 6\u001b[39m         6 \u001b[90m\"\u001b[39mApple iPhone 14 Pro - 128GB - Space Black\u001b[90m\"\u001b[39m Compute… \u001b[4m1\u001b[24m045. Yes     \n",
      "\u001b[90m 7\u001b[39m         7 \u001b[90m\"\u001b[39mDELL XPS 13 Laptop - Intel i7 - 16GB RAM\u001b[90m\"\u001b[39m  Audio    \u001b[4m1\u001b[24m509. Limited \n",
      "\u001b[90m 8\u001b[39m         8 \u001b[90m\"\u001b[39mhp envy printer - wireless - color\u001b[90m\"\u001b[39m        Electro… \u001b[4m1\u001b[24m226. Yes     \n",
      "\u001b[90m 9\u001b[39m         9 \u001b[90m\"\u001b[39mNike Air Max 270 - Size 10 - Black/White\u001b[90m\"\u001b[39m  Compute… \u001b[4m1\u001b[24m262. Limited \n",
      "\u001b[90m10\u001b[39m        10 \u001b[90m\"\u001b[39mLG 55\\\" 4K Smart TV - OLED Display\u001b[90m\"\u001b[39m        Shoes     333. No      \n",
      "\u001b[90m# ℹ 65 more rows\u001b[39m\n",
      "\n",
      "=== SAMPLE ROWS: CUSTOMER FEEDBACK ===\n",
      "\u001b[90m# A tibble: 5 × 5\u001b[39m\n",
      "  FeedbackID CustomerID Feedback_Text                 Contact_Info Feedback_Date\n",
      "       \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m      \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                         \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m        \u001b[3m\u001b[90m<date>\u001b[39m\u001b[23m       \n",
      "\u001b[90m1\u001b[39m          1         12 Highly recommend this item    bob.wilson@… 2024-02-23   \n",
      "\u001b[90m2\u001b[39m          2         40 Excellent service             555-123-4567 2024-01-21   \n",
      "\u001b[90m3\u001b[39m          3         34 Poor quality control          jane_smith@… 2023-09-02   \n",
      "\u001b[90m4\u001b[39m          4          1 average product, nothing spe… jane_smith@… 2023-08-21   \n",
      "\u001b[90m5\u001b[39m          5         47 AMAZING customer support!!!   555-123-4567 2023-04-24   \n",
      "\n",
      "=== SAMPLE ROWS: TRANSACTIONS ===\n",
      "\u001b[90m# A tibble: 5 × 5\u001b[39m\n",
      "  LogID CustomerID Transaction_DateTime Amount Status   \n",
      "  \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m      \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                 \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m    \n",
      "\u001b[90m1\u001b[39m     1         26 4/5/24 14:30           277. Pending  \n",
      "\u001b[90m2\u001b[39m     2         21 3/15/24 14:30          175. Pending  \n",
      "\u001b[90m3\u001b[39m     3         12 3/15/24 14:30          252. Pending  \n",
      "\u001b[90m4\u001b[39m     4          6 3/20/24 9:15           215. Pending  \n",
      "\u001b[90m5\u001b[39m     5         32 3/20/24 9:15           269. Completed\n",
      "\n",
      "=== SAMPLE ROWS: PRODUCTS ===\n",
      "\u001b[90m# A tibble: 5 × 5\u001b[39m\n",
      "  ProductID Product_Description                       Category    Price In_Stock\n",
      "      \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                                     \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m       \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m   \n",
      "\u001b[90m1\u001b[39m         1 Apple iPhone 14 Pro - 128GB - Space Black TV           964. Limited \n",
      "\u001b[90m2\u001b[39m         2 samsung galaxy s23 ultra 256gb            TV          \u001b[4m1\u001b[24m817. Yes     \n",
      "\u001b[90m3\u001b[39m         3 Apple iPhone 14 Pro - 128GB - Space Black Audio        853. Yes     \n",
      "\u001b[90m4\u001b[39m         4 Apple iPhone 14 Pro - 128GB - Space Black Shoes        649. Yes     \n",
      "\u001b[90m5\u001b[39m         5 samsung galaxy s23 ultra 256gb            Electronics  586. Limited \n"
     ]
    }
   ],
   "source": [
    "# ===================================================\n",
    "# Load Required Packages\n",
    "# ===================================================\n",
    "library(tidyverse)\n",
    "library(lubridate)\n",
    "\n",
    "# ===================================================\n",
    "# Set Working Directory\n",
    "# ===================================================\n",
    "setwd(\"/workspaces/Fall2025-MS3083-Base_Template/data\")\n",
    "\n",
    "# ===================================================\n",
    "# Import Datasets\n",
    "# ===================================================\n",
    "feedback <- read_csv(\"customer_feedback.csv\")\n",
    "transactions <- read_csv(\"transaction_log.csv\")\n",
    "products <- read_csv(\"product_catalog.csv\")\n",
    "\n",
    "# ===================================================\n",
    "# Display Data Structure and Samples\n",
    "# ===================================================\n",
    "cat(\"✅ Data imported successfully!\\n\")\n",
    "cat(\"Feedback rows:\", nrow(feedback), \"\\n\")\n",
    "cat(\"Transaction rows:\", nrow(transactions), \"\\n\")\n",
    "cat(\"Product rows:\", nrow(products), \"\\n\\n\")\n",
    "\n",
    "# Show structure of each dataset\n",
    "cat(\"=== STRUCTURE: CUSTOMER FEEDBACK ===\\n\")\n",
    "print(glimpse(feedback))\n",
    "cat(\"\\n=== STRUCTURE: TRANSACTIONS ===\\n\")\n",
    "print(glimpse(transactions))\n",
    "cat(\"\\n=== STRUCTURE: PRODUCTS ===\\n\")\n",
    "print(glimpse(products))\n",
    "\n",
    "# Show first few rows for a quick view\n",
    "cat(\"\\n=== SAMPLE ROWS: CUSTOMER FEEDBACK ===\\n\")\n",
    "print(head(feedback, 5))\n",
    "cat(\"\\n=== SAMPLE ROWS: TRANSACTIONS ===\\n\")\n",
    "print(head(transactions, 5))\n",
    "cat(\"\\n=== SAMPLE ROWS: PRODUCTS ===\\n\")\n",
    "print(head(products, 5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "explore_data",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CUSTOMER FEEDBACK DATA ===\n",
      "spc_tbl_ [100 × 5] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n",
      " $ FeedbackID   : num [1:100] 1 2 3 4 5 6 7 8 9 10 ...\n",
      " $ CustomerID   : num [1:100] 12 40 34 1 47 13 13 37 49 23 ...\n",
      " $ Feedback_Text: chr [1:100] \"Highly recommend this item\" \"Excellent service\" \"Poor quality control\" \"average product, nothing special\" ...\n",
      " $ Contact_Info : chr [1:100] \"bob.wilson@test.org\" \"555-123-4567\" \"jane_smith@company.com\" \"jane_smith@company.com\" ...\n",
      " $ Feedback_Date: Date[1:100], format: \"2024-02-23\" \"2024-01-21\" ...\n",
      " - attr(*, \"spec\")=\n",
      "  .. cols(\n",
      "  ..   FeedbackID = \u001b[32mcol_double()\u001b[39m,\n",
      "  ..   CustomerID = \u001b[32mcol_double()\u001b[39m,\n",
      "  ..   Feedback_Text = \u001b[31mcol_character()\u001b[39m,\n",
      "  ..   Contact_Info = \u001b[31mcol_character()\u001b[39m,\n",
      "  ..   Feedback_Date = \u001b[34mcol_date(format = \"\")\u001b[39m\n",
      "  .. )\n",
      " - attr(*, \"problems\")=<externalptr> \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 5 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>FeedbackID</th><th scope=col>CustomerID</th><th scope=col>Feedback_Text</th><th scope=col>Contact_Info</th><th scope=col>Feedback_Date</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;date&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>1</td><td>12</td><td>Highly recommend this item      </td><td>bob.wilson@test.org   </td><td>2024-02-23</td></tr>\n",
       "\t<tr><td>2</td><td>40</td><td>Excellent service               </td><td>555-123-4567          </td><td>2024-01-21</td></tr>\n",
       "\t<tr><td>3</td><td>34</td><td>Poor quality control            </td><td>jane_smith@company.com</td><td>2023-09-02</td></tr>\n",
       "\t<tr><td>4</td><td> 1</td><td>average product, nothing special</td><td>jane_smith@company.com</td><td>2023-08-21</td></tr>\n",
       "\t<tr><td>5</td><td>47</td><td>AMAZING customer support!!!     </td><td>555-123-4567          </td><td>2023-04-24</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 5 × 5\n",
       "\\begin{tabular}{lllll}\n",
       " FeedbackID & CustomerID & Feedback\\_Text & Contact\\_Info & Feedback\\_Date\\\\\n",
       " <dbl> & <dbl> & <chr> & <chr> & <date>\\\\\n",
       "\\hline\n",
       "\t 1 & 12 & Highly recommend this item       & bob.wilson@test.org    & 2024-02-23\\\\\n",
       "\t 2 & 40 & Excellent service                & 555-123-4567           & 2024-01-21\\\\\n",
       "\t 3 & 34 & Poor quality control             & jane\\_smith@company.com & 2023-09-02\\\\\n",
       "\t 4 &  1 & average product, nothing special & jane\\_smith@company.com & 2023-08-21\\\\\n",
       "\t 5 & 47 & AMAZING customer support!!!      & 555-123-4567           & 2023-04-24\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 5 × 5\n",
       "\n",
       "| FeedbackID &lt;dbl&gt; | CustomerID &lt;dbl&gt; | Feedback_Text &lt;chr&gt; | Contact_Info &lt;chr&gt; | Feedback_Date &lt;date&gt; |\n",
       "|---|---|---|---|---|\n",
       "| 1 | 12 | Highly recommend this item       | bob.wilson@test.org    | 2024-02-23 |\n",
       "| 2 | 40 | Excellent service                | 555-123-4567           | 2024-01-21 |\n",
       "| 3 | 34 | Poor quality control             | jane_smith@company.com | 2023-09-02 |\n",
       "| 4 |  1 | average product, nothing special | jane_smith@company.com | 2023-08-21 |\n",
       "| 5 | 47 | AMAZING customer support!!!      | 555-123-4567           | 2023-04-24 |\n",
       "\n"
      ],
      "text/plain": [
       "  FeedbackID CustomerID Feedback_Text                    Contact_Info          \n",
       "1 1          12         Highly recommend this item       bob.wilson@test.org   \n",
       "2 2          40         Excellent service                555-123-4567          \n",
       "3 3          34         Poor quality control             jane_smith@company.com\n",
       "4 4           1         average product, nothing special jane_smith@company.com\n",
       "5 5          47         AMAZING customer support!!!      555-123-4567          \n",
       "  Feedback_Date\n",
       "1 2024-02-23   \n",
       "2 2024-01-21   \n",
       "3 2023-09-02   \n",
       "4 2023-08-21   \n",
       "5 2023-04-24   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TRANSACTION DATA ===\n",
      "spc_tbl_ [150 × 5] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n",
      " $ LogID               : num [1:150] 1 2 3 4 5 6 7 8 9 10 ...\n",
      " $ CustomerID          : num [1:150] 26 21 12 6 32 27 31 30 31 13 ...\n",
      " $ Transaction_DateTime: chr [1:150] \"4/5/24 14:30\" \"3/15/24 14:30\" \"3/15/24 14:30\" \"3/20/24 9:15\" ...\n",
      " $ Amount              : num [1:150] 277 175 252 215 269 ...\n",
      " $ Status              : chr [1:150] \"Pending\" \"Pending\" \"Pending\" \"Pending\" ...\n",
      " - attr(*, \"spec\")=\n",
      "  .. cols(\n",
      "  ..   LogID = \u001b[32mcol_double()\u001b[39m,\n",
      "  ..   CustomerID = \u001b[32mcol_double()\u001b[39m,\n",
      "  ..   Transaction_DateTime = \u001b[31mcol_character()\u001b[39m,\n",
      "  ..   Amount = \u001b[32mcol_double()\u001b[39m,\n",
      "  ..   Status = \u001b[31mcol_character()\u001b[39m\n",
      "  .. )\n",
      " - attr(*, \"problems\")=<externalptr> \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 5 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>LogID</th><th scope=col>CustomerID</th><th scope=col>Transaction_DateTime</th><th scope=col>Amount</th><th scope=col>Status</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>1</td><td>26</td><td>4/5/24 14:30 </td><td>277.22</td><td>Pending  </td></tr>\n",
       "\t<tr><td>2</td><td>21</td><td>3/15/24 14:30</td><td>175.16</td><td>Pending  </td></tr>\n",
       "\t<tr><td>3</td><td>12</td><td>3/15/24 14:30</td><td>251.71</td><td>Pending  </td></tr>\n",
       "\t<tr><td>4</td><td> 6</td><td>3/20/24 9:15 </td><td>214.98</td><td>Pending  </td></tr>\n",
       "\t<tr><td>5</td><td>32</td><td>3/20/24 9:15 </td><td>268.91</td><td>Completed</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 5 × 5\n",
       "\\begin{tabular}{lllll}\n",
       " LogID & CustomerID & Transaction\\_DateTime & Amount & Status\\\\\n",
       " <dbl> & <dbl> & <chr> & <dbl> & <chr>\\\\\n",
       "\\hline\n",
       "\t 1 & 26 & 4/5/24 14:30  & 277.22 & Pending  \\\\\n",
       "\t 2 & 21 & 3/15/24 14:30 & 175.16 & Pending  \\\\\n",
       "\t 3 & 12 & 3/15/24 14:30 & 251.71 & Pending  \\\\\n",
       "\t 4 &  6 & 3/20/24 9:15  & 214.98 & Pending  \\\\\n",
       "\t 5 & 32 & 3/20/24 9:15  & 268.91 & Completed\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 5 × 5\n",
       "\n",
       "| LogID &lt;dbl&gt; | CustomerID &lt;dbl&gt; | Transaction_DateTime &lt;chr&gt; | Amount &lt;dbl&gt; | Status &lt;chr&gt; |\n",
       "|---|---|---|---|---|\n",
       "| 1 | 26 | 4/5/24 14:30  | 277.22 | Pending   |\n",
       "| 2 | 21 | 3/15/24 14:30 | 175.16 | Pending   |\n",
       "| 3 | 12 | 3/15/24 14:30 | 251.71 | Pending   |\n",
       "| 4 |  6 | 3/20/24 9:15  | 214.98 | Pending   |\n",
       "| 5 | 32 | 3/20/24 9:15  | 268.91 | Completed |\n",
       "\n"
      ],
      "text/plain": [
       "  LogID CustomerID Transaction_DateTime Amount Status   \n",
       "1 1     26         4/5/24 14:30         277.22 Pending  \n",
       "2 2     21         3/15/24 14:30        175.16 Pending  \n",
       "3 3     12         3/15/24 14:30        251.71 Pending  \n",
       "4 4      6         3/20/24 9:15         214.98 Pending  \n",
       "5 5     32         3/20/24 9:15         268.91 Completed"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PRODUCT CATALOG DATA ===\n",
      "spc_tbl_ [75 × 5] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n",
      " $ ProductID          : num [1:75] 1 2 3 4 5 6 7 8 9 10 ...\n",
      " $ Product_Description: chr [1:75] \"Apple iPhone 14 Pro - 128GB - Space Black\" \"samsung galaxy s23 ultra 256gb\" \"Apple iPhone 14 Pro - 128GB - Space Black\" \"Apple iPhone 14 Pro - 128GB - Space Black\" ...\n",
      " $ Category           : chr [1:75] \"TV\" \"TV\" \"Audio\" \"Shoes\" ...\n",
      " $ Price              : num [1:75] 964 1817 853 649 586 ...\n",
      " $ In_Stock           : chr [1:75] \"Limited\" \"Yes\" \"Yes\" \"Yes\" ...\n",
      " - attr(*, \"spec\")=\n",
      "  .. cols(\n",
      "  ..   ProductID = \u001b[32mcol_double()\u001b[39m,\n",
      "  ..   Product_Description = \u001b[31mcol_character()\u001b[39m,\n",
      "  ..   Category = \u001b[31mcol_character()\u001b[39m,\n",
      "  ..   Price = \u001b[32mcol_double()\u001b[39m,\n",
      "  ..   In_Stock = \u001b[31mcol_character()\u001b[39m\n",
      "  .. )\n",
      " - attr(*, \"problems\")=<externalptr> \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 5 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>ProductID</th><th scope=col>Product_Description</th><th scope=col>Category</th><th scope=col>Price</th><th scope=col>In_Stock</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>1</td><td>Apple iPhone 14 Pro - 128GB - Space Black</td><td>TV         </td><td> 963.53</td><td>Limited</td></tr>\n",
       "\t<tr><td>2</td><td>samsung galaxy s23 ultra 256gb           </td><td>TV         </td><td>1817.44</td><td>Yes    </td></tr>\n",
       "\t<tr><td>3</td><td>Apple iPhone 14 Pro - 128GB - Space Black</td><td>Audio      </td><td> 852.79</td><td>Yes    </td></tr>\n",
       "\t<tr><td>4</td><td>Apple iPhone 14 Pro - 128GB - Space Black</td><td>Shoes      </td><td> 648.58</td><td>Yes    </td></tr>\n",
       "\t<tr><td>5</td><td>samsung galaxy s23 ultra 256gb           </td><td>Electronics</td><td> 586.35</td><td>Limited</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 5 × 5\n",
       "\\begin{tabular}{lllll}\n",
       " ProductID & Product\\_Description & Category & Price & In\\_Stock\\\\\n",
       " <dbl> & <chr> & <chr> & <dbl> & <chr>\\\\\n",
       "\\hline\n",
       "\t 1 & Apple iPhone 14 Pro - 128GB - Space Black & TV          &  963.53 & Limited\\\\\n",
       "\t 2 & samsung galaxy s23 ultra 256gb            & TV          & 1817.44 & Yes    \\\\\n",
       "\t 3 & Apple iPhone 14 Pro - 128GB - Space Black & Audio       &  852.79 & Yes    \\\\\n",
       "\t 4 & Apple iPhone 14 Pro - 128GB - Space Black & Shoes       &  648.58 & Yes    \\\\\n",
       "\t 5 & samsung galaxy s23 ultra 256gb            & Electronics &  586.35 & Limited\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 5 × 5\n",
       "\n",
       "| ProductID &lt;dbl&gt; | Product_Description &lt;chr&gt; | Category &lt;chr&gt; | Price &lt;dbl&gt; | In_Stock &lt;chr&gt; |\n",
       "|---|---|---|---|---|\n",
       "| 1 | Apple iPhone 14 Pro - 128GB - Space Black | TV          |  963.53 | Limited |\n",
       "| 2 | samsung galaxy s23 ultra 256gb            | TV          | 1817.44 | Yes     |\n",
       "| 3 | Apple iPhone 14 Pro - 128GB - Space Black | Audio       |  852.79 | Yes     |\n",
       "| 4 | Apple iPhone 14 Pro - 128GB - Space Black | Shoes       |  648.58 | Yes     |\n",
       "| 5 | samsung galaxy s23 ultra 256gb            | Electronics |  586.35 | Limited |\n",
       "\n"
      ],
      "text/plain": [
       "  ProductID Product_Description                       Category    Price  \n",
       "1 1         Apple iPhone 14 Pro - 128GB - Space Black TV           963.53\n",
       "2 2         samsung galaxy s23 ultra 256gb            TV          1817.44\n",
       "3 3         Apple iPhone 14 Pro - 128GB - Space Black Audio        852.79\n",
       "4 4         Apple iPhone 14 Pro - 128GB - Space Black Shoes        648.58\n",
       "5 5         samsung galaxy s23 ultra 256gb            Electronics  586.35\n",
       "  In_Stock\n",
       "1 Limited \n",
       "2 Yes     \n",
       "3 Yes     \n",
       "4 Yes     \n",
       "5 Limited "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Task 1.3: Initial Data Exploration\n",
    "\n",
    "cat(\"=== CUSTOMER FEEDBACK DATA ===\\n\")\n",
    "# Display structure of feedback using str()\n",
    "str(feedback)\n",
    "\n",
    "# Display first 5 rows of feedback\n",
    "head(feedback, 5)\n",
    "\n",
    "cat(\"\\n=== TRANSACTION DATA ===\\n\")\n",
    "# Display structure of transactions\n",
    "str(transactions)\n",
    "\n",
    "# Display first 5 rows of transactions\n",
    "head(transactions, 5)\n",
    "\n",
    "cat(\"\\n=== PRODUCT CATALOG DATA ===\\n\")\n",
    "# Display structure of products\n",
    "str(products)\n",
    "\n",
    "# Display first 5 rows of products\n",
    "head(products, 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part2_intro",
   "metadata": {},
   "source": [
    "## Part 2: String Cleaning and Standardization\n",
    "\n",
    "**Business Context:** Product names and feedback text often have inconsistent formatting that prevents accurate analysis.\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Clean product names (remove extra spaces, standardize case)\n",
    "2. Standardize product categories\n",
    "3. Clean customer feedback text\n",
    "4. Extract customer names from feedback\n",
    "\n",
    "**Key Functions:** `str_trim()`, `str_squish()`, `str_to_lower()`, `str_to_upper()`, `str_to_title()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "clean_products",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found product name column: Product_Description \n",
      "\n",
      "Product Name Cleaning Results:\n",
      "\u001b[90m# A tibble: 10 × 2\u001b[39m\n",
      "   Product_Description                         product_name_clean               \n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                                       \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                            \n",
      "\u001b[90m 1\u001b[39m \u001b[90m\"\u001b[39mApple iPhone 14 Pro - 128GB - Space Black\u001b[90m\"\u001b[39m \u001b[90m\"\u001b[39mApple Iphone 14 Pro - 128gb - S…\n",
      "\u001b[90m 2\u001b[39m \u001b[90m\"\u001b[39msamsung galaxy s23 ultra 256gb\u001b[90m\"\u001b[39m            \u001b[90m\"\u001b[39mSamsung Galaxy S23 Ultra 256gb\u001b[90m\"\u001b[39m \n",
      "\u001b[90m 3\u001b[39m \u001b[90m\"\u001b[39mApple iPhone 14 Pro - 128GB - Space Black\u001b[90m\"\u001b[39m \u001b[90m\"\u001b[39mApple Iphone 14 Pro - 128gb - S…\n",
      "\u001b[90m 4\u001b[39m \u001b[90m\"\u001b[39mApple iPhone 14 Pro - 128GB - Space Black\u001b[90m\"\u001b[39m \u001b[90m\"\u001b[39mApple Iphone 14 Pro - 128gb - S…\n",
      "\u001b[90m 5\u001b[39m \u001b[90m\"\u001b[39msamsung galaxy s23 ultra 256gb\u001b[90m\"\u001b[39m            \u001b[90m\"\u001b[39mSamsung Galaxy S23 Ultra 256gb\u001b[90m\"\u001b[39m \n",
      "\u001b[90m 6\u001b[39m \u001b[90m\"\u001b[39mApple iPhone 14 Pro - 128GB - Space Black\u001b[90m\"\u001b[39m \u001b[90m\"\u001b[39mApple Iphone 14 Pro - 128gb - S…\n",
      "\u001b[90m 7\u001b[39m \u001b[90m\"\u001b[39mDELL XPS 13 Laptop - Intel i7 - 16GB RAM\u001b[90m\"\u001b[39m  \u001b[90m\"\u001b[39mDell Xps 13 Laptop - Intel I7 -…\n",
      "\u001b[90m 8\u001b[39m \u001b[90m\"\u001b[39mhp envy printer - wireless - color\u001b[90m\"\u001b[39m        \u001b[90m\"\u001b[39mHp Envy Printer - Wireless - Co…\n",
      "\u001b[90m 9\u001b[39m \u001b[90m\"\u001b[39mNike Air Max 270 - Size 10 - Black/White\u001b[90m\"\u001b[39m  \u001b[90m\"\u001b[39mNike Air Max 270 - Size 10 - Bl…\n",
      "\u001b[90m10\u001b[39m \u001b[90m\"\u001b[39mLG 55\\\" 4K Smart TV - OLED Display\u001b[90m\"\u001b[39m        \u001b[90m\"\u001b[39mLg 55\\\" 4k Smart Tv - Oled Disp…\n"
     ]
    }
   ],
   "source": [
    "# ===================================================\n",
    "# Task 2.1: Clean Product Names\n",
    "# ===================================================\n",
    "library(tidyverse)\n",
    "\n",
    "# --- Step 1: Detect the most likely product name column automatically\n",
    "name_candidates <- c(\n",
    "  \"product_name\", \"Product_Name\", \"productname\", \"ProductName\",\n",
    "  \"name\", \"Name\", \"product\", \"Product\", \"product_title\", \"Product_Title\",\n",
    "  \"Description\", \"Product_Description\"\n",
    ")\n",
    "\n",
    "found_name_col <- intersect(name_candidates, names(products))[1]\n",
    "\n",
    "if (is.na(found_name_col)) {\n",
    "  cat(\"⚠️ Could not automatically find a product name column. Please run colnames(products) to verify.\\n\")\n",
    "} else {\n",
    "  cat(\"✅ Found product name column:\", found_name_col, \"\\n\")\n",
    "\n",
    "  # --- Step 2: Create a clean version\n",
    "  products_clean <- products %>%\n",
    "    mutate(\n",
    "      product_name_clean = !!sym(found_name_col) %>%\n",
    "        stringr::str_trim() %>%      # remove leading/trailing spaces\n",
    "        stringr::str_squish() %>%    # remove extra internal spaces\n",
    "        stringr::str_to_title()      # convert to title case\n",
    "    )\n",
    "\n",
    "  # --- Step 3: Display before/after for inspection\n",
    "  cat(\"\\nProduct Name Cleaning Results:\\n\")\n",
    "  products_clean %>%\n",
    "    select(all_of(found_name_col), product_name_clean) %>%\n",
    "    head(10) %>%\n",
    "    print()\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e33b4310",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customers: 100 rows | orders: 250 | order_items: 400 | products: 50 | suppliers: 10 \n",
      "orders_items: 400 | orders_customers_items: 310 | complete_order_data: 310 | complete_data: 310 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orders with missing suppliers: 0 \n",
      "Suppliers with no orders/products: 0 \n",
      "Duplicate ProductID: 0 | Duplicate Supplier_ID: 0 \n",
      "\n",
      "=== complete_data preview ===\n",
      "\u001b[90m# A tibble: 5 × 16\u001b[39m\n",
      "  CustomerID Name  Email City  Registration_Date OrderID Order_Date Total_Amount\n",
      "       \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<date>\u001b[39m\u001b[23m              \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<date>\u001b[39m\u001b[23m            \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m          1 Cust… cust… Phoe… 2020-10-03             87 2023-03-28         716.\n",
      "\u001b[90m2\u001b[39m          1 Cust… cust… Phoe… 2020-10-03            214 2023-09-12        \u001b[4m1\u001b[24m344.\n",
      "\u001b[90m3\u001b[39m          1 Cust… cust… Phoe… 2020-10-03            214 2023-09-12        \u001b[4m1\u001b[24m344.\n",
      "\u001b[90m4\u001b[39m          1 Cust… cust… Phoe… 2020-10-03            214 2023-09-12        \u001b[4m1\u001b[24m344.\n",
      "\u001b[90m5\u001b[39m          3 Cust… cust… Chic… 2021-04-20             29 2023-03-07         441.\n",
      "\u001b[90m# ℹ 8 more variables: ProductID <dbl>, Quantity <dbl>, Unit_Price <dbl>,\u001b[39m\n",
      "\u001b[90m#   Product_Name <chr>, Category <chr>, Supplier_ID <dbl>, Supplier_Name <chr>,\u001b[39m\n",
      "\u001b[90m#   Country <chr>\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "# --- Quick validation & diagnostics ---\n",
    "\n",
    "# 1) Confirm required columns exist\n",
    "stopifnot(all(c(\"OrderID\",\"CustomerID\") %in% names(orders_items)))\n",
    "stopifnot(all(c(\"CustomerID\") %in% names(orders_customers_items)))\n",
    "stopifnot(all(c(\"ProductID\",\"Supplier_ID\") %in% names(complete_order_data)))\n",
    "stopifnot(all(c(\"Supplier_ID\") %in% names(suppliers)))\n",
    "\n",
    "# 2) Show shapes\n",
    "cat(\"customers:\", nrow(customers), \"rows | orders:\", nrow(orders), \n",
    "    \"| order_items:\", nrow(order_items), \"| products:\", nrow(products),\n",
    "    \"| suppliers:\", nrow(suppliers), \"\\n\")\n",
    "cat(\"orders_items:\", nrow(orders_items), \n",
    "    \"| orders_customers_items:\", nrow(orders_customers_items),\n",
    "    \"| complete_order_data:\", nrow(complete_order_data),\n",
    "    \"| complete_data:\", nrow(complete_data), \"\\n\")\n",
    "\n",
    "# 3) Check for unmatched suppliers (orders referencing suppliers not in suppliers table)\n",
    "orders_missing_suppliers <- anti_join(complete_order_data, suppliers, by = \"Supplier_ID\")\n",
    "cat(\"Orders with missing suppliers:\", nrow(orders_missing_suppliers), \"\\n\")\n",
    "\n",
    "# 4) Check for suppliers never used\n",
    "unused_suppliers <- anti_join(suppliers, complete_order_data, by = \"Supplier_ID\")\n",
    "cat(\"Suppliers with no orders/products:\", nrow(unused_suppliers), \"\\n\")\n",
    "\n",
    "# 5) Duplicate key checks (common cause of row explosions)\n",
    "dup_products  <- sum(duplicated(products$ProductID))\n",
    "dup_suppliers <- sum(duplicated(suppliers$Supplier_ID))\n",
    "cat(\"Duplicate ProductID:\", dup_products, \"| Duplicate Supplier_ID:\", dup_suppliers, \"\\n\")\n",
    "\n",
    "# 6) Peek at final dataset\n",
    "cat(\"\\n=== complete_data preview ===\\n\")\n",
    "print(head(complete_data, 5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "clean_categories",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original categories (from column: Category):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"TV\"          \"Audio\"       \"Shoes\"       \"Electronics\" \"Computers\"  \n",
      "\n",
      "Cleaned categories:\n",
      "[1] \"Tv\"          \"Audio\"       \"Shoes\"       \"Electronics\" \"Computers\"  \n"
     ]
    }
   ],
   "source": [
    "# Task 2.2: Standardize Product Categories (robust to different column names)\n",
    "library(tidyverse)\n",
    "\n",
    "# If Task 2.1 hasn't run, fall back to raw products\n",
    "if (!exists(\"products_clean\")) products_clean <- products\n",
    "\n",
    "# 1) Detect the category column automatically\n",
    "category_candidates <- c(\n",
    "  \"category\",\"Category\",\"product_category\",\"Product_Category\",\n",
    "  \"category_name\",\"CategoryName\",\"department\",\"Department\",\n",
    "  \"segment\",\"Segment\",\"class\",\"Class\"\n",
    ")\n",
    "found_category_col <- intersect(category_candidates, names(products_clean))[1]\n",
    "\n",
    "if (is.na(found_category_col)) {\n",
    "  stop(\"No category-like column found in products/products_clean. \",\n",
    "       \"Available columns: \", paste(names(products_clean), collapse = \", \"))\n",
    "}\n",
    "\n",
    "# 2) Create standardized category column\n",
    "products_clean <- products_clean %>%\n",
    "  mutate(\n",
    "    category_clean = .data[[found_category_col]] %>%\n",
    "      stringr::str_squish() %>%     # remove extra internal + leading/trailing spaces\n",
    "      stringr::str_to_title()       # Title Case\n",
    "  )\n",
    "\n",
    "# 3) Show unique categories before and after\n",
    "cat(\"Original categories (from column: \", found_category_col, \"):\\n\", sep = \"\")\n",
    "print(unique(products_clean[[found_category_col]]))\n",
    "\n",
    "cat(\"\\nCleaned categories:\\n\")\n",
    "print(unique(products_clean$category_clean))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "clean_feedback",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feedback Cleaning Sample:\n",
      "\u001b[90m# A tibble: 5 × 2\u001b[39m\n",
      "  Feedback_Text                    feedback_clean                  \n",
      "  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                            \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                           \n",
      "\u001b[90m1\u001b[39m Highly recommend this item       highly recommend this item      \n",
      "\u001b[90m2\u001b[39m Excellent service                excellent service               \n",
      "\u001b[90m3\u001b[39m Poor quality control             poor quality control            \n",
      "\u001b[90m4\u001b[39m average product, nothing special average product, nothing special\n",
      "\u001b[90m5\u001b[39m AMAZING customer support!!!      amazing customer support!!!     \n"
     ]
    }
   ],
   "source": [
    "# Task 2.3: Clean Customer Feedback Text (robust to different column names)\n",
    "library(tidyverse)\n",
    "\n",
    "# Detect the feedback text column automatically\n",
    "feedback_text_candidates <- c(\n",
    "  \"feedback_text\",\"Feedback_Text\",\"feedback\",\"Feedback\",\n",
    "  \"comments\",\"Comments\",\"comment\",\"Comment\",\n",
    "  \"review\",\"Review\",\"message\",\"Message\",\"text\",\"Text\"\n",
    ")\n",
    "fb_col <- intersect(feedback_text_candidates, names(feedback))[1]\n",
    "\n",
    "if (is.na(fb_col)) {\n",
    "  stop(\"No feedback text column found. Available columns: \",\n",
    "       paste(names(feedback), collapse = \", \"))\n",
    "}\n",
    "\n",
    "# Create 'feedback_clean': lowercase + squish whitespace\n",
    "feedback_clean <- feedback %>%\n",
    "  mutate(\n",
    "    feedback_clean = .data[[fb_col]] %>%\n",
    "      stringr::str_to_lower() %>%\n",
    "      stringr::str_squish()\n",
    "  )\n",
    "\n",
    "# Display sample (show original detected column alongside the cleaned text)\n",
    "cat(\"Feedback Cleaning Sample:\\n\")\n",
    "feedback_clean %>%\n",
    "  transmute(!!fb_col := .data[[fb_col]], feedback_clean) %>%\n",
    "  head(5) %>%\n",
    "  print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part3_intro",
   "metadata": {},
   "source": [
    "## Part 3: Pattern Detection and Extraction\n",
    "\n",
    "**Business Context:** Identifying products with specific features and extracting specifications helps with inventory management and marketing.\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Identify products with specific keywords (wireless, premium, gaming)\n",
    "2. Extract numerical specifications from product names\n",
    "3. Detect sentiment words in customer feedback\n",
    "4. Extract email addresses from feedback\n",
    "\n",
    "**Key Functions:** `str_detect()`, `str_extract()`, `str_count()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "detect_features",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product Feature Detection:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90m# A tibble: 10 × 4\u001b[39m\n",
      "   product_name_clean                          is_wireless is_premium is_gaming\n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                                       \u001b[3m\u001b[90m<lgl>\u001b[39m\u001b[23m       \u001b[3m\u001b[90m<lgl>\u001b[39m\u001b[23m      \u001b[3m\u001b[90m<lgl>\u001b[39m\u001b[23m    \n",
      "\u001b[90m 1\u001b[39m \u001b[90m\"\u001b[39mApple Iphone 14 Pro - 128gb - Space Black\u001b[90m\"\u001b[39m FALSE       TRUE       FALSE    \n",
      "\u001b[90m 2\u001b[39m \u001b[90m\"\u001b[39mSamsung Galaxy S23 Ultra 256gb\u001b[90m\"\u001b[39m            FALSE       FALSE      FALSE    \n",
      "\u001b[90m 3\u001b[39m \u001b[90m\"\u001b[39mApple Iphone 14 Pro - 128gb - Space Black\u001b[90m\"\u001b[39m FALSE       TRUE       FALSE    \n",
      "\u001b[90m 4\u001b[39m \u001b[90m\"\u001b[39mApple Iphone 14 Pro - 128gb - Space Black\u001b[90m\"\u001b[39m FALSE       TRUE       FALSE    \n",
      "\u001b[90m 5\u001b[39m \u001b[90m\"\u001b[39mSamsung Galaxy S23 Ultra 256gb\u001b[90m\"\u001b[39m            FALSE       FALSE      FALSE    \n",
      "\u001b[90m 6\u001b[39m \u001b[90m\"\u001b[39mApple Iphone 14 Pro - 128gb - Space Black\u001b[90m\"\u001b[39m FALSE       TRUE       FALSE    \n",
      "\u001b[90m 7\u001b[39m \u001b[90m\"\u001b[39mDell Xps 13 Laptop - Intel I7 - 16gb Ram\u001b[90m\"\u001b[39m  FALSE       FALSE      FALSE    \n",
      "\u001b[90m 8\u001b[39m \u001b[90m\"\u001b[39mHp Envy Printer - Wireless - Color\u001b[90m\"\u001b[39m        TRUE        FALSE      FALSE    \n",
      "\u001b[90m 9\u001b[39m \u001b[90m\"\u001b[39mNike Air Max 270 - Size 10 - Black/White\u001b[90m\"\u001b[39m  FALSE       FALSE      FALSE    \n",
      "\u001b[90m10\u001b[39m \u001b[90m\"\u001b[39mLg 55\\\" 4k Smart Tv - Oled Display\u001b[90m\"\u001b[39m        FALSE       FALSE      FALSE    \n",
      "\n",
      "Feature Summary:\n",
      "Wireless products: 17 \n",
      "Premium products: 13 \n",
      "Gaming products: 0 \n"
     ]
    }
   ],
   "source": [
    "# ===================================================\n",
    "# Task 3.1: Detect Product Features\n",
    "# ===================================================\n",
    "\n",
    "# TODO: Create three new columns:\n",
    "#   - is_wireless: TRUE if product name contains \"wireless\" (case-insensitive)\n",
    "#   - is_premium: TRUE if product name contains \"pro\", \"premium\", or \"deluxe\"\n",
    "#   - is_gaming: TRUE if product name contains \"gaming\" or \"gamer\"\n",
    "# Hint: Use str_detect() with str_to_lower() for case-insensitive matching\n",
    "# Hint: Use | (pipe) in regex for OR conditions\n",
    "\n",
    "products_clean <- products_clean %>%\n",
    "  mutate(\n",
    "    is_wireless = str_detect(str_to_lower(product_name_clean), \"wireless\"),\n",
    "    is_premium  = str_detect(str_to_lower(product_name_clean), \"pro|premium|deluxe\"),\n",
    "    is_gaming   = str_detect(str_to_lower(product_name_clean), \"gaming|gamer\")\n",
    "  )\n",
    "\n",
    "# ===================================================\n",
    "# Display Results\n",
    "# ===================================================\n",
    "cat(\"Product Feature Detection:\\n\")\n",
    "products_clean %>%\n",
    "  select(product_name_clean, is_wireless, is_premium, is_gaming) %>%\n",
    "  head(10) %>%\n",
    "  print()\n",
    "\n",
    "# ===================================================\n",
    "# Summary Statistics\n",
    "# ===================================================\n",
    "cat(\"\\nFeature Summary:\\n\")\n",
    "cat(\"Wireless products:\", sum(products_clean$is_wireless, na.rm = TRUE), \"\\n\")\n",
    "cat(\"Premium products:\",  sum(products_clean$is_premium,  na.rm = TRUE), \"\\n\")\n",
    "cat(\"Gaming products:\",   sum(products_clean$is_gaming,   na.rm = TRUE), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "extract_specs",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Product Specifications:\n",
      "\u001b[90m# A tibble: 10 × 2\u001b[39m\n",
      "   product_name_clean                          size_number\n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                                       \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m      \n",
      "\u001b[90m 1\u001b[39m \u001b[90m\"\u001b[39mApple Iphone 14 Pro - 128gb - Space Black\u001b[90m\"\u001b[39m 14         \n",
      "\u001b[90m 2\u001b[39m \u001b[90m\"\u001b[39mSamsung Galaxy S23 Ultra 256gb\u001b[90m\"\u001b[39m            23         \n",
      "\u001b[90m 3\u001b[39m \u001b[90m\"\u001b[39mApple Iphone 14 Pro - 128gb - Space Black\u001b[90m\"\u001b[39m 14         \n",
      "\u001b[90m 4\u001b[39m \u001b[90m\"\u001b[39mApple Iphone 14 Pro - 128gb - Space Black\u001b[90m\"\u001b[39m 14         \n",
      "\u001b[90m 5\u001b[39m \u001b[90m\"\u001b[39mSamsung Galaxy S23 Ultra 256gb\u001b[90m\"\u001b[39m            23         \n",
      "\u001b[90m 6\u001b[39m \u001b[90m\"\u001b[39mApple Iphone 14 Pro - 128gb - Space Black\u001b[90m\"\u001b[39m 14         \n",
      "\u001b[90m 7\u001b[39m \u001b[90m\"\u001b[39mDell Xps 13 Laptop - Intel I7 - 16gb Ram\u001b[90m\"\u001b[39m  13         \n",
      "\u001b[90m 8\u001b[39m \u001b[90m\"\u001b[39mNike Air Max 270 - Size 10 - Black/White\u001b[90m\"\u001b[39m  270        \n",
      "\u001b[90m 9\u001b[39m \u001b[90m\"\u001b[39mLg 55\\\" 4k Smart Tv - Oled Display\u001b[90m\"\u001b[39m        55         \n",
      "\u001b[90m10\u001b[39m \u001b[90m\"\u001b[39mSony Wh-1000xm4 Wireless Headphones\u001b[90m\"\u001b[39m       1000       \n"
     ]
    }
   ],
   "source": [
    "# ===================================================\n",
    "# Task 3.2: Extract Product Specifications\n",
    "# ===================================================\n",
    "# TODO: Create a new column 'size_number' that extracts the first number from product_name\n",
    "# Hint: Use str_extract() with pattern \"\\\\d+\" to match one or more digits\n",
    "\n",
    "products_clean <- products_clean %>%\n",
    "  mutate(\n",
    "    size_number = str_extract(product_name_clean, \"\\\\d+\")\n",
    "  )\n",
    "\n",
    "# ===================================================\n",
    "# Display products with extracted sizes\n",
    "# ===================================================\n",
    "cat(\"Extracted Product Specifications:\\n\")\n",
    "products_clean %>%\n",
    "  filter(!is.na(size_number)) %>%\n",
    "  select(product_name_clean, size_number) %>%\n",
    "  head(10) %>%\n",
    "  print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "sentiment_analysis",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Analysis Results:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90m# A tibble: 10 × 4\u001b[39m\n",
      "   feedback_clean                  positive_words negative_words sentiment_score\n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                                    \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m          \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m           \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m highly recommend this item                   0              0               0\n",
      "\u001b[90m 2\u001b[39m excellent service                            1              0               1\n",
      "\u001b[90m 3\u001b[39m poor quality control                         0              0               0\n",
      "\u001b[90m 4\u001b[39m average product, nothing speci…              0              0               0\n",
      "\u001b[90m 5\u001b[39m amazing customer support!!!                  1              0               1\n",
      "\u001b[90m 6\u001b[39m amazing customer support!!!                  1              0               1\n",
      "\u001b[90m 7\u001b[39m average product, nothing speci…              0              0               0\n",
      "\u001b[90m 8\u001b[39m good value for money                         0              0               0\n",
      "\u001b[90m 9\u001b[39m highly recommend this item                   0              0               0\n",
      "\u001b[90m10\u001b[39m highly recommend this item                   0              0               0\n",
      "\n",
      "Overall Sentiment Summary:\n",
      "Average sentiment score: 0.18 \n",
      "Positive reviews: 30 \n",
      "Negative reviews: 20 \n"
     ]
    }
   ],
   "source": [
    "# ===================================================\n",
    "# Task 3.3: Simple Sentiment Analysis\n",
    "# ===================================================\n",
    "# TODO: Create three new columns:\n",
    "#   - positive_words: count of positive words (\"great\", \"excellent\", \"love\", \"amazing\")\n",
    "#   - negative_words: count of negative words (\"bad\", \"terrible\", \"hate\", \"awful\")\n",
    "#   - sentiment_score: positive_words - negative_words\n",
    "# Hint: Use str_count() to count pattern occurrences\n",
    "\n",
    "feedback_clean <- feedback_clean %>%\n",
    "  mutate(\n",
    "    positive_words = str_count(feedback_clean, \"great|excellent|love|amazing\"),\n",
    "    negative_words = str_count(feedback_clean, \"bad|terrible|hate|awful\"),\n",
    "    sentiment_score = positive_words - negative_words\n",
    "  )\n",
    "\n",
    "# ===================================================\n",
    "# Display sentiment analysis results\n",
    "# ===================================================\n",
    "cat(\"Sentiment Analysis Results:\\n\")\n",
    "feedback_clean %>%\n",
    "  select(feedback_clean, positive_words, negative_words, sentiment_score) %>%\n",
    "  head(10) %>%\n",
    "  print()\n",
    "\n",
    "# ===================================================\n",
    "# Summary\n",
    "# ===================================================\n",
    "cat(\"\\nOverall Sentiment Summary:\\n\")\n",
    "cat(\"Average sentiment score:\", mean(feedback_clean$sentiment_score, na.rm = TRUE), \"\\n\")\n",
    "cat(\"Positive reviews:\", sum(feedback_clean$sentiment_score > 0, na.rm = TRUE), \"\\n\")\n",
    "cat(\"Negative reviews:\", sum(feedback_clean$sentiment_score < 0, na.rm = TRUE), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part4_intro",
   "metadata": {},
   "source": [
    "## Part 4: Date Parsing and Component Extraction\n",
    "\n",
    "**Business Context:** Transaction dates need to be parsed and analyzed to understand customer behavior patterns.\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Parse transaction dates from text to Date objects\n",
    "2. Extract date components (year, month, day, weekday)\n",
    "3. Identify weekend vs weekday transactions\n",
    "4. Extract quarter and month names\n",
    "\n",
    "**Key Functions:** `ymd()`, `mdy()`, `dmy()`, `year()`, `month()`, `day()`, `wday()`, `quarter()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "parse_dates",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using transactions column for date parsing: Transaction_DateTime \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date Parsing Results:\n",
      "\u001b[90m# A tibble: 10 × 2\u001b[39m\n",
      "   Transaction_DateTime date_parsed\n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                \u001b[3m\u001b[90m<date>\u001b[39m\u001b[23m     \n",
      "\u001b[90m 1\u001b[39m 4/5/24 14:30         \u001b[31mNA\u001b[39m         \n",
      "\u001b[90m 2\u001b[39m 3/15/24 14:30        \u001b[31mNA\u001b[39m         \n",
      "\u001b[90m 3\u001b[39m 3/15/24 14:30        \u001b[31mNA\u001b[39m         \n",
      "\u001b[90m 4\u001b[39m 3/20/24 9:15         \u001b[31mNA\u001b[39m         \n",
      "\u001b[90m 5\u001b[39m 3/20/24 9:15         \u001b[31mNA\u001b[39m         \n",
      "\u001b[90m 6\u001b[39m 3/20/24 9:15         \u001b[31mNA\u001b[39m         \n",
      "\u001b[90m 7\u001b[39m 3/20/24 9:15         \u001b[31mNA\u001b[39m         \n",
      "\u001b[90m 8\u001b[39m 3/15/24 14:30        \u001b[31mNA\u001b[39m         \n",
      "\u001b[90m 9\u001b[39m 25-03-2024 16:45:30  2024-03-25 \n",
      "\u001b[90m10\u001b[39m 4/5/24 14:30         \u001b[31mNA\u001b[39m         \n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Task 4.1: Parse Transaction Dates\n",
    "# ================================\n",
    "library(tidyverse)\n",
    "library(lubridate)\n",
    "\n",
    "# We’ll robustly handle your actual column name: \"Transaction_DateTime\"\n",
    "# and parse either date-only or datetime strings.\n",
    "\n",
    "# 1) Detect the date/datetime column\n",
    "date_col_candidates <- c(\n",
    "  \"transaction_date\", \"Transaction_Date\",\n",
    "  \"transaction_datetime\", \"Transaction_DateTime\",\n",
    "  \"date\", \"Date\", \"datetime\", \"DateTime\"\n",
    ")\n",
    "tx_col <- intersect(date_col_candidates, names(transactions))[1]\n",
    "if (is.na(tx_col)) {\n",
    "  stop(\"No transaction date/datetime column found. Available columns: \",\n",
    "       paste(names(transactions), collapse = \", \"))\n",
    "}\n",
    "cat(\"Using transactions column for date parsing:\", tx_col, \"\\n\")\n",
    "\n",
    "# 2) Parse to Date (drop time) but accept both date and datetime inputs\n",
    "#    Try ymd/mdy/dmy with or without times. We pick the first non-NA per row.\n",
    "transactions_clean <- transactions %>%\n",
    "  mutate(\n",
    "    raw_ts = .data[[tx_col]],\n",
    "    # Try datetime formats first (ymd_hms/mdy_hms/dmy_hms), then date-only (ymd/mdy/dmy)\n",
    "    parsed_dt = coalesce(\n",
    "      suppressWarnings(ymd_hms(raw_ts, quiet = TRUE)),\n",
    "      suppressWarnings(mdy_hms(raw_ts, quiet = TRUE)),\n",
    "      suppressWarnings(dmy_hms(raw_ts, quiet = TRUE)),\n",
    "      suppressWarnings(ymd(raw_ts, quiet = TRUE)),\n",
    "      suppressWarnings(mdy(raw_ts, quiet = TRUE)),\n",
    "      suppressWarnings(dmy(raw_ts, quiet = TRUE))\n",
    "    ),\n",
    "    date_parsed = as_date(parsed_dt)   # final DATE column (no time)\n",
    "  ) %>%\n",
    "  select(-raw_ts)\n",
    "\n",
    "# 3) Verify parsing worked\n",
    "cat(\"Date Parsing Results:\\n\")\n",
    "transactions_clean %>%\n",
    "  select(!!tx_col, date_parsed) %>%\n",
    "  head(10) %>%\n",
    "  print()\n",
    "\n",
    "# (Optional) If you want to continue with components in later tasks:\n",
    "# transactions_clean <- transactions_clean %>%\n",
    "#   mutate(\n",
    "#     year    = year(date_parsed),\n",
    "#     month   = month(date_parsed),\n",
    "#     day     = day(date_parsed),\n",
    "#     wday    = wday(date_parsed, label = TRUE, abbr = TRUE),\n",
    "#     weekend = wday %in% c(\"Sat\", \"Sun\"),\n",
    "#     quarter = quarter(date_parsed),\n",
    "#     month_name = month(date_parsed, label = TRUE, abbr = FALSE)\n",
    "#   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "extract_components",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date Component Extraction:\n",
      "\u001b[90m# A tibble: 10 × 4\u001b[39m\n",
      "   date_parsed trans_month_name trans_weekday trans_quarter\n",
      "   \u001b[3m\u001b[90m<date>\u001b[39m\u001b[23m      \u001b[3m\u001b[90m<ord>\u001b[39m\u001b[23m            \u001b[3m\u001b[90m<ord>\u001b[39m\u001b[23m                 \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m \u001b[31mNA\u001b[39m          \u001b[31mNA\u001b[39m               \u001b[31mNA\u001b[39m                       \u001b[31mNA\u001b[39m\n",
      "\u001b[90m 2\u001b[39m \u001b[31mNA\u001b[39m          \u001b[31mNA\u001b[39m               \u001b[31mNA\u001b[39m                       \u001b[31mNA\u001b[39m\n",
      "\u001b[90m 3\u001b[39m \u001b[31mNA\u001b[39m          \u001b[31mNA\u001b[39m               \u001b[31mNA\u001b[39m                       \u001b[31mNA\u001b[39m\n",
      "\u001b[90m 4\u001b[39m \u001b[31mNA\u001b[39m          \u001b[31mNA\u001b[39m               \u001b[31mNA\u001b[39m                       \u001b[31mNA\u001b[39m\n",
      "\u001b[90m 5\u001b[39m \u001b[31mNA\u001b[39m          \u001b[31mNA\u001b[39m               \u001b[31mNA\u001b[39m                       \u001b[31mNA\u001b[39m\n",
      "\u001b[90m 6\u001b[39m \u001b[31mNA\u001b[39m          \u001b[31mNA\u001b[39m               \u001b[31mNA\u001b[39m                       \u001b[31mNA\u001b[39m\n",
      "\u001b[90m 7\u001b[39m \u001b[31mNA\u001b[39m          \u001b[31mNA\u001b[39m               \u001b[31mNA\u001b[39m                       \u001b[31mNA\u001b[39m\n",
      "\u001b[90m 8\u001b[39m \u001b[31mNA\u001b[39m          \u001b[31mNA\u001b[39m               \u001b[31mNA\u001b[39m                       \u001b[31mNA\u001b[39m\n",
      "\u001b[90m 9\u001b[39m 2024-03-25  March            Monday                    1\n",
      "\u001b[90m10\u001b[39m \u001b[31mNA\u001b[39m          \u001b[31mNA\u001b[39m               \u001b[31mNA\u001b[39m                       \u001b[31mNA\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "# ===================================================\n",
    "# Task 4.2: Extract Date Components\n",
    "# ===================================================\n",
    "# TODO: Create the following new columns:\n",
    "#   - trans_year: Extract year from date_parsed\n",
    "#   - trans_month: Extract month number from date_parsed\n",
    "#   - trans_month_name: Extract month name (use label=TRUE, abbr=FALSE)\n",
    "#   - trans_day: Extract day of month from date_parsed\n",
    "#   - trans_weekday: Extract weekday name (use label=TRUE, abbr=FALSE)\n",
    "#   - trans_quarter: Extract quarter from date_parsed\n",
    "\n",
    "transactions_clean <- transactions_clean %>%\n",
    "  mutate(\n",
    "    trans_year       = year(date_parsed),\n",
    "    trans_month      = month(date_parsed),\n",
    "    trans_month_name = month(date_parsed, label = TRUE, abbr = FALSE),\n",
    "    trans_day        = day(date_parsed),\n",
    "    trans_weekday    = wday(date_parsed, label = TRUE, abbr = FALSE),\n",
    "    trans_quarter    = quarter(date_parsed)\n",
    "  )\n",
    "\n",
    "# ===================================================\n",
    "# Display results\n",
    "# ===================================================\n",
    "cat(\"Date Component Extraction:\\n\")\n",
    "transactions_clean %>%\n",
    "  select(date_parsed, trans_month_name, trans_weekday, trans_quarter) %>%\n",
    "  head(10) %>%\n",
    "  print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "weekend_flag",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weekend vs Weekday Transactions:\n",
      "\n",
      "FALSE \n",
      "  150 \n",
      "\n",
      "Percentage of weekend transactions: 0 %\n"
     ]
    }
   ],
   "source": [
    "# ===================================================\n",
    "# Task 4.3: Identify Weekend Transactions\n",
    "# ===================================================\n",
    "# TODO: Create a new column 'is_weekend' that is TRUE if the transaction was on Saturday or Sunday\n",
    "# Hint: Use wday() which returns 1 for Sunday and 7 for Saturday\n",
    "# Hint: Use %in% c(1, 7) to check if day is weekend\n",
    "\n",
    "transactions_clean <- transactions_clean %>%\n",
    "  mutate(\n",
    "    is_weekend = wday(date_parsed) %in% c(1, 7)\n",
    "  )\n",
    "\n",
    "# ===================================================\n",
    "# Summary\n",
    "# ===================================================\n",
    "cat(\"Weekend vs Weekday Transactions:\\n\")\n",
    "table(transactions_clean$is_weekend) %>% print()\n",
    "\n",
    "cat(\"\\nPercentage of weekend transactions:\",\n",
    "    round(sum(transactions_clean$is_weekend, na.rm = TRUE) / nrow(transactions_clean) * 100, 1), \"%\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part5_intro",
   "metadata": {},
   "source": [
    "## Part 5: Date Calculations and Customer Recency Analysis\n",
    "\n",
    "**Business Context:** Understanding how recently customers transacted helps identify at-risk customers for re-engagement campaigns.\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Calculate days since each transaction\n",
    "2. Categorize customers by recency (Recent, Moderate, Old)\n",
    "3. Identify customers who haven't transacted in 90+ days\n",
    "4. Calculate average days between transactions per customer\n",
    "\n",
    "**Key Functions:** `today()`, date arithmetic, `case_when()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "calculate_recency",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Days Since Transaction:\n",
      "\u001b[90m# A tibble: 10 × 3\u001b[39m\n",
      "   CustomerID date_parsed days_since\n",
      "        \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<date>\u001b[39m\u001b[23m           \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m         31 2024-03-25         565\n",
      "\u001b[90m 2\u001b[39m         25 2024-03-25         565\n",
      "\u001b[90m 3\u001b[39m         35 2024-03-25         565\n",
      "\u001b[90m 4\u001b[39m         12 2024-03-25         565\n",
      "\u001b[90m 5\u001b[39m         39 2024-03-25         565\n",
      "\u001b[90m 6\u001b[39m          2 2024-03-25         565\n",
      "\u001b[90m 7\u001b[39m         11 2024-03-25         565\n",
      "\u001b[90m 8\u001b[39m         48 2024-03-25         565\n",
      "\u001b[90m 9\u001b[39m         44 2024-03-25         565\n",
      "\u001b[90m10\u001b[39m          6 2024-03-25         565\n"
     ]
    }
   ],
   "source": [
    "# ===================================================\n",
    "# Task 5.1: Calculate Days Since Transaction\n",
    "# ===================================================\n",
    "# TODO: Create a new column 'days_since' that calculates days from date_parsed to today()\n",
    "# Hint: Use as.numeric(today() - date_parsed)\n",
    "\n",
    "transactions_clean <- transactions_clean %>%\n",
    "  mutate(\n",
    "    days_since = as.numeric(lubridate::today() - date_parsed)\n",
    "  )\n",
    "\n",
    "# ===================================================\n",
    "# Display results\n",
    "# ===================================================\n",
    "cat(\"Days Since Transaction:\\n\")\n",
    "transactions_clean %>%\n",
    "  select(CustomerID, date_parsed, days_since) %>%   # fallback if customer_name doesn’t exist\n",
    "  arrange(desc(days_since)) %>%\n",
    "  head(10) %>%\n",
    "  print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "recency_categories",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recency Category Distribution:\n",
      "\n",
      "At Risk \n",
      "     61 \n",
      "\n",
      "At-Risk Customers (>90 days):\n",
      "\u001b[90m# A tibble: 61 × 3\u001b[39m\n",
      "   CustomerID date_parsed days_since\n",
      "        \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<date>\u001b[39m\u001b[23m           \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m         31 2024-03-25         565\n",
      "\u001b[90m 2\u001b[39m         25 2024-03-25         565\n",
      "\u001b[90m 3\u001b[39m         35 2024-03-25         565\n",
      "\u001b[90m 4\u001b[39m         12 2024-03-25         565\n",
      "\u001b[90m 5\u001b[39m         39 2024-03-25         565\n",
      "\u001b[90m 6\u001b[39m          2 2024-03-25         565\n",
      "\u001b[90m 7\u001b[39m         11 2024-03-25         565\n",
      "\u001b[90m 8\u001b[39m         48 2024-03-25         565\n",
      "\u001b[90m 9\u001b[39m         44 2024-03-25         565\n",
      "\u001b[90m10\u001b[39m          6 2024-03-25         565\n",
      "\u001b[90m# ℹ 51 more rows\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "# ===================================================\n",
    "# Task 5.2: Categorize by Recency\n",
    "# ===================================================\n",
    "# TODO: Create a new column 'recency_category' using case_when():\n",
    "#   - \"Recent\" if days_since <= 30\n",
    "#   - \"Moderate\" if days_since <= 90\n",
    "#   - \"At Risk\" if days_since > 90\n",
    "\n",
    "transactions_clean <- transactions_clean %>%\n",
    "  mutate(\n",
    "    recency_category = case_when(\n",
    "      days_since <= 30 ~ \"Recent\",\n",
    "      days_since <= 90 ~ \"Moderate\",\n",
    "      days_since > 90  ~ \"At Risk\",\n",
    "      TRUE             ~ NA_character_\n",
    "    )\n",
    "  )\n",
    "\n",
    "# ===================================================\n",
    "# Display distribution\n",
    "# ===================================================\n",
    "cat(\"Recency Category Distribution:\\n\")\n",
    "table(transactions_clean$recency_category) %>% print()\n",
    "\n",
    "# ===================================================\n",
    "# Show At-Risk Customers\n",
    "# ===================================================\n",
    "cat(\"\\nAt-Risk Customers (>90 days):\\n\")\n",
    "transactions_clean %>%\n",
    "  filter(recency_category == \"At Risk\") %>%\n",
    "  select(CustomerID, date_parsed, days_since) %>%   # fallback if customer_name not present\n",
    "  arrange(desc(days_since)) %>%\n",
    "  print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part6_intro",
   "metadata": {},
   "source": [
    "## Part 6: Combined String and Date Operations\n",
    "\n",
    "**Business Context:** Create personalized customer outreach messages based on purchase recency.\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Extract first names from customer names\n",
    "2. Create personalized messages based on recency\n",
    "3. Analyze transaction patterns by weekday\n",
    "4. Identify best customers (recent + high value)\n",
    "\n",
    "**Key Functions:** Combine `str_extract()`, date calculations, `case_when()`, `group_by()`, `summarize()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "extract_names",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Personalized Customer Messages:\n",
      "\u001b[90m# A tibble: 10 × 4\u001b[39m\n",
      "   customer_name first_name days_since personalized_message                     \n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m         \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m           \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                                    \n",
      "\u001b[90m 1\u001b[39m Customer 26   Customer           \u001b[31mNA\u001b[39m Hi Customer!                             \n",
      "\u001b[90m 2\u001b[39m Customer 21   Customer           \u001b[31mNA\u001b[39m Hi Customer!                             \n",
      "\u001b[90m 3\u001b[39m Customer 12   Customer           \u001b[31mNA\u001b[39m Hi Customer!                             \n",
      "\u001b[90m 4\u001b[39m Customer 6    Customer           \u001b[31mNA\u001b[39m Hi Customer!                             \n",
      "\u001b[90m 5\u001b[39m Customer 32   Customer           \u001b[31mNA\u001b[39m Hi Customer!                             \n",
      "\u001b[90m 6\u001b[39m Customer 27   Customer           \u001b[31mNA\u001b[39m Hi Customer!                             \n",
      "\u001b[90m 7\u001b[39m Customer 31   Customer           \u001b[31mNA\u001b[39m Hi Customer!                             \n",
      "\u001b[90m 8\u001b[39m Customer 30   Customer           \u001b[31mNA\u001b[39m Hi Customer!                             \n",
      "\u001b[90m 9\u001b[39m Customer 31   Customer          565 Hi Customer, it's been a while! Here's a…\n",
      "\u001b[90m10\u001b[39m Customer 13   Customer           \u001b[31mNA\u001b[39m Hi Customer!                             \n"
     ]
    }
   ],
   "source": [
    "# ===================================================\n",
    "# Task 6.1: Extract First Names and Create Personalized Messages\n",
    "# ===================================================\n",
    "\n",
    "library(tidyverse)\n",
    "library(stringr)\n",
    "\n",
    "# --- Ensure a customer_name column exists in transactions_clean ---\n",
    "# 1) Try to find an existing name column on transactions_clean\n",
    "tx_name_candidates <- c(\"customer_name\", \"Customer_Name\", \"Name\")\n",
    "tx_name_col <- intersect(tx_name_candidates, names(transactions_clean))[1]\n",
    "\n",
    "if (is.na(tx_name_col)) {\n",
    "  # 2) Bring a name column from customers via CustomerID\n",
    "  cust_name_candidates <- c(\"customer_name\", \"Customer_Name\", \"Name\")\n",
    "  cust_name_col <- intersect(cust_name_candidates, names(customers))[1]\n",
    "  if (is.na(cust_name_col)) {\n",
    "    stop(\"Could not find a customer name column in transactions_clean or customers.\")\n",
    "  }\n",
    "  # Join and standardize to `customer_name`\n",
    "  transactions_named <- transactions_clean %>%\n",
    "    left_join(\n",
    "      customers %>% select(CustomerID, !!sym(cust_name_col)) %>%\n",
    "        rename(customer_name = !!sym(cust_name_col)),\n",
    "      by = \"CustomerID\"\n",
    "    )\n",
    "} else {\n",
    "  # Standardize to `customer_name` if needed\n",
    "  transactions_named <- transactions_clean %>%\n",
    "    mutate(customer_name = .data[[tx_name_col]])\n",
    "}\n",
    "\n",
    "# --- Build outreach table with first name + personalized message ---\n",
    "customer_outreach <- transactions_named %>%\n",
    "  mutate(\n",
    "    # Extract first token before first space; fall back to whole string if single token\n",
    "    first_name = str_extract(customer_name %||% \"\", \"^\\\\w+\"),\n",
    "    first_name = if_else(is.na(first_name) | first_name == \"\", \"Friend\", first_name),\n",
    "\n",
    "    personalized_message = case_when(\n",
    "      recency_category == \"Recent\"   ~ paste0(\"Hi \", first_name, \"! Thanks for your recent purchase!\"),\n",
    "      recency_category == \"Moderate\" ~ paste0(\"Hi \", first_name, \", we miss you! Check out our new products.\"),\n",
    "      recency_category == \"At Risk\"  ~ paste0(\"Hi \", first_name, \", it's been a while! Here's a special offer for you.\"),\n",
    "      TRUE                           ~ paste0(\"Hi \", first_name, \"!\")\n",
    "    )\n",
    "  )\n",
    "\n",
    "# --- Display personalized messages ---\n",
    "cat(\"Personalized Customer Messages:\\n\")\n",
    "customer_outreach %>%\n",
    "  select(customer_name, first_name, days_since, personalized_message) %>%\n",
    "  head(10) %>%\n",
    "  print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "weekday_analysis",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transaction Patterns by Weekday:\n",
      "\u001b[90m# A tibble: 2 × 4\u001b[39m\n",
      "  trans_weekday transaction_count total_amount avg_amount\n",
      "  \u001b[3m\u001b[90m<ord>\u001b[39m\u001b[23m                     \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m        \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m      \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m \u001b[31mNA\u001b[39m                           89       \u001b[4m2\u001b[24m\u001b[4m2\u001b[24m367.       251.\n",
      "\u001b[90m2\u001b[39m Monday                       61       \u001b[4m1\u001b[24m\u001b[4m5\u001b[24m367.       252.\n",
      "\n",
      "🔥 Busiest day: NA \n"
     ]
    }
   ],
   "source": [
    "# ===================================================\n",
    "# Task 6.2: Analyze Transaction Patterns by Weekday\n",
    "# ===================================================\n",
    "# TODO: Group by trans_weekday and calculate:\n",
    "#   - transaction_count: number of transactions\n",
    "#   - total_amount: sum of amount (if available)\n",
    "#   - avg_amount: average amount per transaction\n",
    "# TODO: Arrange by transaction_count descending\n",
    "\n",
    "weekday_patterns <- transactions_clean %>%\n",
    "  group_by(trans_weekday) %>%\n",
    "  summarise(\n",
    "    transaction_count = n(),\n",
    "    total_amount = sum(Amount, na.rm = TRUE),\n",
    "    avg_amount = mean(Amount, na.rm = TRUE),\n",
    "    .groups = \"drop\"\n",
    "  ) %>%\n",
    "  arrange(desc(transaction_count))\n",
    "\n",
    "# ===================================================\n",
    "# Display results\n",
    "# ===================================================\n",
    "cat(\"Transaction Patterns by Weekday:\\n\")\n",
    "print(weekday_patterns)\n",
    "\n",
    "# ===================================================\n",
    "# Identify busiest day\n",
    "# ===================================================\n",
    "busiest_day <- weekday_patterns$trans_weekday[1]\n",
    "cat(\"\\n🔥 Busiest day:\", as.character(busiest_day), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "monthly_analysis",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monthly Transaction Patterns:\n",
      "\u001b[90m# A tibble: 3 × 4\u001b[39m\n",
      "  trans_month trans_month_name transaction_count unique_customers\n",
      "        \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<ord>\u001b[39m\u001b[23m                        \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m            \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m           3 March                           28               22\n",
      "\u001b[90m2\u001b[39m           4 April                           33               23\n",
      "\u001b[90m3\u001b[39m          \u001b[31mNA\u001b[39m \u001b[31mNA\u001b[39m                              89               44\n"
     ]
    }
   ],
   "source": [
    "# ===================================================\n",
    "# Task 6.3: Monthly Transaction Analysis\n",
    "# ===================================================\n",
    "# TODO: Group by trans_month_name and calculate:\n",
    "#   - transaction_count\n",
    "#   - unique_customers: use n_distinct(customer_name)\n",
    "# TODO: Arrange by trans_month (to show chronological order)\n",
    "\n",
    "monthly_patterns <- transactions_clean %>%\n",
    "  group_by(trans_month, trans_month_name) %>%\n",
    "  summarise(\n",
    "    transaction_count = n(),\n",
    "    unique_customers  = n_distinct(CustomerID),\n",
    "    .groups = \"drop\"\n",
    "  ) %>%\n",
    "  arrange(trans_month)\n",
    "\n",
    "# ===================================================\n",
    "# Display results\n",
    "# ===================================================\n",
    "cat(\"Monthly Transaction Patterns:\\n\")\n",
    "print(monthly_patterns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part7_intro",
   "metadata": {},
   "source": [
    "## Part 7: Business Intelligence Summary\n",
    "\n",
    "**Business Context:** Create an executive summary that combines all your analyses into actionable insights.\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Calculate key metrics across all datasets\n",
    "2. Identify top products and categories\n",
    "3. Summarize customer sentiment\n",
    "4. Provide data-driven recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "business_summary",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         BUSINESS INTELLIGENCE SUMMARY\n",
      "============================================================\n",
      "\n",
      "📦 PRODUCT ANALYSIS\n",
      "──────────────────────────────\n",
      "Total products: 75 \n",
      "Wireless products: 17 \n",
      "Premium products: 13 \n",
      "Most common category: Electronics \n",
      "\n",
      "💬 CUSTOMER SENTIMENT\n",
      "──────────────────────────────\n",
      "Total feedback entries: 100 \n",
      "Average sentiment score: 0.18 \n",
      "Percentage positive reviews: 30 %\n",
      "Percentage negative reviews: 20 %\n",
      "\n",
      "📊 TRANSACTION PATTERNS\n",
      "──────────────────────────────\n",
      "Total transactions: 150 \n",
      "Date range: 2024-03-25 to 2024-04-01 \n",
      "Busiest weekday: NA \n",
      "Weekend transaction percentage: 0 %\n",
      "\n",
      "👥 CUSTOMER RECENCY\n",
      "──────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“\u001b[1m\u001b[22mThere were 13 warnings in `summarise()`.\n",
      "The first warning was:\n",
      "\u001b[1m\u001b[22m\u001b[36mℹ\u001b[39m In argument: `last_date = max(date_parsed, na.rm = TRUE)`.\n",
      "\u001b[36mℹ\u001b[39m In group 4: `CustomerID = 4`.\n",
      "Caused by warning in `max.default()`:\n",
      "\u001b[33m!\u001b[39m no non-missing arguments to max; returning -Inf\n",
      "\u001b[1m\u001b[22m\u001b[36mℹ\u001b[39m Run `dplyr::last_dplyr_warnings()` to see the 12 remaining warnings.”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of recent customers (≤ 30 days): 0 \n",
      "Number of at-risk customers (> 90 days): 47 \n",
      "Percentage needing re-engagement: 100 %\n"
     ]
    }
   ],
   "source": [
    "# Task 7.1: Create Business Intelligence Dashboard\n",
    "library(tidyverse)\n",
    "library(lubridate)\n",
    "\n",
    "cat(\"\\n\", paste(rep(\"=\", 60), collapse = \"\"), \"\\n\", sep = \"\")\n",
    "cat(\"         BUSINESS INTELLIGENCE SUMMARY\\n\")\n",
    "cat(paste(rep(\"=\", 60), collapse = \"\"), \"\\n\\n\", sep = \"\")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 📦 PRODUCT ANALYSIS\n",
    "# --------------------------------------------------\n",
    "cat(\"📦 PRODUCT ANALYSIS\\n\")\n",
    "cat(paste(rep(\"─\", 30), collapse = \"\"), \"\\n\", sep = \"\")\n",
    "\n",
    "# Totals and feature flags\n",
    "total_products   <- nrow(products_clean)\n",
    "wireless_count   <- sum(products_clean$is_wireless %||% FALSE, na.rm = TRUE)\n",
    "premium_count    <- sum(products_clean$is_premium  %||% FALSE, na.rm = TRUE)\n",
    "\n",
    "# Most common category (using cleaned category if present)\n",
    "cat_col <- if (\"category_clean\" %in% names(products_clean)) \"category_clean\" else\n",
    "           if (\"category\" %in% names(products_clean)) \"category\" else NA_character_\n",
    "most_common_category <- if (!is.na(cat_col)) {\n",
    "  products_clean %>% count(.data[[cat_col]], sort = TRUE) %>% slice(1) %>% pull(1)\n",
    "} else {\"(no category column)\"}\n",
    "\n",
    "cat(\"Total products:\", total_products, \"\\n\")\n",
    "cat(\"Wireless products:\", wireless_count, \"\\n\")\n",
    "cat(\"Premium products:\", premium_count, \"\\n\")\n",
    "cat(\"Most common category:\", most_common_category, \"\\n\")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 💬 CUSTOMER SENTIMENT\n",
    "# --------------------------------------------------\n",
    "cat(\"\\n💬 CUSTOMER SENTIMENT\\n\")\n",
    "cat(paste(rep(\"─\", 30), collapse = \"\"), \"\\n\", sep = \"\")\n",
    "\n",
    "total_feedback <- nrow(feedback_clean)\n",
    "avg_sentiment  <- mean(feedback_clean$sentiment_score %||% NA_real_, na.rm = TRUE)\n",
    "pos_pct <- if (total_feedback > 0) {\n",
    "  round(100 * sum((feedback_clean$sentiment_score %||% 0) > 0, na.rm = TRUE) / total_feedback, 1)\n",
    "} else { NA_real_ }\n",
    "neg_pct <- if (total_feedback > 0) {\n",
    "  round(100 * sum((feedback_clean$sentiment_score %||% 0) < 0, na.rm = TRUE) / total_feedback, 1)\n",
    "} else { NA_real_ }\n",
    "\n",
    "cat(\"Total feedback entries:\", total_feedback, \"\\n\")\n",
    "cat(\"Average sentiment score:\", round(avg_sentiment, 3), \"\\n\")\n",
    "cat(\"Percentage positive reviews:\", pos_pct, \"%\\n\")\n",
    "cat(\"Percentage negative reviews:\", neg_pct, \"%\\n\")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 📊 TRANSACTION PATTERNS\n",
    "# --------------------------------------------------\n",
    "cat(\"\\n📊 TRANSACTION PATTERNS\\n\")\n",
    "cat(paste(rep(\"─\", 30), collapse = \"\"), \"\\n\", sep = \"\")\n",
    "\n",
    "total_tx   <- nrow(transactions_clean)\n",
    "date_min   <- suppressWarnings(min(transactions_clean$date_parsed, na.rm = TRUE))\n",
    "date_max   <- suppressWarnings(max(transactions_clean$date_parsed, na.rm = TRUE))\n",
    "\n",
    "weekday_patterns <- transactions_clean %>%\n",
    "  group_by(trans_weekday) %>%\n",
    "  summarise(transaction_count = n(), .groups = \"drop\") %>%\n",
    "  arrange(desc(transaction_count))\n",
    "\n",
    "busiest_day <- if (nrow(weekday_patterns) > 0) as.character(weekday_patterns$trans_weekday[1]) else \"(none)\"\n",
    "\n",
    "wknd_pct <- if (total_tx > 0) {\n",
    "  round(100 * sum(transactions_clean$is_weekend %||% FALSE, na.rm = TRUE) / total_tx, 1)\n",
    "} else { NA_real_ }\n",
    "\n",
    "cat(\"Total transactions:\", total_tx, \"\\n\")\n",
    "cat(\"Date range:\", as.character(date_min), \"to\", as.character(date_max), \"\\n\")\n",
    "cat(\"Busiest weekday:\", busiest_day, \"\\n\")\n",
    "cat(\"Weekend transaction percentage:\", wknd_pct, \"%\\n\")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 👥 CUSTOMER RECENCY\n",
    "# --------------------------------------------------\n",
    "cat(\"\\n👥 CUSTOMER RECENCY\\n\")\n",
    "cat(paste(rep(\"─\", 30), collapse = \"\"), \"\\n\", sep = \"\")\n",
    "\n",
    "# Choose an identifier for customers\n",
    "cust_id_col <- intersect(c(\"CustomerID\",\"customer_id\",\"customerId\"), names(transactions_clean))[1]\n",
    "cust_name_col <- intersect(c(\"customer_name\",\"Customer_Name\",\"Name\"), names(transactions_clean))[1]\n",
    "\n",
    "# Build a per-customer recency table from last transaction date\n",
    "if (!is.na(cust_id_col)) {\n",
    "  recency_by_customer <- transactions_clean %>%\n",
    "    group_by(.data[[cust_id_col]]) %>%\n",
    "    summarise(last_date = max(date_parsed, na.rm = TRUE), .groups = \"drop\") %>%\n",
    "    mutate(days_since_last = as.numeric(today() - last_date),\n",
    "           recency_band = case_when(\n",
    "             days_since_last <= 30 ~ \"Recent\",\n",
    "             days_since_last <= 90 ~ \"Moderate\",\n",
    "             days_since_last >  90 ~ \"At Risk\",\n",
    "             TRUE ~ NA_character_\n",
    "           ))\n",
    "  total_customers   <- nrow(recency_by_customer)\n",
    "  recent_customers  <- sum(recency_by_customer$recency_band == \"Recent\",  na.rm = TRUE)\n",
    "  atrisk_customers  <- sum(recency_by_customer$recency_band == \"At Risk\", na.rm = TRUE)\n",
    "  reengage_pct      <- if (total_customers > 0) round(100 * atrisk_customers / total_customers, 1) else NA_real_\n",
    "} else if (!is.na(cust_name_col)) {\n",
    "  recency_by_customer <- transactions_clean %>%\n",
    "    group_by(.data[[cust_name_col]]) %>%\n",
    "    summarise(last_date = max(date_parsed, na.rm = TRUE), .groups = \"drop\") %>%\n",
    "    mutate(days_since_last = as.numeric(today() - last_date),\n",
    "           recency_band = case_when(\n",
    "             days_since_last <= 30 ~ \"Recent\",\n",
    "             days_since_last <= 90 ~ \"Moderate\",\n",
    "             days_since_last >  90 ~ \"At Risk\",\n",
    "             TRUE ~ NA_character_\n",
    "           ))\n",
    "  total_customers   <- nrow(recency_by_customer)\n",
    "  recent_customers  <- sum(recency_by_customer$recency_band == \"Recent\",  na.rm = TRUE)\n",
    "  atrisk_customers  <- sum(recency_by_customer$recency_band == \"At Risk\", na.rm = TRUE)\n",
    "  reengage_pct      <- if (total_customers > 0) round(100 * atrisk_customers / total_customers, 1) else NA_real_\n",
    "} else {\n",
    "  total_customers <- recent_customers <- atrisk_customers <- reengage_pct <- NA_real_\n",
    "}\n",
    "\n",
    "cat(\"Number of recent customers (≤ 30 days):\", recent_customers, \"\\n\")\n",
    "cat(\"Number of at-risk customers (> 90 days):\", atrisk_customers, \"\\n\")\n",
    "cat(\"Percentage needing re-engagement:\", reengage_pct, \"%\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "top_products",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Product Categories:\n",
      "\u001b[90m# A tibble: 5 × 2\u001b[39m\n",
      "  category_clean product_count\n",
      "  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                  \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m Electronics               21\n",
      "\u001b[90m2\u001b[39m Computers                 15\n",
      "\u001b[90m3\u001b[39m Audio                     14\n",
      "\u001b[90m4\u001b[39m Tv                        14\n",
      "\u001b[90m5\u001b[39m Shoes                     11\n"
     ]
    }
   ],
   "source": [
    "# ===================================================\n",
    "# Task 7.2: Identify Top Products by Category\n",
    "# ===================================================\n",
    "# TODO: Group products by category_clean and count products in each\n",
    "# TODO: Arrange by count descending\n",
    "# TODO: Display top 5 categories\n",
    "\n",
    "top_categories <- products_clean %>%\n",
    "  group_by(category_clean) %>%\n",
    "  summarise(\n",
    "    product_count = n(),\n",
    "    .groups = \"drop\"\n",
    "  ) %>%\n",
    "  arrange(desc(product_count)) %>%\n",
    "  slice_head(n = 5)\n",
    "\n",
    "# ===================================================\n",
    "# Display results\n",
    "# ===================================================\n",
    "cat(\"Top Product Categories:\\n\")\n",
    "print(top_categories)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part8_intro",
   "metadata": {},
   "source": [
    "## Part 8: Reflection Questions\n",
    "\n",
    "Answer the following questions based on your analysis. Write your answers in the markdown cells below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection1",
   "metadata": {},
   "source": [
    "### Question 8.1: Data Quality Impact\n",
    "\n",
    "**How did cleaning the text data (removing spaces, standardizing case) improve your ability to analyze the data? Provide specific examples from your homework.**\n",
    "\n",
    "Your answer here: Cleaning the text data significantly improved my ability to analyze the data by ensuring consistency across entries. For example, in the product catalog, there were multiple variations of the same product name due to inconsistent casing and extra spaces (e.g., \"  Wireless Mouse\", \"wireless mouse\", \"WIRELESS MOUSE\"). By using functions like `str_trim()` and `str_to_lower()`, I standardized these entries, which allowed me to accurately count occurrences and analyze product popularity without duplication errors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection2",
   "metadata": {},
   "source": [
    "### Question 8.2: Pattern Detection Value\n",
    "\n",
    "**What business insights did you gain from detecting patterns in product names (wireless, premium, gaming)? How could a business use this information?**\n",
    "\n",
    "Your answer here: Detecting patterns in product names provided insights into customer preferences and market trends. For instance, identifying products labeled as \"wireless\" or \"gaming\" helped me understand which categories were more popular among customers. A business could use this information to tailor marketing campaigns, stock inventory based on demand, and develop new products that align with customer interests. For example, if \"gaming\" products are trending, the business could focus on expanding their gaming accessories line to capture more market share.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection3",
   "metadata": {},
   "source": [
    "### Question 8.3: Date Analysis Importance\n",
    "\n",
    "**Why is analyzing transaction dates by weekday and month important for business operations? Provide at least three specific business applications.**\n",
    "\n",
    "Your answer here:\n",
    "\n",
    "1. Better Inventory Management: By analyzing transaction dates, businesses can identify peak shopping days and months, allowing them to optimize inventory levels and reduce stockouts or overstock situations.\n",
    "2. Targeted Marketing Campaigns: Understanding when customers are most active enables businesses to schedule promotions and advertising during high-traffic periods, increasing the effectiveness of their marketing efforts.\n",
    "3. Staffing Optimization: Analyzing transaction patterns helps businesses allocate staff more efficiently during busy periods, ensuring better customer service and reducing wait times.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection4",
   "metadata": {},
   "source": [
    "### Question 8.4: Customer Recency Strategy\n",
    "\n",
    "**Based on your recency analysis, what specific actions would you recommend for customers in each category (Recent, Moderate, At Risk)? How would you prioritize these actions?**\n",
    "\n",
    "Your answer here: I would recommend the following actions for each customer category: \n",
    "- Recent: For recent customers, I would prioritize engagement through personalized thank-you messages and exclusive offers to encourage repeat purchases. These customers are already active, so maintaining their interest is crucial.\n",
    "- Moderate: For moderate customers, I would suggest targeted promotions and reminders about products they previously viewed\n",
    "- or purchased. Offering incentives like discounts or loyalty points could help re-engage them and move them back to the recent category.\n",
    "- At Risk: For at-risk customers, I would recommend a more aggressive re-engagement strategy, such as personalized outreach via email or phone calls. Offering significant discounts or special deals could entice them to return. Prioritizing these actions based on customer lifetime value would ensure that high-value customers receive more attention and resources.\n",
    "- Overall, I would prioritize actions based on the potential revenue impact, focusing first on recent and high-value customers while still addressing at-risk customers to prevent churn.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection5",
   "metadata": {},
   "source": [
    "### Question 8.5: Sentiment Analysis Application\n",
    "\n",
    "**How could the sentiment analysis you performed be used to improve products or customer service? What are the limitations of this simple sentiment analysis approach?**\n",
    "\n",
    "Your answer here: The sentiment analysis I performed can be used to identify common themes in customer feedback, allowing businesses to address specific issues and improve their products or services. For example, if many customers express dissatisfaction with a particular feature, the company can prioritize enhancements in that area. Additionally, positive feedback can highlight strengths that the business can leverage in marketing campaigns. However, the limitations of this simple sentiment analysis approach include its reliance on keyword detection, which may not capture the full context of customer feedback. For instance, a review that contains both positive and negative sentiments may be misclassified if it only focuses on specific words. Additionally, sarcasm or nuanced language can lead to inaccurate sentiment classification. More advanced techniques, such as machine learning-based sentiment analysis, would provide a deeper understanding of customer opinions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection6",
   "metadata": {},
   "source": [
    "### Question 8.6: Real-World Application\n",
    "\n",
    "**Describe a real business scenario where you would need to combine string manipulation and date analysis (like you did in this homework). What insights would you be trying to discover?**\n",
    "\n",
    "Your answer here: A real business scenario where combining string manipulation and date analysis would be essential is in managing a subscription-based e-commerce platform. In this scenario, I would need to analyze customer reviews (string data) alongside their subscription renewal dates (date data) to understand customer satisfaction and retention patterns. By cleaning and standardizing the review text, I could extract sentiment and key themes related to product quality, customer service, and overall experience. Simultaneously, analyzing the renewal dates would help identify trends in subscription renewals, such as peak renewal periods or correlations between negative reviews and subscription cancellations. The insights I would be trying to discover include identifying factors that lead to customer churn, understanding the impact of customer feedback on renewal rates, and developing targeted strategies to improve customer satisfaction and retention. This combined analysis would enable the business to make data-driven decisions to enhance both product offerings and customer service strategies.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## Summary and Submission\n",
    "\n",
    "### What You've Accomplished\n",
    "\n",
    "In this homework, you've successfully:\n",
    "- ✅ Cleaned and standardized messy text data using `stringr` functions\n",
    "- ✅ Detected patterns and extracted information from text\n",
    "- ✅ Parsed dates and extracted temporal components using `lubridate`\n",
    "- ✅ Calculated customer recency for segmentation\n",
    "- ✅ Analyzed transaction patterns by time periods\n",
    "- ✅ Combined string and date operations for business insights\n",
    "- ✅ Created personalized customer communications\n",
    "- ✅ Generated executive-ready business intelligence summaries\n",
    "\n",
    "### Key Skills Mastered\n",
    "\n",
    "**String Manipulation:**\n",
    "- `str_trim()`, `str_squish()` - Whitespace handling\n",
    "- `str_to_lower()`, `str_to_upper()`, `str_to_title()` - Case conversion\n",
    "- `str_detect()` - Pattern detection\n",
    "- `str_extract()` - Information extraction\n",
    "- `str_count()` - Pattern counting\n",
    "\n",
    "**Date/Time Operations:**\n",
    "- `ymd()`, `mdy()`, `dmy()` - Date parsing\n",
    "- `year()`, `month()`, `day()`, `wday()` - Component extraction\n",
    "- `quarter()` - Period extraction\n",
    "- `today()` - Current date\n",
    "- Date arithmetic - Calculating differences\n",
    "\n",
    "**Business Applications:**\n",
    "- Data cleaning and standardization\n",
    "- Customer segmentation by recency\n",
    "- Sentiment analysis\n",
    "- Pattern identification\n",
    "- Temporal trend analysis\n",
    "- Personalized communication\n",
    "\n",
    "### Submission Checklist\n",
    "\n",
    "Before submitting, ensure you have:\n",
    "- [ ] Entered your name, student ID, and date at the top\n",
    "- [ ] Completed all code tasks (Parts 1-7)\n",
    "- [ ] Run all cells successfully without errors\n",
    "- [ ] Answered all reflection questions (Part 8)\n",
    "- [ ] Used proper commenting in your code\n",
    "- [ ] Used the pipe operator (`%>%`) where appropriate\n",
    "- [ ] Verified your results make business sense\n",
    "- [ ] Checked for any remaining TODO comments\n",
    "\n",
    "### Grading Criteria\n",
    "\n",
    "Your homework will be evaluated on:\n",
    "- **Code Correctness (40%)**: All tasks completed correctly\n",
    "- **Code Quality (20%)**: Clean, well-commented, efficient code\n",
    "- **Business Understanding (20%)**: Demonstrates understanding of business applications\n",
    "- **Reflection Questions (15%)**: Thoughtful, complete answers\n",
    "- **Presentation (5%)**: Professional formatting and organization\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "In Lesson 8, you'll learn:\n",
    "- Advanced data wrangling with complex pipelines\n",
    "- Sophisticated conditional logic with `case_when()`\n",
    "- Data validation and quality checks\n",
    "- Creating reproducible analysis workflows\n",
    "- Professional best practices for business analytics\n",
    "\n",
    "**Great work on completing this assignment! 🎉**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
