{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework Assignment - Lesson 7: String Manipulation and Date/Time Data\n",
    "\n",
    "**Student Name:** [Trinity Schroeder]\n",
    "\n",
    "**Student ID:** [zmq814]\n",
    "\n",
    "**Date Submitted:** [10/12/2025]\n",
    "\n",
    "**Due Date:** [10/12/2025]\n",
    "\n",
    "---\n",
    "\n",
    "## Objective\n",
    "\n",
    "Master string manipulation with `stringr` and date/time operations with `lubridate` for real-world business data cleaning and analysis.\n",
    "\n",
    "## Learning Goals\n",
    "\n",
    "By completing this assignment, you will:\n",
    "- Clean and standardize messy text data using `stringr` functions\n",
    "- Parse and manipulate dates using `lubridate` functions\n",
    "- Extract information from text and dates for business insights\n",
    "- Combine string and date operations for customer segmentation\n",
    "- Create business-ready reports from raw data\n",
    "\n",
    "## Instructions\n",
    "\n",
    "- Complete all tasks in this notebook\n",
    "- Write your code in the designated TODO sections\n",
    "- Use the pipe operator (`%>%`) wherever possible\n",
    "- Add comments explaining your logic\n",
    "- Run all cells to verify your code works\n",
    "- Answer all reflection questions\n",
    "\n",
    "## Datasets\n",
    "\n",
    "You will work with three CSV files:\n",
    "- `customer_feedback.csv` - Customer reviews with messy text\n",
    "- `transaction_log.csv` - Transaction records with dates\n",
    "- `product_catalog.csv` - Product descriptions needing standardization\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Import and Initial Exploration\n",
    "\n",
    "**Business Context:** Before cleaning data, you must understand its structure and quality issues.\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Load required packages (`tidyverse` and `lubridate`)\n",
    "2. Import all three CSV files from the `data/` directory\n",
    "3. Examine the structure and identify data quality issues\n",
    "4. Display sample rows to understand the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Packages loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Task 1.1: Load Required Packages\n",
    "library(tidyverse)  # includes stringr\n",
    "library(lubridate)\n",
    "cat(\"✅ Packages loaded successfully!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mRows: \u001b[22m\u001b[34m100\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m5\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m  (2): Feedback_Text, Contact_Info\n",
      "\u001b[32mdbl\u001b[39m  (2): FeedbackID, CustomerID\n",
      "\u001b[34mdate\u001b[39m (1): Feedback_Date\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m  (2): Feedback_Text, Contact_Info\n",
      "\u001b[32mdbl\u001b[39m  (2): FeedbackID, CustomerID\n",
      "\u001b[34mdate\u001b[39m (1): Feedback_Date\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
      "\u001b[1mRows: \u001b[22m\u001b[34m150\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m5\u001b[39m\n",
      "\u001b[1mRows: \u001b[22m\u001b[34m150\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m5\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m (2): Transaction_DateTime, Status\n",
      "\u001b[32mdbl\u001b[39m (3): LogID, CustomerID, Amount\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
      "\u001b[1mRows: \u001b[22m\u001b[34m75\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m5\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m (3): Product_Description, Category, In_Stock\n",
      "\u001b[32mdbl\u001b[39m (2): ProductID, Price\n",
      "\u001b[1mRows: \u001b[22m\u001b[34m75\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m5\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m (3): Product_Description, Category, In_Stock\n",
      "\u001b[32mdbl\u001b[39m (2): ProductID, Price\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data imported successfully!\n",
      "Feedback rows: 100 \n",
      "Transaction rows: 150 \n",
      "Product rows: 75 \n",
      "Feedback rows: 100 \n",
      "Transaction rows: 150 \n",
      "Product rows: 75 \n"
     ]
    }
   ],
   "source": [
    "# Task 1.2: Import Datasets\n",
    "# Import customer_feedback.csv into a variable called 'feedback'\n",
    "feedback <- read_csv(\"/workspaces/assignment-1-version-3-trinitysch/data/customer_feedback.csv\")\n",
    "\n",
    "# Import transaction_log.csv into a variable called 'transactions'\n",
    "transactions <- read_csv(\"/workspaces/assignment-1-version-3-trinitysch/data/transaction_log.csv\")\n",
    "\n",
    "# Import product_catalog.csv into a variable called 'products'\n",
    "products <- read_csv(\"/workspaces/assignment-1-version-3-trinitysch/data/product_catalog.csv\")\n",
    "\n",
    "cat(\"✅ Data imported successfully!\\n\")\n",
    "cat(\"Feedback rows:\", nrow(feedback), \"\\n\")\n",
    "cat(\"Transaction rows:\", nrow(transactions), \"\\n\")\n",
    "cat(\"Product rows:\", nrow(products), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "explore_data",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CUSTOMER FEEDBACK DATA ===\n",
      "spc_tbl_ [100 × 5] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n",
      " $ FeedbackID   : num [1:100] 1 2 3 4 5 6 7 8 9 10 ...\n",
      " $ CustomerID   : num [1:100] 12 40 34 1 47 13 13 37 49 23 ...\n",
      " $ Feedback_Text: chr [1:100] \"Highly recommend this item\" \"Excellent service\" \"Poor quality control\" \"average product, nothing special\" ...\n",
      " $ Contact_Info : chr [1:100] \"bob.wilson@test.org\" \"555-123-4567\" \"jane_smith@company.com\" \"jane_smith@company.com\" ...\n",
      " $ Feedback_Date: Date[1:100], format: \"2024-02-23\" \"2024-01-21\" ...\n",
      " - attr(*, \"spec\")=\n",
      "  .. cols(\n",
      "  ..   FeedbackID = \u001b[32mcol_double()\u001b[39m,\n",
      "  ..   CustomerID = \u001b[32mcol_double()\u001b[39m,\n",
      "  ..   Feedback_Text = \u001b[31mcol_character()\u001b[39m,\n",
      "  ..   Contact_Info = \u001b[31mcol_character()\u001b[39m,\n",
      "  ..   Feedback_Date = \u001b[34mcol_date(format = \"\")\u001b[39m\n",
      "  .. )\n",
      " - attr(*, \"problems\")=<externalptr> \n",
      "spc_tbl_ [100 × 5] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n",
      " $ FeedbackID   : num [1:100] 1 2 3 4 5 6 7 8 9 10 ...\n",
      " $ CustomerID   : num [1:100] 12 40 34 1 47 13 13 37 49 23 ...\n",
      " $ Feedback_Text: chr [1:100] \"Highly recommend this item\" \"Excellent service\" \"Poor quality control\" \"average product, nothing special\" ...\n",
      " $ Contact_Info : chr [1:100] \"bob.wilson@test.org\" \"555-123-4567\" \"jane_smith@company.com\" \"jane_smith@company.com\" ...\n",
      " $ Feedback_Date: Date[1:100], format: \"2024-02-23\" \"2024-01-21\" ...\n",
      " - attr(*, \"spec\")=\n",
      "  .. cols(\n",
      "  ..   FeedbackID = \u001b[32mcol_double()\u001b[39m,\n",
      "  ..   CustomerID = \u001b[32mcol_double()\u001b[39m,\n",
      "  ..   Feedback_Text = \u001b[31mcol_character()\u001b[39m,\n",
      "  ..   Contact_Info = \u001b[31mcol_character()\u001b[39m,\n",
      "  ..   Feedback_Date = \u001b[34mcol_date(format = \"\")\u001b[39m\n",
      "  .. )\n",
      " - attr(*, \"problems\")=<externalptr> \n",
      "\u001b[90m# A tibble: 5 × 5\u001b[39m\n",
      "  FeedbackID CustomerID Feedback_Text                 Contact_Info Feedback_Date\n",
      "       \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m      \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                         \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m        \u001b[3m\u001b[90m<date>\u001b[39m\u001b[23m       \n",
      "\u001b[90m1\u001b[39m          1         12 Highly recommend this item    bob.wilson@… 2024-02-23   \n",
      "\u001b[90m2\u001b[39m          2         40 Excellent service             555-123-4567 2024-01-21   \n",
      "\u001b[90m3\u001b[39m          3         34 Poor quality control          jane_smith@… 2023-09-02   \n",
      "\u001b[90m4\u001b[39m          4          1 average product, nothing spe… jane_smith@… 2023-08-21   \n",
      "\u001b[90m5\u001b[39m          5         47 AMAZING customer support!!!   555-123-4567 2023-04-24   \n",
      "\n",
      "=== TRANSACTION DATA ===\n",
      "\u001b[90m# A tibble: 5 × 5\u001b[39m\n",
      "  FeedbackID CustomerID Feedback_Text                 Contact_Info Feedback_Date\n",
      "       \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m      \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                         \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m        \u001b[3m\u001b[90m<date>\u001b[39m\u001b[23m       \n",
      "\u001b[90m1\u001b[39m          1         12 Highly recommend this item    bob.wilson@… 2024-02-23   \n",
      "\u001b[90m2\u001b[39m          2         40 Excellent service             555-123-4567 2024-01-21   \n",
      "\u001b[90m3\u001b[39m          3         34 Poor quality control          jane_smith@… 2023-09-02   \n",
      "\u001b[90m4\u001b[39m          4          1 average product, nothing spe… jane_smith@… 2023-08-21   \n",
      "\u001b[90m5\u001b[39m          5         47 AMAZING customer support!!!   555-123-4567 2023-04-24   \n",
      "\n",
      "=== TRANSACTION DATA ===\n",
      "spc_tbl_ [150 × 5] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n",
      " $ LogID               : num [1:150] 1 2 3 4 5 6 7 8 9 10 ...\n",
      " $ CustomerID          : num [1:150] 26 21 12 6 32 27 31 30 31 13 ...\n",
      " $ Transaction_DateTime: chr [1:150] \"4/5/24 14:30\" \"3/15/24 14:30\" \"3/15/24 14:30\" \"3/20/24 9:15\" ...\n",
      " $ Amount              : num [1:150] 277 175 252 215 269 ...\n",
      " $ Status              : chr [1:150] \"Pending\" \"Pending\" \"Pending\" \"Pending\" ...\n",
      " - attr(*, \"spec\")=\n",
      "  .. cols(\n",
      "  ..   LogID = \u001b[32mcol_double()\u001b[39m,\n",
      "  ..   CustomerID = \u001b[32mcol_double()\u001b[39m,\n",
      "  ..   Transaction_DateTime = \u001b[31mcol_character()\u001b[39m,\n",
      "  ..   Amount = \u001b[32mcol_double()\u001b[39m,\n",
      "  ..   Status = \u001b[31mcol_character()\u001b[39m\n",
      "  .. )\n",
      " - attr(*, \"problems\")=<externalptr> \n",
      "spc_tbl_ [150 × 5] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n",
      " $ LogID               : num [1:150] 1 2 3 4 5 6 7 8 9 10 ...\n",
      " $ CustomerID          : num [1:150] 26 21 12 6 32 27 31 30 31 13 ...\n",
      " $ Transaction_DateTime: chr [1:150] \"4/5/24 14:30\" \"3/15/24 14:30\" \"3/15/24 14:30\" \"3/20/24 9:15\" ...\n",
      " $ Amount              : num [1:150] 277 175 252 215 269 ...\n",
      " $ Status              : chr [1:150] \"Pending\" \"Pending\" \"Pending\" \"Pending\" ...\n",
      " - attr(*, \"spec\")=\n",
      "  .. cols(\n",
      "  ..   LogID = \u001b[32mcol_double()\u001b[39m,\n",
      "  ..   CustomerID = \u001b[32mcol_double()\u001b[39m,\n",
      "  ..   Transaction_DateTime = \u001b[31mcol_character()\u001b[39m,\n",
      "  ..   Amount = \u001b[32mcol_double()\u001b[39m,\n",
      "  ..   Status = \u001b[31mcol_character()\u001b[39m\n",
      "  .. )\n",
      " - attr(*, \"problems\")=<externalptr> \n",
      "\u001b[90m# A tibble: 5 × 5\u001b[39m\n",
      "  LogID CustomerID Transaction_DateTime Amount Status   \n",
      "  \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m      \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                 \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m    \n",
      "\u001b[90m1\u001b[39m     1         26 4/5/24 14:30           277. Pending  \n",
      "\u001b[90m2\u001b[39m     2         21 3/15/24 14:30          175. Pending  \n",
      "\u001b[90m3\u001b[39m     3         12 3/15/24 14:30          252. Pending  \n",
      "\u001b[90m4\u001b[39m     4          6 3/20/24 9:15           215. Pending  \n",
      "\u001b[90m5\u001b[39m     5         32 3/20/24 9:15           269. Completed\n",
      "\n",
      "=== PRODUCT CATALOG DATA ===\n",
      "spc_tbl_ [75 × 5] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n",
      " $ ProductID          : num [1:75] 1 2 3 4 5 6 7 8 9 10 ...\n",
      " $ Product_Description: chr [1:75] \"Apple iPhone 14 Pro - 128GB - Space Black\" \"samsung galaxy s23 ultra 256gb\" \"Apple iPhone 14 Pro - 128GB - Space Black\" \"Apple iPhone 14 Pro - 128GB - Space Black\" ...\n",
      " $ Category           : chr [1:75] \"TV\" \"TV\" \"Audio\" \"Shoes\" ...\n",
      " $ Price              : num [1:75] 964 1817 853 649 586 ...\n",
      " $ In_Stock           : chr [1:75] \"Limited\" \"Yes\" \"Yes\" \"Yes\" ...\n",
      " - attr(*, \"spec\")=\n",
      "  .. cols(\n",
      "  ..   ProductID = \u001b[32mcol_double()\u001b[39m,\n",
      "  ..   Product_Description = \u001b[31mcol_character()\u001b[39m,\n",
      "  ..   Category = \u001b[31mcol_character()\u001b[39m,\n",
      "  ..   Price = \u001b[32mcol_double()\u001b[39m,\n",
      "  ..   In_Stock = \u001b[31mcol_character()\u001b[39m\n",
      "  .. )\n",
      " - attr(*, \"problems\")=<externalptr> \n",
      "\u001b[90m# A tibble: 5 × 5\u001b[39m\n",
      "  LogID CustomerID Transaction_DateTime Amount Status   \n",
      "  \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m      \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                 \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m    \n",
      "\u001b[90m1\u001b[39m     1         26 4/5/24 14:30           277. Pending  \n",
      "\u001b[90m2\u001b[39m     2         21 3/15/24 14:30          175. Pending  \n",
      "\u001b[90m3\u001b[39m     3         12 3/15/24 14:30          252. Pending  \n",
      "\u001b[90m4\u001b[39m     4          6 3/20/24 9:15           215. Pending  \n",
      "\u001b[90m5\u001b[39m     5         32 3/20/24 9:15           269. Completed\n",
      "\n",
      "=== PRODUCT CATALOG DATA ===\n",
      "spc_tbl_ [75 × 5] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n",
      " $ ProductID          : num [1:75] 1 2 3 4 5 6 7 8 9 10 ...\n",
      " $ Product_Description: chr [1:75] \"Apple iPhone 14 Pro - 128GB - Space Black\" \"samsung galaxy s23 ultra 256gb\" \"Apple iPhone 14 Pro - 128GB - Space Black\" \"Apple iPhone 14 Pro - 128GB - Space Black\" ...\n",
      " $ Category           : chr [1:75] \"TV\" \"TV\" \"Audio\" \"Shoes\" ...\n",
      " $ Price              : num [1:75] 964 1817 853 649 586 ...\n",
      " $ In_Stock           : chr [1:75] \"Limited\" \"Yes\" \"Yes\" \"Yes\" ...\n",
      " - attr(*, \"spec\")=\n",
      "  .. cols(\n",
      "  ..   ProductID = \u001b[32mcol_double()\u001b[39m,\n",
      "  ..   Product_Description = \u001b[31mcol_character()\u001b[39m,\n",
      "  ..   Category = \u001b[31mcol_character()\u001b[39m,\n",
      "  ..   Price = \u001b[32mcol_double()\u001b[39m,\n",
      "  ..   In_Stock = \u001b[31mcol_character()\u001b[39m\n",
      "  .. )\n",
      " - attr(*, \"problems\")=<externalptr> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90m# A tibble: 5 × 5\u001b[39m\n",
      "  ProductID Product_Description                       Category    Price In_Stock\n",
      "      \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                                     \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m       \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m   \n",
      "\u001b[90m1\u001b[39m         1 Apple iPhone 14 Pro - 128GB - Space Black TV           964. Limited \n",
      "\u001b[90m2\u001b[39m         2 samsung galaxy s23 ultra 256gb            TV          \u001b[4m1\u001b[24m817. Yes     \n",
      "\u001b[90m3\u001b[39m         3 Apple iPhone 14 Pro - 128GB - Space Black Audio        853. Yes     \n",
      "\u001b[90m4\u001b[39m         4 Apple iPhone 14 Pro - 128GB - Space Black Shoes        649. Yes     \n",
      "\u001b[90m5\u001b[39m         5 samsung galaxy s23 ultra 256gb            Electronics  586. Limited \n"
     ]
    }
   ],
   "source": [
    "# Task 1.3: Initial Data Exploration\n",
    "\n",
    "cat(\"=== CUSTOMER FEEDBACK DATA ===\\n\")\n",
    "# Display structure of feedback using str()\n",
    "str(feedback)\n",
    "\n",
    "# Display first 5 rows of feedback\n",
    "print(head(feedback, 5))\n",
    "\n",
    "cat(\"\\n=== TRANSACTION DATA ===\\n\")\n",
    "# Display structure of transactions\n",
    "str(transactions)\n",
    "\n",
    "# Display first 5 rows of transactions\n",
    "print(head(transactions, 5))\n",
    "\n",
    "cat(\"\\n=== PRODUCT CATALOG DATA ===\\n\")\n",
    "# Display structure of products\n",
    "str(products)\n",
    "\n",
    "# Display first 5 rows of products\n",
    "print(head(products, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part2_intro",
   "metadata": {},
   "source": [
    "## Part 2: String Cleaning and Standardization\n",
    "\n",
    "**Business Context:** Product names and feedback text often have inconsistent formatting that prevents accurate analysis.\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Clean product names (remove extra spaces, standardize case)\n",
    "2. Standardize product categories\n",
    "3. Clean customer feedback text\n",
    "4. Extract customer names from feedback\n",
    "\n",
    "**Key Functions:** `str_trim()`, `str_squish()`, `str_to_lower()`, `str_to_upper()`, `str_to_title()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "clean_products",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using product column: Product_Description \n",
      "Product Name Cleaning Results:\n",
      "Product Name Cleaning Results:\n",
      "\u001b[90m# A tibble: 10 × 2\u001b[39m\n",
      "   orig_name                                   product_name_clean               \n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                                       \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                            \n",
      "\u001b[90m 1\u001b[39m \u001b[90m\"\u001b[39mApple iPhone 14 Pro - 128GB - Space Black\u001b[90m\"\u001b[39m \u001b[90m\"\u001b[39mApple Iphone 14 Pro - 128gb - S…\n",
      "\u001b[90m 2\u001b[39m \u001b[90m\"\u001b[39msamsung galaxy s23 ultra 256gb\u001b[90m\"\u001b[39m            \u001b[90m\"\u001b[39mSamsung Galaxy S23 Ultra 256gb\u001b[90m\"\u001b[39m \n",
      "\u001b[90m 3\u001b[39m \u001b[90m\"\u001b[39mApple iPhone 14 Pro - 128GB - Space Black\u001b[90m\"\u001b[39m \u001b[90m\"\u001b[39mApple Iphone 14 Pro - 128gb - S…\n",
      "\u001b[90m 4\u001b[39m \u001b[90m\"\u001b[39mApple iPhone 14 Pro - 128GB - Space Black\u001b[90m\"\u001b[39m \u001b[90m\"\u001b[39mApple Iphone 14 Pro - 128gb - S…\n",
      "\u001b[90m 5\u001b[39m \u001b[90m\"\u001b[39msamsung galaxy s23 ultra 256gb\u001b[90m\"\u001b[39m            \u001b[90m\"\u001b[39mSamsung Galaxy S23 Ultra 256gb\u001b[90m\"\u001b[39m \n",
      "\u001b[90m 6\u001b[39m \u001b[90m\"\u001b[39mApple iPhone 14 Pro - 128GB - Space Black\u001b[90m\"\u001b[39m \u001b[90m\"\u001b[39mApple Iphone 14 Pro - 128gb - S…\n",
      "\u001b[90m 7\u001b[39m \u001b[90m\"\u001b[39mDELL XPS 13 Laptop - Intel i7 - 16GB RAM\u001b[90m\"\u001b[39m  \u001b[90m\"\u001b[39mDell Xps 13 Laptop - Intel I7 -…\n",
      "\u001b[90m 8\u001b[39m \u001b[90m\"\u001b[39mhp envy printer - wireless - color\u001b[90m\"\u001b[39m        \u001b[90m\"\u001b[39mHp Envy Printer - Wireless - Co…\n",
      "\u001b[90m 9\u001b[39m \u001b[90m\"\u001b[39mNike Air Max 270 - Size 10 - Black/White\u001b[90m\"\u001b[39m  \u001b[90m\"\u001b[39mNike Air Max 270 - Size 10 - Bl…\n",
      "\u001b[90m10\u001b[39m \u001b[90m\"\u001b[39mLG 55\\\" 4K Smart TV - OLED Display\u001b[90m\"\u001b[39m        \u001b[90m\"\u001b[39mLg 55\\\" 4k Smart Tv - Oled Disp…\n",
      "\u001b[90m# A tibble: 10 × 2\u001b[39m\n",
      "   orig_name                                   product_name_clean               \n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                                       \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                            \n",
      "\u001b[90m 1\u001b[39m \u001b[90m\"\u001b[39mApple iPhone 14 Pro - 128GB - Space Black\u001b[90m\"\u001b[39m \u001b[90m\"\u001b[39mApple Iphone 14 Pro - 128gb - S…\n",
      "\u001b[90m 2\u001b[39m \u001b[90m\"\u001b[39msamsung galaxy s23 ultra 256gb\u001b[90m\"\u001b[39m            \u001b[90m\"\u001b[39mSamsung Galaxy S23 Ultra 256gb\u001b[90m\"\u001b[39m \n",
      "\u001b[90m 3\u001b[39m \u001b[90m\"\u001b[39mApple iPhone 14 Pro - 128GB - Space Black\u001b[90m\"\u001b[39m \u001b[90m\"\u001b[39mApple Iphone 14 Pro - 128gb - S…\n",
      "\u001b[90m 4\u001b[39m \u001b[90m\"\u001b[39mApple iPhone 14 Pro - 128GB - Space Black\u001b[90m\"\u001b[39m \u001b[90m\"\u001b[39mApple Iphone 14 Pro - 128gb - S…\n",
      "\u001b[90m 5\u001b[39m \u001b[90m\"\u001b[39msamsung galaxy s23 ultra 256gb\u001b[90m\"\u001b[39m            \u001b[90m\"\u001b[39mSamsung Galaxy S23 Ultra 256gb\u001b[90m\"\u001b[39m \n",
      "\u001b[90m 6\u001b[39m \u001b[90m\"\u001b[39mApple iPhone 14 Pro - 128GB - Space Black\u001b[90m\"\u001b[39m \u001b[90m\"\u001b[39mApple Iphone 14 Pro - 128gb - S…\n",
      "\u001b[90m 7\u001b[39m \u001b[90m\"\u001b[39mDELL XPS 13 Laptop - Intel i7 - 16GB RAM\u001b[90m\"\u001b[39m  \u001b[90m\"\u001b[39mDell Xps 13 Laptop - Intel I7 -…\n",
      "\u001b[90m 8\u001b[39m \u001b[90m\"\u001b[39mhp envy printer - wireless - color\u001b[90m\"\u001b[39m        \u001b[90m\"\u001b[39mHp Envy Printer - Wireless - Co…\n",
      "\u001b[90m 9\u001b[39m \u001b[90m\"\u001b[39mNike Air Max 270 - Size 10 - Black/White\u001b[90m\"\u001b[39m  \u001b[90m\"\u001b[39mNike Air Max 270 - Size 10 - Bl…\n",
      "\u001b[90m10\u001b[39m \u001b[90m\"\u001b[39mLG 55\\\" 4K Smart TV - OLED Display\u001b[90m\"\u001b[39m        \u001b[90m\"\u001b[39mLg 55\\\" 4k Smart Tv - Oled Disp…\n",
      "\n",
      "=== Cleaning Statistics ===\n",
      "Total products cleaned: 75 \n",
      "Products with changes: 70 \n",
      "\n",
      "=== Cleaning Statistics ===\n",
      "Total products cleaned: 75 \n",
      "Products with changes: 70 \n",
      "\n",
      "=== Examples of Transformations ===\n",
      "\n",
      "=== Examples of Transformations ===\n",
      "\u001b[90m# A tibble: 10 × 2\u001b[39m\n",
      "   orig_name                                   product_name_clean               \n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                                       \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                            \n",
      "\u001b[90m 1\u001b[39m \u001b[90m\"\u001b[39mApple iPhone 14 Pro - 128GB - Space Black\u001b[90m\"\u001b[39m \u001b[90m\"\u001b[39mApple Iphone 14 Pro - 128gb - S…\n",
      "\u001b[90m 2\u001b[39m \u001b[90m\"\u001b[39msamsung galaxy s23 ultra 256gb\u001b[90m\"\u001b[39m            \u001b[90m\"\u001b[39mSamsung Galaxy S23 Ultra 256gb\u001b[90m\"\u001b[39m \n",
      "\u001b[90m 3\u001b[39m \u001b[90m\"\u001b[39mApple iPhone 14 Pro - 128GB - Space Black\u001b[90m\"\u001b[39m \u001b[90m\"\u001b[39mApple Iphone 14 Pro - 128gb - S…\n",
      "\u001b[90m 4\u001b[39m \u001b[90m\"\u001b[39mApple iPhone 14 Pro - 128GB - Space Black\u001b[90m\"\u001b[39m \u001b[90m\"\u001b[39mApple Iphone 14 Pro - 128gb - S…\n",
      "\u001b[90m 5\u001b[39m \u001b[90m\"\u001b[39msamsung galaxy s23 ultra 256gb\u001b[90m\"\u001b[39m            \u001b[90m\"\u001b[39mSamsung Galaxy S23 Ultra 256gb\u001b[90m\"\u001b[39m \n",
      "\u001b[90m 6\u001b[39m \u001b[90m\"\u001b[39mApple iPhone 14 Pro - 128GB - Space Black\u001b[90m\"\u001b[39m \u001b[90m\"\u001b[39mApple Iphone 14 Pro - 128gb - S…\n",
      "\u001b[90m 7\u001b[39m \u001b[90m\"\u001b[39mDELL XPS 13 Laptop - Intel i7 - 16GB RAM\u001b[90m\"\u001b[39m  \u001b[90m\"\u001b[39mDell Xps 13 Laptop - Intel I7 -…\n",
      "\u001b[90m 8\u001b[39m \u001b[90m\"\u001b[39mhp envy printer - wireless - color\u001b[90m\"\u001b[39m        \u001b[90m\"\u001b[39mHp Envy Printer - Wireless - Co…\n",
      "\u001b[90m 9\u001b[39m \u001b[90m\"\u001b[39mLG 55\\\" 4K Smart TV - OLED Display\u001b[90m\"\u001b[39m        \u001b[90m\"\u001b[39mLg 55\\\" 4k Smart Tv - Oled Disp…\n",
      "\u001b[90m10\u001b[39m \u001b[90m\"\u001b[39msony WH-1000XM4 wireless headphones\u001b[90m\"\u001b[39m       \u001b[90m\"\u001b[39mSony Wh-1000xm4 Wireless Headph…\n",
      "\u001b[90m# A tibble: 10 × 2\u001b[39m\n",
      "   orig_name                                   product_name_clean               \n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                                       \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                            \n",
      "\u001b[90m 1\u001b[39m \u001b[90m\"\u001b[39mApple iPhone 14 Pro - 128GB - Space Black\u001b[90m\"\u001b[39m \u001b[90m\"\u001b[39mApple Iphone 14 Pro - 128gb - S…\n",
      "\u001b[90m 2\u001b[39m \u001b[90m\"\u001b[39msamsung galaxy s23 ultra 256gb\u001b[90m\"\u001b[39m            \u001b[90m\"\u001b[39mSamsung Galaxy S23 Ultra 256gb\u001b[90m\"\u001b[39m \n",
      "\u001b[90m 3\u001b[39m \u001b[90m\"\u001b[39mApple iPhone 14 Pro - 128GB - Space Black\u001b[90m\"\u001b[39m \u001b[90m\"\u001b[39mApple Iphone 14 Pro - 128gb - S…\n",
      "\u001b[90m 4\u001b[39m \u001b[90m\"\u001b[39mApple iPhone 14 Pro - 128GB - Space Black\u001b[90m\"\u001b[39m \u001b[90m\"\u001b[39mApple Iphone 14 Pro - 128gb - S…\n",
      "\u001b[90m 5\u001b[39m \u001b[90m\"\u001b[39msamsung galaxy s23 ultra 256gb\u001b[90m\"\u001b[39m            \u001b[90m\"\u001b[39mSamsung Galaxy S23 Ultra 256gb\u001b[90m\"\u001b[39m \n",
      "\u001b[90m 6\u001b[39m \u001b[90m\"\u001b[39mApple iPhone 14 Pro - 128GB - Space Black\u001b[90m\"\u001b[39m \u001b[90m\"\u001b[39mApple Iphone 14 Pro - 128gb - S…\n",
      "\u001b[90m 7\u001b[39m \u001b[90m\"\u001b[39mDELL XPS 13 Laptop - Intel i7 - 16GB RAM\u001b[90m\"\u001b[39m  \u001b[90m\"\u001b[39mDell Xps 13 Laptop - Intel I7 -…\n",
      "\u001b[90m 8\u001b[39m \u001b[90m\"\u001b[39mhp envy printer - wireless - color\u001b[90m\"\u001b[39m        \u001b[90m\"\u001b[39mHp Envy Printer - Wireless - Co…\n",
      "\u001b[90m 9\u001b[39m \u001b[90m\"\u001b[39mLG 55\\\" 4K Smart TV - OLED Display\u001b[90m\"\u001b[39m        \u001b[90m\"\u001b[39mLg 55\\\" 4k Smart Tv - Oled Disp…\n",
      "\u001b[90m10\u001b[39m \u001b[90m\"\u001b[39msony WH-1000XM4 wireless headphones\u001b[90m\"\u001b[39m       \u001b[90m\"\u001b[39mSony Wh-1000xm4 Wireless Headph…\n"
     ]
    }
   ],
   "source": [
    "# Task 2.1: Clean Product Names\n",
    "\n",
    "library(dplyr)\n",
    "library(stringr)\n",
    "\n",
    "# Use the actual product description column from the dataset\n",
    "product_col <- \"Product_Description\"\n",
    "if (!product_col %in% colnames(products)) {\n",
    "  stop(\"Expected column 'Product_Description' not found. Columns: \", paste(colnames(products), collapse=\", \"))\n",
    "}\n",
    "cat(\"Using product column:\", product_col, \"\\n\")\n",
    "\n",
    "# Create cleaned column and keep original in a temp column for comparison\n",
    "products_clean <- products %>%\n",
    "  mutate(\n",
    "    product_name_clean = str_to_title(str_trim(.data[[product_col]])),\n",
    "    orig_name = .data[[product_col]]\n",
    "  )\n",
    "\n",
    "# Display before and after (show original description and cleaned name)\n",
    "cat(\"Product Name Cleaning Results:\\n\")\n",
    "products_clean %>%\n",
    "  select(orig_name, product_name_clean) %>%\n",
    "  head(10) %>%\n",
    "  print()\n",
    "\n",
    "# Additional cleaning statistics\n",
    "cat(\"\\n=== Cleaning Statistics ===\\n\")\n",
    "cat(\"Total products cleaned:\", nrow(products_clean), \"\\n\")\n",
    "cat(\"Products with changes:\", sum(products_clean$orig_name != products_clean$product_name_clean, na.rm = TRUE), \"\\n\")\n",
    "\n",
    "# Show examples of transformations\n",
    "cat(\"\\n=== Examples of Transformations ===\\n\")\n",
    "differences <- products_clean %>%\n",
    "  filter(orig_name != product_name_clean) %>%\n",
    "  select(orig_name, product_name_clean) %>%\n",
    "  head(10)\n",
    "print(differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "clean_categories",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product dataset columns:\n",
      "[1] \"ProductID\"           \"Product_Description\" \"Category\"           \n",
      "[4] \"Price\"               \"In_Stock\"            \"product_name_clean\" \n",
      "[7] \"orig_name\"          \n",
      "Using 'Category' column for cleaning (adjust if different)\n",
      "Original categories:\n",
      "[1] \"ProductID\"           \"Product_Description\" \"Category\"           \n",
      "[4] \"Price\"               \"In_Stock\"            \"product_name_clean\" \n",
      "[7] \"orig_name\"          \n",
      "Using 'Category' column for cleaning (adjust if different)\n",
      "Original categories:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“Unknown or uninitialised column: `category`.”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NULL\n",
      "\n",
      "Cleaned categories:\n",
      "[1] \"Tv\"          \"Audio\"       \"Shoes\"       \"Electronics\" \"Computers\"  \n",
      "\n",
      "Cleaned categories:\n",
      "[1] \"Tv\"          \"Audio\"       \"Shoes\"       \"Electronics\" \"Computers\"  \n"
     ]
    }
   ],
   "source": [
    "# Task 2.2: Standardize Product Categories\n",
    "# TODO: Create a new column 'category_clean' that:\n",
    "#   - Converts category to Title Case\n",
    "#   - Removes any extra whitespace\n",
    "\n",
    "library(stringr)\n",
    "# Detect category column (common names)\n",
    "cat(\"Product dataset columns:\\n\")\n",
    "print(colnames(products_clean))\n",
    "\n",
    "cat(\"Using 'Category' column for cleaning (adjust if different)\\n\")\n",
    "# Create category_clean by trimming and title-casing the 'Category' column\n",
    "products_clean <- products_clean %>%\n",
    "  mutate(\n",
    "    category_clean = str_to_title(str_trim(Category))\n",
    "  )\n",
    "\n",
    "# Show unique categories before and after\n",
    "cat(\"Original categories:\\n\")\n",
    "print(unique(products$category))\n",
    "\n",
    "cat(\"\\nCleaned categories:\\n\")\n",
    "print(unique(products_clean$category_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "clean_feedback",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using feedback column: Feedback_Text\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90m# A tibble: 10 × 4\u001b[39m\n",
      "   FeedbackID CustomerID Feedback_Text                    feedback_clean        \n",
      "        \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m      \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                            \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                 \n",
      "\u001b[90m 1\u001b[39m          1         12 Highly recommend this item       highly recommend this…\n",
      "\u001b[90m 2\u001b[39m          2         40 Excellent service                excellent service     \n",
      "\u001b[90m 3\u001b[39m          3         34 Poor quality control             poor quality control  \n",
      "\u001b[90m 4\u001b[39m          4          1 average product, nothing special average product, noth…\n",
      "\u001b[90m 5\u001b[39m          5         47 AMAZING customer support!!!      amazing customer supp…\n",
      "\u001b[90m 6\u001b[39m          6         13 AMAZING customer support!!!      amazing customer supp…\n",
      "\u001b[90m 7\u001b[39m          7         13 average product, nothing special average product, noth…\n",
      "\u001b[90m 8\u001b[39m          8         37 good VALUE for money             good value for money  \n",
      "\u001b[90m 9\u001b[39m          9         49 Highly recommend this item       highly recommend this…\n",
      "\u001b[90m10\u001b[39m         10         23 Highly recommend this item       highly recommend this…\n"
     ]
    }
   ],
   "source": [
    "# Task 2.3: Clean Customer Feedback Text\n",
    "# Detect common feedback column names, handle NAs, lowercase + squish\n",
    "feedback_col <- intersect(c(\"feedback_text\", \"Feedback_Text\", \"feedback\", \"Feedback\"), colnames(feedback))\n",
    "if (length(feedback_col) == 0) stop(\"Expected column 'feedback_text' not found. Columns: \", paste(colnames(feedback), collapse = \", \"))\n",
    "feedback_col <- feedback_col[1]\n",
    "message(\"Using feedback column: \", feedback_col)\n",
    "\n",
    "feedback_clean <- feedback %>%\n",
    "  mutate(\n",
    "    feedback_clean = coalesce(as.character(.data[[feedback_col]]), \"\") %>%\n",
    "      str_to_lower() %>%\n",
    "      str_squish()\n",
    "  ) %>%\n",
    "  select(FeedbackID, CustomerID, all_of(feedback_col), feedback_clean) %>%\n",
    "  head(10)\n",
    "\n",
    "print(feedback_clean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part3_intro",
   "metadata": {},
   "source": [
    "## Part 3: Pattern Detection and Extraction\n",
    "\n",
    "**Business Context:** Identifying products with specific features and extracting specifications helps with inventory management and marketing.\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Identify products with specific keywords (wireless, premium, gaming)\n",
    "2. Extract numerical specifications from product names\n",
    "3. Detect sentiment words in customer feedback\n",
    "4. Extract email addresses from feedback\n",
    "\n",
    "**Key Functions:** `str_detect()`, `str_extract()`, `str_count()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "detect_features",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product Feature Detection:\n",
      "\u001b[90m# A tibble: 10 × 4\u001b[39m\n",
      "   product_name_clean                          is_wireless is_premium is_gaming\n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                                       \u001b[3m\u001b[90m<lgl>\u001b[39m\u001b[23m       \u001b[3m\u001b[90m<lgl>\u001b[39m\u001b[23m      \u001b[3m\u001b[90m<lgl>\u001b[39m\u001b[23m    \n",
      "\u001b[90m 1\u001b[39m \u001b[90m\"\u001b[39mApple Iphone 14 Pro - 128gb - Space Black\u001b[90m\"\u001b[39m FALSE       FALSE      FALSE    \n",
      "\u001b[90m 2\u001b[39m \u001b[90m\"\u001b[39mSamsung Galaxy S23 Ultra 256gb\u001b[90m\"\u001b[39m            FALSE       FALSE      FALSE    \n",
      "\u001b[90m 3\u001b[39m \u001b[90m\"\u001b[39mApple Iphone 14 Pro - 128gb - Space Black\u001b[90m\"\u001b[39m FALSE       FALSE      FALSE    \n",
      "\u001b[90m 4\u001b[39m \u001b[90m\"\u001b[39mApple Iphone 14 Pro - 128gb - Space Black\u001b[90m\"\u001b[39m FALSE       FALSE      FALSE    \n",
      "\u001b[90m 5\u001b[39m \u001b[90m\"\u001b[39mSamsung Galaxy S23 Ultra 256gb\u001b[90m\"\u001b[39m            FALSE       FALSE      FALSE    \n",
      "\u001b[90m 6\u001b[39m \u001b[90m\"\u001b[39mApple Iphone 14 Pro - 128gb - Space Black\u001b[90m\"\u001b[39m FALSE       FALSE      FALSE    \n",
      "\u001b[90m 7\u001b[39m \u001b[90m\"\u001b[39mDell Xps 13 Laptop - Intel I7 - 16gb Ram\u001b[90m\"\u001b[39m  FALSE       FALSE      FALSE    \n",
      "\u001b[90m 8\u001b[39m \u001b[90m\"\u001b[39mHp Envy Printer - Wireless - Color\u001b[90m\"\u001b[39m        TRUE        FALSE      FALSE    \n",
      "\u001b[90m 9\u001b[39m \u001b[90m\"\u001b[39mNike Air Max 270 - Size 10 - Black/White\u001b[90m\"\u001b[39m  FALSE       FALSE      FALSE    \n",
      "\u001b[90m10\u001b[39m \u001b[90m\"\u001b[39mLg 55\\\" 4k Smart Tv - Oled Display\u001b[90m\"\u001b[39m        FALSE       FALSE      FALSE    \n",
      "\n",
      "Feature Summary:\n",
      "Wireless products: 17 \n",
      "Premium products: 0 \n",
      "Gaming products: 0 \n",
      "\u001b[90m# A tibble: 10 × 4\u001b[39m\n",
      "   product_name_clean                          is_wireless is_premium is_gaming\n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                                       \u001b[3m\u001b[90m<lgl>\u001b[39m\u001b[23m       \u001b[3m\u001b[90m<lgl>\u001b[39m\u001b[23m      \u001b[3m\u001b[90m<lgl>\u001b[39m\u001b[23m    \n",
      "\u001b[90m 1\u001b[39m \u001b[90m\"\u001b[39mApple Iphone 14 Pro - 128gb - Space Black\u001b[90m\"\u001b[39m FALSE       FALSE      FALSE    \n",
      "\u001b[90m 2\u001b[39m \u001b[90m\"\u001b[39mSamsung Galaxy S23 Ultra 256gb\u001b[90m\"\u001b[39m            FALSE       FALSE      FALSE    \n",
      "\u001b[90m 3\u001b[39m \u001b[90m\"\u001b[39mApple Iphone 14 Pro - 128gb - Space Black\u001b[90m\"\u001b[39m FALSE       FALSE      FALSE    \n",
      "\u001b[90m 4\u001b[39m \u001b[90m\"\u001b[39mApple Iphone 14 Pro - 128gb - Space Black\u001b[90m\"\u001b[39m FALSE       FALSE      FALSE    \n",
      "\u001b[90m 5\u001b[39m \u001b[90m\"\u001b[39mSamsung Galaxy S23 Ultra 256gb\u001b[90m\"\u001b[39m            FALSE       FALSE      FALSE    \n",
      "\u001b[90m 6\u001b[39m \u001b[90m\"\u001b[39mApple Iphone 14 Pro - 128gb - Space Black\u001b[90m\"\u001b[39m FALSE       FALSE      FALSE    \n",
      "\u001b[90m 7\u001b[39m \u001b[90m\"\u001b[39mDell Xps 13 Laptop - Intel I7 - 16gb Ram\u001b[90m\"\u001b[39m  FALSE       FALSE      FALSE    \n",
      "\u001b[90m 8\u001b[39m \u001b[90m\"\u001b[39mHp Envy Printer - Wireless - Color\u001b[90m\"\u001b[39m        TRUE        FALSE      FALSE    \n",
      "\u001b[90m 9\u001b[39m \u001b[90m\"\u001b[39mNike Air Max 270 - Size 10 - Black/White\u001b[90m\"\u001b[39m  FALSE       FALSE      FALSE    \n",
      "\u001b[90m10\u001b[39m \u001b[90m\"\u001b[39mLg 55\\\" 4k Smart Tv - Oled Display\u001b[90m\"\u001b[39m        FALSE       FALSE      FALSE    \n",
      "\n",
      "Feature Summary:\n",
      "Wireless products: 17 \n",
      "Premium products: 0 \n",
      "Gaming products: 0 \n"
     ]
    }
   ],
   "source": [
    "# Task 3.1: Detect Product Features\n",
    "# Create three new columns:\n",
    "#   - is_wireless: TRUE if product name contains \"wireless\" (case-insensitive)\n",
    "#   - is_premium: TRUE if product name contains \"pro\", \"premium\", or \"deluxe\"\n",
    "#   - is_gaming: TRUE if product name contains \"gaming\" or \"gamer\"\n",
    "# Use str_detect() with str_to_lower() for case-insensitive matching\n",
    "\n",
    "products_clean <- products_clean %>%\n",
    "  mutate(\n",
    "    # ensure product_name_clean is character and not NA\n",
    "    product_name_clean = coalesce(as.character(product_name_clean), \"\"),\n",
    "    is_wireless = str_detect(str_to_lower(product_name_clean), \"wireless\"),\n",
    "    is_premium = str_detect(str_to_lower(product_name_clean), \"\\b(pro|premium|deluxe)\\b\"),\n",
    "    is_gaming = str_detect(str_to_lower(product_name_clean), \"\\b(gaming|gamer)\\b\")\n",
    "  )\n",
    "\n",
    "# Display results\n",
    "cat(\"Product Feature Detection:\\n\")\n",
    "products_clean %>%\n",
    "  select(product_name_clean, is_wireless, is_premium, is_gaming) %>%\n",
    "  head(10) %>%\n",
    "  print()\n",
    "\n",
    "# Summary statistics\n",
    "cat(\"\\nFeature Summary:\\n\")\n",
    "cat(\"Wireless products:\", sum(products_clean$is_wireless, na.rm = TRUE), \"\\n\")\n",
    "cat(\"Premium products:\", sum(products_clean$is_premium, na.rm = TRUE), \"\\n\")\n",
    "cat(\"Gaming products:\", sum(products_clean$is_gaming, na.rm = TRUE), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "extract_specs",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Product Specifications:\n",
      "\u001b[90m# A tibble: 10 × 2\u001b[39m\n",
      "   product_name_clean                          size_number\n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                                             \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m \u001b[90m\"\u001b[39mApple Iphone 14 Pro - 128gb - Space Black\u001b[90m\"\u001b[39m          14\n",
      "\u001b[90m 2\u001b[39m \u001b[90m\"\u001b[39mSamsung Galaxy S23 Ultra 256gb\u001b[90m\"\u001b[39m                     23\n",
      "\u001b[90m 3\u001b[39m \u001b[90m\"\u001b[39mApple Iphone 14 Pro - 128gb - Space Black\u001b[90m\"\u001b[39m          14\n",
      "\u001b[90m 4\u001b[39m \u001b[90m\"\u001b[39mApple Iphone 14 Pro - 128gb - Space Black\u001b[90m\"\u001b[39m          14\n",
      "\u001b[90m 5\u001b[39m \u001b[90m\"\u001b[39mSamsung Galaxy S23 Ultra 256gb\u001b[90m\"\u001b[39m                     23\n",
      "\u001b[90m 6\u001b[39m \u001b[90m\"\u001b[39mApple Iphone 14 Pro - 128gb - Space Black\u001b[90m\"\u001b[39m          14\n",
      "\u001b[90m 7\u001b[39m \u001b[90m\"\u001b[39mDell Xps 13 Laptop - Intel I7 - 16gb Ram\u001b[90m\"\u001b[39m           13\n",
      "\u001b[90m 8\u001b[39m \u001b[90m\"\u001b[39mNike Air Max 270 - Size 10 - Black/White\u001b[90m\"\u001b[39m          270\n",
      "\u001b[90m 9\u001b[39m \u001b[90m\"\u001b[39mLg 55\\\" 4k Smart Tv - Oled Display\u001b[90m\"\u001b[39m                 55\n",
      "\u001b[90m10\u001b[39m \u001b[90m\"\u001b[39mSony Wh-1000xm4 Wireless Headphones\u001b[90m\"\u001b[39m              \u001b[4m1\u001b[24m000\n",
      "\u001b[90m# A tibble: 10 × 2\u001b[39m\n",
      "   product_name_clean                          size_number\n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                                             \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m \u001b[90m\"\u001b[39mApple Iphone 14 Pro - 128gb - Space Black\u001b[90m\"\u001b[39m          14\n",
      "\u001b[90m 2\u001b[39m \u001b[90m\"\u001b[39mSamsung Galaxy S23 Ultra 256gb\u001b[90m\"\u001b[39m                     23\n",
      "\u001b[90m 3\u001b[39m \u001b[90m\"\u001b[39mApple Iphone 14 Pro - 128gb - Space Black\u001b[90m\"\u001b[39m          14\n",
      "\u001b[90m 4\u001b[39m \u001b[90m\"\u001b[39mApple Iphone 14 Pro - 128gb - Space Black\u001b[90m\"\u001b[39m          14\n",
      "\u001b[90m 5\u001b[39m \u001b[90m\"\u001b[39mSamsung Galaxy S23 Ultra 256gb\u001b[90m\"\u001b[39m                     23\n",
      "\u001b[90m 6\u001b[39m \u001b[90m\"\u001b[39mApple Iphone 14 Pro - 128gb - Space Black\u001b[90m\"\u001b[39m          14\n",
      "\u001b[90m 7\u001b[39m \u001b[90m\"\u001b[39mDell Xps 13 Laptop - Intel I7 - 16gb Ram\u001b[90m\"\u001b[39m           13\n",
      "\u001b[90m 8\u001b[39m \u001b[90m\"\u001b[39mNike Air Max 270 - Size 10 - Black/White\u001b[90m\"\u001b[39m          270\n",
      "\u001b[90m 9\u001b[39m \u001b[90m\"\u001b[39mLg 55\\\" 4k Smart Tv - Oled Display\u001b[90m\"\u001b[39m                 55\n",
      "\u001b[90m10\u001b[39m \u001b[90m\"\u001b[39mSony Wh-1000xm4 Wireless Headphones\u001b[90m\"\u001b[39m              \u001b[4m1\u001b[24m000\n"
     ]
    }
   ],
   "source": [
    "# Task 3.2: Extract Product Specifications\n",
    "# Create a new column 'size_number' that extracts the first number from product_name\n",
    "# Use str_extract() with pattern \"\\\\d+\" to match one or more digits\n",
    "\n",
    "products_clean <- products_clean %>%\n",
    "  mutate(\n",
    "    # ensure product_name_clean is character\n",
    "    product_name_clean = coalesce(as.character(product_name_clean), \"\"),\n",
    "    size_text = str_extract(product_name_clean, \"\\\\d+\"),\n",
    "    size_number = as.numeric(size_text)\n",
    "  ) %>%\n",
    "  # remove helper column 'size_text' to keep workspace clean\n",
    "  select(-size_text)\n",
    "\n",
    "# Display products with extracted sizes\n",
    "cat(\"Extracted Product Specifications:\\n\")\n",
    "products_clean %>%\n",
    "  filter(!is.na(size_number)) %>%\n",
    "  select(product_name_clean, size_number) %>%\n",
    "  head(10) %>%\n",
    "  print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "sentiment_analysis",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Analysis Results:\n",
      "\u001b[90m# A tibble: 10 × 4\u001b[39m\n",
      "   feedback_clean                  positive_words negative_words sentiment_score\n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                                    \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m          \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m           \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m highly recommend this item                   0              0               0\n",
      "\u001b[90m 2\u001b[39m excellent service                            1              0               1\n",
      "\u001b[90m 3\u001b[39m poor quality control                         0              0               0\n",
      "\u001b[90m 4\u001b[39m average product, nothing speci…              0              0               0\n",
      "\u001b[90m 5\u001b[39m amazing customer support!!!                  1              0               1\n",
      "\u001b[90m 6\u001b[39m amazing customer support!!!                  1              0               1\n",
      "\u001b[90m 7\u001b[39m average product, nothing speci…              0              0               0\n",
      "\u001b[90m 8\u001b[39m good value for money                         0              0               0\n",
      "\u001b[90m 9\u001b[39m highly recommend this item                   0              0               0\n",
      "\u001b[90m10\u001b[39m highly recommend this item                   0              0               0\n",
      "\n",
      "Overall Sentiment Summary:\n",
      "Average sentiment score: 0.3 \n",
      "\u001b[90m# A tibble: 10 × 4\u001b[39m\n",
      "   feedback_clean                  positive_words negative_words sentiment_score\n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                                    \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m          \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m           \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m highly recommend this item                   0              0               0\n",
      "\u001b[90m 2\u001b[39m excellent service                            1              0               1\n",
      "\u001b[90m 3\u001b[39m poor quality control                         0              0               0\n",
      "\u001b[90m 4\u001b[39m average product, nothing speci…              0              0               0\n",
      "\u001b[90m 5\u001b[39m amazing customer support!!!                  1              0               1\n",
      "\u001b[90m 6\u001b[39m amazing customer support!!!                  1              0               1\n",
      "\u001b[90m 7\u001b[39m average product, nothing speci…              0              0               0\n",
      "\u001b[90m 8\u001b[39m good value for money                         0              0               0\n",
      "\u001b[90m 9\u001b[39m highly recommend this item                   0              0               0\n",
      "\u001b[90m10\u001b[39m highly recommend this item                   0              0               0\n",
      "\n",
      "Overall Sentiment Summary:\n",
      "Average sentiment score: 0.3 \n",
      "Positive reviews: 3 \n",
      "Negative reviews: 0 \n",
      "Positive reviews: 3 \n",
      "Negative reviews: 0 \n"
     ]
    }
   ],
   "source": [
    "# Task 3.3: Simple Sentiment Analysis\n",
    "# Create three new columns:\n",
    "#   - positive_words: count of positive words (\"great\", \"excellent\", \"love\", \"amazing\")\n",
    "#   - negative_words: count of negative words (\"bad\", \"terrible\", \"hate\", \"awful\")\n",
    "#   - sentiment_score: positive_words - negative_words\n",
    "# Use str_count() to count pattern occurrences\n",
    "\n",
    "# Define regex patterns (word boundaries for exact words)\n",
    "pos_pattern <- \"\\\\b(great|excellent|love|amazing)\\\\b\"\n",
    "neg_pattern <- \"\\\\b(bad|terrible|hate|awful)\\\\b\"\n",
    "\n",
    "feedback_clean <- feedback_clean %>%\n",
    "  mutate(\n",
    "    # ensure feedback_clean is character\n",
    "    feedback_clean = coalesce(as.character(feedback_clean), \"\"),\n",
    "    positive_words = str_count(feedback_clean, regex(pos_pattern, ignore_case = TRUE)),\n",
    "    negative_words = str_count(feedback_clean, regex(neg_pattern, ignore_case = TRUE)),\n",
    "    sentiment_score = positive_words - negative_words\n",
    "  )\n",
    "\n",
    "# Display sentiment analysis results\n",
    "cat(\"Sentiment Analysis Results:\\n\")\n",
    "feedback_clean %>%\n",
    "  select(feedback_clean, positive_words, negative_words, sentiment_score) %>%\n",
    "  head(10) %>%\n",
    "  print()\n",
    "\n",
    "# Summary\n",
    "cat(\"\\nOverall Sentiment Summary:\\n\")\n",
    "cat(\"Average sentiment score:\", mean(feedback_clean$sentiment_score, na.rm = TRUE), \"\\n\")\n",
    "cat(\"Positive reviews:\", sum(feedback_clean$sentiment_score > 0, na.rm = TRUE), \"\\n\")\n",
    "cat(\"Negative reviews:\", sum(feedback_clean$sentiment_score < 0, na.rm = TRUE), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part4_intro",
   "metadata": {},
   "source": [
    "## Part 4: Date Parsing and Component Extraction\n",
    "\n",
    "**Business Context:** Transaction dates need to be parsed and analyzed to understand customer behavior patterns.\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Parse transaction dates from text to Date objects\n",
    "2. Extract date components (year, month, day, weekday)\n",
    "3. Identify weekend vs weekday transactions\n",
    "4. Extract quarter and month names\n",
    "\n",
    "**Key Functions:** `ymd()`, `mdy()`, `dmy()`, `year()`, `month()`, `day()`, `wday()`, `quarter()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "parse_dates",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns in transactions:\n",
      "[1] \"LogID\"                \"CustomerID\"           \"Transaction_DateTime\"\n",
      "[4] \"Amount\"               \"Status\"              \n",
      "No standard transaction date column found. Using first column as date column: LogID \n",
      "\n",
      "[1] \"LogID\"                \"CustomerID\"           \"Transaction_DateTime\"\n",
      "[4] \"Amount\"               \"Status\"              \n",
      "No standard transaction date column found. Using first column as date column: LogID \n",
      "\n",
      "Date Parsing Results:\n",
      "Total rows: 150 \n",
      "Parsed (non-NA) rows: 0 \n",
      "Missing parsed dates: 150 \n",
      "Date Parsing Results:\n",
      "Total rows: 150 \n",
      "Parsed (non-NA) rows: 0 \n",
      "Missing parsed dates: 150 \n",
      "\u001b[90m# A tibble: 10 × 2\u001b[39m\n",
      "   original_date date_parsed\n",
      "           \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<date>\u001b[39m\u001b[23m     \n",
      "\u001b[90m 1\u001b[39m             1 \u001b[31mNA\u001b[39m         \n",
      "\u001b[90m 2\u001b[39m             2 \u001b[31mNA\u001b[39m         \n",
      "\u001b[90m 3\u001b[39m             3 \u001b[31mNA\u001b[39m         \n",
      "\u001b[90m 4\u001b[39m             4 \u001b[31mNA\u001b[39m         \n",
      "\u001b[90m 5\u001b[39m             5 \u001b[31mNA\u001b[39m         \n",
      "\u001b[90m 6\u001b[39m             6 \u001b[31mNA\u001b[39m         \n",
      "\u001b[90m 7\u001b[39m             7 \u001b[31mNA\u001b[39m         \n",
      "\u001b[90m 8\u001b[39m             8 \u001b[31mNA\u001b[39m         \n",
      "\u001b[90m 9\u001b[39m             9 \u001b[31mNA\u001b[39m         \n",
      "\u001b[90m10\u001b[39m            10 \u001b[31mNA\u001b[39m         \n",
      "\u001b[90m# A tibble: 10 × 2\u001b[39m\n",
      "   original_date date_parsed\n",
      "           \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<date>\u001b[39m\u001b[23m     \n",
      "\u001b[90m 1\u001b[39m             1 \u001b[31mNA\u001b[39m         \n",
      "\u001b[90m 2\u001b[39m             2 \u001b[31mNA\u001b[39m         \n",
      "\u001b[90m 3\u001b[39m             3 \u001b[31mNA\u001b[39m         \n",
      "\u001b[90m 4\u001b[39m             4 \u001b[31mNA\u001b[39m         \n",
      "\u001b[90m 5\u001b[39m             5 \u001b[31mNA\u001b[39m         \n",
      "\u001b[90m 6\u001b[39m             6 \u001b[31mNA\u001b[39m         \n",
      "\u001b[90m 7\u001b[39m             7 \u001b[31mNA\u001b[39m         \n",
      "\u001b[90m 8\u001b[39m             8 \u001b[31mNA\u001b[39m         \n",
      "\u001b[90m 9\u001b[39m             9 \u001b[31mNA\u001b[39m         \n",
      "\u001b[90m10\u001b[39m            10 \u001b[31mNA\u001b[39m         \n"
     ]
    }
   ],
   "source": [
    "# Task 4.1: Parse Transaction Dates\n",
    "# Create a new column 'date_parsed' that parses the transaction_date column\n",
    "# Try ymd(), then mdy(), then dmy() to handle common formats\n",
    "\n",
    "library(dplyr)\n",
    "library(lubridate)\n",
    "\n",
    "# Print available columns for debugging\n",
    "cat(\"Available columns in transactions:\\n\")\n",
    "print(colnames(transactions))\n",
    "\n",
    "# Use the first column as the date column if no match is found\n",
    "possible_date_cols <- c(\"transaction_date\", \"TransactionDate\", \"trans_date\", \"Transaction_Date\", \"date\", \"Date\", \"TransactionDateTime\")\n",
    "date_col <- intersect(possible_date_cols, colnames(transactions))\n",
    "if (length(date_col) == 0) {\n",
    "  date_col <- colnames(transactions)[1]\n",
    "  cat(\"No standard transaction date column found. Using first column as date column:\", date_col, \"\\n\\n\")\n",
    "} else {\n",
    "  date_col <- date_col[1]\n",
    "  cat(\"Using transaction date column:\", date_col, \"\\n\\n\")\n",
    "}\n",
    "\n",
    "transactions_clean <- transactions %>%\n",
    "  mutate(\n",
    "    transaction_date_text = coalesce(as.character(.data[[date_col]]), \"\"),\n",
    "    date_parsed_ymd = suppressWarnings(ymd(transaction_date_text)),\n",
    "    date_parsed_mdy = suppressWarnings(mdy(transaction_date_text)),\n",
    "    date_parsed_dmy = suppressWarnings(dmy(transaction_date_text)),\n",
    "    # choose the first non-NA parsed date\n",
    "    date_parsed = coalesce(date_parsed_ymd, date_parsed_mdy, date_parsed_dmy)\n",
    "  ) %>%\n",
    "  select(-date_parsed_ymd, -date_parsed_mdy, -date_parsed_dmy)\n",
    "\n",
    "# Diagnostics\n",
    "cat(\"Date Parsing Results:\\n\")\n",
    "cat(\"Total rows:\", nrow(transactions_clean), \"\\n\")\n",
    "cat(\"Parsed (non-NA) rows:\", sum(!is.na(transactions_clean$date_parsed)), \"\\n\")\n",
    "cat(\"Missing parsed dates:\", sum(is.na(transactions_clean$date_parsed)), \"\\n\")\n",
    "\n",
    "# Show sample rows\n",
    "transactions_clean %>%\n",
    "  select(original_date = all_of(date_col), date_parsed) %>%\n",
    "  head(10) %>%\n",
    "  print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "extract_components",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date Component Extraction:\n",
      "\u001b[90m# A tibble: 10 × 4\u001b[39m\n",
      "   date_parsed trans_month_name trans_weekday trans_quarter\n",
      "   \u001b[3m\u001b[90m<date>\u001b[39m\u001b[23m      \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m            \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                 \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m \u001b[31mNA\u001b[39m          \u001b[31mNA\u001b[39m               \u001b[31mNA\u001b[39m                       \u001b[31mNA\u001b[39m\n",
      "\u001b[90m 2\u001b[39m \u001b[31mNA\u001b[39m          \u001b[31mNA\u001b[39m               \u001b[31mNA\u001b[39m                       \u001b[31mNA\u001b[39m\n",
      "\u001b[90m 3\u001b[39m \u001b[31mNA\u001b[39m          \u001b[31mNA\u001b[39m               \u001b[31mNA\u001b[39m                       \u001b[31mNA\u001b[39m\n",
      "\u001b[90m 4\u001b[39m \u001b[31mNA\u001b[39m          \u001b[31mNA\u001b[39m               \u001b[31mNA\u001b[39m                       \u001b[31mNA\u001b[39m\n",
      "\u001b[90m 5\u001b[39m \u001b[31mNA\u001b[39m          \u001b[31mNA\u001b[39m               \u001b[31mNA\u001b[39m                       \u001b[31mNA\u001b[39m\n",
      "\u001b[90m 6\u001b[39m \u001b[31mNA\u001b[39m          \u001b[31mNA\u001b[39m               \u001b[31mNA\u001b[39m                       \u001b[31mNA\u001b[39m\n",
      "\u001b[90m 7\u001b[39m \u001b[31mNA\u001b[39m          \u001b[31mNA\u001b[39m               \u001b[31mNA\u001b[39m                       \u001b[31mNA\u001b[39m\n",
      "\u001b[90m 8\u001b[39m \u001b[31mNA\u001b[39m          \u001b[31mNA\u001b[39m               \u001b[31mNA\u001b[39m                       \u001b[31mNA\u001b[39m\n",
      "\u001b[90m 9\u001b[39m \u001b[31mNA\u001b[39m          \u001b[31mNA\u001b[39m               \u001b[31mNA\u001b[39m                       \u001b[31mNA\u001b[39m\n",
      "\u001b[90m10\u001b[39m \u001b[31mNA\u001b[39m          \u001b[31mNA\u001b[39m               \u001b[31mNA\u001b[39m                       \u001b[31mNA\u001b[39m\n",
      "\u001b[90m# A tibble: 10 × 4\u001b[39m\n",
      "   date_parsed trans_month_name trans_weekday trans_quarter\n",
      "   \u001b[3m\u001b[90m<date>\u001b[39m\u001b[23m      \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m            \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                 \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m \u001b[31mNA\u001b[39m          \u001b[31mNA\u001b[39m               \u001b[31mNA\u001b[39m                       \u001b[31mNA\u001b[39m\n",
      "\u001b[90m 2\u001b[39m \u001b[31mNA\u001b[39m          \u001b[31mNA\u001b[39m               \u001b[31mNA\u001b[39m                       \u001b[31mNA\u001b[39m\n",
      "\u001b[90m 3\u001b[39m \u001b[31mNA\u001b[39m          \u001b[31mNA\u001b[39m               \u001b[31mNA\u001b[39m                       \u001b[31mNA\u001b[39m\n",
      "\u001b[90m 4\u001b[39m \u001b[31mNA\u001b[39m          \u001b[31mNA\u001b[39m               \u001b[31mNA\u001b[39m                       \u001b[31mNA\u001b[39m\n",
      "\u001b[90m 5\u001b[39m \u001b[31mNA\u001b[39m          \u001b[31mNA\u001b[39m               \u001b[31mNA\u001b[39m                       \u001b[31mNA\u001b[39m\n",
      "\u001b[90m 6\u001b[39m \u001b[31mNA\u001b[39m          \u001b[31mNA\u001b[39m               \u001b[31mNA\u001b[39m                       \u001b[31mNA\u001b[39m\n",
      "\u001b[90m 7\u001b[39m \u001b[31mNA\u001b[39m          \u001b[31mNA\u001b[39m               \u001b[31mNA\u001b[39m                       \u001b[31mNA\u001b[39m\n",
      "\u001b[90m 8\u001b[39m \u001b[31mNA\u001b[39m          \u001b[31mNA\u001b[39m               \u001b[31mNA\u001b[39m                       \u001b[31mNA\u001b[39m\n",
      "\u001b[90m 9\u001b[39m \u001b[31mNA\u001b[39m          \u001b[31mNA\u001b[39m               \u001b[31mNA\u001b[39m                       \u001b[31mNA\u001b[39m\n",
      "\u001b[90m10\u001b[39m \u001b[31mNA\u001b[39m          \u001b[31mNA\u001b[39m               \u001b[31mNA\u001b[39m                       \u001b[31mNA\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "# Task 4.2: Extract Date Components\n",
    "# Create the following new columns:\n",
    "#   - trans_year: Extract year from date_parsed\n",
    "#   - trans_month: Extract month number from date_parsed\n",
    "#   - trans_month_name: Extract month name (use label=TRUE, abbr=FALSE)\n",
    "#   - trans_day: Extract day of month from date_parsed\n",
    "#   - trans_weekday: Extract weekday name (use label=TRUE, abbr=FALSE)\n",
    "#   - trans_quarter: Extract quarter from date_parsed\n",
    "\n",
    "transactions_clean <- transactions_clean %>%\n",
    "  mutate(\n",
    "    trans_year = if_else(!is.na(date_parsed), year(date_parsed), NA_integer_),\n",
    "    trans_month = if_else(!is.na(date_parsed), month(date_parsed), NA_integer_),\n",
    "    trans_month_name = if_else(!is.na(date_parsed), month(date_parsed, label = TRUE, abbr = FALSE), NA_character_),\n",
    "    trans_day = if_else(!is.na(date_parsed), day(date_parsed), NA_integer_),\n",
    "    trans_weekday = if_else(!is.na(date_parsed), wday(date_parsed, label = TRUE, abbr = FALSE), NA_character_),\n",
    "    trans_quarter = if_else(!is.na(date_parsed), quarter(date_parsed), NA_integer_)\n",
    "  )\n",
    "\n",
    "# Display results\n",
    "cat(\"Date Component Extraction:\\n\")\n",
    "transactions_clean %>%\n",
    "  select(date_parsed, trans_month_name, trans_weekday, trans_quarter) %>%\n",
    "  head(10) %>%\n",
    "  print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "weekend_flag",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weekend vs Weekday Transactions:\n",
      "< table of extent 0 >\n",
      "\n",
      "Percentage of weekend transactions: NaN %\n",
      "< table of extent 0 >\n",
      "\n",
      "Percentage of weekend transactions: NaN %\n"
     ]
    }
   ],
   "source": [
    "# Task 4.3: Identify Weekend Transactions\n",
    "# Create a new column 'is_weekend' that is TRUE if the transaction was on Saturday or Sunday\n",
    "# Use wday() which returns 1 for Sunday and 7 for Saturday\n",
    "\n",
    "transactions_clean <- transactions_clean %>%\n",
    "  mutate(\n",
    "    is_weekend = if_else(!is.na(date_parsed), wday(date_parsed) %in% c(1, 7), NA)\n",
    "  )\n",
    "\n",
    "# Summary\n",
    "cat(\"Weekend vs Weekday Transactions:\\n\")\n",
    "table(transactions_clean$is_weekend) %>% print()\n",
    "\n",
    "cat(\"\\nPercentage of weekend transactions:\",\n",
    "    round(sum(transactions_clean$is_weekend, na.rm = TRUE) / sum(!is.na(transactions_clean$is_weekend)) * 100, 1), \"%\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part5_intro",
   "metadata": {},
   "source": [
    "## Part 5: Date Calculations and Customer Recency Analysis\n",
    "\n",
    "**Business Context:** Understanding how recently customers transacted helps identify at-risk customers for re-engagement campaigns.\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Calculate days since each transaction\n",
    "2. Categorize customers by recency (Recent, Moderate, Old)\n",
    "3. Identify customers who haven't transacted in 90+ days\n",
    "4. Calculate average days between transactions per customer\n",
    "\n",
    "**Key Functions:** `today()`, date arithmetic, `case_when()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "calculate_recency",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No standard transaction date column found in transactions_clean. Using first column as date column: LogID \n",
      "\n",
      "Days Since Transaction:\n",
      "Days Since Transaction:\n",
      "\u001b[90m# A tibble: 10 × 4\u001b[39m\n",
      "   CustomerID original_date date_parsed days_since\n",
      "        \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m         \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<date>\u001b[39m\u001b[23m           \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m         26             1 \u001b[31mNA\u001b[39m                  \u001b[31mNA\u001b[39m\n",
      "\u001b[90m 2\u001b[39m         21             2 \u001b[31mNA\u001b[39m                  \u001b[31mNA\u001b[39m\n",
      "\u001b[90m 3\u001b[39m         12             3 \u001b[31mNA\u001b[39m                  \u001b[31mNA\u001b[39m\n",
      "\u001b[90m 4\u001b[39m          6             4 \u001b[31mNA\u001b[39m                  \u001b[31mNA\u001b[39m\n",
      "\u001b[90m 5\u001b[39m         32             5 \u001b[31mNA\u001b[39m                  \u001b[31mNA\u001b[39m\n",
      "\u001b[90m 6\u001b[39m         27             6 \u001b[31mNA\u001b[39m                  \u001b[31mNA\u001b[39m\n",
      "\u001b[90m 7\u001b[39m         31             7 \u001b[31mNA\u001b[39m                  \u001b[31mNA\u001b[39m\n",
      "\u001b[90m 8\u001b[39m         30             8 \u001b[31mNA\u001b[39m                  \u001b[31mNA\u001b[39m\n",
      "\u001b[90m 9\u001b[39m         31             9 \u001b[31mNA\u001b[39m                  \u001b[31mNA\u001b[39m\n",
      "\u001b[90m10\u001b[39m         13            10 \u001b[31mNA\u001b[39m                  \u001b[31mNA\u001b[39m\n",
      "\u001b[90m# A tibble: 10 × 4\u001b[39m\n",
      "   CustomerID original_date date_parsed days_since\n",
      "        \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m         \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<date>\u001b[39m\u001b[23m           \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m         26             1 \u001b[31mNA\u001b[39m                  \u001b[31mNA\u001b[39m\n",
      "\u001b[90m 2\u001b[39m         21             2 \u001b[31mNA\u001b[39m                  \u001b[31mNA\u001b[39m\n",
      "\u001b[90m 3\u001b[39m         12             3 \u001b[31mNA\u001b[39m                  \u001b[31mNA\u001b[39m\n",
      "\u001b[90m 4\u001b[39m          6             4 \u001b[31mNA\u001b[39m                  \u001b[31mNA\u001b[39m\n",
      "\u001b[90m 5\u001b[39m         32             5 \u001b[31mNA\u001b[39m                  \u001b[31mNA\u001b[39m\n",
      "\u001b[90m 6\u001b[39m         27             6 \u001b[31mNA\u001b[39m                  \u001b[31mNA\u001b[39m\n",
      "\u001b[90m 7\u001b[39m         31             7 \u001b[31mNA\u001b[39m                  \u001b[31mNA\u001b[39m\n",
      "\u001b[90m 8\u001b[39m         30             8 \u001b[31mNA\u001b[39m                  \u001b[31mNA\u001b[39m\n",
      "\u001b[90m 9\u001b[39m         31             9 \u001b[31mNA\u001b[39m                  \u001b[31mNA\u001b[39m\n",
      "\u001b[90m10\u001b[39m         13            10 \u001b[31mNA\u001b[39m                  \u001b[31mNA\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "# Task 5.1: Calculate Days Since Transaction\n",
    "# Create a new column 'days_since' that calculates days from date_parsed to today()\n",
    "# Hint: Use as.numeric(today() - date_parsed)\n",
    "\n",
    "# Robustly detect the transaction date column used in previous step\n",
    "possible_date_cols <- c(\"transaction_date\", \"TransactionDate\", \"trans_date\", \"Transaction_Date\", \"date\", \"Date\", \"TransactionDateTime\")\n",
    "transaction_date_col <- intersect(possible_date_cols, colnames(transactions_clean))\n",
    "if (length(transaction_date_col) == 0) {\n",
    "  transaction_date_col <- colnames(transactions_clean)[1]\n",
    "  cat(\"No standard transaction date column found in transactions_clean. Using first column as date column:\", transaction_date_col, \"\\n\\n\")\n",
    "} else {\n",
    "  transaction_date_col <- transaction_date_col[1]\n",
    "}\n",
    "\n",
    "transactions_clean <- transactions_clean %>%\n",
    "  mutate(\n",
    "    # days_since should be numeric (number of days). Coerce date_parsed to Date first\n",
    "    days_since = as.numeric(difftime(today(), as.Date(date_parsed), units = \"days\"))\n",
    "  )\n",
    "\n",
    "# Display results\n",
    "cat(\"Days Since Transaction:\\n\")\n",
    "transactions_clean %>%\n",
    "  select(CustomerID, original_date = all_of(transaction_date_col), date_parsed, days_since) %>%\n",
    "  arrange(desc(days_since)) %>%\n",
    "  head(10) %>%\n",
    "  print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "recency_categories",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recency Category Distribution:\n",
      "< table of extent 0 >\n",
      "\n",
      "At-Risk Customers (>90 days):\n",
      "< table of extent 0 >\n",
      "\n",
      "At-Risk Customers (>90 days):\n",
      "\u001b[90m# A tibble: 0 × 4\u001b[39m\n",
      "\u001b[90m# ℹ 4 variables: CustomerID <dbl>, date_parsed <date>, days_since <dbl>,\u001b[39m\n",
      "\u001b[90m#   recency_category <chr>\u001b[39m\n",
      "\u001b[90m# A tibble: 0 × 4\u001b[39m\n",
      "\u001b[90m# ℹ 4 variables: CustomerID <dbl>, date_parsed <date>, days_since <dbl>,\u001b[39m\n",
      "\u001b[90m#   recency_category <chr>\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "# Task 5.2: Categorize by Recency\n",
    "# TODO: Create a new column 'recency_category' using case_when():\n",
    "#   - \"Recent\" if days_since <= 30\n",
    "#   - \"Moderate\" if days_since <= 90\n",
    "#   - \"At Risk\" if days_since > 90\n",
    "\n",
    "transactions_clean <- transactions_clean %>%\n",
    "  mutate(\n",
    "    # recency_category based on numeric days_since (NA stays NA)\n",
    "    recency_category = case_when(\n",
    "      is.na(days_since) ~ NA_character_,\n",
    "      days_since <= 30 ~ \"Recent\",\n",
    "      days_since <= 90 ~ \"Moderate\",\n",
    "      days_since > 90  ~ \"At Risk\",\n",
    "      TRUE ~ NA_character_\n",
    "    )\n",
    "  )\n",
    "\n",
    "# Display distribution\n",
    "cat(\"Recency Category Distribution:\\n\")\n",
    "table(transactions_clean$recency_category) %>% print()\n",
    "\n",
    "# Show at-risk customers\n",
    "cat(\"\\nAt-Risk Customers (>90 days):\\n\")\n",
    "transactions_clean %>%\n",
    "  filter(recency_category == \"At Risk\") %>%\n",
    "  select(CustomerID, date_parsed, days_since, recency_category) %>%\n",
    "  arrange(desc(days_since)) %>%\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b8ad47",
   "metadata": {},
   "source": [
    "## Part 6: Personalized Customer Outreach\n",
    "\n",
    "**Business Context:** Use recency and cleaned text to create personalized messages for re-engagement campaigns.\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Extract first names from available customer name columns or fall back to CustomerID\n",
    "2. Create a `personalized_message` that uses the customer's first name and their `recency_category`\n",
    "\n",
    "**Key Functions:** `str_extract()`, `case_when()`, `coalesce()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ae314c5b",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No customer_name column found. Using CustomerID for first_name.\n",
      "Personalized Customer Messages:\n",
      "Personalized Customer Messages:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90m# A tibble: 10 × 4\u001b[39m\n",
      "   customer_name first_name days_since personalized_message\n",
      "           \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m           \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m               \n",
      "\u001b[90m 1\u001b[39m            26 26                 \u001b[31mNA\u001b[39m \u001b[31mNA\u001b[39m                  \n",
      "\u001b[90m 2\u001b[39m            21 21                 \u001b[31mNA\u001b[39m \u001b[31mNA\u001b[39m                  \n",
      "\u001b[90m 3\u001b[39m            12 12                 \u001b[31mNA\u001b[39m \u001b[31mNA\u001b[39m                  \n",
      "\u001b[90m 4\u001b[39m             6 6                  \u001b[31mNA\u001b[39m \u001b[31mNA\u001b[39m                  \n",
      "\u001b[90m 5\u001b[39m            32 32                 \u001b[31mNA\u001b[39m \u001b[31mNA\u001b[39m                  \n",
      "\u001b[90m 6\u001b[39m            27 27                 \u001b[31mNA\u001b[39m \u001b[31mNA\u001b[39m                  \n",
      "\u001b[90m 7\u001b[39m            31 31                 \u001b[31mNA\u001b[39m \u001b[31mNA\u001b[39m                  \n",
      "\u001b[90m 8\u001b[39m            30 30                 \u001b[31mNA\u001b[39m \u001b[31mNA\u001b[39m                  \n",
      "\u001b[90m 9\u001b[39m            31 31                 \u001b[31mNA\u001b[39m \u001b[31mNA\u001b[39m                  \n",
      "\u001b[90m10\u001b[39m            13 13                 \u001b[31mNA\u001b[39m \u001b[31mNA\u001b[39m                  \n"
     ]
    }
   ],
   "source": [
    "# Task 6.1: Extract First Names and Create Personalized Messages\n",
    "# Create two new columns:\n",
    "#   - first_name: Extract first name from customer_name (everything before first space)\n",
    "#   - personalized_message: Create message based on recency_category\n",
    "#     * Recent: \"Hi [name]! Thanks for your recent purchase!\"\n",
    "#     * Moderate: \"Hi [name], we miss you! Check out our new products.\"\n",
    "#     * At Risk: \"Hi [name], it's been a while! Here's a special offer for you.\"\n",
    "# Hint: Use str_extract() with pattern \"^\\\\w+\" for first name\n",
    "# Hint: Use paste() to combine strings in case_when()\n",
    "\n",
    "# Defensive: detect customer_name column, fallback to CustomerID\n",
    "possible_name_cols <- c(\"customer_name\", \"CustomerName\", \"Customer_Name\", \"name\", \"Name\")\n",
    "name_col <- intersect(possible_name_cols, colnames(transactions_clean))\n",
    "if (length(name_col) == 0) {\n",
    "  name_col <- \"CustomerID\"\n",
    "  cat(\"No customer_name column found. Using CustomerID for first_name.\\n\")\n",
    "} else {\n",
    "  name_col <- name_col[1]\n",
    "}\n",
    "\n",
    "# Use correct regex for R: \"^\\\\\\w+\" is not valid, use \"^[A-Za-z]+\" or \"^[^ ]+\"\n",
    "customer_outreach <- transactions_clean %>%\n",
    "  mutate(\n",
    "    # Extract first name (everything before first space, fallback to CustomerID if missing)\n",
    "    first_name = if_else(\n",
    "      !is.na(.data[[name_col]]),\n",
    "      str_extract(as.character(.data[[name_col]]), \"^[^ ]+\"),\n",
    "      as.character(CustomerID)\n",
    "    ),\n",
    "    # Personalized message based on recency_category\n",
    "    personalized_message = case_when(\n",
    "      recency_category == \"Recent\" & !is.na(first_name) ~ paste0(\"Hi \", first_name, \"! Thanks for your recent purchase!\"),\n",
    "      recency_category == \"Moderate\" & !is.na(first_name) ~ paste0(\"Hi \", first_name, \", we miss you! Check out our new products.\"),\n",
    "      recency_category == \"At Risk\" & !is.na(first_name) ~ paste0(\"Hi \", first_name, \", it's been a while! Here's a special offer for you.\"),\n",
    "      TRUE ~ NA_character_\n",
    "    )\n",
    "  )\n",
    "\n",
    "# Display personalized messages\n",
    "cat(\"Personalized Customer Messages:\\n\")\n",
    "customer_outreach %>%\n",
    "  select(customer_name = all_of(name_col), first_name, days_since, personalized_message) %>%\n",
    "  head(10) %>%\n",
    "  print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4879386a",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transaction Patterns by Weekday:\n",
      "\u001b[90m# A tibble: 1 × 4\u001b[39m\n",
      "  trans_weekday transaction_count total_amount avg_amount\n",
      "  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                     \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m        \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m      \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m \u001b[31mNA\u001b[39m                          150       \u001b[4m3\u001b[24m\u001b[4m7\u001b[24m734.       252.\n",
      "\n",
      "🔥 Busiest day: NA \n",
      "\u001b[90m# A tibble: 1 × 4\u001b[39m\n",
      "  trans_weekday transaction_count total_amount avg_amount\n",
      "  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                     \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m        \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m      \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m \u001b[31mNA\u001b[39m                          150       \u001b[4m3\u001b[24m\u001b[4m7\u001b[24m734.       252.\n",
      "\n",
      "🔥 Busiest day: NA \n"
     ]
    }
   ],
   "source": [
    "# Task 6.2: Analyze Transaction Patterns by Weekday\n",
    "# Group by trans_weekday and calculate:\n",
    "#   - transaction_count: number of transactions\n",
    "#   - total_amount: sum of amount (if available)\n",
    "#   - avg_amount: average amount per transaction\n",
    "# Arrange by transaction_count descending\n",
    "\n",
    "# Defensive: detect amount column (case-insensitive)\n",
    "possible_amount_cols <- c(\"amount\", \"Amount\", \"transaction_amount\", \"TransactionAmount\", \"total\", \"Total\")\n",
    "amount_col <- intersect(possible_amount_cols, colnames(transactions_clean))\n",
    "amount_col <- if (length(amount_col) > 0) amount_col[1] else NA_character_\n",
    "\n",
    "weekday_patterns <- transactions_clean %>%\n",
    "  group_by(trans_weekday) %>%\n",
    "  summarise(\n",
    "    transaction_count = n(),\n",
    "    total_amount = if (!is.na(amount_col)) sum(.data[[amount_col]], na.rm = TRUE) else NA_real_,\n",
    "    avg_amount = if (!is.na(amount_col)) mean(.data[[amount_col]], na.rm = TRUE) else NA_real_\n",
    "  ) %>%\n",
    "  arrange(desc(transaction_count))\n",
    "\n",
    "# Display results\n",
    "cat(\"Transaction Patterns by Weekday:\\n\")\n",
    "print(weekday_patterns)\n",
    "\n",
    "# Identify busiest day\n",
    "busiest_day <- weekday_patterns$trans_weekday[1]\n",
    "cat(\"\\n🔥 Busiest day:\", as.character(busiest_day), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0a2363c1",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'trans_month'. You can override using the\n",
      "`.groups` argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monthly Transaction Patterns:\n",
      "\u001b[90m# A tibble: 1 × 4\u001b[39m\n",
      "\u001b[90m# Groups:   trans_month [1]\u001b[39m\n",
      "  trans_month trans_month_name transaction_count unique_customers\n",
      "        \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                        \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m            \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m          \u001b[31mNA\u001b[39m \u001b[31mNA\u001b[39m                             150               47\n",
      "\u001b[90m# A tibble: 1 × 4\u001b[39m\n",
      "\u001b[90m# Groups:   trans_month [1]\u001b[39m\n",
      "  trans_month trans_month_name transaction_count unique_customers\n",
      "        \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                        \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m            \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m          \u001b[31mNA\u001b[39m \u001b[31mNA\u001b[39m                             150               47\n"
     ]
    }
   ],
   "source": [
    "# Task 6.3: Monthly Transaction Analysis\n",
    "# Group by trans_month_name and calculate:\n",
    "#   - transaction_count\n",
    "#   - unique_customers: use n_distinct(customer_name)\n",
    "# Arrange by trans_month (to show chronological order)\n",
    "\n",
    "# Defensive: detect customer_name column, fallback to CustomerID\n",
    "possible_name_cols <- c(\"customer_name\", \"CustomerName\", \"Customer_Name\", \"name\", \"Name\")\n",
    "name_col <- intersect(possible_name_cols, colnames(transactions_clean))\n",
    "if (length(name_col) == 0) {\n",
    "  name_col <- \"CustomerID\"\n",
    "}\n",
    "\n",
    "monthly_patterns <- transactions_clean %>%\n",
    "  group_by(trans_month, trans_month_name) %>%\n",
    "  summarise(\n",
    "    transaction_count = n(),\n",
    "    unique_customers = n_distinct(.data[[name_col]])\n",
    "  ) %>%\n",
    "  arrange(trans_month)\n",
    "\n",
    "# Display results\n",
    "cat(\"Monthly Transaction Patterns:\\n\")\n",
    "print(monthly_patterns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2103d6c9",
   "metadata": {},
   "source": [
    "## Part 7: Reporting and Export\n",
    "\n",
    "**Business Context:** Produce summary reports and export outreach lists for marketing teams.\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Create a recency distribution summary and save as a small table\n",
    "2. Identify top products by sales or mentions (use available data)\n",
    "3. Save `customer_outreach` to CSV for downstream use\n",
    "4. Create a simple bar plot of recency categories\n",
    "\n",
    "**Key Functions:** `group_by()`, `summarise()`, `write_csv()`, `ggplot2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e946b86e",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "         BUSINESS INTELLIGENCE SUMMARY\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "\n",
      "📦 PRODUCT ANALYSIS\n",
      "─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ \n",
      "         BUSINESS INTELLIGENCE SUMMARY\n",
      "= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
      "\n",
      "📦 PRODUCT ANALYSIS\n",
      "─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ \n",
      "Total products: 75 \n",
      "Wireless products: 17 \n",
      "Premium products: 0 \n",
      "Most common category: Electronics \n",
      "\n",
      "💬 CUSTOMER SENTIMENT\n",
      "Total products: 75 \n",
      "Wireless products: 17 \n",
      "Premium products: 0 \n",
      "Most common category: Electronics \n",
      "\n",
      "💬 CUSTOMER SENTIMENT\n",
      "─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ \n",
      "Total feedback entries: 10 \n",
      "Average sentiment score: 0.3 \n",
      "% Positive reviews: 30 %\n",
      "─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ \n",
      "Total feedback entries: 10 \n",
      "Average sentiment score: 0.3 \n",
      "% Positive reviews: 30 %\n",
      "% Negative reviews: 0 %\n",
      "\n",
      "📊 TRANSACTION PATTERNS\n",
      "─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ \n",
      "% Negative reviews: 0 %\n",
      "\n",
      "📊 TRANSACTION PATTERNS\n",
      "─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in min.default(structure(numeric(0), class = \"Date\"), na.rm = FALSE):\n",
      "“no non-missing arguments to min; returning Inf”\n",
      "Warning message in max.default(structure(numeric(0), class = \"Date\"), na.rm = FALSE):\n",
      "“no non-missing arguments to max; returning -Inf”\n",
      "Warning message in max.default(structure(numeric(0), class = \"Date\"), na.rm = FALSE):\n",
      "“no non-missing arguments to max; returning -Inf”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total transactions: 150 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date range: Inf to -Inf \n",
      "Busiest weekday: NA \n",
      "Weekend transaction %: NaN %\n",
      "Busiest weekday: NA \n",
      "Weekend transaction %: NaN %\n",
      "\n",
      "👥 CUSTOMER RECENCY\n",
      "─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ \n",
      "\n",
      "👥 CUSTOMER RECENCY\n",
      "─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ \n",
      "Recent customers (<30 days): 0 \n",
      "At-risk customers (>90 days): 0 \n",
      "Recent customers (<30 days): 0 \n",
      "At-risk customers (>90 days): 0 \n",
      "% Needing re-engagement: NaN %\n",
      "% Needing re-engagement: NaN %\n"
     ]
    }
   ],
   "source": [
    "# Task 7.1: Create Business Intelligence Dashboard\n",
    "\n",
    "cat(\"\\n\", rep(\"=\", 60), \"\\n\")\n",
    "cat(\"         BUSINESS INTELLIGENCE SUMMARY\\n\")\n",
    "cat(rep(\"=\", 60), \"\\n\\n\")\n",
    "\n",
    "# Product Analysis\n",
    "cat(\"\\U0001F4E6 PRODUCT ANALYSIS\\n\")\n",
    "cat(rep(\"\\u2500\", 30), \"\\n\")\n",
    "# Defensive: check for required columns\n",
    "product_count <- nrow(products_clean)\n",
    "wireless_count <- if (\"is_wireless\" %in% colnames(products_clean)) sum(products_clean$is_wireless, na.rm = TRUE) else NA_integer_\n",
    "premium_count <- if (\"is_premium\" %in% colnames(products_clean)) sum(products_clean$is_premium, na.rm = TRUE) else NA_integer_\n",
    "most_common_category <- if (\"category_clean\" %in% colnames(products_clean)) {\n",
    "  products_clean %>% count(category_clean) %>% arrange(desc(n)) %>% slice(1) %>% pull(category_clean)\n",
    "} else { NA_character_ }\n",
    "cat(\"Total products:\", product_count, \"\\n\")\n",
    "cat(\"Wireless products:\", wireless_count, \"\\n\")\n",
    "cat(\"Premium products:\", premium_count, \"\\n\")\n",
    "cat(\"Most common category:\", most_common_category, \"\\n\")\n",
    "\n",
    "# Customer Sentiment\n",
    "cat(\"\\n\\U0001F4AC CUSTOMER SENTIMENT\\n\")\n",
    "cat(rep(\"\\u2500\", 30), \"\\n\")\n",
    "feedback_count <- if (exists(\"feedback_clean\")) nrow(feedback_clean) else NA_integer_\n",
    "avg_sentiment <- if (exists(\"feedback_clean\") && \"sentiment_score\" %in% colnames(feedback_clean)) mean(feedback_clean$sentiment_score, na.rm = TRUE) else NA_real_\n",
    "pos_pct <- if (exists(\"feedback_clean\") && \"sentiment_score\" %in% colnames(feedback_clean)) round(sum(feedback_clean$sentiment_score > 0, na.rm = TRUE) / nrow(feedback_clean) * 100, 1) else NA_real_\n",
    "neg_pct <- if (exists(\"feedback_clean\") && \"sentiment_score\" %in% colnames(feedback_clean)) round(sum(feedback_clean$sentiment_score < 0, na.rm = TRUE) / nrow(feedback_clean) * 100, 1) else NA_real_\n",
    "cat(\"Total feedback entries:\", feedback_count, \"\\n\")\n",
    "cat(\"Average sentiment score:\", avg_sentiment, \"\\n\")\n",
    "cat(\"% Positive reviews:\", pos_pct, \"%\\n\")\n",
    "cat(\"% Negative reviews:\", neg_pct, \"%\\n\")\n",
    "\n",
    "# Transaction Patterns\n",
    "cat(\"\\n\\U0001F4CA TRANSACTION PATTERNS\\n\")\n",
    "cat(rep(\"\\u2500\", 30), \"\\n\")\n",
    "trans_count <- nrow(transactions_clean)\n",
    "date_range <- if (\"date_parsed\" %in% colnames(transactions_clean)) {\n",
    "  range(transactions_clean$date_parsed, na.rm = TRUE)\n",
    "} else { c(NA, NA) }\n",
    "busiest_weekday <- if (\"trans_weekday\" %in% colnames(transactions_clean)) {\n",
    "  transactions_clean %>% count(trans_weekday) %>% arrange(desc(n)) %>% slice(1) %>% pull(trans_weekday)\n",
    "} else { NA_character_ }\n",
    "weekend_pct <- if (\"is_weekend\" %in% colnames(transactions_clean)) {\n",
    "  round(sum(transactions_clean$is_weekend, na.rm = TRUE) / sum(!is.na(transactions_clean$is_weekend)) * 100, 1)\n",
    "} else { NA_real_ }\n",
    "cat(\"Total transactions:\", trans_count, \"\\n\")\n",
    "cat(\"Date range:\", as.character(date_range[1]), \"to\", as.character(date_range[2]), \"\\n\")\n",
    "cat(\"Busiest weekday:\", busiest_weekday, \"\\n\")\n",
    "cat(\"Weekend transaction %:\", weekend_pct, \"%\\n\")\n",
    "\n",
    "# Customer Recency\n",
    "cat(\"\\n\\U0001F465 CUSTOMER RECENCY\\n\")\n",
    "cat(rep(\"\\u2500\", 30), \"\\n\")\n",
    "recent_count <- if (\"recency_category\" %in% colnames(transactions_clean)) sum(transactions_clean$recency_category == \"Recent\", na.rm = TRUE) else NA_integer_\n",
    "at_risk_count <- if (\"recency_category\" %in% colnames(transactions_clean)) sum(transactions_clean$recency_category == \"At Risk\", na.rm = TRUE) else NA_integer_\n",
    "reengage_pct <- if (\"recency_category\" %in% colnames(transactions_clean)) round(at_risk_count / sum(!is.na(transactions_clean$recency_category)) * 100, 1) else NA_real_\n",
    "cat(\"Recent customers (<30 days):\", recent_count, \"\\n\")\n",
    "cat(\"At-risk customers (>90 days):\", at_risk_count, \"\\n\")\n",
    "cat(\"% Needing re-engagement:\", reengage_pct, \"%\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "294d90b6",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Product Categories:\n",
      "\u001b[90m# A tibble: 5 × 2\u001b[39m\n",
      "  category_clean product_count\n",
      "  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                  \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m Electronics               21\n",
      "\u001b[90m2\u001b[39m Computers                 15\n",
      "\u001b[90m3\u001b[39m Audio                     14\n",
      "\u001b[90m4\u001b[39m Tv                        14\n",
      "\u001b[90m5\u001b[39m Shoes                     11\n",
      "\u001b[90m# A tibble: 5 × 2\u001b[39m\n",
      "  category_clean product_count\n",
      "  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                  \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m Electronics               21\n",
      "\u001b[90m2\u001b[39m Computers                 15\n",
      "\u001b[90m3\u001b[39m Audio                     14\n",
      "\u001b[90m4\u001b[39m Tv                        14\n",
      "\u001b[90m5\u001b[39m Shoes                     11\n"
     ]
    }
   ],
   "source": [
    "# Task 7.2: Identify Top Products by Category\n",
    "# Group products by category_clean and count products in each\n",
    "# Arrange by count descending\n",
    "# Display top 5 categories\n",
    "\n",
    "top_categories <- products_clean %>%\n",
    "  group_by(category_clean) %>%\n",
    "  summarise(product_count = n()) %>%\n",
    "  arrange(desc(product_count)) %>%\n",
    "  slice_head(n = 5)\n",
    "\n",
    "cat(\"Top Product Categories:\\n\")\n",
    "print(top_categories)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part8_intro",
   "metadata": {},
   "source": [
    "## Part 8: Reflection Questions\n",
    "\n",
    "Answer the following questions based on your analysis. Write your answers in the markdown cells below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extract_names",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "### Question 8.1: Data Quality Impact\n",
    "\n",
    "**How did cleaning the text data (removing spaces, standardizing case) improve your ability to analyze the data? Provide specific examples from your homework.**\n",
    "\n",
    "Text cleaning significantly improves my data analysis by ensuring consistency across all operations. When you cleaned product names with str_trim() and str_to_title(), products like \"laptop\", \"Laptop\", and \" laptop \" were treated as the same product rather than three separate ones, which prevented fragmented aggregations and made supplier metrics, revenue calculations, and product performance metrics accurate. This consistency was critical for joins across datasets—if supplier names had inconsistent spacing or capitalization, my inner_join() operations might fail to match related records, creating orphaned data and incomplete relationships between customers, orders, products, and suppliers. Without cleaning, calculations like n_distinct(ProductID) in my supplier_metrics analysis could be artificially inflated by counting the same product multiple times, skewing insights about which suppliers were truly most valuable. Additionally, the cleaning process itself revealed data quality issues; for example, if a significant percentage of product names had leading or trailing spaces, that's a critical problem to address. Finally, clean, consistently-formatted names in regional_analysis and customer_metrics not only look more professional in reports and dashboards but also make insights more credible and easier to communicate to stakeholders, demonstrating how text standardization transforms raw, messy data into reliable analytical insights.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection2",
   "metadata": {},
   "source": [
    "### Question 8.2: Pattern Detection Value\n",
    "\n",
    "**What business insights did you gain from detecting patterns in product names (wireless, premium, gaming)? How could a business use this information?**\n",
    "\n",
    "Detecting patterns in product names allowed me to identify which features and categories are most popular among customers. For example, by flagging products as \"wireless,\" \"premium,\" or \"gaming,\" I could quickly see which segments had the highest product counts and potentially the highest sales. This insight helps a business understand current market trends and customer preferences.\n",
    "\n",
    "A business could use this information to:\n",
    "- Target marketing campaigns to customers interested in specific features (e.g., promoting new wireless products to tech-savvy customers).\n",
    "- Optimize inventory by stocking more of the most popular categories, such as gaming accessories if those are trending.\n",
    "- Guide product development by focusing on features that are in high demand, like premium or wireless capabilities.\n",
    "- Benchmark performance by comparing sales or feedback across these segments to identify growth opportunities or areas needing improvement.\n",
    "\n",
    "Overall, pattern detection in product names supports data-driven decisions in marketing, inventory management, and product strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection3",
   "metadata": {},
   "source": [
    "### Question 8.3: Date Analysis Importance\n",
    "\n",
    "**Why is analyzing transaction dates by weekday and month important for business operations? Provide at least three specific business applications.**\n",
    "\n",
    "Analyzing transaction dates by weekday and month is crucial for understanding customer behavior and optimizing business operations. Here are three specific business applications:\n",
    "\n",
    "1. **Staffing and Resource Planning:** By identifying the busiest days of the week or months of the year, businesses can schedule more staff or allocate resources more efficiently to meet customer demand and reduce wait times.\n",
    "2. **Targeted Marketing Campaigns:** Understanding seasonal or weekly sales patterns allows businesses to launch promotions or special offers at times when customers are most likely to purchase, maximizing the impact of marketing spend.\n",
    "3. **Inventory Management:** Recognizing peak sales periods helps businesses stock up on popular products ahead of time, reducing the risk of stockouts or overstocking, and improving overall supply chain efficiency.\n",
    "\n",
    "These insights help businesses make data-driven decisions that improve customer satisfaction and operational efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection4",
   "metadata": {},
   "source": [
    "### Question 8.4: Customer Recency Strategy\n",
    "\n",
    "**Based on your recency analysis, what specific actions would you recommend for customers in each category (Recent, Moderate, At Risk)? How would you prioritize these actions?**\n",
    "\n",
    "For each recency category, I would recommend the following actions:\n",
    "\n",
    "- **Recent (≤30 days):** Send a thank-you message and offer a small incentive (like a discount on their next purchase) to encourage repeat business and build loyalty.\n",
    "- **Moderate (31–90 days):** Re-engage with personalized product recommendations or updates about new arrivals, reminding them of your brand and encouraging them to return.\n",
    "- **At Risk (>90 days):** Prioritize these customers for special win-back campaigns, such as exclusive offers, larger discounts, or personalized outreach to address potential reasons for their inactivity.\n",
    "\n",
    "**Prioritization:**\n",
    "1. Focus first on \"At Risk\" customers, as they are most likely to churn and require immediate attention to win them back.\n",
    "2. Next, target \"Moderate\" customers to prevent them from becoming \"At Risk.\"\n",
    "3. Continue nurturing \"Recent\" customers to maintain engagement and encourage ongoing loyalty.\n",
    "\n",
    "This approach maximizes retention and ensures marketing resources are used effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection5",
   "metadata": {},
   "source": [
    "### Question 8.5: Sentiment Analysis Application\n",
    "\n",
    "**How could the sentiment analysis you performed be used to improve products or customer service? What are the limitations of this simple sentiment analysis approach?**\n",
    "\n",
    "Sentiment analysis can help businesses quickly identify trends in customer feedback, such as common complaints or praise for specific products or services. By monitoring sentiment scores, a company can:\n",
    "- Detect negative feedback early and address customer service issues before they escalate.\n",
    "- Identify which products or features are most appreciated by customers, guiding product improvements and marketing focus.\n",
    "- Track changes in customer satisfaction over time to evaluate the impact of new initiatives or changes.\n",
    "\n",
    "However, this simple sentiment analysis approach has limitations:\n",
    "- It only counts a small set of positive and negative keywords, missing more nuanced expressions or context (e.g., sarcasm, mixed reviews).\n",
    "- It does not account for the intensity of sentiment or the presence of negations (e.g., \"not great\" would be misclassified as positive).\n",
    "- It may overlook domain-specific language or slang that could be important in real feedback.\n",
    "\n",
    "For more accurate insights, more advanced natural language processing techniques would be needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection6",
   "metadata": {},
   "source": [
    "### Question 8.6: Real-World Application\n",
    "\n",
    "**Describe a real business scenario where you would need to combine string manipulation and date analysis (like you did in this homework). What insights would you be trying to discover?**\n",
    "\n",
    "A real business scenario would be analyzing customer support tickets to improve service quality. For example, a company could extract keywords from the text of support requests (using string manipulation) to categorize issues (e.g., \"login problem,\" \"payment failed,\" \"shipping delay\"). By combining this with date analysis of when tickets were submitted, the business could:\n",
    "- Identify peak times or seasons for certain types of issues (e.g., more \"shipping delay\" tickets during holidays).\n",
    "- Track how quickly different types of issues are resolved over time.\n",
    "- Discover if new product launches or updates lead to spikes in specific complaints.\n",
    "\n",
    "These insights would help the company allocate support resources more effectively, proactively address recurring problems, and improve customer satisfaction by resolving issues faster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## Summary and Submission\n",
    "\n",
    "### What You've Accomplished\n",
    "\n",
    "In this homework, you've successfully:\n",
    "- ✅ Cleaned and standardized messy text data using `stringr` functions\n",
    "- ✅ Detected patterns and extracted information from text\n",
    "- ✅ Parsed dates and extracted temporal components using `lubridate`\n",
    "- ✅ Calculated customer recency for segmentation\n",
    "- ✅ Analyzed transaction patterns by time periods\n",
    "- ✅ Combined string and date operations for business insights\n",
    "- ✅ Created personalized customer communications\n",
    "- ✅ Generated executive-ready business intelligence summaries\n",
    "\n",
    "### Key Skills Mastered\n",
    "\n",
    "**String Manipulation:**\n",
    "- `str_trim()`, `str_squish()` - Whitespace handling\n",
    "- `str_to_lower()`, `str_to_upper()`, `str_to_title()` - Case conversion\n",
    "- `str_detect()` - Pattern detection\n",
    "- `str_extract()` - Information extraction\n",
    "- `str_count()` - Pattern counting\n",
    "\n",
    "**Date/Time Operations:**\n",
    "- `ymd()`, `mdy()`, `dmy()` - Date parsing\n",
    "- `year()`, `month()`, `day()`, `wday()` - Component extraction\n",
    "- `quarter()` - Period extraction\n",
    "- `today()` - Current date\n",
    "- Date arithmetic - Calculating differences\n",
    "\n",
    "**Business Applications:**\n",
    "- Data cleaning and standardization\n",
    "- Customer segmentation by recency\n",
    "- Sentiment analysis\n",
    "- Pattern identification\n",
    "- Temporal trend analysis\n",
    "- Personalized communication\n",
    "\n",
    "### Submission Checklist\n",
    "\n",
    "Before submitting, ensure you have:\n",
    "- [ ] Entered your name, student ID, and date at the top\n",
    "- [ ] Completed all code tasks (Parts 1-7)\n",
    "- [ ] Run all cells successfully without errors\n",
    "- [ ] Answered all reflection questions (Part 8)\n",
    "- [ ] Used proper commenting in your code\n",
    "- [ ] Used the pipe operator (`%>%`) where appropriate\n",
    "- [ ] Verified your results make business sense\n",
    "- [ ] Checked for any remaining TODO comments\n",
    "\n",
    "### Grading Criteria\n",
    "\n",
    "Your homework will be evaluated on:\n",
    "- **Code Correctness (40%)**: All tasks completed correctly\n",
    "- **Code Quality (20%)**: Clean, well-commented, efficient code\n",
    "- **Business Understanding (20%)**: Demonstrates understanding of business applications\n",
    "- **Reflection Questions (15%)**: Thoughtful, complete answers\n",
    "- **Presentation (5%)**: Professional formatting and organization\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "In Lesson 8, you'll learn:\n",
    "- Advanced data wrangling with complex pipelines\n",
    "- Sophisticated conditional logic with `case_when()`\n",
    "- Data validation and quality checks\n",
    "- Creating reproducible analysis workflows\n",
    "- Professional best practices for business analytics\n",
    "\n",
    "**Great work on completing this assignment! 🎉**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
