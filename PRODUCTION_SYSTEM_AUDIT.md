# Production System Audit & Productization Plan

## Current State Analysis

### Core Production Files (KEEP - ACTIVELY USED)

#### Main Application
- `connect_web_interface.py` - Main Streamlit web interface
- `business_analytics_grader_v2.py` - Core grading engine with 4-layer validation
- `disaggregated_client.py` - Orchestrator for DGX+Mac inference

#### Grading Components
- `prompt_manager.py` - Manages Ollama prompts
- `grading_validator.py` - Validates scoring calculations
- `report_generator.py` - Generates PDF reports
- `score_validator.py` - Score validation logic
- `notebook_executor.py` - Executes notebooks if needed
- `submission_preprocessor.py` - Cleans/normalizes submissions
- `anonymization_utils.py` - Anonymizes student names

#### Validators (validators/)
- `validators/rubric_driven_validator.py` - Generic rubric-based validation
- `validators/assignment_6_systematic_validator.py` - Assignment 6 specific
- `validators/smart_output_validator.py` - Output comparison with solution

#### Legacy Validators (KEEP for backward compatibility)
- `notebook_validation.py` - Legacy validator (fallback)
- `output_comparator.py` - Legacy output comparison

#### Prompts (prompt_templates/ollama/)
- `prompt_templates/ollama/code_analysis_prompt.txt` - Qwen code analysis
- `prompt_templates/ollama/feedback_prompt.txt` - GPT-OSS feedback generation

#### Disaggregated Inference (disaggregated_inference/)
- `disaggregated_inference/prefill_server_ollama.py` - DGX prefill server
- `disaggregated_inference/decode_server_ollama.py` - Mac decode server
- `disaggregated_inference/config_current.json` - Server configuration

#### Data & Configuration
- `grading_system.db` - SQLite database (assignments, submissions, students)
- `rubrics/*.json` - Assignment rubrics
- `data/raw/*.ipynb` - Solution notebooks
- `requirements.txt` - Python dependencies

#### Model Status
- `model_status_display.py` - Shows AI model status in UI

---

### Legacy/Experimental Files (ARCHIVE OR DELETE)

#### Old Grader Versions
- `business_analytics_grader_old.py` ‚ùå DELETE
- `business_analytics_grader_original.py` ‚ùå DELETE
- `business_analytics_grader_v2_broken.py` ‚ùå DELETE
- `business_analytics_grader_v2_master.py` ‚ùå DELETE
- `business_analytics_grader.py` ‚ùå DELETE
- `ai_grader.py` ‚ö†Ô∏è KEEP (has filter_ai_feedback_for_storage function)

#### Test Files
- `test_*.py` (all test files) üì¶ MOVE TO tests/
- `grade_with_systematic_validator.py` üì¶ MOVE TO tests/
- `regrade_with_new_validator.py` üì¶ MOVE TO tests/

#### Documentation (Keep but organize)
- `*.md` files üì¶ MOVE TO docs/
- Keep only `README.md` in root

#### Unused Interfaces
- `grading_interface.py` ‚ùå DELETE (replaced by connect_web_interface.py)
- `app.py` ‚ùå DELETE (old interface)
- `training_interface.py` ‚ùå DELETE
- `enhanced_training_interface.py` ‚ùå DELETE
- `modern_training_interface.py` ‚ùå DELETE
- `enhanced_training_page.py` ‚ùå DELETE

#### Unused Utilities
- `alternative_approaches.py` ‚ùå DELETE
- `assignment_editor.py` ‚ùå DELETE
- `assignment_manager.py` ‚ùå DELETE
- `assignment_matcher.py` ‚ùå DELETE
- `assignment_setup_helper.py` ‚ùå DELETE
- `correction_analyzer.py` ‚ùå DELETE
- `correction_helpers.py` ‚ùå DELETE
- `create_solution_notebook.py` ‚ùå DELETE
- `create_solution.py` ‚ùå DELETE
- `migration_helper.py` ‚ùå DELETE
- `rubric_manager.py` ‚ùå DELETE
- `server_manager.py` ‚ùå DELETE
- `unified_model_interface.py` ‚ùå DELETE

#### Unused Monitoring
- `monitor_dashboard_full.py` ‚ùå DELETE
- `monitor_dashboard.py` ‚ö†Ô∏è KEEP (might be used)
- `monitor_app.py` ‚ö†Ô∏è KEEP (might be used)
- `performance_logger.py` ‚ùå DELETE

#### Unused Databases
- `enhanced_training.db` ‚ùå DELETE
- `grading_database.db` ‚ùå DELETE (use grading_system.db)

#### Shell Scripts (Organize)
- `clean_restart.sh` üì¶ MOVE TO scripts/
- `cleanup_root_directory.sh` üì¶ MOVE TO scripts/
- `quick_restart.sh` üì¶ MOVE TO scripts/
- `safe_cleanup.sh` üì¶ MOVE TO scripts/
- `restart_oss_server.sh` üì¶ MOVE TO scripts/
- `monitor_macs.sh` üì¶ MOVE TO scripts/

#### Unused Config
- `distributed_config.json.mlx_not_used` ‚ùå DELETE
- `ollama_servers.json` ‚ùå DELETE
- `server_config.json` ‚ùå DELETE
- `model_config.py` ‚ùå DELETE

---

## Proposed Clean Structure

```
ai-homework-grader/
‚îú‚îÄ‚îÄ README.md                          # Main documentation
‚îú‚îÄ‚îÄ requirements.txt                   # Python dependencies
‚îú‚îÄ‚îÄ startup.sh                         # ONE-CLICK STARTUP SCRIPT
‚îú‚îÄ‚îÄ grading_system.db                  # Main database
‚îÇ
‚îú‚îÄ‚îÄ app/                               # Main application
‚îÇ   ‚îú‚îÄ‚îÄ connect_web_interface.py       # Streamlit UI
‚îÇ   ‚îú‚îÄ‚îÄ business_analytics_grader_v2.py
‚îÇ   ‚îú‚îÄ‚îÄ disaggregated_client.py
‚îÇ   ‚îú‚îÄ‚îÄ prompt_manager.py
‚îÇ   ‚îú‚îÄ‚îÄ grading_validator.py
‚îÇ   ‚îú‚îÄ‚îÄ report_generator.py
‚îÇ   ‚îú‚îÄ‚îÄ score_validator.py
‚îÇ   ‚îú‚îÄ‚îÄ notebook_executor.py
‚îÇ   ‚îú‚îÄ‚îÄ submission_preprocessor.py
‚îÇ   ‚îú‚îÄ‚îÄ anonymization_utils.py
‚îÇ   ‚îú‚îÄ‚îÄ model_status_display.py
‚îÇ   ‚îú‚îÄ‚îÄ notebook_validation.py         # Legacy fallback
‚îÇ   ‚îú‚îÄ‚îÄ output_comparator.py           # Legacy fallback
‚îÇ   ‚îî‚îÄ‚îÄ ai_grader.py                   # Helper functions
‚îÇ
‚îú‚îÄ‚îÄ validators/                        # Validation modules
‚îÇ   ‚îú‚îÄ‚îÄ rubric_driven_validator.py
‚îÇ   ‚îú‚îÄ‚îÄ assignment_6_systematic_validator.py
‚îÇ   ‚îî‚îÄ‚îÄ smart_output_validator.py
‚îÇ
‚îú‚îÄ‚îÄ disaggregated_inference/           # Distributed inference
‚îÇ   ‚îú‚îÄ‚îÄ config_current.json
‚îÇ   ‚îú‚îÄ‚îÄ prefill_server_ollama.py
‚îÇ   ‚îú‚îÄ‚îÄ decode_server_ollama.py
‚îÇ   ‚îú‚îÄ‚îÄ start_all_servers.sh           # Start DGX + Mac servers
‚îÇ   ‚îî‚îÄ‚îÄ stop_all_servers.sh
‚îÇ
‚îú‚îÄ‚îÄ prompt_templates/                  # AI prompts
‚îÇ   ‚îî‚îÄ‚îÄ ollama/
‚îÇ       ‚îú‚îÄ‚îÄ code_analysis_prompt.txt
‚îÇ       ‚îî‚îÄ‚îÄ feedback_prompt.txt
‚îÇ
‚îú‚îÄ‚îÄ rubrics/                           # Assignment rubrics
‚îÇ   ‚îú‚îÄ‚îÄ assignment_6_rubric.json
‚îÇ   ‚îî‚îÄ‚îÄ assignment_7_rubric_v2.json
‚îÇ
‚îú‚îÄ‚îÄ data/                              # Data files
‚îÇ   ‚îú‚îÄ‚îÄ raw/                           # Solution notebooks
‚îÇ   ‚îî‚îÄ‚îÄ processed/                     # Processed data
‚îÇ
‚îú‚îÄ‚îÄ reports/                           # Generated PDF reports
‚îÇ   ‚îú‚îÄ‚îÄ Assignment_6/
‚îÇ   ‚îî‚îÄ‚îÄ Assignment_7/
‚îÇ
‚îú‚îÄ‚îÄ submissions/                       # Student submissions
‚îÇ
‚îú‚îÄ‚îÄ docs/                              # Documentation
‚îÇ   ‚îú‚îÄ‚îÄ DISAGGREGATED_INFERENCE_SYSTEM_DOCUMENTATION.md
‚îÇ   ‚îú‚îÄ‚îÄ SYSTEM_DIAGRAMS.md
‚îÇ   ‚îú‚îÄ‚îÄ REPORT_FORMATTING_IMPROVEMENTS.md
‚îÇ   ‚îî‚îÄ‚îÄ *.md                           # All other docs
‚îÇ
‚îú‚îÄ‚îÄ scripts/                           # Utility scripts
‚îÇ   ‚îú‚îÄ‚îÄ clean_restart.sh
‚îÇ   ‚îú‚îÄ‚îÄ quick_restart.sh
‚îÇ   ‚îî‚îÄ‚îÄ monitor_macs.sh
‚îÇ
‚îú‚îÄ‚îÄ tests/                             # Test files
‚îÇ   ‚îú‚îÄ‚îÄ test_*.py
‚îÇ   ‚îî‚îÄ‚îÄ grade_with_systematic_validator.py
‚îÇ
‚îî‚îÄ‚îÄ archive/                           # Old/unused files
    ‚îú‚îÄ‚îÄ old_graders/
    ‚îú‚îÄ‚îÄ old_interfaces/
    ‚îî‚îÄ‚îÄ old_utilities/
```

---

## ONE-CLICK STARTUP SYSTEM

### startup.sh (Main Launcher)

```bash
#!/bin/bash
# AI Homework Grader - One-Click Startup
# Starts all servers and opens the web interface

set -e  # Exit on error

echo "üöÄ Starting AI Homework Grader System..."
echo ""

# Check if running on Mac (orchestrator)
if [[ "$OSTYPE" == "darwin"* ]]; then
    echo "üìç Detected Mac - Starting as Orchestrator"
    
    # 1. Check Python environment
    if [ ! -d ".venv" ]; then
        echo "‚ùå Virtual environment not found. Run: python3 -m venv .venv"
        exit 1
    fi
    
    source .venv/bin/activate
    
    # 2. Check dependencies
    echo "üì¶ Checking dependencies..."
    pip install -q -r requirements.txt
    
    # 3. Start disaggregated servers (DGX + Mac)
    echo "üñ•Ô∏è  Starting disaggregated inference servers..."
    cd disaggregated_inference
    ./start_all_servers.sh
    cd ..
    
    # Wait for servers to be ready
    echo "‚è≥ Waiting for servers to initialize..."
    sleep 5
    
    # 4. Check server health
    echo "üè• Checking server health..."
    python3 -c "
from disaggregated_client import DisaggregatedClient
try:
    client = DisaggregatedClient()
    print('‚úÖ Disaggregated system ready')
except Exception as e:
    print(f'‚ö†Ô∏è  Warning: {e}')
    print('   System will use fallback mode')
"
    
    # 5. Start Streamlit app
    echo ""
    echo "üåê Starting web interface..."
    echo "   URL: http://localhost:8501"
    echo ""
    echo "Press Ctrl+C to stop all services"
    echo ""
    
    # Open browser after 2 seconds
    (sleep 2 && open http://localhost:8501) &
    
    # Start Streamlit
    streamlit run app/connect_web_interface.py --server.port 8501
    
else
    echo "‚ùå This script should be run on the Mac orchestrator"
    echo "   For DGX servers, use: disaggregated_inference/start_prefill_server.sh"
    exit 1
fi
```

### disaggregated_inference/start_all_servers.sh

```bash
#!/bin/bash
# Start all disaggregated inference servers

echo "Starting disaggregated inference system..."

# Start DGX prefill servers (via SSH)
echo "üñ•Ô∏è  Starting DGX Spark 1 (Qwen prefill)..."
ssh dgx1 "cd /opt/inference && nohup python3 prefill_server_ollama.py --model qwen3-coder:30b --port 8000 > prefill.log 2>&1 &"

echo "üñ•Ô∏è  Starting DGX Spark 2 (GPT-OSS prefill)..."
ssh dgx2 "cd /opt/inference && nohup python3 prefill_server_ollama.py --model gpt-oss:120b --port 8000 > prefill.log 2>&1 &"

# Start Mac decode servers (local)
echo "üçé Starting Mac Studio 1 (GPT-OSS decode)..."
ssh mac1 "cd /opt/inference && nohup python3 decode_server_ollama.py --model gpt-oss:120b --port 8001 > decode.log 2>&1 &"

echo "üçé Starting Mac Studio 2 (Qwen decode)..."
ssh mac2 "cd /opt/inference && nohup python3 decode_server_ollama.py --model qwen3-coder:30b --port 8001 > decode.log 2>&1 &"

echo "‚úÖ All servers started"
echo "   Check status: ./check_status.sh"
```

### disaggregated_inference/stop_all_servers.sh

```bash
#!/bin/bash
# Stop all disaggregated inference servers

echo "Stopping disaggregated inference system..."

# Stop DGX servers
ssh dgx1 "pkill -f prefill_server_ollama.py"
ssh dgx2 "pkill -f prefill_server_ollama.py"

# Stop Mac servers
ssh mac1 "pkill -f decode_server_ollama.py"
ssh mac2 "pkill -f decode_server_ollama.py"

echo "‚úÖ All servers stopped"
```

### disaggregated_inference/check_status.sh

```bash
#!/bin/bash
# Check status of all servers

echo "Checking server status..."
echo ""

# Check DGX 1
echo "DGX Spark 1 (Qwen prefill):"
curl -s http://169.254.150.103:8000/health | python3 -m json.tool || echo "‚ùå Offline"
echo ""

# Check DGX 2
echo "DGX Spark 2 (GPT-OSS prefill):"
curl -s http://169.254.150.104:8000/health | python3 -m json.tool || echo "‚ùå Offline"
echo ""

# Check Mac 1
echo "Mac Studio 1 (GPT-OSS decode):"
curl -s http://169.254.150.101:8001/health | python3 -m json.tool || echo "‚ùå Offline"
echo ""

# Check Mac 2
echo "Mac Studio 2 (Qwen decode):"
curl -s http://169.254.150.102:8001/health | python3 -m json.tool || echo "‚ùå Offline"
```

---

## Migration Steps

### Phase 1: Organize (No Breaking Changes)
1. Create new directory structure
2. Move files to appropriate locations
3. Update imports in moved files
4. Test that everything still works

### Phase 2: Create Startup Scripts
1. Create `startup.sh` in root
2. Create server management scripts in `disaggregated_inference/`
3. Make all scripts executable
4. Test startup process

### Phase 3: Clean Up
1. Move old files to `archive/`
2. Delete truly unused files
3. Update documentation
4. Create clean README.md

### Phase 4: Productize
1. Add error handling to startup script
2. Add health checks
3. Add automatic recovery
4. Create systemd services (optional)

---

## Usage After Productization

### For Daily Use:
```bash
# Start everything
./startup.sh

# That's it! Browser opens automatically to http://localhost:8501
```

### For Maintenance:
```bash
# Check server status
cd disaggregated_inference && ./check_status.sh

# Restart servers
cd disaggregated_inference && ./stop_all_servers.sh && ./start_all_servers.sh

# View logs
tail -f disaggregated_inference/logs/*.log
```

### For Development:
```bash
# Run tests
cd tests && python3 -m pytest

# Grade single submission (testing)
python3 tests/test_grade_marc.py
```

---

## Benefits

1. **One-Click Startup**: Just run `./startup.sh`
2. **Clean Structure**: Easy to navigate and understand
3. **Maintainable**: Clear separation of concerns
4. **Documented**: Each component has clear purpose
5. **Testable**: Tests separated from production code
6. **Scalable**: Easy to add new features

---

## Next Steps

1. **Review this plan** - Confirm what to keep/delete
2. **Create migration script** - Automate the reorganization
3. **Test migration** - Ensure nothing breaks
4. **Create startup scripts** - Implement one-click startup
5. **Document** - Update README with new structure

Would you like me to proceed with any of these phases?
